2025-08-02 16:08:58,411 - INFO - args.exp_name : Test
2025-08-02 16:08:58,416 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': None,
  'model': 'Transolver_2D',
  'n_heads': 4,
  'n_hidden': 64,
  'n_layers': 3,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 32,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-02 16:08:58,416 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:10:28,737 - INFO - args.exp_name : Test
2025-08-02 16:10:28,741 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': None,
  'model': 'Transolver_2D',
  'n_heads': 4,
  'n_hidden': 64,
  'n_layers': 3,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 32,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-02 16:10:28,741 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:13:39,436 - INFO - args.exp_name : Test
2025-08-02 16:13:39,440 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': None,
  'model': 'Transolver_2D',
  'n_heads': 4,
  'n_hidden': 64,
  'n_layers': 3,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 32,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-02 16:13:39,440 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:15:35,300 - INFO - args.exp_name : Test
2025-08-02 16:15:35,304 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': None,
  'model': 'Transolver_2D',
  'n_heads': 4,
  'n_hidden': 64,
  'n_layers': 3,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 32,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-02 16:15:35,304 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:28:05,899 - INFO - args.exp_name : Test
2025-08-02 16:28:05,900 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-08-02 16:28:05,903 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:31:09,811 - INFO - args.exp_name : Test
2025-08-02 16:31:09,816 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-08-02 16:31:09,817 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:34:44,197 - INFO - args.exp_name : Test
2025-08-02 16:34:44,201 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-08-02 16:34:44,201 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-02 16:36:29,447 - INFO - args.exp_name : Test
2025-08-02 16:36:29,452 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-08-02 16:36:29,452 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:02:38,717 - INFO - args.exp_name : Test
2025-08-04 09:02:38,723 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-08-04 09:02:38,723 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:05:22,437 - INFO - args.exp_name : Test
2025-08-04 09:05:22,442 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-08-04 09:05:22,442 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:19:48,014 - INFO - args.exp_name : Test
2025-08-04 09:19:48,019 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 09:19:48,019 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:19:48,427 - INFO - Total trainable parameters: 714177
2025-08-04 09:33:01,715 - INFO - args.exp_name : Test
2025-08-04 09:33:01,719 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 09:33:01,719 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:33:02,090 - INFO - Total trainable parameters: 714177
2025-08-04 09:33:02,114 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 09:34:43,181 - INFO - args.exp_name : Test
2025-08-04 09:34:43,185 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 09:34:43,186 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:34:43,549 - INFO - Total trainable parameters: 714177
2025-08-04 09:34:43,573 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 09:41:37,784 - INFO - args.exp_name : Test
2025-08-04 09:41:37,788 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 09:41:37,788 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 09:41:38,153 - INFO - Total trainable parameters: 714177
2025-08-04 09:41:38,176 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 09:41:38,177 - INFO - Staring training for 10 epochs
2025-08-04 10:05:14,498 - INFO - args.exp_name : Test
2025-08-04 10:05:14,503 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:05:14,503 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:05:14,865 - INFO - Total trainable parameters: 714177
2025-08-04 10:08:50,951 - INFO - args.exp_name : Test
2025-08-04 10:08:50,957 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:08:50,957 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:08:51,321 - INFO - Total trainable parameters: 714177
2025-08-04 10:08:51,346 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:08:51,347 - INFO - Staring training for 10 epochs
2025-08-04 10:08:57,965 - INFO - [35m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:08:57,971 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:22:16,676 - INFO - args.exp_name : Test
2025-08-04 10:22:16,682 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:22:16,683 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:22:17,051 - INFO - Total trainable parameters: 714177
2025-08-04 10:22:17,077 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:22:17,078 - INFO - Staring training for 10 epochs
2025-08-04 10:23:41,551 - INFO - args.exp_name : Test
2025-08-04 10:23:41,555 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:23:41,555 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:23:41,922 - INFO - Total trainable parameters: 714177
2025-08-04 10:23:41,945 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:23:41,946 - INFO - Staring training for 10 epochs
2025-08-04 10:23:48,733 - INFO - [35m data_point.shape: torch.Size([6, 3, 10000]) [0m
2025-08-04 10:23:48,739 - INFO - [35m targets.shape: torch.Size([6, 10000]) [0m
2025-08-04 10:23:48,915 - INFO - [33m batch 0, point 0, coordinate: (tensor(1.6813, device='cuda:0'), tensor(-0.9769, device='cuda:0'), tensor(0.7376, device='cuda:0')) [0m
2025-08-04 10:33:50,988 - INFO - args.exp_name : Test
2025-08-04 10:33:50,992 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:33:50,992 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:33:51,355 - INFO - Total trainable parameters: 714177
2025-08-04 10:33:51,380 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:33:51,384 - INFO - Staring training for 10 epochs
2025-08-04 10:33:57,824 - INFO - [35m data_point.shape: torch.Size([6, 3, 10000]) [0m
2025-08-04 10:33:57,828 - INFO - [35m targets.shape: torch.Size([1, 18, 10000]) [0m
2025-08-04 10:39:51,453 - INFO - args.exp_name : Test
2025-08-04 10:39:51,457 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:39:51,458 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:39:51,814 - INFO - Total trainable parameters: 714177
2025-08-04 10:39:51,840 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:39:51,841 - INFO - Staring training for 10 epochs
2025-08-04 10:39:58,339 - INFO - [35m data_point.shape: torch.Size([6, 3, 10000]) [0m
2025-08-04 10:39:58,345 - INFO - [35m targets.shape: torch.Size([6, 3, 10000]) [0m
2025-08-04 10:42:23,452 - INFO - args.exp_name : Test
2025-08-04 10:42:23,457 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:42:23,457 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:42:23,814 - INFO - Total trainable parameters: 714177
2025-08-04 10:42:23,840 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:42:23,840 - INFO - Staring training for 10 epochs
2025-08-04 10:46:31,680 - INFO - args.exp_name : Test
2025-08-04 10:46:31,685 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:46:31,685 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:46:32,045 - INFO - Total trainable parameters: 714177
2025-08-04 10:46:32,070 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:46:32,071 - INFO - Staring training for 10 epochs
2025-08-04 10:46:38,496 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:46:38,501 - INFO - [35m targets.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:50:10,662 - INFO - args.exp_name : Test
2025-08-04 10:50:10,664 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:50:10,664 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:50:11,033 - INFO - Total trainable parameters: 714177
2025-08-04 10:50:11,056 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:50:11,056 - INFO - Staring training for 10 epochs
2025-08-04 10:50:17,659 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:50:17,659 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:50:17,667 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:50:17,667 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:41,371 - INFO - args.exp_name : Test
2025-08-04 10:51:41,376 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:51:41,376 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:51:41,753 - INFO - Total trainable parameters: 714177
2025-08-04 10:51:41,781 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:51:41,782 - INFO - Staring training for 10 epochs
2025-08-04 10:51:48,484 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:51:48,489 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:48,497 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:51:48,497 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:51:48,712 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:51:48,712 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:48,713 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:51:48,713 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:51:48,744 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:51:48,745 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:48,779 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:51:48,781 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:51:55,844 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:51:55,852 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:55,853 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:51:55,853 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:51:55,878 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:51:55,878 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:55,919 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:51:55,919 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:51:55,944 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:51:55,944 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:51:55,984 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:51:55,984 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:03,110 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:03,110 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:03,110 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:03,111 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:03,146 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:03,146 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:03,171 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:03,172 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:03,201 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:03,201 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:03,232 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:03,232 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:10,637 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:10,637 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:10,638 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:10,638 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:10,666 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:10,666 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:10,696 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:10,696 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:10,727 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:10,727 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:10,755 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:10,755 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:17,784 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:17,784 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:17,785 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:17,785 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:17,816 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:17,816 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:17,843 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:17,844 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:17,875 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:17,875 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:17,904 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:17,904 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:24,932 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:24,932 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:24,933 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:24,933 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:24,963 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:24,964 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:24,991 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:24,991 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:25,016 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:25,016 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:25,050 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:25,050 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:32,333 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:32,333 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:32,334 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:32,334 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:32,367 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:32,367 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:32,392 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:32,392 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:32,423 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:32,423 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:32,451 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:32,451 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:39,869 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:39,869 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:39,869 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:39,869 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:39,898 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:39,898 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:39,935 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:39,935 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:39,964 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:39,964 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:40,000 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:40,000 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:47,125 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:47,125 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:47,125 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:47,126 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:47,158 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:47,158 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:47,186 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:47,186 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:47,217 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:47,217 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:47,247 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:47,247 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:54,297 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:54,297 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:54,298 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:54,298 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:54,332 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:54,334 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:54,357 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:54,357 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:52:54,384 - INFO - [35m data_point.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-04 10:52:54,384 - INFO - [35m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-04 10:52:54,415 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:52:54,415 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:53:51,783 - INFO - args.exp_name : Test
2025-08-04 10:53:51,787 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:53:51,788 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:53:52,149 - INFO - Total trainable parameters: 714177
2025-08-04 10:53:52,177 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:53:52,178 - INFO - Staring training for 10 epochs
2025-08-04 10:53:58,986 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:53:58,991 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:53:59,351 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:53:59,351 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:53:59,494 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:53:59,494 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:06,794 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:06,799 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:06,946 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:06,946 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:07,087 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:07,087 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:14,485 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:14,490 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:14,642 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:14,642 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:14,787 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:14,787 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:22,195 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:22,200 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:22,341 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:22,341 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:22,482 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:22,483 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:29,770 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:29,770 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:29,912 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:29,915 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:30,056 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:30,056 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:37,139 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:37,139 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:37,281 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:37,281 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:37,422 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:37,422 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:44,847 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:44,847 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:44,990 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:44,991 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:45,131 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:45,131 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:52,318 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:52,318 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:52,462 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:52,462 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:54:52,603 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:54:52,603 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:00,032 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:55:00,032 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:00,186 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:55:00,186 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:00,331 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:55:00,331 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:07,505 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:55:07,506 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:07,647 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:55:07,647 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:07,788 - INFO - [35m data_point.shape: torch.Size([6, 10000, 3]) [0m
2025-08-04 10:55:07,788 - INFO - [35m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-04 10:55:43,876 - INFO - args.exp_name : Test
2025-08-04 10:55:43,881 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 10:55:43,881 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 10:55:44,247 - INFO - Total trainable parameters: 714177
2025-08-04 10:55:44,273 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 10:55:44,274 - INFO - Staring training for 10 epochs
2025-08-04 11:15:37,952 - INFO - args.exp_name : Test
2025-08-04 11:15:37,956 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 11:15:37,956 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 11:15:38,329 - INFO - Total trainable parameters: 714177
2025-08-04 11:15:38,354 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 11:15:38,355 - INFO - Staring training for 10 epochs
2025-08-04 11:17:10,305 - INFO - args.exp_name : Test
2025-08-04 11:17:10,310 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 11:17:10,310 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 11:17:10,678 - INFO - Total trainable parameters: 714177
2025-08-04 11:17:10,701 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-04 11:17:10,702 - INFO - Staring training for 10 epochs
2025-08-04 11:17:26,315 - INFO - Epoch 1/10 - Train Loss: 0.803133, Val Loss: 0.497473
2025-08-04 11:17:26,341 - INFO - New best model saved with Val Loss: 0.497473
2025-08-04 11:17:41,721 - INFO - Epoch 2/10 - Train Loss: 0.452560, Val Loss: 0.351013
2025-08-04 11:17:41,747 - INFO - New best model saved with Val Loss: 0.351013
2025-08-04 11:17:56,855 - INFO - Epoch 3/10 - Train Loss: 0.333392, Val Loss: 0.292948
2025-08-04 11:17:56,880 - INFO - New best model saved with Val Loss: 0.292948
2025-08-04 11:18:11,984 - INFO - Epoch 4/10 - Train Loss: 0.281344, Val Loss: 0.233950
2025-08-04 11:18:12,008 - INFO - New best model saved with Val Loss: 0.233950
2025-08-04 11:18:26,915 - INFO - Epoch 5/10 - Train Loss: 0.252313, Val Loss: 0.198070
2025-08-04 11:18:26,939 - INFO - New best model saved with Val Loss: 0.198070
2025-08-04 11:18:41,592 - INFO - Epoch 6/10 - Train Loss: 0.218822, Val Loss: 0.187986
2025-08-04 11:18:41,617 - INFO - New best model saved with Val Loss: 0.187986
2025-08-04 11:18:56,426 - INFO - Epoch 7/10 - Train Loss: 0.201827, Val Loss: 0.161274
2025-08-04 11:18:56,451 - INFO - New best model saved with Val Loss: 0.161274
2025-08-04 11:19:11,215 - INFO - Epoch 8/10 - Train Loss: 0.184439, Val Loss: 0.160605
2025-08-04 11:19:11,240 - INFO - New best model saved with Val Loss: 0.160605
2025-08-04 11:19:26,516 - INFO - Epoch 9/10 - Train Loss: 0.174530, Val Loss: 0.144398
2025-08-04 11:19:26,542 - INFO - New best model saved with Val Loss: 0.144398
2025-08-04 11:19:41,481 - INFO - Epoch 10/10 - Train Loss: 0.162107, Val Loss: 0.138230
2025-08-04 11:19:41,506 - INFO - New best model saved with Val Loss: 0.138230
2025-08-04 11:19:41,752 - INFO - Final model saved to experiments/Test/final_model.pth
2025-08-04 11:19:41,753 - INFO - Testing the final model
2025-08-04 11:19:41,753 - INFO - Testing the best model
2025-08-04 11:30:27,193 - INFO - args.exp_name : Test
2025-08-04 11:30:27,199 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-04 11:30:27,199 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-04 11:30:27,568 - INFO - Total trainable parameters: 714177
2025-08-04 11:30:27,867 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-04 11:30:27,867 - INFO - Staring training for 10 epochs
2025-08-04 11:31:38,934 - INFO - Epoch 1/10 - Train Loss: 0.195183, Val Loss: 0.092994
2025-08-04 11:31:38,982 - INFO - New best model saved with Val Loss: 0.092994
2025-08-04 11:32:05,965 - INFO - Epoch 2/10 - Train Loss: 0.091444, Val Loss: 0.072784
2025-08-04 11:32:05,989 - INFO - New best model saved with Val Loss: 0.072784
2025-08-04 11:32:32,134 - INFO - Epoch 3/10 - Train Loss: 0.073507, Val Loss: 0.059109
2025-08-04 11:32:32,172 - INFO - New best model saved with Val Loss: 0.059109
2025-08-04 11:32:58,175 - INFO - Epoch 4/10 - Train Loss: 0.060795, Val Loss: 0.048532
2025-08-04 11:32:58,200 - INFO - New best model saved with Val Loss: 0.048532
2025-08-04 11:33:24,491 - INFO - Epoch 5/10 - Train Loss: 0.050783, Val Loss: 0.040491
2025-08-04 11:33:24,515 - INFO - New best model saved with Val Loss: 0.040491
2025-08-04 11:33:50,806 - INFO - Epoch 6/10 - Train Loss: 0.043555, Val Loss: 0.034384
2025-08-04 11:33:50,831 - INFO - New best model saved with Val Loss: 0.034384
2025-08-04 11:34:17,819 - INFO - Epoch 7/10 - Train Loss: 0.037972, Val Loss: 0.029739
2025-08-04 11:34:17,866 - INFO - New best model saved with Val Loss: 0.029739
2025-08-04 11:34:44,179 - INFO - Epoch 8/10 - Train Loss: 0.033721, Val Loss: 0.026144
2025-08-04 11:34:44,204 - INFO - New best model saved with Val Loss: 0.026144
2025-08-04 11:35:10,819 - INFO - Epoch 9/10 - Train Loss: 0.030197, Val Loss: 0.023313
2025-08-04 11:35:10,844 - INFO - New best model saved with Val Loss: 0.023313
2025-08-04 11:35:37,037 - INFO - Epoch 10/10 - Train Loss: 0.027334, Val Loss: 0.021054
2025-08-04 11:35:37,062 - INFO - New best model saved with Val Loss: 0.021054
2025-08-04 11:35:37,292 - INFO - Final model saved to experiments/Test/final_model.pth
2025-08-04 11:35:37,295 - INFO - Testing the final model
2025-08-04 11:35:37,295 - INFO - Testing the best model
2025-08-05 09:48:10,046 - INFO - args.exp_name : Test
2025-08-05 09:48:10,050 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 1,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 09:48:10,050 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 09:48:10,487 - INFO - Total trainable parameters: 714177
2025-08-05 09:48:10,825 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 09:48:10,826 - INFO - Loading best model for testing only
2025-08-05 09:51:12,218 - INFO - args.exp_name : Test
2025-08-05 09:51:12,223 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 1,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 09:51:12,223 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 09:51:12,568 - INFO - Total trainable parameters: 714177
2025-08-05 09:51:12,849 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 09:51:12,854 - INFO - Loading best model for testing only
2025-08-05 09:51:30,115 - INFO - Total MSE across all processes: 491.1652526855469
2025-08-05 09:51:30,120 - INFO - mean value for all_targets: {tmp}
2025-08-05 09:51:30,127 - INFO - Test MSE: 4.308467, Test MAE: 1.800510, Max AE: 28.971830, Test R2: -3.0555
2025-08-05 09:51:30,129 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-05 09:51:30,130 - INFO - Total inference time:  0.44s for 114 samples
2025-08-05 09:52:48,650 - INFO - args.exp_name : Test
2025-08-05 09:52:48,655 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 1,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 09:52:48,655 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 09:52:49,044 - INFO - Total trainable parameters: 714177
2025-08-05 09:52:49,123 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-05 09:52:49,125 - INFO - Loading best model for testing only
2025-08-05 09:52:56,888 - INFO - Total MSE across all processes: 27.66598129272461
2025-08-05 09:52:56,889 - INFO - mean value for all_targets: {tmp}
2025-08-05 09:52:56,889 - INFO - Test MSE: 4.610997, Test MAE: 1.804709, Max AE: 9.572763, Test R2: -3.0851
2025-08-05 09:52:56,889 - INFO - Relative L2 Error: 33.887634, Relative L1 error: 33.887634
2025-08-05 09:52:56,889 - INFO - Total inference time:  0.14s for 6 samples
2025-08-05 09:53:53,945 - INFO - args.exp_name : Test
2025-08-05 09:53:53,949 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 09:53:53,950 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 09:53:54,288 - INFO - Total trainable parameters: 714177
2025-08-05 09:53:54,568 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 09:53:54,573 - INFO - Staring training for 150 epochs
2025-08-05 09:54:21,401 - INFO - Epoch 1/150 - Train Loss: 0.195183, Val Loss: 0.092994
2025-08-05 09:54:21,428 - INFO - New best model saved with Val Loss: 0.092994
2025-08-05 09:54:48,369 - INFO - Epoch 2/150 - Train Loss: 0.091444, Val Loss: 0.072784
2025-08-05 09:54:48,394 - INFO - New best model saved with Val Loss: 0.072784
2025-08-05 09:55:14,931 - INFO - Epoch 3/150 - Train Loss: 0.073507, Val Loss: 0.059109
2025-08-05 09:55:14,956 - INFO - New best model saved with Val Loss: 0.059109
2025-08-05 09:55:41,523 - INFO - Epoch 4/150 - Train Loss: 0.060795, Val Loss: 0.048532
2025-08-05 09:55:41,549 - INFO - New best model saved with Val Loss: 0.048532
2025-08-05 09:56:08,566 - INFO - Epoch 5/150 - Train Loss: 0.050783, Val Loss: 0.040491
2025-08-05 09:56:08,591 - INFO - New best model saved with Val Loss: 0.040491
2025-08-05 09:56:34,732 - INFO - Epoch 6/150 - Train Loss: 0.043555, Val Loss: 0.034384
2025-08-05 09:56:34,757 - INFO - New best model saved with Val Loss: 0.034384
2025-08-05 09:57:01,153 - INFO - Epoch 7/150 - Train Loss: 0.037972, Val Loss: 0.029739
2025-08-05 09:57:01,178 - INFO - New best model saved with Val Loss: 0.029739
2025-08-05 09:57:28,139 - INFO - Epoch 8/150 - Train Loss: 0.033721, Val Loss: 0.026144
2025-08-05 09:57:28,164 - INFO - New best model saved with Val Loss: 0.026144
2025-08-05 09:57:54,930 - INFO - Epoch 9/150 - Train Loss: 0.030197, Val Loss: 0.023313
2025-08-05 09:57:54,956 - INFO - New best model saved with Val Loss: 0.023313
2025-08-05 09:58:21,834 - INFO - Epoch 10/150 - Train Loss: 0.027334, Val Loss: 0.021054
2025-08-05 09:58:21,859 - INFO - New best model saved with Val Loss: 0.021054
2025-08-05 09:58:48,884 - INFO - Epoch 11/150 - Train Loss: 0.025580, Val Loss: 0.019247
2025-08-05 09:58:48,910 - INFO - New best model saved with Val Loss: 0.019247
2025-08-05 09:59:15,493 - INFO - Epoch 12/150 - Train Loss: 0.023795, Val Loss: 0.017743
2025-08-05 09:59:15,518 - INFO - New best model saved with Val Loss: 0.017743
2025-08-05 09:59:41,977 - INFO - Epoch 13/150 - Train Loss: 0.022188, Val Loss: 0.016488
2025-08-05 09:59:42,003 - INFO - New best model saved with Val Loss: 0.016488
2025-08-05 10:00:08,718 - INFO - Epoch 14/150 - Train Loss: 0.020958, Val Loss: 0.015360
2025-08-05 10:00:08,744 - INFO - New best model saved with Val Loss: 0.015360
2025-08-05 10:00:35,409 - INFO - Epoch 15/150 - Train Loss: 0.019845, Val Loss: 0.014416
2025-08-05 10:00:35,433 - INFO - New best model saved with Val Loss: 0.014416
2025-08-05 10:01:01,858 - INFO - Epoch 16/150 - Train Loss: 0.018873, Val Loss: 0.013452
2025-08-05 10:01:01,884 - INFO - New best model saved with Val Loss: 0.013452
2025-08-05 10:01:28,310 - INFO - Epoch 17/150 - Train Loss: 0.017931, Val Loss: 0.012651
2025-08-05 10:01:28,335 - INFO - New best model saved with Val Loss: 0.012651
2025-08-05 10:01:54,972 - INFO - Epoch 18/150 - Train Loss: 0.017014, Val Loss: 0.011881
2025-08-05 10:01:54,999 - INFO - New best model saved with Val Loss: 0.011881
2025-08-05 10:02:21,756 - INFO - Epoch 19/150 - Train Loss: 0.016266, Val Loss: 0.011317
2025-08-05 10:02:21,781 - INFO - New best model saved with Val Loss: 0.011317
2025-08-05 10:02:48,626 - INFO - Epoch 20/150 - Train Loss: 0.015474, Val Loss: 0.010878
2025-08-05 10:02:48,651 - INFO - New best model saved with Val Loss: 0.010878
2025-08-05 10:07:52,780 - INFO - args.exp_name : Test
2025-08-05 10:07:52,786 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:07:52,786 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:07:53,135 - INFO - Total trainable parameters: 713921
2025-08-05 10:07:53,415 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 10:07:53,416 - INFO - Staring training for 150 epochs
2025-08-05 10:08:00,072 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:00,262 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:00,404 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:00,545 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:00,689 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:00,830 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:00,971 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,111 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,252 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,393 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,534 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,678 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,819 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:01,959 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,100 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,243 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,383 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,524 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,667 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:02,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,089 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,230 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,370 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,512 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,655 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,796 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:03,937 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,219 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,359 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,500 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,643 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,784 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:04,925 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,066 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,207 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,347 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,488 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,629 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,770 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:05,911 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,193 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,333 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,615 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:06,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,040 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,464 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,604 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,745 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:07,886 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,027 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,168 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,449 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,731 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:08,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,154 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,295 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,436 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,576 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,858 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:09,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:10,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:10,280 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:10,421 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:10,562 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:10,703 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:08:10,844 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:44,586 - INFO - args.exp_name : Test
2025-08-05 10:12:44,590 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:12:44,591 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:12:44,956 - INFO - Total trainable parameters: 713921
2025-08-05 10:12:45,234 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 10:12:45,235 - INFO - Staring training for 150 epochs
2025-08-05 10:12:51,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:51,713 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:51,856 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:51,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,138 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,420 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,560 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,701 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,842 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:52,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,124 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,265 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,405 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,546 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,687 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:53,969 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,111 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,251 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,392 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,533 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,814 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:54,955 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,096 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,378 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,518 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:55,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,082 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,505 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,646 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,787 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:56,927 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,068 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,209 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,491 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,632 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:57,913 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,195 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,336 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,477 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,617 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:58,900 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,042 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,323 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,464 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,604 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,746 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:12:59,886 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,027 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,168 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,732 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:00,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,014 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,154 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,295 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,436 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,577 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:01,859 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:02,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:02,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:02,281 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-05 10:13:57,335 - INFO - args.exp_name : Test
2025-08-05 10:13:57,338 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:13:57,338 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:13:57,693 - INFO - Total trainable parameters: 713921
2025-08-05 10:13:57,971 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 10:13:57,972 - INFO - Staring training for 150 epochs
2025-08-05 10:23:54,682 - INFO - args.exp_name : Test
2025-08-05 10:23:54,688 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/small_samples/Pressure_VTK',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:23:54,688 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:23:55,065 - INFO - Total trainable parameters: 713921
2025-08-05 10:23:55,090 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-08-05 10:23:55,091 - INFO - Staring training for 150 epochs
2025-08-05 10:24:10,794 - INFO - Epoch 1/150 - Train Loss: 1.217155, Val Loss: 1.129727
2025-08-05 10:24:10,822 - INFO - New best model saved with Val Loss: 1.129727
2025-08-05 10:24:25,442 - INFO - Epoch 2/150 - Train Loss: 1.162042, Val Loss: 1.104278
2025-08-05 10:24:25,467 - INFO - New best model saved with Val Loss: 1.104278
2025-08-05 10:24:39,440 - INFO - Epoch 3/150 - Train Loss: 1.136828, Val Loss: 1.074645
2025-08-05 10:24:39,465 - INFO - New best model saved with Val Loss: 1.074645
2025-08-05 10:24:53,671 - INFO - Epoch 4/150 - Train Loss: 1.111161, Val Loss: 1.054567
2025-08-05 10:24:53,696 - INFO - New best model saved with Val Loss: 1.054567
2025-08-05 10:25:08,432 - INFO - Epoch 5/150 - Train Loss: 1.092947, Val Loss: 1.018665
2025-08-05 10:25:08,459 - INFO - New best model saved with Val Loss: 1.018665
2025-08-05 10:25:23,206 - INFO - Epoch 6/150 - Train Loss: 1.058124, Val Loss: 0.982657
2025-08-05 10:25:23,234 - INFO - New best model saved with Val Loss: 0.982657
2025-08-05 10:25:37,815 - INFO - Epoch 7/150 - Train Loss: 1.030523, Val Loss: 0.948917
2025-08-05 10:25:37,840 - INFO - New best model saved with Val Loss: 0.948917
2025-08-05 10:26:09,968 - INFO - args.exp_name : Test
2025-08-05 10:26:09,974 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 10,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:26:09,974 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:26:10,401 - INFO - Total trainable parameters: 713921
2025-08-05 10:26:10,677 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 10:26:10,681 - INFO - Staring training for 10 epochs
2025-08-05 10:26:38,460 - INFO - Epoch 1/10 - Train Loss: 0.872728, Val Loss: 0.770381
2025-08-05 10:26:38,498 - INFO - New best model saved with Val Loss: 0.770381
2025-08-05 10:27:06,640 - INFO - Epoch 2/10 - Train Loss: 0.746029, Val Loss: 0.714486
2025-08-05 10:27:06,669 - INFO - New best model saved with Val Loss: 0.714486
2025-08-05 10:27:34,867 - INFO - Epoch 3/10 - Train Loss: 0.689046, Val Loss: 0.652508
2025-08-05 10:27:34,896 - INFO - New best model saved with Val Loss: 0.652508
2025-08-05 10:28:03,203 - INFO - Epoch 4/10 - Train Loss: 0.596089, Val Loss: 0.517790
2025-08-05 10:28:03,233 - INFO - New best model saved with Val Loss: 0.517790
2025-08-05 10:28:31,463 - INFO - Epoch 5/10 - Train Loss: 0.487988, Val Loss: 0.471622
2025-08-05 10:28:31,490 - INFO - New best model saved with Val Loss: 0.471622
2025-08-05 10:28:59,622 - INFO - Epoch 6/10 - Train Loss: 0.457196, Val Loss: 0.443875
2025-08-05 10:28:59,652 - INFO - New best model saved with Val Loss: 0.443875
2025-08-05 10:29:27,799 - INFO - Epoch 7/10 - Train Loss: 0.438555, Val Loss: 0.427619
2025-08-05 10:29:27,827 - INFO - New best model saved with Val Loss: 0.427619
2025-08-05 10:30:27,164 - INFO - args.exp_name : Test
2025-08-05 10:30:27,168 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:30:27,168 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:30:27,527 - INFO - Total trainable parameters: 713921
2025-08-05 10:30:27,807 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 10:30:27,811 - INFO - Staring training for 150 epochs
2025-08-05 10:30:54,678 - INFO - Epoch 1/150 - Train Loss: 0.872728, Val Loss: 0.770381
2025-08-05 10:30:54,707 - INFO - New best model saved with Val Loss: 0.770381
2025-08-05 10:31:20,914 - INFO - Epoch 2/150 - Train Loss: 0.746029, Val Loss: 0.714486
2025-08-05 10:31:20,939 - INFO - New best model saved with Val Loss: 0.714486
2025-08-05 10:31:47,080 - INFO - Epoch 3/150 - Train Loss: 0.689046, Val Loss: 0.652508
2025-08-05 10:31:47,105 - INFO - New best model saved with Val Loss: 0.652508
2025-08-05 10:32:13,642 - INFO - Epoch 4/150 - Train Loss: 0.596089, Val Loss: 0.517790
2025-08-05 10:32:13,667 - INFO - New best model saved with Val Loss: 0.517790
2025-08-05 10:32:40,391 - INFO - Epoch 5/150 - Train Loss: 0.487988, Val Loss: 0.471622
2025-08-05 10:32:40,415 - INFO - New best model saved with Val Loss: 0.471622
2025-08-05 10:33:06,627 - INFO - Epoch 6/150 - Train Loss: 0.457196, Val Loss: 0.443875
2025-08-05 10:33:06,653 - INFO - New best model saved with Val Loss: 0.443875
2025-08-05 10:33:33,570 - INFO - Epoch 7/150 - Train Loss: 0.438555, Val Loss: 0.427619
2025-08-05 10:33:33,596 - INFO - New best model saved with Val Loss: 0.427619
2025-08-05 10:34:00,086 - INFO - Epoch 8/150 - Train Loss: 0.426537, Val Loss: 0.443644
2025-08-05 10:34:27,199 - INFO - Epoch 9/150 - Train Loss: 0.420910, Val Loss: 0.407189
2025-08-05 10:34:27,226 - INFO - New best model saved with Val Loss: 0.407189
2025-08-05 10:34:53,819 - INFO - Epoch 10/150 - Train Loss: 0.405058, Val Loss: 0.395317
2025-08-05 10:34:53,844 - INFO - New best model saved with Val Loss: 0.395317
2025-08-05 10:35:20,707 - INFO - Epoch 11/150 - Train Loss: 0.396889, Val Loss: 0.394301
2025-08-05 10:35:20,733 - INFO - New best model saved with Val Loss: 0.394301
2025-08-05 10:35:47,261 - INFO - Epoch 12/150 - Train Loss: 0.393854, Val Loss: 0.398666
2025-08-05 10:36:13,800 - INFO - Epoch 13/150 - Train Loss: 0.393448, Val Loss: 0.395053
2025-08-05 10:36:40,496 - INFO - Epoch 14/150 - Train Loss: 0.393088, Val Loss: 0.382051
2025-08-05 10:36:40,521 - INFO - New best model saved with Val Loss: 0.382051
2025-08-05 10:37:07,681 - INFO - Epoch 15/150 - Train Loss: 0.380370, Val Loss: 0.376395
2025-08-05 10:37:07,709 - INFO - New best model saved with Val Loss: 0.376395
2025-08-05 10:37:34,198 - INFO - Epoch 16/150 - Train Loss: 0.384243, Val Loss: 0.382050
2025-08-05 10:38:00,874 - INFO - Epoch 17/150 - Train Loss: 0.377425, Val Loss: 0.366214
2025-08-05 10:38:00,900 - INFO - New best model saved with Val Loss: 0.366214
2025-08-05 10:38:27,777 - INFO - Epoch 18/150 - Train Loss: 0.371412, Val Loss: 0.371318
2025-08-05 10:38:54,525 - INFO - Epoch 19/150 - Train Loss: 0.363831, Val Loss: 0.358968
2025-08-05 10:38:54,552 - INFO - New best model saved with Val Loss: 0.358968
2025-08-05 10:39:20,623 - INFO - Epoch 20/150 - Train Loss: 0.355873, Val Loss: 0.345916
2025-08-05 10:39:20,649 - INFO - New best model saved with Val Loss: 0.345916
2025-08-05 10:39:47,297 - INFO - Epoch 21/150 - Train Loss: 0.348938, Val Loss: 0.328994
2025-08-05 10:39:47,323 - INFO - New best model saved with Val Loss: 0.328994
2025-08-05 10:40:13,928 - INFO - Epoch 22/150 - Train Loss: 0.328250, Val Loss: 0.317762
2025-08-05 10:40:13,953 - INFO - New best model saved with Val Loss: 0.317762
2025-08-05 10:40:40,890 - INFO - Epoch 23/150 - Train Loss: 0.309963, Val Loss: 0.297027
2025-08-05 10:40:40,919 - INFO - New best model saved with Val Loss: 0.297027
2025-08-05 10:41:07,854 - INFO - Epoch 24/150 - Train Loss: 0.306142, Val Loss: 0.289150
2025-08-05 10:41:07,879 - INFO - New best model saved with Val Loss: 0.289150
2025-08-05 10:41:34,956 - INFO - Epoch 25/150 - Train Loss: 0.298667, Val Loss: 0.288754
2025-08-05 10:41:34,982 - INFO - New best model saved with Val Loss: 0.288754
2025-08-05 10:42:01,641 - INFO - Epoch 26/150 - Train Loss: 0.292320, Val Loss: 0.282417
2025-08-05 10:42:01,666 - INFO - New best model saved with Val Loss: 0.282417
2025-08-05 10:42:28,103 - INFO - Epoch 27/150 - Train Loss: 0.286816, Val Loss: 0.280205
2025-08-05 10:42:28,130 - INFO - New best model saved with Val Loss: 0.280205
2025-08-05 10:42:54,803 - INFO - Epoch 28/150 - Train Loss: 0.281554, Val Loss: 0.275352
2025-08-05 10:42:54,828 - INFO - New best model saved with Val Loss: 0.275352
2025-08-05 10:43:21,547 - INFO - Epoch 29/150 - Train Loss: 0.273313, Val Loss: 0.259936
2025-08-05 10:43:21,573 - INFO - New best model saved with Val Loss: 0.259936
2025-08-05 10:43:48,391 - INFO - Epoch 30/150 - Train Loss: 0.264080, Val Loss: 0.253437
2025-08-05 10:43:48,417 - INFO - New best model saved with Val Loss: 0.253437
2025-08-05 10:44:14,992 - INFO - Epoch 31/150 - Train Loss: 0.259967, Val Loss: 0.255636
2025-08-05 10:44:41,906 - INFO - Epoch 32/150 - Train Loss: 0.257382, Val Loss: 0.256045
2025-08-05 10:49:02,255 - INFO - args.exp_name : Test
2025-08-05 10:49:02,259 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-05 10:49:02,259 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-05 10:49:02,627 - INFO - Total trainable parameters: 713921
2025-08-05 10:49:02,911 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-05 10:49:02,911 - INFO - Staring training for 150 epochs
2025-08-05 10:49:29,479 - INFO - Epoch 1/150 - Train Loss: 0.872728, Val Loss: 0.770381
2025-08-05 10:49:29,506 - INFO - New best model saved with Val Loss: 0.770381
2025-08-05 10:49:55,880 - INFO - Epoch 2/150 - Train Loss: 0.746029, Val Loss: 0.714486
2025-08-05 10:49:55,905 - INFO - New best model saved with Val Loss: 0.714486
2025-08-05 10:50:22,616 - INFO - Epoch 3/150 - Train Loss: 0.689046, Val Loss: 0.652508
2025-08-05 10:50:22,642 - INFO - New best model saved with Val Loss: 0.652508
2025-08-05 10:50:49,350 - INFO - Epoch 4/150 - Train Loss: 0.596089, Val Loss: 0.517790
2025-08-05 10:50:49,376 - INFO - New best model saved with Val Loss: 0.517790
2025-08-05 10:51:16,113 - INFO - Epoch 5/150 - Train Loss: 0.487988, Val Loss: 0.471622
2025-08-05 10:51:16,139 - INFO - New best model saved with Val Loss: 0.471622
2025-08-05 10:51:42,755 - INFO - Epoch 6/150 - Train Loss: 0.457196, Val Loss: 0.443875
2025-08-05 10:51:42,783 - INFO - New best model saved with Val Loss: 0.443875
2025-08-05 10:52:09,178 - INFO - Epoch 7/150 - Train Loss: 0.438555, Val Loss: 0.427619
2025-08-05 10:52:09,204 - INFO - New best model saved with Val Loss: 0.427619
2025-08-05 10:52:35,599 - INFO - Epoch 8/150 - Train Loss: 0.426537, Val Loss: 0.443644
2025-08-05 10:53:01,826 - INFO - Epoch 9/150 - Train Loss: 0.420910, Val Loss: 0.407189
2025-08-05 10:53:01,851 - INFO - New best model saved with Val Loss: 0.407189
2025-08-05 10:53:28,323 - INFO - Epoch 10/150 - Train Loss: 0.405058, Val Loss: 0.395317
2025-08-05 10:53:28,348 - INFO - New best model saved with Val Loss: 0.395317
2025-08-05 10:53:54,890 - INFO - Epoch 11/150 - Train Loss: 0.396889, Val Loss: 0.394301
2025-08-05 10:53:54,916 - INFO - New best model saved with Val Loss: 0.394301
2025-08-05 10:54:21,844 - INFO - Epoch 12/150 - Train Loss: 0.393854, Val Loss: 0.398666
2025-08-05 10:54:48,439 - INFO - Epoch 13/150 - Train Loss: 0.393448, Val Loss: 0.395053
2025-08-05 10:55:15,166 - INFO - Epoch 14/150 - Train Loss: 0.393088, Val Loss: 0.382051
2025-08-05 10:55:15,192 - INFO - New best model saved with Val Loss: 0.382051
2025-08-05 10:55:42,005 - INFO - Epoch 15/150 - Train Loss: 0.380370, Val Loss: 0.376395
2025-08-05 10:55:42,031 - INFO - New best model saved with Val Loss: 0.376395
2025-08-05 10:56:08,972 - INFO - Epoch 16/150 - Train Loss: 0.384243, Val Loss: 0.382050
2025-08-05 10:56:35,913 - INFO - Epoch 17/150 - Train Loss: 0.377425, Val Loss: 0.366214
2025-08-05 10:56:35,938 - INFO - New best model saved with Val Loss: 0.366214
2025-08-05 10:57:02,185 - INFO - Epoch 18/150 - Train Loss: 0.371412, Val Loss: 0.371318
2025-08-05 10:57:29,059 - INFO - Epoch 19/150 - Train Loss: 0.363831, Val Loss: 0.358968
2025-08-05 10:57:29,084 - INFO - New best model saved with Val Loss: 0.358968
2025-08-05 10:57:55,300 - INFO - Epoch 20/150 - Train Loss: 0.355873, Val Loss: 0.345916
2025-08-05 10:57:55,325 - INFO - New best model saved with Val Loss: 0.345916
2025-08-05 10:58:22,181 - INFO - Epoch 21/150 - Train Loss: 0.348938, Val Loss: 0.328994
2025-08-05 10:58:22,207 - INFO - New best model saved with Val Loss: 0.328994
2025-08-05 10:58:48,171 - INFO - Epoch 22/150 - Train Loss: 0.328250, Val Loss: 0.317762
2025-08-05 10:58:48,197 - INFO - New best model saved with Val Loss: 0.317762
2025-08-05 10:59:14,643 - INFO - Epoch 23/150 - Train Loss: 0.309963, Val Loss: 0.297027
2025-08-05 10:59:14,669 - INFO - New best model saved with Val Loss: 0.297027
2025-08-05 10:59:41,378 - INFO - Epoch 24/150 - Train Loss: 0.306142, Val Loss: 0.289150
2025-08-05 10:59:41,404 - INFO - New best model saved with Val Loss: 0.289150
2025-08-05 11:00:08,057 - INFO - Epoch 25/150 - Train Loss: 0.298667, Val Loss: 0.288754
2025-08-05 11:00:08,082 - INFO - New best model saved with Val Loss: 0.288754
2025-08-05 11:00:34,955 - INFO - Epoch 26/150 - Train Loss: 0.292320, Val Loss: 0.282417
2025-08-05 11:00:34,981 - INFO - New best model saved with Val Loss: 0.282417
2025-08-05 11:01:01,602 - INFO - Epoch 27/150 - Train Loss: 0.286816, Val Loss: 0.280205
2025-08-05 11:01:01,628 - INFO - New best model saved with Val Loss: 0.280205
2025-08-05 11:01:28,285 - INFO - Epoch 28/150 - Train Loss: 0.281554, Val Loss: 0.275352
2025-08-05 11:01:28,311 - INFO - New best model saved with Val Loss: 0.275352
2025-08-05 11:01:55,033 - INFO - Epoch 29/150 - Train Loss: 0.273313, Val Loss: 0.259936
2025-08-05 11:01:55,058 - INFO - New best model saved with Val Loss: 0.259936
2025-08-05 11:02:21,590 - INFO - Epoch 30/150 - Train Loss: 0.264080, Val Loss: 0.253437
2025-08-05 11:02:21,617 - INFO - New best model saved with Val Loss: 0.253437
2025-08-05 11:02:48,395 - INFO - Epoch 31/150 - Train Loss: 0.259967, Val Loss: 0.255636
2025-08-05 11:03:15,252 - INFO - Epoch 32/150 - Train Loss: 0.257382, Val Loss: 0.256045
2025-08-05 11:03:41,960 - INFO - Epoch 33/150 - Train Loss: 0.252600, Val Loss: 0.253996
2025-08-05 11:04:08,790 - INFO - Epoch 34/150 - Train Loss: 0.256595, Val Loss: 0.255327
2025-08-05 11:04:35,199 - INFO - Epoch 35/150 - Train Loss: 0.252030, Val Loss: 0.235432
2025-08-05 11:04:35,226 - INFO - New best model saved with Val Loss: 0.235432
2025-08-05 11:05:02,116 - INFO - Epoch 36/150 - Train Loss: 0.250305, Val Loss: 0.243129
2025-08-05 11:05:28,437 - INFO - Epoch 37/150 - Train Loss: 0.243904, Val Loss: 0.244168
2025-08-05 11:05:54,632 - INFO - Epoch 38/150 - Train Loss: 0.244118, Val Loss: 0.228261
2025-08-05 11:05:54,657 - INFO - New best model saved with Val Loss: 0.228261
2025-08-05 11:06:20,881 - INFO - Epoch 39/150 - Train Loss: 0.239221, Val Loss: 0.248252
2025-08-05 11:06:47,292 - INFO - Epoch 40/150 - Train Loss: 0.240437, Val Loss: 0.230236
2025-08-05 11:07:14,240 - INFO - Epoch 41/150 - Train Loss: 0.237910, Val Loss: 0.234242
2025-08-05 11:07:41,378 - INFO - Epoch 42/150 - Train Loss: 0.239524, Val Loss: 0.225113
2025-08-05 11:07:41,403 - INFO - New best model saved with Val Loss: 0.225113
2025-08-05 11:08:07,958 - INFO - Epoch 43/150 - Train Loss: 0.235790, Val Loss: 0.231976
2025-08-05 11:08:34,546 - INFO - Epoch 44/150 - Train Loss: 0.232867, Val Loss: 0.226040
2025-08-05 11:09:00,785 - INFO - Epoch 45/150 - Train Loss: 0.232822, Val Loss: 0.230853
2025-08-05 11:09:27,843 - INFO - Epoch 46/150 - Train Loss: 0.232508, Val Loss: 0.234469
2025-08-05 11:09:54,811 - INFO - Epoch 47/150 - Train Loss: 0.228633, Val Loss: 0.230019
2025-08-05 11:10:21,686 - INFO - Epoch 48/150 - Train Loss: 0.230986, Val Loss: 0.226691
2025-08-05 11:10:48,974 - INFO - Epoch 49/150 - Train Loss: 0.228577, Val Loss: 0.230252
2025-08-05 11:11:16,280 - INFO - Epoch 50/150 - Train Loss: 0.225610, Val Loss: 0.224138
2025-08-05 11:11:16,305 - INFO - New best model saved with Val Loss: 0.224138
2025-08-05 11:11:43,916 - INFO - Epoch 51/150 - Train Loss: 0.226096, Val Loss: 0.220608
2025-08-05 11:11:43,941 - INFO - New best model saved with Val Loss: 0.220608
2025-08-05 11:12:11,362 - INFO - Epoch 52/150 - Train Loss: 0.220978, Val Loss: 0.229232
2025-08-05 11:12:38,878 - INFO - Epoch 53/150 - Train Loss: 0.224083, Val Loss: 0.214109
2025-08-05 11:12:38,903 - INFO - New best model saved with Val Loss: 0.214109
2025-08-05 11:13:06,060 - INFO - Epoch 54/150 - Train Loss: 0.219357, Val Loss: 0.213314
2025-08-05 11:13:06,084 - INFO - New best model saved with Val Loss: 0.213314
2025-08-05 11:13:33,649 - INFO - Epoch 55/150 - Train Loss: 0.213263, Val Loss: 0.210136
2025-08-05 11:13:33,674 - INFO - New best model saved with Val Loss: 0.210136
2025-08-05 11:14:01,262 - INFO - Epoch 56/150 - Train Loss: 0.211504, Val Loss: 0.208160
2025-08-05 11:14:01,286 - INFO - New best model saved with Val Loss: 0.208160
2025-08-05 11:14:28,851 - INFO - Epoch 57/150 - Train Loss: 0.210533, Val Loss: 0.201559
2025-08-05 11:14:28,876 - INFO - New best model saved with Val Loss: 0.201559
2025-08-05 11:14:56,476 - INFO - Epoch 58/150 - Train Loss: 0.212218, Val Loss: 0.210462
2025-08-05 11:15:24,146 - INFO - Epoch 59/150 - Train Loss: 0.213248, Val Loss: 0.202650
2025-08-05 11:15:51,662 - INFO - Epoch 60/150 - Train Loss: 0.206235, Val Loss: 0.199456
2025-08-05 11:15:51,686 - INFO - New best model saved with Val Loss: 0.199456
2025-08-05 11:16:19,374 - INFO - Epoch 61/150 - Train Loss: 0.207568, Val Loss: 0.199422
2025-08-05 11:16:19,399 - INFO - New best model saved with Val Loss: 0.199422
2025-08-05 11:16:46,603 - INFO - Epoch 62/150 - Train Loss: 0.208362, Val Loss: 0.208728
2025-08-05 11:17:14,462 - INFO - Epoch 63/150 - Train Loss: 0.204394, Val Loss: 0.201039
2025-08-05 11:17:42,499 - INFO - Epoch 64/150 - Train Loss: 0.208318, Val Loss: 0.198614
2025-08-05 11:17:42,539 - INFO - New best model saved with Val Loss: 0.198614
2025-08-05 11:18:09,890 - INFO - Epoch 65/150 - Train Loss: 0.202805, Val Loss: 0.199201
2025-08-05 11:18:37,347 - INFO - Epoch 66/150 - Train Loss: 0.201434, Val Loss: 0.198030
2025-08-05 11:18:37,372 - INFO - New best model saved with Val Loss: 0.198030
2025-08-05 11:19:04,693 - INFO - Epoch 67/150 - Train Loss: 0.203481, Val Loss: 0.191895
2025-08-05 11:19:04,718 - INFO - New best model saved with Val Loss: 0.191895
2025-08-05 11:19:31,669 - INFO - Epoch 68/150 - Train Loss: 0.203677, Val Loss: 0.199056
2025-08-05 11:19:59,017 - INFO - Epoch 69/150 - Train Loss: 0.202387, Val Loss: 0.186813
2025-08-05 11:19:59,041 - INFO - New best model saved with Val Loss: 0.186813
2025-08-05 11:20:26,208 - INFO - Epoch 70/150 - Train Loss: 0.198160, Val Loss: 0.192520
2025-08-05 11:20:53,543 - INFO - Epoch 71/150 - Train Loss: 0.199944, Val Loss: 0.184624
2025-08-05 11:20:53,568 - INFO - New best model saved with Val Loss: 0.184624
2025-08-05 11:21:21,501 - INFO - Epoch 72/150 - Train Loss: 0.197394, Val Loss: 0.186144
2025-08-05 11:21:48,542 - INFO - Epoch 73/150 - Train Loss: 0.196352, Val Loss: 0.181895
2025-08-05 11:21:48,567 - INFO - New best model saved with Val Loss: 0.181895
2025-08-05 11:22:15,989 - INFO - Epoch 74/150 - Train Loss: 0.193869, Val Loss: 0.180310
2025-08-05 11:22:16,016 - INFO - New best model saved with Val Loss: 0.180310
2025-08-05 11:22:43,845 - INFO - Epoch 75/150 - Train Loss: 0.200038, Val Loss: 0.186844
2025-08-05 11:23:11,235 - INFO - Epoch 76/150 - Train Loss: 0.192535, Val Loss: 0.191764
2025-08-05 11:23:38,500 - INFO - Epoch 77/150 - Train Loss: 0.194147, Val Loss: 0.196323
2025-08-05 11:24:05,160 - INFO - Epoch 78/150 - Train Loss: 0.196658, Val Loss: 0.189077
2025-08-05 11:24:32,216 - INFO - Epoch 79/150 - Train Loss: 0.193587, Val Loss: 0.184888
2025-08-05 11:24:59,205 - INFO - Epoch 80/150 - Train Loss: 0.190023, Val Loss: 0.187345
2025-08-05 11:25:25,945 - INFO - Epoch 81/150 - Train Loss: 0.190995, Val Loss: 0.200955
2025-08-05 11:25:53,043 - INFO - Epoch 82/150 - Train Loss: 0.193073, Val Loss: 0.175856
2025-08-05 11:25:53,068 - INFO - New best model saved with Val Loss: 0.175856
2025-08-05 11:26:20,090 - INFO - Epoch 83/150 - Train Loss: 0.187177, Val Loss: 0.173618
2025-08-05 11:26:20,115 - INFO - New best model saved with Val Loss: 0.173618
2025-08-05 11:26:47,164 - INFO - Epoch 84/150 - Train Loss: 0.190742, Val Loss: 0.185113
2025-08-05 11:27:14,243 - INFO - Epoch 85/150 - Train Loss: 0.189131, Val Loss: 0.186732
2025-08-05 11:27:41,134 - INFO - Epoch 86/150 - Train Loss: 0.187560, Val Loss: 0.182538
2025-08-05 11:28:08,294 - INFO - Epoch 87/150 - Train Loss: 0.185677, Val Loss: 0.179216
2025-08-05 11:28:35,262 - INFO - Epoch 88/150 - Train Loss: 0.187251, Val Loss: 0.177919
2025-08-05 11:29:02,385 - INFO - Epoch 89/150 - Train Loss: 0.186919, Val Loss: 0.176347
2025-08-05 11:29:29,149 - INFO - Epoch 90/150 - Train Loss: 0.187990, Val Loss: 0.177680
2025-08-05 11:29:56,126 - INFO - Epoch 91/150 - Train Loss: 0.186254, Val Loss: 0.184298
2025-08-05 11:30:22,568 - INFO - Epoch 92/150 - Train Loss: 0.185842, Val Loss: 0.180589
2025-08-05 11:30:49,630 - INFO - Epoch 93/150 - Train Loss: 0.189019, Val Loss: 0.185677
2025-08-05 11:31:16,335 - INFO - Epoch 94/150 - Train Loss: 0.180291, Val Loss: 0.173412
2025-08-05 11:31:16,360 - INFO - New best model saved with Val Loss: 0.173412
2025-08-05 11:31:43,552 - INFO - Epoch 95/150 - Train Loss: 0.181950, Val Loss: 0.173773
2025-08-05 11:32:10,672 - INFO - Epoch 96/150 - Train Loss: 0.181616, Val Loss: 0.173494
2025-08-05 11:32:37,252 - INFO - Epoch 97/150 - Train Loss: 0.180635, Val Loss: 0.173400
2025-08-05 11:32:37,277 - INFO - New best model saved with Val Loss: 0.173400
2025-08-05 11:33:04,631 - INFO - Epoch 98/150 - Train Loss: 0.180529, Val Loss: 0.166746
2025-08-05 11:33:04,656 - INFO - New best model saved with Val Loss: 0.166746
2025-08-05 11:33:31,107 - INFO - Epoch 99/150 - Train Loss: 0.177881, Val Loss: 0.169999
2025-08-05 11:33:57,454 - INFO - Epoch 100/150 - Train Loss: 0.181925, Val Loss: 0.178844
2025-08-05 11:34:24,463 - INFO - Epoch 101/150 - Train Loss: 0.179741, Val Loss: 0.173282
2025-08-05 11:34:50,992 - INFO - Epoch 102/150 - Train Loss: 0.175484, Val Loss: 0.166298
2025-08-05 11:34:51,018 - INFO - New best model saved with Val Loss: 0.166298
2025-08-05 11:35:17,610 - INFO - Epoch 103/150 - Train Loss: 0.182369, Val Loss: 0.180797
2025-08-05 11:35:44,520 - INFO - Epoch 104/150 - Train Loss: 0.175286, Val Loss: 0.178063
2025-08-05 11:36:11,122 - INFO - Epoch 105/150 - Train Loss: 0.179769, Val Loss: 0.176597
2025-08-05 11:36:38,052 - INFO - Epoch 106/150 - Train Loss: 0.178734, Val Loss: 0.171249
2025-08-05 11:37:05,048 - INFO - Epoch 107/150 - Train Loss: 0.175057, Val Loss: 0.169115
2025-08-05 11:37:31,337 - INFO - Epoch 108/150 - Train Loss: 0.171155, Val Loss: 0.161660
2025-08-05 11:37:31,362 - INFO - New best model saved with Val Loss: 0.161660
2025-08-05 11:37:58,063 - INFO - Epoch 109/150 - Train Loss: 0.168656, Val Loss: 0.156935
2025-08-05 11:37:58,089 - INFO - New best model saved with Val Loss: 0.156935
2025-08-05 11:38:24,909 - INFO - Epoch 110/150 - Train Loss: 0.174492, Val Loss: 0.171248
2025-08-05 11:38:51,875 - INFO - Epoch 111/150 - Train Loss: 0.173698, Val Loss: 0.157079
2025-08-05 11:39:18,519 - INFO - Epoch 112/150 - Train Loss: 0.173057, Val Loss: 0.171179
2025-08-05 11:39:45,373 - INFO - Epoch 113/150 - Train Loss: 0.171933, Val Loss: 0.158344
2025-08-05 11:40:12,146 - INFO - Epoch 114/150 - Train Loss: 0.168685, Val Loss: 0.160595
2025-08-05 11:40:38,943 - INFO - Epoch 115/150 - Train Loss: 0.172755, Val Loss: 0.163555
2025-08-05 11:41:05,711 - INFO - Epoch 116/150 - Train Loss: 0.168799, Val Loss: 0.160622
2025-08-05 11:41:32,781 - INFO - Epoch 117/150 - Train Loss: 0.167079, Val Loss: 0.155232
2025-08-05 11:41:32,806 - INFO - New best model saved with Val Loss: 0.155232
2025-08-05 11:41:59,315 - INFO - Epoch 118/150 - Train Loss: 0.164205, Val Loss: 0.167679
2025-08-05 11:42:25,867 - INFO - Epoch 119/150 - Train Loss: 0.169456, Val Loss: 0.159380
2025-08-05 11:42:52,153 - INFO - Epoch 120/150 - Train Loss: 0.166856, Val Loss: 0.155844
2025-08-05 11:43:18,487 - INFO - Epoch 121/150 - Train Loss: 0.162645, Val Loss: 0.150523
2025-08-05 11:43:18,511 - INFO - New best model saved with Val Loss: 0.150523
2025-08-05 11:43:45,378 - INFO - Epoch 122/150 - Train Loss: 0.160670, Val Loss: 0.156735
2025-08-05 11:44:11,933 - INFO - Epoch 123/150 - Train Loss: 0.166765, Val Loss: 0.157434
2025-08-05 11:44:38,821 - INFO - Epoch 124/150 - Train Loss: 0.162084, Val Loss: 0.152554
2025-08-05 11:45:05,850 - INFO - Epoch 125/150 - Train Loss: 0.161687, Val Loss: 0.164457
2025-08-05 11:45:32,217 - INFO - Epoch 126/150 - Train Loss: 0.167346, Val Loss: 0.153950
2025-08-05 11:45:58,805 - INFO - Epoch 127/150 - Train Loss: 0.161249, Val Loss: 0.151141
2025-08-05 11:46:25,357 - INFO - Epoch 128/150 - Train Loss: 0.161787, Val Loss: 0.153222
2025-08-05 11:46:52,245 - INFO - Epoch 129/150 - Train Loss: 0.159798, Val Loss: 0.158385
2025-08-05 11:47:18,909 - INFO - Epoch 130/150 - Train Loss: 0.160324, Val Loss: 0.153991
2025-08-05 11:47:45,802 - INFO - Epoch 131/150 - Train Loss: 0.161151, Val Loss: 0.157029
2025-08-05 11:48:11,711 - INFO - Epoch 132/150 - Train Loss: 0.165424, Val Loss: 0.153071
2025-08-05 11:48:38,267 - INFO - Epoch 133/150 - Train Loss: 0.162374, Val Loss: 0.159798
2025-08-05 11:49:04,376 - INFO - Epoch 134/150 - Train Loss: 0.159582, Val Loss: 0.149246
2025-08-05 11:49:04,402 - INFO - New best model saved with Val Loss: 0.149246
2025-08-05 11:49:31,215 - INFO - Epoch 135/150 - Train Loss: 0.160795, Val Loss: 0.154453
2025-08-05 11:49:57,714 - INFO - Epoch 136/150 - Train Loss: 0.159031, Val Loss: 0.147768
2025-08-05 11:49:57,739 - INFO - New best model saved with Val Loss: 0.147768
2025-08-05 11:50:24,421 - INFO - Epoch 137/150 - Train Loss: 0.157372, Val Loss: 0.150005
2025-08-05 11:50:51,155 - INFO - Epoch 138/150 - Train Loss: 0.158123, Val Loss: 0.150963
2025-08-05 11:51:18,106 - INFO - Epoch 139/150 - Train Loss: 0.157200, Val Loss: 0.146379
2025-08-05 11:51:18,131 - INFO - New best model saved with Val Loss: 0.146379
2025-08-05 11:51:45,128 - INFO - Epoch 140/150 - Train Loss: 0.162747, Val Loss: 0.161523
2025-08-05 11:52:12,050 - INFO - Epoch 141/150 - Train Loss: 0.159889, Val Loss: 0.150652
2025-08-05 11:52:38,595 - INFO - Epoch 142/150 - Train Loss: 0.152182, Val Loss: 0.154791
2025-08-05 11:53:05,583 - INFO - Epoch 143/150 - Train Loss: 0.157511, Val Loss: 0.150151
2025-08-05 11:53:32,543 - INFO - Epoch 144/150 - Train Loss: 0.149904, Val Loss: 0.138871
2025-08-05 11:53:32,568 - INFO - New best model saved with Val Loss: 0.138871
2025-08-05 11:53:59,019 - INFO - Epoch 145/150 - Train Loss: 0.149150, Val Loss: 0.141733
2025-08-05 11:54:25,672 - INFO - Epoch 146/150 - Train Loss: 0.153972, Val Loss: 0.141633
2025-08-05 11:54:52,745 - INFO - Epoch 147/150 - Train Loss: 0.152560, Val Loss: 0.154813
2025-08-05 11:55:19,398 - INFO - Epoch 148/150 - Train Loss: 0.153007, Val Loss: 0.153307
2025-08-05 11:55:45,812 - INFO - Epoch 149/150 - Train Loss: 0.152381, Val Loss: 0.146191
2025-08-05 11:56:12,557 - INFO - Epoch 150/150 - Train Loss: 0.148153, Val Loss: 0.138824
2025-08-05 11:56:12,582 - INFO - New best model saved with Val Loss: 0.138824
2025-08-05 11:56:12,764 - INFO - Final model saved to experiments/Test/final_model.pth
2025-08-05 11:56:12,765 - INFO - Testing the final model
2025-08-05 11:56:12,765 - INFO - Testing the best model
2025-08-07 10:23:13,252 - INFO - args.exp_name : Test
2025-08-07 10:23:13,255 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 1,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-07 10:23:13,255 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-07 10:23:13,781 - INFO - Total trainable parameters: 713921
2025-08-07 10:23:14,249 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-07 10:23:14,267 - INFO - Loading best model for testing only
2025-08-07 10:23:27,370 - INFO - Total MSE across all processes: 15.575870513916016
2025-08-07 10:23:27,376 - INFO - mean value for all_targets: {tmp}
2025-08-07 10:23:27,384 - INFO - Test MSE: 0.136630, Test MAE: 0.207219, Max AE: 26.918663, Test R2: 0.8714
2025-08-07 10:23:27,384 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-07 10:23:27,389 - INFO - Total inference time:  0.53s for 114 samples
2025-08-07 10:42:06,398 - INFO - args.exp_name : Test
2025-08-07 10:42:06,401 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 1,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-07 10:42:06,402 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-07 10:42:06,828 - INFO - Total trainable parameters: 713921
2025-08-07 10:42:07,329 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-07 10:42:07,346 - INFO - Loading best model for testing only
2025-08-07 10:42:18,875 - INFO - Total MSE across all processes: 15.575870513916016
2025-08-07 10:42:18,881 - INFO - mean value for all_targets: {tmp}
2025-08-07 10:42:18,890 - INFO - Test MSE: 0.136630, Test MAE: 0.207219, Max AE: 26.918663, Test R2: 0.8714
2025-08-07 10:42:18,891 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-07 10:42:18,891 - INFO - Total inference time:  0.46s for 114 samples
2025-08-07 10:43:22,791 - INFO - args.exp_name : Test
2025-08-07 10:43:22,794 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-07 10:43:22,794 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-07 10:43:23,273 - INFO - Total trainable parameters: 713921
2025-08-07 10:43:23,670 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-07 10:43:23,673 - INFO - Staring training for 150 epochs
2025-08-07 10:43:31,757 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:31,759 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:31,768 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:31,769 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,025 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,229 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:32,229 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:32,230 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:32,230 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:32,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:32,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:32,348 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:32,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:32,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:32,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,635 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:32,647 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:32,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:32,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,692 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,790 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:32,790 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:32,791 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:32,791 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,809 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,917 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:32,917 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:32,918 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:32,918 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:32,933 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,092 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,092 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,092 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,225 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,225 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,226 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,226 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,241 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,371 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,371 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,371 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,372 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,387 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,502 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,502 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,518 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,656 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,656 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,837 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,837 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,837 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,837 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,855 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:33,990 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:33,990 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:33,991 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:33,991 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,009 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,127 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:34,128 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:34,128 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:34,128 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,143 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,336 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:34,336 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:34,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:34,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:34,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:34,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:34,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,527 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,652 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:34,652 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:34,653 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:34,653 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,796 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:34,796 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:34,797 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:34,797 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,961 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:34,961 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:34,962 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:34,962 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:34,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,113 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:35,113 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:35,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:35,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,132 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:35,306 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:35,307 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:35,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,461 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:35,461 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:35,462 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:35,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,477 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,634 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:35,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:35,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:35,635 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,650 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,796 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:35,796 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:35,797 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:35,797 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:35,934 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:35,935 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:35,935 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:35,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:36,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:36,105 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:36,105 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,120 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,288 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:36,288 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:36,289 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:36,289 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,304 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,474 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:36,474 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:36,474 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:36,474 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,489 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,650 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:36,650 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:36,650 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:36,651 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,665 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,836 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:36,836 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:36,836 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:36,837 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:36,852 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,023 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:37,023 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:37,024 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:37,024 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,039 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:37,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:37,210 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:37,210 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,226 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:37,382 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:37,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:37,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,544 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:37,544 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:37,544 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:37,544 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,560 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:37,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:37,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:37,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:37,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:37,924 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:37,924 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:37,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,108 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:38,108 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:38,109 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:38,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,124 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:38,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:38,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:38,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,292 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,416 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:38,416 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:38,417 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:38,417 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,435 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,597 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:38,597 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:38,597 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:38,598 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,613 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,768 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:38,768 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:38,769 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:38,769 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,784 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,899 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:38,899 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:38,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:38,900 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:38,915 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,064 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:39,064 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:39,065 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:39,065 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,080 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,268 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:39,269 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:39,269 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:39,272 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,287 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:39,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:39,431 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:39,431 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,447 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,639 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:39,639 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:39,639 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:39,640 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,655 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:39,804 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:39,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:39,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,820 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:39,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:39,972 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:39,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:39,987 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,180 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:40,180 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:40,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:40,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,199 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,319 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:40,319 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:40,320 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:40,320 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,335 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,482 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:40,482 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:40,482 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:40,483 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,500 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,638 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:40,638 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:40,639 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:40,639 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,654 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,835 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:40,835 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:40,835 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:40,835 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,851 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,983 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:40,983 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:40,983 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:40,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:40,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:41,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:41,112 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:41,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,262 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:41,262 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:41,262 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:41,263 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,278 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,434 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:41,434 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:41,435 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:41,435 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,454 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,602 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:41,602 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:41,602 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:41,602 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,617 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:41,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:41,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:41,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,756 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,864 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:41,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:41,865 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:41,865 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:41,880 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,054 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:42,054 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:42,055 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:42,055 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,070 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:42,213 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:42,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:42,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,229 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,385 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:42,385 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:42,385 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:42,385 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,403 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:42,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:42,570 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:42,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,588 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,726 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:42,726 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:42,727 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:42,727 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,745 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,881 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:42,881 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:42,882 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:42,882 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:42,897 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,058 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:43,058 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:43,059 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:43,059 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:43,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:43,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:43,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,450 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:43,450 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:43,450 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:43,450 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,592 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:43,593 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:43,593 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:43,593 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,609 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,787 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:43,787 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:43,788 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:43,788 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,803 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,973 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:43,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:43,974 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:43,974 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:43,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,145 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:44,146 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:44,146 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:44,146 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,161 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,315 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:44,315 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:44,316 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:44,316 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,332 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,473 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:44,473 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:44,473 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:44,474 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,489 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,700 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:43:44,700 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:43:44,701 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:43:44,701 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:44,716 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:43:56,177 - INFO - Epoch 1/150 - Train Loss: 0.872068, Val Loss: 0.769350
2025-08-07 10:43:56,230 - INFO - New best model saved with Val Loss: 0.769350
2025-08-07 10:44:04,033 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,034 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,034 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,053 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,151 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,151 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,152 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,152 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,268 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,268 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,268 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,269 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,284 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,385 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,385 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,385 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,385 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,404 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,502 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,502 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,518 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,619 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,619 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,736 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,736 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,752 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,853 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,970 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:04,970 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:04,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:04,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:04,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,087 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,204 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,204 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,220 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,321 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,442 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,458 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,559 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,559 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,560 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,560 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,575 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,676 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,676 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,677 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,677 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,692 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,793 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,793 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,794 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,794 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,809 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,910 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:05,910 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:05,911 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:05,911 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:05,926 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,029 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,029 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,029 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,146 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,146 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,146 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,147 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,162 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,263 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,263 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,263 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,264 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,282 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,380 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,380 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,380 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,380 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,396 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,497 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,497 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,498 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,498 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,516 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,614 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,614 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,614 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,615 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,632 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,733 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,734 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,734 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,734 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,749 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,853 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,869 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,970 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:06,970 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:06,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:06,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:06,986 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,087 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,103 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,204 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,204 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,220 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,321 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,441 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,457 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,558 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,558 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,558 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,559 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,675 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,807 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,909 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:07,909 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:07,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:07,910 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:07,925 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,026 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,026 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,026 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,026 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,041 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,142 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,143 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,143 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,143 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,163 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,259 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,260 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,260 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,260 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,280 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,377 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,377 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,377 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,377 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,397 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,494 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,494 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,494 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,514 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,610 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,611 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,611 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,611 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,626 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,727 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,728 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,728 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,748 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,844 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,844 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,845 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,860 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,961 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:08,961 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:08,962 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:08,962 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:08,981 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,078 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,078 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,079 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,079 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,094 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,195 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,195 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,196 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,196 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,211 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,312 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,312 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,313 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,313 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,332 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,429 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,429 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,430 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,430 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,445 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,543 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,543 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,544 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,544 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,562 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,660 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,660 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,660 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,661 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,676 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,777 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,777 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,777 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,778 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,793 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,894 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:09,894 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:09,895 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:09,895 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:09,910 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,014 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,014 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,014 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,014 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,029 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,135 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,135 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,135 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,135 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,150 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,253 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,253 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,253 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,254 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,268 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,371 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,371 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,372 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,372 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,387 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,489 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,489 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,490 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,490 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,505 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,607 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,607 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,608 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,608 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,623 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,726 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,726 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,726 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,726 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,742 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,844 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,844 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,844 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,860 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,962 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:10,962 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:10,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:10,963 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:10,978 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,080 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,080 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,081 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,081 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,096 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,198 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,198 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,199 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,199 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,214 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,316 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,317 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,317 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,317 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,333 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,435 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,435 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,436 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,436 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,451 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,553 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,553 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,554 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,554 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,569 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,671 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,671 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,672 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,672 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,687 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,789 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,790 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,790 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,790 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,805 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:11,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:11,908 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:11,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:11,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,026 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,026 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,027 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,027 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,042 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,144 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,144 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,145 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,145 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,160 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,262 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,262 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,263 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,263 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,381 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,381 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,381 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,381 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,396 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,499 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,499 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,499 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,500 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,515 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,617 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,617 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,618 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,618 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,633 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,735 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,735 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,736 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,736 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,751 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,853 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,869 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:12,967 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:12,968 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:12,968 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:12,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:23,484 - INFO - Epoch 2/150 - Train Loss: 0.745479, Val Loss: 0.716564
2025-08-07 10:44:23,511 - INFO - New best model saved with Val Loss: 0.716564
2025-08-07 10:44:31,217 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,217 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,218 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,218 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,335 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,335 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,351 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,468 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,570 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,687 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,803 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:31,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:31,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:31,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:31,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,037 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,037 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,038 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,038 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,154 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,154 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,155 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,155 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,271 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,271 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,271 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,272 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,290 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,388 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,388 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,389 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,389 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,404 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,505 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,505 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,506 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,506 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,524 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,622 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,622 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,623 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,623 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,739 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,739 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,740 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,740 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,856 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,856 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,857 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,857 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,875 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,975 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:32,976 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:32,976 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:32,976 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:32,991 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,093 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,093 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,093 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,209 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,210 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,210 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,228 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,326 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,330 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,330 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,330 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,345 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,446 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,447 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,447 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,563 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,563 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,564 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,564 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,579 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,680 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,680 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,681 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,681 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,699 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,797 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,797 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,798 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,798 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,813 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,915 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:33,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:33,915 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:33,916 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:33,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,032 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,149 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,149 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,150 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,150 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,168 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,282 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,383 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,384 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,384 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,402 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,500 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,501 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,501 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,617 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,617 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,618 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,618 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,633 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,734 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,734 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,735 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,735 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,851 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,851 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,852 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,852 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,867 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,969 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:34,969 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:34,970 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:34,970 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:34,988 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,086 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,086 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,087 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,087 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,102 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,203 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,203 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,204 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,204 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,219 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,320 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,320 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,321 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,321 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,339 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,437 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,437 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,438 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,438 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,456 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,554 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,554 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,555 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,555 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,573 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,671 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,671 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,672 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,672 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,788 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,788 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,789 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,789 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,807 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,905 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:35,905 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:35,905 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:35,906 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:35,923 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,024 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,024 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,025 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,025 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,040 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,141 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,141 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,142 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,142 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,157 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,258 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,258 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,259 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,259 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,375 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,375 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,376 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,376 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,391 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,492 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,492 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,493 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,493 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,512 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,613 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,613 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,614 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,614 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,629 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,732 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,732 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,732 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,732 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,747 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,850 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,850 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,850 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,850 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,866 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,968 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:36,968 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:36,969 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:36,969 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:36,984 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,082 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,082 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,083 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,083 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,102 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,199 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,199 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,200 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,200 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,219 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,320 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,320 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,321 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,321 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,336 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,438 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,439 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,454 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,557 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,557 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,557 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,557 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,572 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,675 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,676 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,676 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,793 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,793 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,794 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,794 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,809 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,911 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:37,911 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:37,912 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:37,912 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:37,927 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,030 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,030 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,030 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,046 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,148 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,148 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,148 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,148 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,164 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,282 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,384 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,384 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,385 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,385 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,400 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,503 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,518 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,621 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,621 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,621 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,637 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,735 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,735 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,736 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,736 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,755 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,852 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,852 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,853 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,853 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,871 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,969 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:38,969 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:38,970 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:38,970 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:38,988 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,086 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,086 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,087 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,087 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,105 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,206 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,206 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,206 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,206 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,221 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,323 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,323 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,323 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,323 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,338 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,440 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,440 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,441 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,441 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,456 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,557 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,557 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,557 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,557 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,573 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,674 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,674 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,674 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,694 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,791 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,791 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,791 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,791 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,811 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,912 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:39,912 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:39,913 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:39,913 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:39,928 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:40,030 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:40,030 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:40,031 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:40,031 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:40,046 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:40,144 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:40,144 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:40,145 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:40,145 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:40,160 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:50,838 - INFO - Epoch 3/150 - Train Loss: 0.688537, Val Loss: 0.648317
2025-08-07 10:44:50,864 - INFO - New best model saved with Val Loss: 0.648317
2025-08-07 10:44:58,765 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:58,765 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:58,766 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:58,766 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:58,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:58,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:58,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:58,883 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:58,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:58,901 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:58,999 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:58,999 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,000 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,000 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,018 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,116 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,135 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,233 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,233 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,234 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,234 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,252 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,350 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,366 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,467 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,587 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,587 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,587 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,588 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,603 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,704 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,704 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,704 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,704 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,722 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,820 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,821 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,821 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,821 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,836 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,937 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:44:59,937 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:44:59,938 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:44:59,938 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:44:59,953 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,054 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,054 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,055 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,055 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,073 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,171 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,171 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,172 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,172 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,187 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,288 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,288 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,289 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,289 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,307 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,405 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,405 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,406 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,406 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,421 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,525 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,525 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,525 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,525 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,540 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,644 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,644 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,645 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,645 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,761 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,761 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,762 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,762 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,878 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,878 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,879 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,879 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,894 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:00,995 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:00,995 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:00,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:00,996 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,112 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,112 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,112 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,128 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,229 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,229 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,229 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,230 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,245 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,346 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,346 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,346 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,346 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,463 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,463 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,463 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,463 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,580 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,580 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,580 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,580 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,696 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,696 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,697 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,697 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,712 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,813 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,813 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,814 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:01,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:01,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:01,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:01,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,048 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,048 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,165 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,165 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,183 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,281 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,281 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,282 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,282 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,399 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,399 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,515 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,516 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,516 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,531 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,632 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,633 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,651 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,749 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,749 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,750 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,768 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,866 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,866 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,867 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,884 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,983 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:02,983 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:02,983 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:02,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:02,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,099 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,100 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,100 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,100 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,118 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,216 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,217 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,217 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,217 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,232 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,333 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,333 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,334 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,352 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,454 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,454 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,469 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,571 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,571 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,687 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,687 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,688 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,706 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,804 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,804 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,819 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:03,921 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:03,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:03,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:03,940 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,037 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,037 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,038 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,038 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,154 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,154 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,155 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,155 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,271 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,271 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,272 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,272 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,290 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,391 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,391 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,392 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,392 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,407 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,508 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,509 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,509 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,524 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,625 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,625 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,625 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,625 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,641 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,741 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,742 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,742 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,742 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,760 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,859 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,859 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,859 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,859 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,976 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:04,976 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:04,976 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:04,976 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:04,996 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,096 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,096 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,097 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,112 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,214 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,215 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,215 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,230 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,332 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,333 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,333 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,333 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,451 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,451 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,451 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,451 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,466 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,570 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,687 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,687 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,688 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,688 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,703 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,806 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,821 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,923 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:05,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:05,924 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:05,924 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:05,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,042 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,042 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,042 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,042 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,058 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,160 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,160 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,161 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,161 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,176 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,279 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,279 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,279 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,279 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,295 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,397 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,397 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,398 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,413 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,515 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,516 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,516 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,531 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,633 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,633 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,634 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,634 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,649 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,751 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,767 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,869 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,869 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,870 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,870 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:06,987 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:06,988 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:06,988 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:06,988 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,003 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,106 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:07,106 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:07,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:07,106 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,122 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,224 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:07,224 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:07,224 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:07,225 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,343 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:07,343 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:07,344 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:07,344 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,461 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:07,461 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:07,462 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:07,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,477 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,579 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:07,579 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:07,580 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:07,580 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:07,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:07,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:07,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:07,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:18,102 - INFO - Epoch 4/150 - Train Loss: 0.592505, Val Loss: 0.522496
2025-08-07 10:45:18,129 - INFO - New best model saved with Val Loss: 0.522496
2025-08-07 10:45:25,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:25,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:25,883 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:25,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:25,902 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:25,999 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:25,999 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,000 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,000 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,018 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,116 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,132 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,233 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,233 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,234 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,234 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,249 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,350 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,367 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,702 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,703 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,819 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,835 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,938 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:26,938 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:26,939 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:26,939 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:26,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,172 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,172 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,173 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,173 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,188 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,289 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,289 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,290 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,290 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,406 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,406 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,407 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,425 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,523 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,523 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,524 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,524 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,539 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,643 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,643 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,760 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,760 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,760 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,761 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,779 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,877 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,877 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,877 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,877 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:27,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:27,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:27,994 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:27,994 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,012 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,111 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,129 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,227 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,228 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,246 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,344 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,344 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,345 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,463 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,463 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,579 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,579 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,580 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,580 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,598 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,696 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,696 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,697 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,697 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,712 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,813 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,813 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,814 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,832 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:28,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:28,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:28,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:28,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,048 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,281 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,281 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,281 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,281 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,398 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,515 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,515 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,515 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,632 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,632 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,748 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,749 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,749 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,749 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,764 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,865 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,865 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,866 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,866 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,881 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,982 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:29,982 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:29,983 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:29,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:29,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,099 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,099 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,100 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,100 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,118 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,216 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,216 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,217 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,217 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,333 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,333 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,334 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,334 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,352 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,450 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,450 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,451 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,451 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,469 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,567 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,567 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,568 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,568 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,583 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,684 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,684 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,685 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,685 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,703 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,801 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,801 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,802 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,802 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,918 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:30,918 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:30,918 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:30,919 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:30,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,035 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,035 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,035 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,035 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,152 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,152 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,152 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,153 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,171 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,269 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,269 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,269 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,269 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,288 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,386 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,386 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,402 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,503 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,503 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,503 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,518 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,620 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,736 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,736 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,752 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,853 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,869 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,970 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:31,970 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:31,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:31,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:31,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,087 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,207 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,207 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,207 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,208 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,324 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,324 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,324 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,441 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,441 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,461 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,557 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,558 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,558 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,558 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,573 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,795 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,796 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,796 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,796 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,811 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,914 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:32,914 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:32,915 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:32,915 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:32,930 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,032 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,048 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,150 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,150 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,151 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,151 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,166 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,269 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,269 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,269 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,269 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,387 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,387 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,387 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,387 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,403 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,505 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,505 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,505 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,506 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,521 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,623 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,623 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,624 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,624 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,639 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,738 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,738 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,739 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,739 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,754 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,856 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,856 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,857 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,857 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,974 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:33,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:33,975 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:33,975 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:33,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,093 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,093 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,093 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,109 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,211 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,211 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,212 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,226 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,329 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,329 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,330 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,330 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,345 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,463 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,581 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,683 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,683 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,684 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,685 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,700 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,798 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:34,798 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:34,798 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:34,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:34,814 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:45,371 - INFO - Epoch 5/150 - Train Loss: 0.485806, Val Loss: 0.468122
2025-08-07 10:45:45,399 - INFO - New best model saved with Val Loss: 0.468122
2025-08-07 10:45:53,168 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,168 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,169 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,169 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,186 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,286 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,403 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,403 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,520 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,538 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,754 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,754 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,870 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,871 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,871 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,889 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:53,988 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:53,988 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:53,988 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:53,988 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,006 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,107 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,107 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,108 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,108 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,123 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,224 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,224 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,225 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,225 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,341 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,341 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,342 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,342 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,458 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,458 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,459 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,459 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,477 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,572 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,572 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,573 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,573 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,689 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,689 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,690 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,690 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,806 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,806 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,807 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,807 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:54,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:54,925 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:54,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:54,940 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,044 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,044 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,045 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,045 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,060 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,161 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,161 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,162 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,162 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,180 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,278 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,278 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,279 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,279 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,297 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,531 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,648 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,762 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,863 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,864 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,882 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:55,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:55,981 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:55,981 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:55,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,097 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,097 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,101 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,101 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,217 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,217 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,217 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,218 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,233 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,334 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,334 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,334 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,334 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,451 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,451 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,452 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,452 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,468 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,568 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,568 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,569 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,584 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,686 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,686 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,803 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,819 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:56,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:56,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:56,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:56,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,040 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,055 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,177 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,275 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,275 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,391 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,391 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,391 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,392 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,407 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,508 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,508 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,508 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,624 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,625 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,625 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,625 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,640 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,741 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,741 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,742 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,742 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,757 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,858 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,858 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,859 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,859 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,975 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:57,975 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:57,976 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:57,976 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:57,991 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,092 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,092 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,093 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,113 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,229 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,332 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,332 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,332 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,332 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,450 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,450 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,451 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,451 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,466 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,568 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,568 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,569 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,584 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,684 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,684 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,685 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,685 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,700 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,802 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,802 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,803 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,803 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,818 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,921 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:58,921 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:58,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:58,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:58,937 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,039 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,040 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,055 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,157 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,157 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,158 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,158 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,173 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,291 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,394 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,394 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,395 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,410 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,626 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,626 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,627 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,627 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,649 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,743 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,743 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,744 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,744 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,860 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,860 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,860 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,861 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,876 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,977 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:45:59,977 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:45:59,977 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:45:59,978 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:45:59,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,094 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,094 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,094 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,095 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,114 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,211 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,211 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,227 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,327 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,328 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,328 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,328 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,343 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,444 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,444 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,445 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,445 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,460 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,566 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,581 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,684 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,684 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,684 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,684 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,700 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,802 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,802 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,803 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,803 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,818 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:00,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:00,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:00,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:00,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,038 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,038 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,157 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,291 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,527 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,630 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,630 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,646 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,748 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,748 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,749 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,749 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,764 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,866 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,867 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,867 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,882 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:01,984 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:01,984 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:01,985 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:01,985 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:02,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:02,098 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:02,098 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:02,099 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:02,099 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:02,114 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:12,323 - INFO - Epoch 6/150 - Train Loss: 0.458963, Val Loss: 0.452188
2025-08-07 10:46:12,350 - INFO - New best model saved with Val Loss: 0.452188
2025-08-07 10:46:20,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,286 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,287 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,304 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,407 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,407 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,407 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,423 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,524 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,524 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,524 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,524 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,542 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,641 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,758 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,758 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,758 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,759 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,875 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,891 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:20,992 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:20,992 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:20,993 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:20,993 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,008 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,109 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,109 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,110 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,110 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,128 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,226 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,226 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,227 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,227 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,242 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,343 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,343 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,344 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,344 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,362 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,460 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,460 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,461 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,461 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,476 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,577 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,577 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,577 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,593 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,811 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,811 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,811 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,827 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,927 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:21,927 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:21,928 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:21,928 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:21,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,044 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,044 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,045 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,045 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,161 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,161 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,162 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,162 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,177 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,281 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,281 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,282 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,282 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,297 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,399 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,515 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,515 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,515 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,531 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,632 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,632 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,651 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,752 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,767 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,884 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:22,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:22,985 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:22,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:22,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,001 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,102 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,102 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,336 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,336 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,352 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,454 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,454 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,469 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,571 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,571 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,588 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,687 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,687 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,688 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,703 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,804 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,804 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,805 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,805 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,823 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,921 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:23,921 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:23,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:23,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:23,937 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,038 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,038 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,155 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,155 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,155 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,156 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,171 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,272 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,272 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,272 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,272 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,291 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,389 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,389 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,389 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,389 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,407 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,505 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,506 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,506 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,506 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,522 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,623 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,623 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,623 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,623 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,641 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,739 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,740 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,740 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,740 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,859 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,859 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,860 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,860 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,875 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,976 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:24,976 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:24,977 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:24,977 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:24,996 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,093 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,093 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,093 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,109 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,210 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,210 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,225 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,326 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,326 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,327 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,327 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,347 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,443 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,443 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,444 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,444 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,463 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,560 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,560 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,561 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,561 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,677 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,677 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,678 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,678 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,693 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,794 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,794 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,795 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,795 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,810 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,911 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:25,911 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:25,912 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:25,912 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:25,931 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,028 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,028 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,028 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,029 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,048 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,145 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,145 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,145 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,145 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,261 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,261 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,262 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,262 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,278 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,378 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,378 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,379 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,379 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,394 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,495 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,495 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,496 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,496 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,514 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,612 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,612 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,613 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,613 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,628 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,729 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,729 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,730 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,730 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,745 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,846 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,846 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,847 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,847 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,866 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,963 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:26,963 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:26,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:26,964 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:26,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,080 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,080 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,080 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,096 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,196 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,197 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,197 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,197 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,212 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,314 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,314 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,314 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,314 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,334 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,430 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,430 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,431 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,431 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,547 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,547 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,548 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,566 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,664 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,664 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,680 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,781 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,781 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,782 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,782 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,797 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:27,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:27,898 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:27,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:27,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,014 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,015 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,015 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,030 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,136 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,136 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,136 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,137 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,152 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,254 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,254 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,255 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,255 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,270 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,372 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,372 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,373 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,373 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,388 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,490 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,490 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,491 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,491 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,506 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,608 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,608 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,609 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,609 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,624 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,726 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,726 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,727 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,727 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,742 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,845 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,845 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,845 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,860 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,963 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:28,963 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:28,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:28,964 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:28,979 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:29,081 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:29,081 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:29,082 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:29,082 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:29,097 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:29,195 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:29,195 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:29,196 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:29,196 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:29,211 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:39,658 - INFO - Epoch 7/150 - Train Loss: 0.438410, Val Loss: 0.424061
2025-08-07 10:46:39,684 - INFO - New best model saved with Val Loss: 0.424061
2025-08-07 10:46:47,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:47,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:47,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:47,503 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,620 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:47,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:47,621 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:47,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,639 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:47,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:47,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:47,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:47,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:47,855 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:47,855 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,870 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:47,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:47,972 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:47,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:47,987 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,089 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,089 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,089 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,090 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,105 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,206 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,206 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,206 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,206 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,222 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,324 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,325 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,325 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,343 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,442 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,460 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,558 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,558 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,559 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,559 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,675 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,676 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,676 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,793 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,811 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,909 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:48,909 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:48,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:48,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:48,927 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,028 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,028 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,029 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,029 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,044 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,145 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,145 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,146 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,146 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,161 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,262 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,262 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,263 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,263 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,281 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,382 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,382 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,499 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,499 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,499 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,499 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,515 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,616 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,616 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,617 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,617 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,730 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,730 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,731 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,731 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,749 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,847 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,847 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,848 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,848 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,866 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,964 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:49,964 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:49,965 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:49,965 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:49,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,081 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,081 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,082 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,082 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,100 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,201 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,201 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,201 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,201 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,217 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,318 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,319 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,338 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,435 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,435 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,435 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,435 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,455 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,552 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,552 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,552 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,552 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,570 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,669 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,669 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,669 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,669 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,684 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,785 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,785 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,786 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,786 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,805 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,902 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:50,902 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:50,903 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:50,903 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:50,923 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,019 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,019 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,020 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,020 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,136 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,136 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,137 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,137 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,152 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,253 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,253 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,254 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,254 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,273 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,370 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,370 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,371 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,371 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,390 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,487 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,487 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,488 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,488 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,503 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,604 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,604 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,605 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,605 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,620 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,721 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,721 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,722 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,722 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,741 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,838 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,838 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,839 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,839 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,858 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,955 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:51,955 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:51,956 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:51,956 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:51,971 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,072 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,072 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,073 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,092 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,193 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,193 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,194 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,194 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,209 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,311 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,311 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,312 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,312 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,327 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,429 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,429 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,430 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,430 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,445 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,547 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,548 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,563 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,666 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,666 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,666 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,666 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,682 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,784 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,784 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,785 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,785 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,800 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:52,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:52,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:52,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:52,918 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,019 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,019 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,020 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,020 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,137 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,137 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,138 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,138 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,153 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,255 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,255 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,256 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,256 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,271 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,374 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,374 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,374 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,374 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,390 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,492 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,492 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,492 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,492 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,508 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,610 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,610 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,610 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,611 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,626 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,728 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,729 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,729 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,744 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,846 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,846 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,847 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,847 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,862 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,964 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:53,965 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:53,965 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:53,965 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:53,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,083 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,083 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,083 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,083 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,099 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,201 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,201 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,201 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,202 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,217 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,319 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,319 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,320 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,320 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,335 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,437 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,437 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,438 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,438 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,453 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,556 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,556 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,556 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,556 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,572 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,674 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,674 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,674 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,793 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,793 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,910 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:54,910 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:54,911 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:54,911 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:54,926 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,029 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,029 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,029 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,147 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,147 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,148 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,148 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,163 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,265 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,265 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,266 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,266 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,281 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,383 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,384 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,384 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,399 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,501 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,501 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,502 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,502 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,517 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,620 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,855 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,856 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,856 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,856 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,974 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:55,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:55,974 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:55,974 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:55,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,092 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:56,092 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:56,092 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:56,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:56,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:56,210 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:56,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,226 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,328 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:56,328 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:56,329 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:56,329 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,344 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,442 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:46:56,442 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:46:56,443 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:46:56,443 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:46:56,458 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:07,015 - INFO - Epoch 8/150 - Train Loss: 0.427005, Val Loss: 0.426281
2025-08-07 10:47:14,654 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:14,654 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:14,655 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:14,655 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:14,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:14,774 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:14,774 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:14,775 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:14,775 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:14,790 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:14,891 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:14,891 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:14,892 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:14,892 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:14,910 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,008 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,008 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,009 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,009 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,024 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,125 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,125 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,126 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,126 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,144 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,242 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,242 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,243 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,243 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,258 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,359 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,359 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,360 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,360 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,375 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,476 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,476 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,477 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,477 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,495 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,594 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,594 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,594 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,594 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,610 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,710 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,711 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,711 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,711 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,729 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,827 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,828 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,828 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,828 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,846 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:15,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:15,945 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:15,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:15,963 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,061 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,061 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,062 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,062 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,080 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,178 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,179 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,179 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,194 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,295 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,295 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,296 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,296 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,311 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,413 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,413 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,413 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,413 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,429 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,529 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,530 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,530 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,530 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,545 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,647 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,662 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,763 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,763 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,764 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,764 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,881 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:16,997 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:16,997 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:16,998 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:16,998 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,115 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,115 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,133 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,367 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,467 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,483 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,584 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,584 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,602 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,701 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,702 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,818 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,935 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:17,935 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:17,936 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:17,936 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:17,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,055 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,055 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,070 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,176 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,176 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,176 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,192 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,291 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,291 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,292 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,292 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,307 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,409 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,410 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,410 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,425 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,528 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,528 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,528 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,529 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,544 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,647 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,662 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,764 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,764 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,765 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,765 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,780 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:18,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:18,883 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:18,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:18,898 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,000 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,000 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,001 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,001 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,016 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,118 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,119 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,119 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,119 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,134 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,237 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,237 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,237 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,237 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,253 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,355 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,355 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,355 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,356 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,371 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,473 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,473 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,474 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,474 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,489 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,592 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,592 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,592 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,592 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,607 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,710 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,710 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,710 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,710 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,726 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,828 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,828 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,828 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,829 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,844 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,946 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:19,946 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:19,947 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:19,947 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:19,962 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,064 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,064 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,065 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,065 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,080 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,182 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,182 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,183 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,183 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,198 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,301 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,301 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,302 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,302 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,317 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,419 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,419 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,420 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,420 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,435 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,537 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,538 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,538 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,538 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,553 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,656 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,656 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,672 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,774 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,774 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,774 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,775 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,790 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,892 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:20,892 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:20,892 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:20,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:20,908 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,010 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,010 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,011 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,128 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,128 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,129 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,129 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,144 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,246 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,246 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,247 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,247 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,262 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,365 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,365 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,365 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,365 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,381 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,483 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,483 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,483 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,483 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,499 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,601 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,601 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,601 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,602 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,617 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,719 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,719 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,720 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,720 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,735 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,837 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,837 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,838 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,838 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,853 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,955 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:21,955 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:21,956 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:21,956 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:21,971 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,074 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,074 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,074 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,075 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,090 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,192 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,192 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,193 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,193 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,208 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,310 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,310 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,311 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,311 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,326 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,428 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,428 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,429 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,429 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,444 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,547 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,547 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,547 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,547 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,562 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,665 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,665 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,666 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,666 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,681 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,783 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,783 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,784 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,784 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,799 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,901 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:22,902 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:22,902 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:22,902 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:22,917 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,019 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:23,020 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:23,020 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:23,020 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,138 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:23,138 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:23,138 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:23,139 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,153 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,256 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:23,256 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:23,257 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:23,257 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,272 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,374 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:23,374 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:23,375 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:23,375 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,390 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,488 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:23,488 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:23,489 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:23,489 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,508 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,602 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:23,602 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:23,603 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:23,603 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:23,618 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:34,136 - INFO - Epoch 9/150 - Train Loss: 0.418697, Val Loss: 0.408864
2025-08-07 10:47:34,187 - INFO - New best model saved with Val Loss: 0.408864
2025-08-07 10:47:42,105 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,105 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,106 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,122 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,223 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,223 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,242 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,340 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,457 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,475 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,574 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:42,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:42,925 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:42,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:42,943 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,044 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,044 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,060 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,161 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,161 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,161 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,161 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,278 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,278 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,279 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,279 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,411 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,629 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,745 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,746 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,746 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,761 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,862 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,862 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,863 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,863 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,878 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,979 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:43,979 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:43,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:43,980 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:43,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,096 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,096 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,097 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,115 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,232 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,330 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,330 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,331 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,346 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,466 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,564 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,564 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,681 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,681 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,700 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,798 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,798 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,915 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:44,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:44,916 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:44,916 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:44,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,032 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,152 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,152 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,152 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,152 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,167 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,269 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,269 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,269 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,269 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,288 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,385 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,386 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,401 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,503 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,521 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,620 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,736 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,736 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,752 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,853 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,869 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,970 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:45,970 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:45,970 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:45,970 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:45,988 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,087 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,087 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,087 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,105 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,203 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,204 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,204 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,204 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,222 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,320 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,320 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,321 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,321 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,339 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,437 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,438 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,438 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,438 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,456 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,557 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,557 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,558 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,558 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,573 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,674 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,791 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,791 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,791 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,807 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:46,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:46,908 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:46,908 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:46,928 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,029 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,029 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,030 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,147 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,147 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,148 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,148 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,163 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,265 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,265 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,266 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,266 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,281 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,383 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,384 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,384 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,399 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,501 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,502 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,502 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,517 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,615 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,616 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,616 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,616 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,636 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,733 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,733 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,733 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,733 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,869 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:47,968 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:47,968 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:47,968 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:47,988 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,084 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,085 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,085 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,085 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,104 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,201 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,201 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,202 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,202 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,217 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,319 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,319 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,338 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,435 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,435 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,436 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,436 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,451 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,552 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,552 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,553 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,553 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,572 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,669 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,669 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,669 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,670 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,685 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,786 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,786 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,786 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,786 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,903 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:48,903 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:48,903 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:48,903 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:48,923 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,024 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,024 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,024 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,024 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,040 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,142 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,142 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,143 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,143 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,158 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,260 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,260 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,261 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,261 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,276 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,379 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,379 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,379 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,379 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,395 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,497 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,497 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,498 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,498 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,513 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,615 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,615 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,616 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,616 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,631 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,733 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,733 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,734 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,734 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,749 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,851 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,852 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,852 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,852 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,867 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,970 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:49,970 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:49,970 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:49,970 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:49,986 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,088 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,089 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,089 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,104 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,206 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,206 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,207 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,207 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,222 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,324 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,325 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,325 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,442 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,443 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,443 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,443 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,458 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,561 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,561 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,561 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,561 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,576 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,679 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,679 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,679 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,680 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,695 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,797 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,797 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,798 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,798 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,813 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,915 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:50,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:50,916 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:50,916 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:50,931 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:51,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:47:51,029 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:47:51,030 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:47:51,030 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:47:51,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:01,458 - INFO - Epoch 10/150 - Train Loss: 0.407012, Val Loss: 0.403224
2025-08-07 10:48:01,485 - INFO - New best model saved with Val Loss: 0.403224
2025-08-07 10:48:09,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:09,805 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:09,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:09,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:09,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:09,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:09,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:09,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:09,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:09,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,040 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,040 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,159 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,159 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,160 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,160 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,175 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,295 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,396 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,396 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,412 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,516 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,516 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,517 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,517 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,633 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,633 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,634 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,634 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,649 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,750 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,750 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,750 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,751 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,768 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,867 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,867 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,867 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,867 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,984 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:10,984 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:10,984 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:10,984 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:10,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,100 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,101 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,101 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,220 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,220 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,221 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,221 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,236 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,337 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,337 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,338 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,338 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,356 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,454 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,454 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,455 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,455 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,473 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,571 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,571 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,572 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,572 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,688 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,688 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,689 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,689 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,704 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,805 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,821 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:11,922 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:11,922 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:11,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:11,938 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,039 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,055 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,174 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,411 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,632 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,633 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,633 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,648 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,749 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,749 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,749 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,769 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,866 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,866 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,866 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,884 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:12,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:12,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:12,981 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:12,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,097 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,097 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,098 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,214 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,215 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,230 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,331 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,331 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,448 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,448 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,467 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,581 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,698 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,814 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,915 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:13,916 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:13,916 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:13,916 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:13,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,152 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,152 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,153 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,153 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,168 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,269 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,269 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,270 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,270 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,293 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,386 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,387 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,387 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,406 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,503 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,503 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,504 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,504 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,620 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,621 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,636 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,757 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,874 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:14,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:14,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:14,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:14,987 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,088 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,209 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,209 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,209 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,209 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,225 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,327 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,327 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,328 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,328 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,343 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,445 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,445 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,446 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,446 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,461 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,563 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,563 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,564 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,564 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,579 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,697 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,800 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,800 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,800 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,801 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,816 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,918 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:15,918 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:15,919 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:15,919 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:15,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,036 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,036 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,037 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,037 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,052 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,154 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,155 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,155 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,155 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,273 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,273 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,273 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,273 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,289 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,391 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,391 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,392 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,392 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,407 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,509 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,509 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,510 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,510 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,525 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,627 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,627 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,628 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,628 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,643 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,746 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,746 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,761 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,864 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,864 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,880 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,982 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:16,982 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:16,983 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:16,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:16,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,100 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,100 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,101 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,101 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,337 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,337 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,338 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,338 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,353 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,455 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,455 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,691 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,691 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,692 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,692 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,707 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,810 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,810 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,825 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,928 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:17,928 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:17,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:17,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:17,944 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,046 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,046 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,062 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,165 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,165 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,180 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,282 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,283 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,283 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,401 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,401 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,401 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,401 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,417 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,519 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,519 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,520 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,520 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,535 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:18,751 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:18,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:18,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:18,767 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:29,433 - INFO - Epoch 11/150 - Train Loss: 0.401429, Val Loss: 0.403475
2025-08-07 10:48:37,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,117 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,137 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,234 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,234 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,235 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,235 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,253 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,351 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,351 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,352 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,352 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,370 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,469 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,469 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,586 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,586 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,703 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,703 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,819 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,820 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,837 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,936 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:37,936 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:37,936 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:37,937 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:37,952 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,056 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,172 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,173 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,173 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,173 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,191 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,289 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,289 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,290 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,290 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,306 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,409 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,409 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,410 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,425 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,527 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,542 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,646 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,662 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,763 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,763 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,763 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,763 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,779 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,879 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,880 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,880 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,898 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:38,996 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:38,996 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:38,997 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:38,997 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,015 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,111 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,129 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,227 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,227 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,228 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,243 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,344 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,344 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,345 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,463 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,463 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,579 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,579 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,580 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,580 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,598 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,696 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,696 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,697 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,697 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,712 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,813 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,813 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:39,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:39,930 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:39,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:39,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,281 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,281 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,281 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,281 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,299 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,397 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,398 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,515 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,515 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,515 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,533 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,636 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,636 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,652 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,756 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,756 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,757 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,757 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,874 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:40,992 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:40,992 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:40,993 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:40,993 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,008 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,111 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,229 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,229 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,230 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,230 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,245 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,347 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,347 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,348 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,465 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,466 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,584 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,584 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,600 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,703 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,703 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,820 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,820 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,821 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,821 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,836 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,939 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:41,939 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:41,939 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:41,939 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:41,955 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,057 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,057 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,058 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,058 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,073 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,175 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,175 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,176 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,176 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,191 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,293 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,293 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,294 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,294 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,411 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,411 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,412 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,412 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,427 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,530 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,530 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,530 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,530 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,546 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,648 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,648 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,649 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,649 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,664 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,766 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,766 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,767 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,767 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,884 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:42,885 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:42,885 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:42,885 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:42,900 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,003 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,003 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,004 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,004 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,019 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,121 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,121 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,122 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,122 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,137 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,239 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,239 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,240 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,240 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,255 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,358 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,358 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,358 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,374 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,476 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,476 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,476 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,477 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,491 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,594 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,594 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,595 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,595 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,610 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,712 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,712 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,713 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,713 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,728 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,830 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,831 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,831 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,831 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,846 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,949 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:43,949 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:43,950 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:43,950 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:43,965 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,067 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,067 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,068 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,068 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,083 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,185 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,185 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,186 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,186 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,201 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,303 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,303 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,304 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,304 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,319 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,421 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,422 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,422 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,422 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,437 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,540 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,540 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,541 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,541 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,556 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,658 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,658 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,659 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,659 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,776 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,777 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,777 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,777 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,792 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,895 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:44,895 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:44,895 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:44,896 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:44,911 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,013 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,013 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,014 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,014 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,029 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,131 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,131 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,132 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,132 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,147 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,249 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,249 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,250 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,250 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,265 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,367 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,368 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,368 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,368 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,383 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,486 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,486 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,486 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,486 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,502 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,604 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,604 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,605 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,605 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,620 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,722 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,722 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,723 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,723 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,738 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,840 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,840 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,841 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,841 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,856 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,958 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:45,958 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:45,959 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:45,959 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:45,974 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:46,072 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:48:46,072 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:48:46,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:48:46,073 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:46,088 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:48:56,843 - INFO - Epoch 12/150 - Train Loss: 0.393588, Val Loss: 0.399000
2025-08-07 10:48:56,870 - INFO - New best model saved with Val Loss: 0.399000
2025-08-07 10:49:04,664 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:04,664 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:04,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:04,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:04,684 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:04,781 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:04,782 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:04,782 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:04,782 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:04,798 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:04,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:04,899 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:04,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:04,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:04,915 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,034 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,132 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,132 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,133 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,133 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,151 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,250 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,250 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,250 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,251 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,266 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,369 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,369 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,370 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,370 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,385 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,489 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,489 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,490 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,490 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,505 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,606 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,606 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,607 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,607 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,625 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,723 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,723 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,724 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,724 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,742 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,843 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,843 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,844 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,844 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,859 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,960 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:05,960 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:05,960 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:05,961 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:05,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,081 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,082 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,082 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,082 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,097 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,200 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,200 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,200 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,200 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,216 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,319 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,319 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,334 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,436 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,436 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,437 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,437 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,452 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,554 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,555 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,555 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,555 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,570 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,673 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,673 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,674 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,689 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,791 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,791 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,807 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,909 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:06,909 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:06,910 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:06,910 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:06,925 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,027 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,027 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,028 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,028 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,043 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,146 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,146 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,146 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,147 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,162 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,264 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,264 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,265 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,265 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,280 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,382 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,500 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,501 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,501 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,501 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,516 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,619 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,619 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,634 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,855 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,855 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,856 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,856 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,871 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,973 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:07,973 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:07,974 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:07,974 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:07,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,092 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,092 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,092 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,092 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,226 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,328 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,328 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,329 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,329 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,344 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,446 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,447 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,447 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,462 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,581 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,683 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,683 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,684 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,684 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,699 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,801 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,801 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,802 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,802 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:08,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:08,920 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:08,920 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:08,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,038 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,038 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,038 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,275 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,275 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,291 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,527 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,645 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,747 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,748 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,748 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,748 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,866 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,866 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,866 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,882 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:09,984 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:09,984 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:09,985 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:09,985 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,102 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,118 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,221 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,221 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,339 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,339 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,457 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,457 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,458 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,458 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,473 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,575 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,575 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,576 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,811 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,811 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,812 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,812 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,929 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:10,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:10,930 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:10,930 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:10,945 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,048 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,048 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,048 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,049 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,064 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,167 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,284 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,285 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,285 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,403 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,403 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,403 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,521 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,521 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,522 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,537 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,639 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,639 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,640 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,640 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,655 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,757 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,757 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,758 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,758 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,773 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,875 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,876 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,876 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,891 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:11,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:11,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:11,994 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:11,994 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,010 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,112 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,112 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,113 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,113 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,128 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,230 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,230 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,231 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,231 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,246 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,365 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,466 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,467 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,467 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,482 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,703 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,703 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,704 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,704 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,719 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,821 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,821 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,822 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,822 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,837 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,939 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:12,940 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:12,940 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:12,940 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:12,955 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,058 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:13,058 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:13,058 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:13,058 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,176 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:13,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:13,177 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:13,177 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,192 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,294 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:13,294 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:13,295 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:13,295 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,310 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:13,412 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:13,413 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:13,413 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,428 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,530 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:13,531 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:13,531 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:13,531 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,546 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,644 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:13,645 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:13,645 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:13,645 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:13,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:24,233 - INFO - Epoch 13/150 - Train Loss: 0.391261, Val Loss: 0.390037
2025-08-07 10:49:24,259 - INFO - New best model saved with Val Loss: 0.390037
2025-08-07 10:49:32,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,218 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,218 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,570 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,588 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,687 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,806 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,806 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,807 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,807 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,923 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:32,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:32,924 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:32,924 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:32,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,040 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,041 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,041 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,059 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,157 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,157 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,158 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,158 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,176 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,274 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,275 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,293 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,412 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,510 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,510 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,511 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,511 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,526 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,630 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,645 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,748 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,748 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,748 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,749 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,764 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,865 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,865 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,865 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,866 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,881 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:33,982 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:33,982 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:33,982 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:33,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,099 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,099 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,099 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,099 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,118 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,216 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,216 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,216 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,216 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,332 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,333 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,333 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,333 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,449 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,449 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,450 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,450 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,566 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,566 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,567 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,567 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,687 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,702 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,803 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,923 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:34,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:34,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:34,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:34,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,044 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,045 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,045 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,045 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,061 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,163 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,282 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,282 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,282 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,283 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,401 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,401 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,518 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,518 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,519 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,519 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,534 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,636 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,652 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,755 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,755 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,771 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,873 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,873 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,874 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,874 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,889 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:35,991 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:35,991 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:35,992 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:35,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,105 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,105 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,106 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,224 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,224 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,224 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,224 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,343 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,460 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,460 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,461 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,461 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,476 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,578 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,579 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,579 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,579 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,594 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,697 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,697 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,698 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,698 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,713 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,815 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,815 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,816 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,831 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:36,934 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:36,934 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:36,934 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:36,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,052 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,052 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,052 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,053 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,068 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,170 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,170 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,171 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,171 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,186 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,288 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,288 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,289 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,289 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,304 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,406 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,407 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,407 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,422 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,525 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,525 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,526 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,526 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,541 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,643 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,761 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,762 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,762 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,762 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,880 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,880 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,896 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:37,998 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:37,998 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:37,998 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:37,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,116 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,132 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,234 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,234 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,235 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,235 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,352 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,352 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,353 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,353 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,369 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,470 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,471 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,471 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,589 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,589 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,590 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,590 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,605 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,707 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,707 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,708 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,723 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,825 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,825 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,826 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,826 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,841 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:38,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:38,944 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:38,944 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:38,960 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,062 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,062 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,063 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,063 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,180 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,180 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,196 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,296 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,296 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,297 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,297 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,312 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,414 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,414 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,415 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,415 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,533 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,533 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,533 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,534 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,549 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,651 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,651 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,652 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,652 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,667 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,769 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,769 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,770 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,770 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,785 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,887 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:39,887 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:39,888 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:39,888 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:39,904 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,006 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,006 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,006 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,006 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,021 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,124 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,124 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,125 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,244 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,260 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,360 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,360 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,361 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,361 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,381 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,478 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,478 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,478 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,479 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,494 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,595 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,595 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,596 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,596 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,614 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,712 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,712 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,713 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,713 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,732 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,829 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,829 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,830 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,830 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,845 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,946 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:40,946 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:40,947 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:40,947 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:40,965 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:41,060 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:41,060 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:41,061 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:41,061 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:41,076 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:51,729 - INFO - Epoch 14/150 - Train Loss: 0.395312, Val Loss: 0.379477
2025-08-07 10:49:51,756 - INFO - New best model saved with Val Loss: 0.379477
2025-08-07 10:49:59,491 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:59,491 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:59,491 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:59,492 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,511 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,608 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:59,608 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:59,609 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:59,609 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,627 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,728 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:59,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:59,729 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:59,729 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,744 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,845 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:59,845 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:59,846 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:59,846 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,861 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,962 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:49:59,962 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:49:59,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:49:59,963 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:49:59,981 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,079 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,079 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,080 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,095 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,196 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,196 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,197 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,197 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,212 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,313 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,313 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,314 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,314 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,332 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,432 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,432 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,447 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,548 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,549 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,549 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,564 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,665 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,665 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,666 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,666 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,681 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,782 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,782 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,783 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,783 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,798 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,899 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:00,899 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:00,900 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:00,900 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:00,918 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,016 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,016 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,017 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,017 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,130 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,130 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,131 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,131 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,149 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,247 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,247 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,248 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,248 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,266 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,362 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,362 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,363 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,363 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,381 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,479 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,479 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,480 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,480 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,495 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,596 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,596 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,596 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,597 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,614 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,713 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,713 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,713 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,714 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,731 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,830 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,830 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,830 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,830 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,848 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,949 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:01,949 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:01,950 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:01,950 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:01,965 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,067 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,067 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,068 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,068 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,083 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,184 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,184 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,185 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,185 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,200 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,301 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,301 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,302 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,302 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,320 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,418 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,418 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,419 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,419 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,434 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,535 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,535 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,535 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,536 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,551 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,652 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,652 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,652 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,653 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,769 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,769 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,769 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,769 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,785 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,886 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:02,886 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:02,886 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:02,886 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:02,905 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,003 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,003 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,004 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,004 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,022 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,120 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,120 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,121 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,121 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,139 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,240 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,240 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,240 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,240 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,256 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,357 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,357 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,357 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,375 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,473 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,473 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,474 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,474 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,489 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,590 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,590 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,591 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,591 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,606 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,707 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,707 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,708 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,723 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,827 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,827 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,828 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,828 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,843 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:03,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:03,945 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:03,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:03,963 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,061 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,061 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,062 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,062 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,077 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,178 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,178 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,179 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,194 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,295 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,295 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,295 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,296 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,412 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,412 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,412 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,427 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,528 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,529 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,529 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,529 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,545 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,645 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,645 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,646 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,646 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,661 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,762 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,762 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,763 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,763 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,781 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,883 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:04,884 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:04,884 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:04,884 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:04,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,005 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,005 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,005 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,006 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,021 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,123 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,123 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,124 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,124 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,139 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,237 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,237 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,238 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,238 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,257 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,354 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,354 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,355 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,355 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,375 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,491 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,588 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,588 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,589 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,604 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,708 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,708 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,709 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,709 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,728 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,825 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,825 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,825 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,826 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,845 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,942 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:05,942 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:05,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:05,942 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:05,962 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,059 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,059 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,175 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,176 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,176 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,192 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,292 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,292 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,293 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,293 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,409 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,409 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,410 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,425 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,527 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,546 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,643 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,663 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,760 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,760 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,761 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,761 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,780 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,874 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:06,991 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:06,991 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:06,992 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:06,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,108 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,108 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,109 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,124 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,225 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,225 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,226 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,226 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,343 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,461 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,461 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,461 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,477 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,578 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,578 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,578 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,578 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,596 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,695 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,713 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,812 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,812 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,812 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,812 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,830 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,928 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:07,929 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:07,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:07,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:07,947 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,045 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:08,045 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:08,046 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:08,046 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,061 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,162 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:08,162 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:08,163 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:08,163 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,181 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,279 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:08,279 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:08,280 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:08,280 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:08,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:08,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:08,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:08,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:19,057 - INFO - Epoch 15/150 - Train Loss: 0.382580, Val Loss: 0.376339
2025-08-07 10:50:19,083 - INFO - New best model saved with Val Loss: 0.376339
2025-08-07 10:50:27,006 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,010 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,011 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,030 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,128 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,128 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,128 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,128 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,147 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,245 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,245 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,246 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,246 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,265 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,365 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,365 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,366 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,366 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,381 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,482 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,483 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,483 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,483 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,499 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,600 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,600 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,600 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,601 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,619 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,717 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,717 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,718 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,718 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,736 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,837 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,837 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,837 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,838 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,853 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,954 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:27,954 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:27,954 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:27,955 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:27,970 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,071 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,071 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,071 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,072 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,090 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,188 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,188 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,188 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,188 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,204 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,305 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,305 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,305 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,305 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,320 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,422 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,422 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,422 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,422 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,440 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,538 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,539 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,539 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,539 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,557 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,655 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,655 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,775 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,775 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,776 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,776 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,791 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,892 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:28,892 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:28,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:28,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:28,911 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,009 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,009 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,009 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,010 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,025 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,126 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,126 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,127 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,127 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,143 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,244 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,259 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,360 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,360 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,361 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,361 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,376 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,477 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,477 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,478 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,478 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,493 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,594 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,594 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,595 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,595 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,613 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,711 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,711 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,712 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,712 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,727 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,828 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,828 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,829 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,829 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,847 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,945 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:29,945 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:29,946 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:29,946 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:29,964 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,062 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,062 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,062 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,063 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,179 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,179 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,179 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,179 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,197 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,296 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,296 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,296 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,296 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,314 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,413 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,413 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,413 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,529 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,530 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,530 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,530 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,548 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,647 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,665 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,763 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,763 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,764 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,764 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,881 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,896 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:30,997 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:30,997 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:30,998 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:30,998 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,115 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,115 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,133 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,367 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,484 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,582 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,582 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,600 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,700 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,700 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,816 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,816 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,817 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,832 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:31,933 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:31,933 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:31,933 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:31,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,050 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,050 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,050 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,066 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,167 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,401 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,401 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,517 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,517 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,518 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,518 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,533 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,634 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,635 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,751 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,767 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,869 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,869 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:32,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:32,986 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:32,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:32,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,003 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,103 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,224 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,224 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,225 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,225 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,245 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,343 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,361 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,459 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,459 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,460 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,460 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,577 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,710 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,811 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,811 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,812 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,812 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,830 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,928 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:33,928 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:33,928 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:33,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:33,947 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,045 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,045 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,045 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,045 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,161 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,162 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,162 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,162 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,180 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,279 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,279 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,280 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,280 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,396 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,396 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,397 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,412 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,513 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,513 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,529 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,630 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,646 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,747 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,747 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,765 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,864 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,882 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,981 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:34,981 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:34,981 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:34,981 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:34,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,097 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,098 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,098 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,098 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,214 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,215 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,215 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,233 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,331 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,332 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,332 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,448 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,448 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,449 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,449 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,467 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,581 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,683 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,683 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,701 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,800 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,913 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:35,913 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:35,913 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:35,914 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:35,929 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:46,707 - INFO - Epoch 16/150 - Train Loss: 0.378712, Val Loss: 0.384692
2025-08-07 10:50:54,557 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:54,557 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:54,558 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:54,558 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,577 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,675 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:54,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:54,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:54,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:54,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:54,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:54,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,909 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:54,909 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:54,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:54,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:54,925 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,025 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,026 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,026 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,026 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,044 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,145 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,145 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,145 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,146 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,161 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,262 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,262 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,262 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,262 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,278 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,379 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,379 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,379 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,379 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,397 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,496 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,496 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,496 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,496 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,515 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,613 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,613 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,613 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,614 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,629 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,730 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,730 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,731 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,731 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,746 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,847 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,847 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,847 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,848 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,865 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,964 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:55,964 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:55,964 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:55,965 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:55,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,081 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,081 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,081 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,081 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,097 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,197 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,198 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,198 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,198 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,213 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,314 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,315 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,315 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,315 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,330 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,432 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,432 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,548 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,549 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,549 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,567 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,665 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,665 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,666 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,666 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,685 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,782 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,782 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,783 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,783 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,799 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,899 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:56,899 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:56,900 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:56,900 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:56,915 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,016 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,016 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,017 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,017 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,133 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,133 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,134 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,134 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,152 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,250 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,250 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,251 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,251 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,269 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,367 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,367 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,368 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,368 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,383 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,484 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,484 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,485 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,485 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,503 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,598 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,598 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,599 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,599 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,617 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,713 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,713 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,714 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,714 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,732 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,830 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,830 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,831 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,831 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,849 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,947 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:57,947 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:57,948 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:57,948 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:57,966 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,064 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,064 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,065 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,065 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,083 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,181 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,181 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,182 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,197 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,298 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,298 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,298 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,299 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,314 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,415 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,415 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,415 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,415 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,532 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,532 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,532 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,532 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,548 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,651 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,651 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,652 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,652 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,667 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,768 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,768 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,769 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,769 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,787 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,888 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:58,888 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:58,889 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:58,889 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:58,904 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,005 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,005 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,006 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,006 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,021 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,122 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,122 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,123 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,123 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,141 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,239 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,239 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,239 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,239 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,257 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,356 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,356 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,356 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,356 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,375 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,475 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,475 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,476 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,476 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,491 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,592 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,592 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,593 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,593 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,612 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,709 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,709 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,710 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,710 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,729 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,826 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,826 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,827 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,827 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,846 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,943 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:50:59,943 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:50:59,944 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:50:59,944 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:50:59,959 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,060 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,060 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,061 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,061 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,080 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,177 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,177 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,178 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,178 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,197 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,294 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,294 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,294 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,295 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,314 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,411 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,411 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,411 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,411 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,426 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,528 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,528 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,528 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,528 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,548 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,645 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,645 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,645 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,645 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,761 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,762 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,762 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,762 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,781 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,879 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,879 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,880 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,880 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,895 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:00,996 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:00,996 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:00,997 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:00,997 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,015 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,115 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,115 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,130 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,465 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,465 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,582 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,700 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,700 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,715 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,816 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,816 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,816 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:01,933 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:01,933 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:01,933 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:01,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,050 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,050 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,051 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,051 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,066 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,287 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,287 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,303 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,404 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,424 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,521 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,541 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,658 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,774 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,872 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:02,990 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:02,990 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:02,991 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:02,991 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,006 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,107 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:03,107 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:03,108 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:03,108 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,224 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:03,224 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:03,225 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:03,225 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,341 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:03,341 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:03,342 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:03,342 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,361 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,455 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:03,455 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:03,455 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:03,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:03,470 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:13,810 - INFO - Epoch 17/150 - Train Loss: 0.376918, Val Loss: 0.368021
2025-08-07 10:51:13,836 - INFO - New best model saved with Val Loss: 0.368021
2025-08-07 10:51:21,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:21,350 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:21,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:21,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,370 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:21,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:21,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:21,469 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:21,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:21,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:21,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,704 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:21,705 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:21,705 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:21,705 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,720 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,821 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:21,821 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:21,822 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:21,822 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,938 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:21,939 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:21,939 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:21,939 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:21,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,056 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,172 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,172 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,173 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,173 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,188 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,289 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,289 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,290 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,290 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,305 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,406 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,406 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,407 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,422 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,523 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,523 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,524 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,524 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,539 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,640 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,757 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,757 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,758 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,758 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,773 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,874 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:22,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:22,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:22,994 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:22,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,010 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,130 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,228 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,344 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,345 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,345 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,461 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,462 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,480 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,578 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,578 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,579 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,579 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,597 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,698 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,698 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,699 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,714 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,815 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,815 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,816 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,932 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:23,932 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:23,932 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:23,933 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:23,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,049 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,166 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,166 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,283 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,283 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,301 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,399 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,400 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,400 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,415 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,516 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,516 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,517 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,517 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,633 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,633 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,634 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,634 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,652 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,750 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,750 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,751 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,751 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,766 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,867 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,867 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,868 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,868 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,886 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:24,984 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:24,984 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:24,985 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:24,985 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,117 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,218 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,218 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,351 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,468 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,686 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,686 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,702 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,803 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,803 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,803 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,819 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:25,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:25,920 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:25,920 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:25,938 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,037 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,037 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,037 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,037 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,052 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,151 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,151 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,152 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,152 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,268 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,268 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,268 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,269 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,287 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,387 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,387 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,388 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,388 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,403 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,504 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,504 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,505 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,505 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,520 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,621 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,621 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,622 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,622 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,637 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,739 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,739 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,740 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,740 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,759 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,856 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,856 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,857 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,857 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:26,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:26,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:26,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:26,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,090 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,090 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,091 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,091 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,204 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,205 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,321 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,438 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,438 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,457 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,555 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,555 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,556 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,556 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,673 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,787 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,787 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,788 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,788 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,806 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,906 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:27,907 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:27,907 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:27,907 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:27,922 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,023 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,023 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,024 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,024 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,039 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,143 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,143 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,144 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,144 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,159 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,260 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,260 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,261 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,261 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,377 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,377 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,378 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,378 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,393 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,494 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,494 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,495 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,513 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,611 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,611 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,612 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,612 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,627 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,728 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,728 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,729 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,746 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,845 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,845 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,845 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,861 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,963 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:28,963 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:28,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:28,963 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:28,979 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,080 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,080 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,080 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,095 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,197 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,197 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,197 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,197 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,217 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,313 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,314 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,314 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,314 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,334 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,430 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,430 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,431 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,431 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,449 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,547 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,548 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,568 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,664 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,664 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,685 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,781 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,781 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,782 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,782 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:29,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:29,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:29,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:29,918 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:30,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:30,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:30,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:30,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:30,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:30,132 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:30,132 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:30,132 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:30,133 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:30,148 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:30,246 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:30,246 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:30,246 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:30,246 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:30,261 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:41,006 - INFO - Epoch 18/150 - Train Loss: 0.367722, Val Loss: 0.358435
2025-08-07 10:51:41,032 - INFO - New best model saved with Val Loss: 0.358435
2025-08-07 10:51:48,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:48,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:48,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:48,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:48,715 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:48,812 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:48,812 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:48,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:48,813 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:48,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:48,929 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:48,929 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:48,930 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:48,930 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:48,948 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,046 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,046 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,163 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,163 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,283 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,299 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,400 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,400 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,517 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,517 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,517 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,517 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,634 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,634 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,634 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,750 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,751 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,751 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,751 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,769 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:49,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:49,985 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:49,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:49,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,004 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,102 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,102 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,336 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,336 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,573 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,573 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,690 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,690 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:50,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:50,924 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:50,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:50,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,041 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,041 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,041 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,041 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,057 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,158 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,158 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,174 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,275 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,275 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,389 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,389 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,390 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,390 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,408 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,506 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,506 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,507 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,507 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,525 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,623 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,623 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,624 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,624 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,639 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,740 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,740 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,741 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,741 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,756 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,857 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,857 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,857 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,858 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:51,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:51,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:51,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:51,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,088 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,089 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,205 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,205 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,206 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,224 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,322 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,322 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,439 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,439 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,457 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,555 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,556 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,556 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,556 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,571 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,789 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,790 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,790 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,790 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,906 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:52,907 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:52,907 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:52,907 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:52,922 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,023 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,023 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,024 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,024 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,039 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,140 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,140 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,141 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,141 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,159 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,257 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,257 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,258 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,258 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,273 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,374 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,374 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,375 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,375 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,390 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,491 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,491 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,492 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,492 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,507 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,605 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,605 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,606 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,606 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,624 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,722 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,722 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,723 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,723 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,738 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,839 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,839 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,840 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,840 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,858 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,956 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:53,956 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:53,957 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:53,957 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:53,972 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,073 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,073 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,074 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,089 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,190 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,190 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,190 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,190 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,206 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,307 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,307 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,325 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,423 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,423 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,424 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,424 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,440 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,540 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,541 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,541 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,541 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,556 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,657 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,658 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,658 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,658 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,676 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,774 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,774 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,775 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,775 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,790 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,891 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:54,891 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:54,892 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:54,892 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:54,907 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,008 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,008 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,009 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,009 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,027 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,125 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,125 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,126 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,126 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,144 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,242 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,242 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,243 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,243 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,258 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,359 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,359 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,360 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,360 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,378 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,476 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,476 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,477 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,477 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,495 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,593 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,593 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,594 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,594 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,612 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,710 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,710 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,711 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,711 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,729 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,827 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,827 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,827 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,828 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,843 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:55,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:55,944 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:55,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:55,960 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,061 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,061 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,061 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,061 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,079 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,178 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,178 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,178 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,194 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,294 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,295 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,295 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,295 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,412 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,412 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,412 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,430 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,528 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,529 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,529 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,529 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,547 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,645 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,646 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,646 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,661 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,762 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,762 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,763 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,763 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,778 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,882 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,898 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:56,999 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:56,999 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:56,999 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:56,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,015 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:57,116 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:57,116 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:57,116 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,134 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,233 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:57,233 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:57,234 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:57,234 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,252 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:57,350 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:57,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:57,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,369 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,467 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:57,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:57,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:57,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,581 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:51:57,581 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:51:57,582 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:51:57,582 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:51:57,597 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:08,414 - INFO - Epoch 19/150 - Train Loss: 0.354541, Val Loss: 0.346365
2025-08-07 10:52:08,441 - INFO - New best model saved with Val Loss: 0.346365
2025-08-07 10:52:16,493 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:16,493 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:16,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:16,494 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,514 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,611 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:16,611 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:16,612 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:16,612 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,627 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,728 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:16,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:16,729 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:16,729 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,747 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,845 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:16,845 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:16,846 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:16,846 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,861 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,962 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:16,962 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:16,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:16,963 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:16,981 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,080 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,080 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,081 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,096 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,197 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,197 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,197 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,197 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,215 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,314 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,314 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,314 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,314 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,332 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,430 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,431 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,431 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,547 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,547 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,548 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,566 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,664 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,664 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,680 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,781 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,781 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,782 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,782 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,800 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:17,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:17,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:17,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:17,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,015 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,031 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,134 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,134 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,134 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,135 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,150 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,251 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,251 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,251 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,251 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,269 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,370 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,370 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,371 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,371 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,386 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,487 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,487 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,488 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,488 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,503 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,604 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,604 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,605 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,605 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,620 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,721 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,721 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,722 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,722 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,737 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,838 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,838 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,839 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,839 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,857 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,955 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:18,955 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:18,956 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:18,956 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:18,971 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,072 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,072 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,073 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,088 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,189 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,189 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,190 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,190 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,205 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,306 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,307 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,423 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,423 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,424 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,424 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,441 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,540 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,540 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,540 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,541 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,556 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,657 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,657 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,657 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,657 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,676 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,774 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,774 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,774 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,774 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,793 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,893 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:19,893 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:19,894 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:19,894 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:19,909 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,010 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,010 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,011 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,127 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,127 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,128 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,128 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,147 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,244 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,244 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,245 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,245 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,260 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,361 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,361 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,362 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,362 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,377 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,478 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,478 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,478 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,479 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,498 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,595 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,595 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,595 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,595 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,611 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,712 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,712 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,712 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,712 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,732 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,828 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,828 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,829 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,829 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,845 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,945 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:20,945 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:20,946 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:20,946 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:20,961 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,062 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,062 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,063 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,063 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,179 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,179 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,180 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,180 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,198 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,296 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,296 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,297 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,297 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,312 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,413 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,413 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,414 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,414 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,434 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,530 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,530 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,531 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,531 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,551 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,647 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,647 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,648 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,648 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,766 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,766 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,766 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,766 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,884 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:21,884 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:21,884 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:21,884 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:21,900 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,002 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,002 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,003 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,003 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,018 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,120 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,121 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,121 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,121 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,136 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,239 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,239 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,239 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,239 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,255 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,357 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,357 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,358 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,373 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,475 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,475 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,476 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,476 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,491 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,593 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,593 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,594 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,594 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,609 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,711 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,711 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,712 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,712 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,727 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,830 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,830 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,830 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,830 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,846 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,948 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:22,948 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:22,949 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:22,949 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:22,964 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,066 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,066 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,067 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,067 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,082 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,180 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,180 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,200 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,297 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,297 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,298 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,298 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,414 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,414 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,415 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,415 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,434 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,531 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,531 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,531 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,531 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,547 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,648 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,648 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,648 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,648 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,663 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,764 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,764 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,765 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,765 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,781 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,881 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,881 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,882 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,882 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,897 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:23,998 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:23,998 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:23,999 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:23,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,014 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,115 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,115 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,116 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,116 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,135 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,232 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,232 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,233 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,233 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,252 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,349 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,349 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,350 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,369 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,466 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,466 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,583 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,598 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,700 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,700 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,720 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,816 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,816 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,817 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,817 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,836 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:24,933 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:24,934 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:24,934 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:24,953 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,050 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:25,050 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:25,051 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:25,051 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,070 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:25,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:25,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:25,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,187 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,284 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:25,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:25,285 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:25,285 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:25,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:25,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:25,399 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:25,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:36,024 - INFO - Epoch 20/150 - Train Loss: 0.347017, Val Loss: 0.340778
2025-08-07 10:52:36,067 - INFO - New best model saved with Val Loss: 0.340778
2025-08-07 10:52:43,904 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:43,904 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:43,905 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:43,905 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:43,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,021 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,021 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,022 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,022 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,040 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,138 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,138 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,139 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,139 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,157 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,255 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,255 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,256 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,256 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,274 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,375 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,375 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,376 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,376 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,391 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,492 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,492 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,493 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,493 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,511 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,609 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,609 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,610 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,610 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,625 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,726 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,726 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,726 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,727 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,742 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,843 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,843 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,843 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,844 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,861 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,960 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:44,960 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:44,960 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:44,960 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:44,978 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,079 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,079 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,080 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,095 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,196 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,197 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,197 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,197 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,215 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,313 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,314 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,314 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,314 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,332 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,431 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,432 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,449 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,548 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,548 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,566 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,664 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,665 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,680 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,781 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,782 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,782 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,782 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,797 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:45,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:45,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:45,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:45,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,031 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,132 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,132 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,133 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,133 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,148 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,250 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,250 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,250 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,251 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,266 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,367 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,367 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,367 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,367 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,386 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,484 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,484 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,485 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,485 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,500 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,601 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,601 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,602 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,602 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,617 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,718 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,718 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,719 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,719 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,737 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,835 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,835 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,835 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,836 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,851 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,952 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:46,952 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:46,952 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:46,952 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:46,968 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,068 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,069 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,069 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,069 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,087 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,185 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,186 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,186 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,186 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,205 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,302 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,302 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,303 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,303 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,318 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,419 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,419 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,420 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,420 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,438 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,536 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,536 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,537 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,537 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,555 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,653 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,653 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,654 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,654 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,669 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,770 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,770 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,771 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,771 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,789 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,887 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:47,887 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:47,888 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:47,888 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:47,903 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,004 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,004 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,004 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,005 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,020 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,121 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,121 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,121 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,122 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,238 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,238 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,238 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,238 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,354 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,355 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,355 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,355 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,373 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,472 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,490 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,588 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,588 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,589 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,604 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,705 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,705 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,706 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,706 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,721 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,822 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,822 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,823 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,823 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,939 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:48,939 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:48,940 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:48,940 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:48,955 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,056 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,056 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,057 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,057 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,075 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,173 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,173 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,174 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,174 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,189 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,290 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,290 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,291 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,291 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,407 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,407 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,408 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,408 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,423 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,524 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,524 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,524 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,525 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,542 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,641 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,641 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,657 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,758 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,758 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,758 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,758 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,773 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:49,992 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:49,992 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:49,992 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:49,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,228 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,344 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,345 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,345 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,462 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,693 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,711 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,810 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,810 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,825 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,926 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:50,927 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:50,927 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:50,927 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:50,945 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,044 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,044 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,062 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,160 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,161 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,161 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,161 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,278 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,278 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,278 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,278 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,297 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,395 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,413 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,628 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,629 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,745 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,745 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,746 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,746 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,764 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,862 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,862 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,863 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,863 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,982 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:51,982 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:51,983 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:51,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:51,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,099 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,099 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,100 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,100 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,115 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,336 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,336 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,571 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,571 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,687 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,687 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,688 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,706 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,801 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:52:52,801 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:52:52,801 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:52:52,802 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:52:52,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:03,524 - INFO - Epoch 21/150 - Train Loss: 0.330183, Val Loss: 0.316436
2025-08-07 10:53:03,550 - INFO - New best model saved with Val Loss: 0.316436
2025-08-07 10:53:11,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,016 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,036 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,134 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,134 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,135 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,135 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,154 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,251 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,252 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,252 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,252 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,270 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,368 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,368 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,369 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,369 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,387 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,488 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,488 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,489 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,489 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,504 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,605 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,605 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,606 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,606 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,621 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,722 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,722 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,722 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,723 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,738 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,839 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,839 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,839 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,839 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,855 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,955 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:11,956 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:11,956 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:11,956 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:11,972 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,072 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,072 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,073 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,091 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,189 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,189 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,190 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,190 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,205 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,306 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,307 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,325 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,423 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,423 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,424 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,424 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,439 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,543 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,543 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,543 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,543 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,559 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,659 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,660 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,660 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,660 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,676 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,776 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,776 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,777 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,777 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,795 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,893 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:12,893 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:12,894 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:12,894 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:12,912 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,010 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,010 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,011 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,029 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,130 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,130 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,130 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,130 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,145 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,246 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,247 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,247 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,247 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,265 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,363 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,363 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,364 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,364 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,379 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,480 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,480 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,481 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,481 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,498 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,597 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,597 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,598 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,598 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,616 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,714 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,714 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,715 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,715 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,733 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,831 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,831 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,832 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,832 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,850 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,948 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:13,948 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:13,949 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:13,949 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:13,964 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,065 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,065 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,065 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,065 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,083 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,182 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,182 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,182 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,182 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,197 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,298 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,298 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,299 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,299 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,314 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,415 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,415 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,416 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,416 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,532 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,532 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,533 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,533 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,551 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,649 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,650 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,650 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,650 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,766 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,766 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,767 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,767 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,785 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,883 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:14,883 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:14,884 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:14,884 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:14,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,000 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,000 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,001 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,001 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,016 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,117 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,117 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,118 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,118 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,133 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,234 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,234 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,234 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,234 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,351 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,366 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,467 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,587 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,587 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,588 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,588 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,603 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,701 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,702 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,720 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,818 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,935 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:15,935 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:15,936 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:15,936 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:15,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,052 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,052 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,053 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,053 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,068 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,284 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,285 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,285 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,401 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,401 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,402 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,402 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,417 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,518 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,518 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,518 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,519 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,635 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,635 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,635 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,651 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,752 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,768 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:16,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:16,985 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:16,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:16,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,004 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,099 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,099 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,100 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,100 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,115 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,216 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,216 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,217 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,217 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,333 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,333 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,334 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,334 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,352 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,454 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,469 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,570 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,586 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,687 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,687 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,687 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,803 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:17,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:17,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:17,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:17,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,039 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,155 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,155 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,156 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,156 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,272 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,272 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,273 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,273 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,291 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,389 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,389 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,390 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,390 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,405 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,503 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,503 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,504 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,504 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,522 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,620 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,621 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,636 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,756 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,855 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,855 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:18,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:18,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:18,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:18,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,088 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,089 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,089 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,104 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,205 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,205 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,322 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,338 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,438 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,438 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,454 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,555 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,555 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,556 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,556 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,688 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,906 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:19,906 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:19,906 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:19,906 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:19,921 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:30,468 - INFO - Epoch 22/150 - Train Loss: 0.325603, Val Loss: 0.318754
2025-08-07 10:53:38,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:38,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:38,343 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:38,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,460 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:38,460 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:38,461 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:38,461 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,479 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,580 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:38,580 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:38,580 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:38,580 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,596 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,696 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:38,697 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:38,697 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:38,697 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,713 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,814 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:38,814 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:38,814 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:38,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:38,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:38,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:38,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:38,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,048 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,048 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,066 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,165 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,165 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,183 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,284 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,285 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,285 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,401 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,401 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,402 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,402 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,417 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,518 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,518 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,519 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,519 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,537 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,635 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,635 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,636 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,752 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,752 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,753 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,753 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,771 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,869 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,869 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,870 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,870 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,888 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:39,986 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:39,986 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:39,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:39,987 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,005 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,103 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,104 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,122 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,220 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,220 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,337 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,337 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:40,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:40,925 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:40,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:40,943 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,041 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,041 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,042 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,042 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,057 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,174 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,275 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,394 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,394 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,395 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,413 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,628 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,628 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,745 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,745 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,746 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,746 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,864 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,865 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,865 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,865 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,880 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,981 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:41,981 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:41,982 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:41,982 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:41,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,098 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,098 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,099 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,099 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,114 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,215 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,215 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,216 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,216 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,332 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,332 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,333 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,333 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,449 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,449 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,450 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,450 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,566 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,566 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,567 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,567 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,582 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,683 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,683 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,683 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,684 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,702 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,800 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,800 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,800 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,800 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,818 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,917 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:42,917 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:42,917 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:42,917 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:42,935 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,034 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,034 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,034 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,034 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,052 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,150 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,151 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,151 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,151 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,166 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,267 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,267 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,268 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,268 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,286 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,384 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,384 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,385 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,385 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,400 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,503 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,503 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,504 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,504 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,620 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,639 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,870 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:43,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:43,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:43,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:43,987 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,087 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,103 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,204 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,204 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,220 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,321 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,438 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,438 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,454 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,555 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,555 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,556 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,556 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,789 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,789 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,790 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,790 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:44,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:44,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:44,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:44,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,025 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,025 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,026 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,026 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,041 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,142 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,142 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,143 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,143 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,158 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,259 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,259 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,260 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,260 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,278 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,376 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,376 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,377 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,377 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,392 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,493 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,493 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,494 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,513 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,610 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,610 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,610 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,611 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,630 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,727 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,727 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,727 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,727 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,747 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,843 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,844 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,844 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,844 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,867 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,960 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:45,960 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:45,961 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:45,961 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:45,976 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,077 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,077 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,078 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,078 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,093 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,191 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,191 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,192 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,192 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,210 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,308 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,308 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,309 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,309 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,324 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,425 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,425 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,426 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,426 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,441 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,542 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,542 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,543 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,543 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,558 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,659 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,659 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,660 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,660 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,675 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,776 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,776 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,776 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,777 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,792 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,893 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:46,893 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:46,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:46,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:46,911 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:47,007 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:47,007 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:47,007 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:47,008 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:47,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:47,124 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:47,124 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:47,125 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:47,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:47,143 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:47,238 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:53:47,238 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:53:47,239 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:53:47,239 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:47,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:53:57,859 - INFO - Epoch 23/150 - Train Loss: 0.307702, Val Loss: 0.293929
2025-08-07 10:53:57,886 - INFO - New best model saved with Val Loss: 0.293929
2025-08-07 10:54:05,633 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:05,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:05,634 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:05,634 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:05,651 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:05,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:05,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:05,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:05,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:05,770 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:05,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:05,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:05,871 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:05,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:05,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:05,991 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:05,991 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:05,991 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:05,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,108 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,108 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,109 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,124 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,225 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,225 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,226 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,226 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,342 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,459 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,459 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,459 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,459 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,576 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,594 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,811 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,811 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,927 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:06,927 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:06,928 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:06,928 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:06,943 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,046 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,062 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,163 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,163 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,281 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,281 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,281 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,282 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,398 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,514 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,515 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,515 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,533 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,634 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,635 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,650 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,751 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,767 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,889 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:07,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:07,985 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:07,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:07,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,006 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,102 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,102 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,122 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,336 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,336 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,454 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,454 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,573 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,573 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,710 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,812 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,812 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,813 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:08,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:08,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:08,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:08,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,048 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,049 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,183 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,285 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,285 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,286 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,301 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,404 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,404 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,522 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,522 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,522 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,522 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,538 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,640 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,758 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,758 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,759 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,759 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,774 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,876 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,876 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,877 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,877 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,892 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:09,995 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:09,995 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:09,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:09,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,011 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,113 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,113 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,129 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,247 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,349 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,349 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,350 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,350 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,365 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,469 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,484 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,586 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,586 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,587 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,587 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,602 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,704 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,704 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,705 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,705 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,720 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,823 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,823 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,823 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,824 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,839 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,941 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:10,941 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:10,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:10,942 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:10,957 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,060 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,060 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,075 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,177 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,178 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,178 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,193 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,296 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,296 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,296 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,296 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,312 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,414 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,414 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,414 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,415 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,430 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,532 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,532 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,533 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,533 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,548 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,650 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,650 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,651 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,651 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,666 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,768 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,768 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,769 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,769 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,784 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:11,883 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:11,883 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:11,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:11,999 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,000 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,000 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,000 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,020 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,116 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,137 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,233 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,233 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,234 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,234 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,350 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,370 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,467 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,584 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,584 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,600 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,701 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,701 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,721 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,818 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,939 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:12,939 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:12,940 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:12,940 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:12,955 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,057 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,057 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,058 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,058 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,073 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,175 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,176 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,176 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,191 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,294 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,294 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,294 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,294 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,310 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,412 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,412 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,413 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,428 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,530 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,530 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,531 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,531 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,546 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,648 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,648 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,649 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,649 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,664 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,765 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,765 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,766 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,766 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,785 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:13,883 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:13,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,898 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:13,999 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:13,999 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:14,000 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:14,000 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,015 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,113 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:14,113 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:14,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:14,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,132 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,230 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:14,230 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:14,231 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:14,231 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,249 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,347 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:14,347 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:14,347 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:14,348 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,464 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:14,464 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:14,464 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:14,464 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,480 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,578 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:14,578 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:14,578 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:14,578 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:14,593 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:25,154 - INFO - Epoch 24/150 - Train Loss: 0.306396, Val Loss: 0.306673
2025-08-07 10:54:32,663 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:32,663 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:32,664 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:32,664 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:32,683 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:32,780 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:32,780 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:32,781 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:32,781 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:32,799 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:32,897 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:32,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:32,898 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:32,898 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:32,916 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,014 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,014 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,015 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,015 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,033 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,134 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,135 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,135 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,135 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,153 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,251 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,252 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,252 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,252 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,270 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,368 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,368 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,369 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,369 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,384 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,485 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,485 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,486 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,486 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,504 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,602 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,603 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,603 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,603 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,621 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,719 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,720 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,720 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,720 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,735 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,836 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,836 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,837 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,837 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,852 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,953 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:33,953 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:33,954 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:33,954 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:33,972 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,071 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,071 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,071 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,071 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,089 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,188 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,188 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,189 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,189 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,207 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,305 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,305 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,305 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,306 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,321 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,422 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,422 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,422 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,423 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,438 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,539 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,539 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,539 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,540 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,555 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,656 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,656 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,773 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,773 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,773 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,773 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,791 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,890 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:34,890 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:34,890 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:34,890 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:34,908 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,007 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,007 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,007 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,007 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,124 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,124 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,124 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,124 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,240 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,241 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,241 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,241 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,259 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,358 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,358 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,358 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,376 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,474 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,474 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,475 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,475 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,490 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,591 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,591 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,592 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,592 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,610 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,708 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,708 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,709 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,709 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,724 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,825 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,825 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,826 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,826 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,841 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,942 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:35,942 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:35,943 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:35,943 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:35,961 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,060 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,060 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,176 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,177 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,177 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,195 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,293 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,293 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,293 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,294 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,410 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,410 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,410 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,426 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,527 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,527 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,528 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,543 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,644 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,644 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,760 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,761 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,761 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,761 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,776 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,877 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,877 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,878 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,878 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:36,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:36,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:36,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:36,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,112 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,229 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,229 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,247 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,345 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,345 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,346 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,346 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,463 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,463 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,579 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,579 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,580 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,580 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,696 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,696 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,697 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,697 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,715 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,813 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,813 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:37,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:37,930 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:37,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:37,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,403 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,754 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,774 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,874 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:38,991 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:38,991 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:38,991 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:38,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,011 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,108 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,108 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,108 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,128 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,225 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,225 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,225 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,225 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,241 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,342 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,342 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,458 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,458 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,459 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,459 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,575 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,575 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,576 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,692 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,692 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,693 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,712 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,809 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,809 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,810 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,810 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,830 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,926 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:39,926 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:39,927 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:39,927 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:39,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,043 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,043 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,160 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,160 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,161 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,161 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,180 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,277 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,277 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,278 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,278 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,293 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,394 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,394 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,395 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,527 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,628 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,629 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,747 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,748 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,748 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,748 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,864 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,865 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,865 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,880 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,981 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:40,981 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:40,982 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:40,982 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:40,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,098 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:41,098 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:41,099 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:41,099 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,114 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,212 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:41,212 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:41,213 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:41,213 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,231 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,329 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:41,329 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:41,330 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:41,330 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,446 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:41,446 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:41,447 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:41,447 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,462 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,560 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:54:41,561 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:54:41,561 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:54:41,561 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:41,576 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:54:52,198 - INFO - Epoch 25/150 - Train Loss: 0.306879, Val Loss: 0.290387
2025-08-07 10:54:52,225 - INFO - New best model saved with Val Loss: 0.290387
2025-08-07 10:55:00,122 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,122 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,123 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,123 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,142 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,240 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,240 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,240 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,240 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,258 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,357 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,357 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,357 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,376 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,473 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,474 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,474 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,474 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,492 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,590 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,590 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,591 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,591 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,606 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,707 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,707 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,708 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,723 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,824 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,824 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,825 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,825 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,843 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,941 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:00,941 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:00,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:00,942 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:00,957 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,058 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,058 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,059 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,059 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,175 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,175 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,176 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,176 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,194 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,295 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,295 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,296 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,296 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,311 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,412 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,413 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,413 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,529 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,529 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,530 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,530 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,545 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,646 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,665 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,763 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,763 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,763 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,764 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,779 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,880 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,896 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:01,997 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:01,997 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:01,997 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:01,997 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,015 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,115 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,133 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,231 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,348 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,464 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,465 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,465 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,480 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,581 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,581 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,582 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,582 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,597 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,698 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,698 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,699 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,815 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,815 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,816 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,932 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:02,932 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:02,933 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:02,933 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:02,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,172 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,172 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,173 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,173 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,188 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,289 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,289 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,290 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,290 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,406 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,406 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,407 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,422 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,526 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,526 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,541 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,642 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,643 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,643 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,663 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,764 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,764 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,764 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,764 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,780 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:03,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:03,882 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:03,883 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:03,897 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,000 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,000 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,001 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,001 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,016 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,117 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,117 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,118 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,137 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,465 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,465 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,465 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,584 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,600 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,702 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,837 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,935 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:04,935 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:04,936 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:04,936 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:04,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,052 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,052 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,053 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,053 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,169 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,169 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,170 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,170 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,188 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,286 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,287 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,305 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,404 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,638 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,770 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,872 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:05,988 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:05,988 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:05,989 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:05,989 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,004 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,105 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,105 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,106 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,124 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,241 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,475 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,576 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,692 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,693 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,809 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,810 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,810 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,926 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:06,926 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:06,927 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:06,927 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:06,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,043 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,043 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,059 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,160 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,160 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,161 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,161 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,176 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,282 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,282 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,282 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,283 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,401 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,401 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,518 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,518 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,519 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,519 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,534 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,636 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,652 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,755 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,755 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,756 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,771 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,873 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,873 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,874 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,874 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,889 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:07,991 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:07,991 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:07,992 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:07,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,110 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,110 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,110 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,110 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,126 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,229 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,346 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,346 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,347 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,347 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,362 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,464 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,464 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,465 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,480 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,582 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,598 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,700 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,700 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,701 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,701 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,716 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,835 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,937 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:08,937 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:08,938 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:08,938 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:08,953 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:09,051 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:09,051 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:09,052 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:09,052 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:09,067 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:19,718 - INFO - Epoch 26/150 - Train Loss: 0.291754, Val Loss: 0.278166
2025-08-07 10:55:19,744 - INFO - New best model saved with Val Loss: 0.278166
2025-08-07 10:55:27,402 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:27,402 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:27,403 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:27,403 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,422 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:27,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:27,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:27,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:27,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:27,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:27,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:27,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:27,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:27,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:27,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:27,871 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:27,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:27,990 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:27,990 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:27,991 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:27,991 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,006 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,107 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,107 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,108 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,108 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,126 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,224 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,224 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,225 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,225 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,338 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,339 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,339 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,357 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,458 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,458 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,459 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,459 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,926 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:28,926 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:28,926 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:28,926 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:28,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,043 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,043 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,059 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,160 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,160 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,160 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,160 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,178 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,277 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,280 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,280 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,280 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,296 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,531 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,648 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,762 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,863 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,863 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:29,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:29,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:29,980 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:29,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,096 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,097 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,097 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,112 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,213 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,232 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,330 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,330 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,331 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,349 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,466 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,564 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,564 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,583 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,683 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,684 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,684 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,684 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,699 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,800 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,800 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,801 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,801 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,820 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,921 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:30,921 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:30,922 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:30,922 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:30,937 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,040 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,158 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,158 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,174 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,292 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,394 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,394 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,395 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,410 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,513 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,513 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,631 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,631 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,632 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,749 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,749 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,750 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,765 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,867 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,867 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,868 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,868 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,883 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:31,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:31,986 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:31,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:31,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,002 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,104 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,104 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,119 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,340 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,340 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,341 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,341 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,356 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,458 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,458 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,459 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,459 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,577 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,695 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,695 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,711 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,813 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,813 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,931 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:32,931 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:32,932 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:32,932 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:32,947 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,050 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,050 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,183 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,286 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,404 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,404 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,405 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,405 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,420 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,522 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,522 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,523 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,523 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,538 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,640 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,759 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,759 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,759 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,759 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,774 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,877 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,877 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,877 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,878 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:33,995 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:33,995 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:33,996 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:33,996 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,011 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,113 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,113 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,129 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,232 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,248 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,350 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,350 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,367 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,469 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,469 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,469 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,470 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,485 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,587 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,587 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,588 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,588 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,603 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,706 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,706 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,706 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,706 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,722 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,824 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,824 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,825 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,825 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,840 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,942 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:34,942 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:34,943 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:34,943 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:34,958 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,060 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,061 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,061 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,061 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,076 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,179 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,179 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,179 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,179 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,195 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,297 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,297 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,298 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,298 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,415 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,415 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,416 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,416 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,533 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,533 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,534 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,534 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,549 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,651 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,652 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,652 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,652 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,770 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,770 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,770 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,771 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,786 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,888 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:35,888 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:35,888 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:35,889 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:35,904 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,006 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:36,006 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:36,007 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:36,007 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,022 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,124 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:36,124 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:36,125 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:36,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:36,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:36,243 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:36,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,259 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:36,357 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:36,358 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:36,358 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:36,373 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:47,081 - INFO - Epoch 27/150 - Train Loss: 0.284545, Val Loss: 0.276351
2025-08-07 10:55:47,108 - INFO - New best model saved with Val Loss: 0.276351
2025-08-07 10:55:54,516 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:54,516 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:54,517 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:54,517 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,636 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:54,636 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:54,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:54,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,753 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:54,753 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:54,754 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:54,754 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,870 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:54,870 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:54,871 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:54,871 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,886 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:54,987 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:54,987 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:54,988 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:54,988 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,003 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,105 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,105 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,120 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,570 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,687 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,687 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,803 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,803 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,819 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:55,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:55,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:55,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:55,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,038 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,038 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,155 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,155 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,156 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,156 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,171 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,272 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,272 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,272 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,272 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,288 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,392 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,408 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,509 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,509 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,509 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,510 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,525 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,626 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,626 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,626 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,626 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,644 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,742 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,743 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,743 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,743 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,761 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,859 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,859 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,860 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,860 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,878 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,976 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:56,976 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:56,977 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:56,977 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:56,995 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,093 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,093 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,094 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,094 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,112 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,229 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,330 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,330 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,331 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,346 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,466 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,564 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,564 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,564 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,681 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,681 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,681 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,681 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,697 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,798 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,798 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,798 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,798 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,816 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,914 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:57,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:57,915 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:57,915 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:57,930 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,031 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,032 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,032 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,032 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,048 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,149 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,149 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,149 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,149 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,265 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,266 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,266 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,499 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,499 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,500 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,500 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,515 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,616 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,616 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,617 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,617 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,733 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,733 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,734 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,734 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,749 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,850 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,850 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,851 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,851 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,866 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:58,967 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:58,967 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:58,968 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:58,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,084 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,084 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,085 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,085 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,103 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,201 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,201 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,201 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,202 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,220 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,318 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,318 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,336 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,435 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,435 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,435 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,435 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,551 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,552 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,552 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,552 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,567 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,668 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,668 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,669 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,669 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,687 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,785 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,785 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,786 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,786 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,902 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:55:59,902 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:55:59,903 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:55:59,903 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:55:59,921 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,019 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,019 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,020 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,020 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,136 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,137 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,137 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,137 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,155 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,253 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,253 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,254 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,254 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,272 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,370 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,370 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,371 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,371 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,386 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,490 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,490 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,491 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,491 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,506 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,607 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,607 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,607 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,608 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,623 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,724 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,724 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,724 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,725 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,743 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,841 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,841 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,841 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,842 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,857 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,955 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:00,955 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:00,956 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:00,956 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:00,974 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,072 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,072 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,073 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,088 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,189 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,189 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,189 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,190 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,207 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,306 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,306 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,423 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,423 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,423 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,423 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,438 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,539 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,540 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,540 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,540 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,555 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,656 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,656 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,657 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,657 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,672 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,773 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,773 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,774 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,774 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,789 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,890 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:01,890 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:01,891 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:01,891 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:01,909 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,007 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,007 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,008 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,008 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,124 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,124 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,125 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,143 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,241 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,241 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,242 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,242 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,257 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,358 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,358 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,358 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,359 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,376 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,475 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,475 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,475 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,475 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,491 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,591 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,592 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,592 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,592 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,610 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,708 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,709 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,709 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,709 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,727 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,827 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,827 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,827 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,827 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,845 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,943 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:02,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:02,944 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:02,944 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:02,962 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,060 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:03,061 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:03,061 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:03,061 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,079 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,177 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:03,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:03,178 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:03,178 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,196 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,294 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:03,294 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:03,295 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:03,295 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,408 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:03,408 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:03,409 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:03,409 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:03,424 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:13,816 - INFO - Epoch 28/150 - Train Loss: 0.279916, Val Loss: 0.281842
2025-08-07 10:56:21,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:21,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:21,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:21,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:21,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:21,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:21,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,646 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,749 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:21,749 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:21,750 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:21,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,765 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:21,866 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:21,867 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:21,867 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:21,983 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:21,983 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:21,984 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:21,984 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,002 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,117 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,218 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,218 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,351 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,688 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,688 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,689 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,689 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,704 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,805 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,824 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:22,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:22,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:22,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:22,941 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,042 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,042 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,043 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,043 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,058 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,159 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,159 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,160 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,160 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,178 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,292 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,510 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,510 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,511 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,511 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,529 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,627 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,627 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,628 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,628 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,643 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,744 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,744 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,745 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,745 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,861 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,861 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,862 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,862 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,880 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,978 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:23,978 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:23,979 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:23,979 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:23,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,095 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,095 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,096 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,096 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,212 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,212 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,213 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,213 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,231 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,332 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,332 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,332 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,333 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,449 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,449 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,449 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,449 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,566 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,582 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,683 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,683 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,683 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,698 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,800 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,800 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,818 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,916 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:24,916 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:24,917 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:24,917 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:24,932 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,033 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,034 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,034 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,052 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,150 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,150 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,150 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,151 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,168 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,267 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,267 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,283 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,383 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,384 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,384 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,384 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,399 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,500 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,501 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,501 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,617 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,617 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,618 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,618 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,633 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,734 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,734 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,735 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,735 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,852 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,852 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,852 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,852 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,868 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,969 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:25,969 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:25,969 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:25,969 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:25,984 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,085 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,085 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,086 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,086 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,101 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,202 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,202 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,203 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,203 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,218 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,319 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,319 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,320 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,320 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,436 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,436 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,437 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,437 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,452 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,553 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,553 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,554 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,554 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,569 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,670 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,670 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,671 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,671 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,787 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,787 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,787 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,788 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,807 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,904 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:26,904 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:26,904 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:26,905 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:26,920 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,020 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,021 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,021 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,021 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,036 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,137 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,138 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,138 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,138 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,158 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,254 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,254 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,255 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,255 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,275 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,371 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,371 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,372 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,372 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,387 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,488 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,488 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,489 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,489 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,504 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,605 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,605 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,606 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,606 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,627 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,723 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,723 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,723 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,723 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,743 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,840 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,840 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,841 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,841 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,857 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,960 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:27,960 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:27,961 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:27,961 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:27,976 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,077 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,077 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,078 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,078 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,093 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,194 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,194 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,195 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,195 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,210 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,311 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,311 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,312 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,312 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,331 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,428 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,428 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,428 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,429 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,448 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,545 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,545 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,545 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,546 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,561 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,666 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,666 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,667 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,667 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,682 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,784 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,784 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,785 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,785 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,800 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,902 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:28,902 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:28,903 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:28,903 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:28,918 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,021 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,021 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,021 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,021 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,037 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,139 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,139 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,139 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,140 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,155 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,257 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,257 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,258 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,258 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,273 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,375 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,375 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,376 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,376 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,391 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,493 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,493 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,494 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,509 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,611 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,612 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,612 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,612 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,628 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,729 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,730 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,730 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,730 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,745 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,848 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,848 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,849 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,849 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,865 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:29,967 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:29,967 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:29,968 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:29,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,085 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:30,085 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:30,086 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:30,086 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,101 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,203 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:30,203 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:30,204 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:30,204 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,219 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:30,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:30,319 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:30,319 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,334 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,432 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:30,432 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:30,433 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:30,433 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:30,448 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:41,178 - INFO - Epoch 29/150 - Train Loss: 0.272210, Val Loss: 0.262212
2025-08-07 10:56:41,219 - INFO - New best model saved with Val Loss: 0.262212
2025-08-07 10:56:49,168 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,168 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,169 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,285 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,285 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,286 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,304 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,402 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,402 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,403 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,403 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,421 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,519 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,519 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,520 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,520 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,535 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,636 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,636 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,652 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,753 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,753 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,754 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,754 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,769 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,870 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,870 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,870 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,871 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,886 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:49,987 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:49,987 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:49,987 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:49,988 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,003 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,104 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,104 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,119 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,220 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,221 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,221 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,236 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,337 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,338 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,338 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,338 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,357 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,454 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,455 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,455 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,455 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,473 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,571 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,571 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,572 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,572 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,688 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,688 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,689 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,689 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,707 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,805 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,824 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:50,922 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:50,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:50,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:50,941 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,039 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,057 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,156 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,156 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,273 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,273 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,273 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,273 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,292 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,408 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,509 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,509 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,510 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,510 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,525 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,626 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,626 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,627 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,627 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,642 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,743 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,743 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,744 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,744 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,759 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,860 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,860 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,861 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,861 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,977 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:51,977 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:51,978 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:51,978 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:51,996 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,095 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,099 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,099 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,100 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,118 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,216 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,216 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,216 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,216 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,232 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,334 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,334 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,335 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,335 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,468 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,571 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,571 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,586 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,689 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,689 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,689 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,689 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,807 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,823 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,925 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:52,925 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:52,926 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:52,926 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:52,941 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,043 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,043 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,059 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,161 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,161 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,162 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,162 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,177 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,280 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,280 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,280 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,281 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,296 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,399 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,399 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,414 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,516 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,516 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,517 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,517 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,634 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,635 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,651 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,753 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,753 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,754 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,754 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,769 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,872 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:53,990 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:53,990 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:53,990 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:53,990 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,005 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,108 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,108 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,108 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,123 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,226 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,226 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,227 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,227 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,242 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,344 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,344 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,345 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,463 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,463 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,580 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,580 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,581 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,581 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,596 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,699 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,715 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,817 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,817 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,818 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,818 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,833 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,935 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:54,935 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:54,936 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:54,936 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:54,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,053 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,053 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,054 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,054 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,069 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,171 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,171 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,172 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,172 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,188 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,290 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,290 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,290 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,291 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,306 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,408 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,408 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,409 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,409 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,424 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,527 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,542 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,644 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,644 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,645 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,645 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,762 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,762 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,763 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,763 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,778 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,881 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,896 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:55,999 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:55,999 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:55,999 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:55,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,015 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,117 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,117 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,118 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,118 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,133 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,235 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,235 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,236 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,236 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,251 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,353 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,353 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,354 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,354 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,369 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,590 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,590 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,590 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,590 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,606 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,708 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,708 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,709 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,724 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,826 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,826 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,827 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,827 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,842 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:56,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:56,945 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:56,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:56,960 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,063 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,063 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,064 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,064 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,079 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,181 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,181 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,182 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,182 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,197 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,300 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,300 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,300 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,300 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,316 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,418 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,418 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,418 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,418 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,434 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,536 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,536 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,537 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,537 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,552 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,654 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,654 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,655 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,655 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,670 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,772 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,772 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,773 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,773 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,788 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,890 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:57,891 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:57,891 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:57,891 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:57,906 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:58,009 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:58,009 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:58,009 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:58,009 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:58,024 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:58,123 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:56:58,123 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:56:58,123 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:56:58,123 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:56:58,138 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:08,526 - INFO - Epoch 30/150 - Train Loss: 0.263505, Val Loss: 0.254954
2025-08-07 10:57:08,553 - INFO - New best model saved with Val Loss: 0.254954
2025-08-07 10:57:16,621 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:16,621 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:16,622 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:16,622 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,642 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,739 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:16,739 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:16,739 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:16,740 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,856 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:16,856 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:16,856 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:16,857 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,875 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,973 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:16,973 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:16,973 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:16,974 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:16,991 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,090 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,090 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,090 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,090 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,207 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,207 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,207 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,207 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,222 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,323 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,324 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,324 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,342 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,440 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,441 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,441 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,457 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,557 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,557 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,558 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,558 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,576 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,674 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,791 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,791 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,810 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:17,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:17,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:17,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:17,927 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,025 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,025 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,026 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,026 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,044 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,142 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,142 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,142 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,143 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,161 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,262 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,262 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,262 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,262 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,277 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,378 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,379 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,379 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,379 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,397 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,495 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,496 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,496 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,496 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,514 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,613 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,613 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,613 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,613 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,631 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,729 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,730 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,730 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,730 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,748 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,846 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,846 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,847 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,847 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,862 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,963 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:18,963 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:18,964 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:18,964 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:18,982 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,080 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,080 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,081 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,081 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,099 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,197 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,197 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,198 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,198 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,213 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,314 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,314 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,315 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,315 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,333 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,432 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,432 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,548 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,549 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,549 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,567 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,665 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,665 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,683 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,781 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,782 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,782 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,782 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,797 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:19,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:19,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:19,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:19,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,031 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,133 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,133 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,133 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,134 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,149 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,250 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,250 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,250 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,250 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,266 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,369 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,369 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,370 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,370 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,385 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,484 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,484 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,484 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,484 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,502 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,600 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,601 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,601 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,601 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,619 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,717 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,717 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,718 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,718 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,733 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,834 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,834 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,835 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,835 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,850 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,951 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:20,951 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:20,952 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:20,952 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:20,970 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,068 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,068 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,069 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,069 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,087 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,185 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,185 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,186 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,186 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,204 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,302 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,302 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,303 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,303 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,318 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,419 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,419 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,420 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,420 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,439 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,536 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,536 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,537 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,537 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,552 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,653 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,653 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,653 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,653 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,669 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,770 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,770 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,770 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,770 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,785 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,886 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:21,886 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:21,887 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:21,887 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:21,903 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,003 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,004 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,004 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,004 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,024 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,125 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,125 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,125 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,141 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,243 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,259 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,361 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,361 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,362 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,362 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,377 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,479 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,479 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,480 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,480 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,495 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,597 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,597 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,598 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,598 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,613 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,715 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,715 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,716 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,716 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,731 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,834 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,834 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,834 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,834 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,850 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,952 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:22,952 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:22,952 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:22,953 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:22,968 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,070 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,070 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,071 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,071 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,086 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,188 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,188 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,189 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,189 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,204 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,306 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,307 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,424 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,424 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,425 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,425 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,440 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,542 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,543 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,543 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,543 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,558 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,661 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,661 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,661 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,661 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,677 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,779 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,779 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,780 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,780 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,795 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,897 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:23,897 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:23,898 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:23,898 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:23,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,016 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,032 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,134 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,134 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,134 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,134 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,150 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,252 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,252 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,252 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,253 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,268 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,370 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,370 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,371 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,371 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,386 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,488 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,488 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,489 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,489 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,504 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,606 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,606 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,607 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,607 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,622 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,725 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,725 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,725 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,725 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,740 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,843 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,843 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,843 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,843 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,859 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,961 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:24,961 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:24,962 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:24,962 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:24,977 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,079 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:25,079 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:25,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:25,080 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,095 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,198 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:25,198 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:25,198 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:25,198 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,213 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,316 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:25,316 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:25,316 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:25,316 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,331 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,434 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:25,434 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:25,434 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:25,435 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,548 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:25,548 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:25,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:25,549 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:25,564 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:36,198 - INFO - Epoch 31/150 - Train Loss: 0.260322, Val Loss: 0.256993
2025-08-07 10:57:44,207 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,207 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,208 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,208 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,227 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,324 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,325 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,325 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,442 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,460 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,558 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,558 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,559 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,559 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,577 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,675 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,676 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,676 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,694 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,795 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,795 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,796 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,796 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,811 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,912 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:44,912 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:44,913 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:44,913 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:44,928 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,029 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,030 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,030 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,146 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,146 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,147 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,147 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,263 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,263 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,263 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,264 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,282 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,499 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,500 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,500 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,515 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,616 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,616 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,617 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,617 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,632 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,733 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,733 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,734 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,734 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,749 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,850 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,850 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,851 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,851 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,866 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:45,967 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:45,968 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:45,968 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:45,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,084 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,084 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,085 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,085 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,103 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,201 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,201 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,202 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,202 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,217 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,318 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,319 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,336 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,437 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,438 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,438 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,438 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,453 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,554 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,554 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,555 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,555 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,573 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,674 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,791 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,791 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,807 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:46,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:46,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:46,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:46,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,025 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,025 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,026 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,026 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,044 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,142 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,142 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,143 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,143 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,162 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,263 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,263 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,264 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,264 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,381 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,381 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,382 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,382 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,397 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,499 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,500 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,500 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,515 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,618 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,618 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,618 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,619 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,634 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,736 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,736 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,752 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,855 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,855 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,870 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,972 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:47,973 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:47,973 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:47,973 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:47,988 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,091 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,091 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,092 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,092 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,107 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,209 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,209 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,210 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,210 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,225 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,327 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,327 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,328 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,328 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,345 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,442 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,442 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,442 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,462 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,558 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,559 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,559 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,559 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,579 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,675 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,676 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,676 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,676 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,696 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,793 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,793 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,793 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,813 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,910 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:48,910 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:48,910 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:48,910 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:48,930 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,027 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,027 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,027 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,027 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,042 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,148 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,148 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,148 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,148 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,164 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,282 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,384 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,384 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,385 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,385 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,400 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,503 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,621 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,621 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,622 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,622 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,637 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,739 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,739 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,740 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,740 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,755 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,857 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,858 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,858 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,858 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,976 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:49,976 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:49,977 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:49,977 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:49,992 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,094 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,094 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,095 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,095 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,110 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,212 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,213 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,213 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,213 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,228 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,331 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,331 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,347 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,449 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,449 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,450 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,450 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,567 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,567 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,568 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,568 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,583 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,685 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,685 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,686 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,686 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,701 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,804 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,804 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,804 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,804 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,820 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:50,922 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:50,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:50,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:50,938 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,040 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,041 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,041 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,174 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,277 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,277 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,293 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,412 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,514 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,514 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,514 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,514 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,632 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,633 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,633 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,648 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,750 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,750 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,751 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,751 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,766 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,869 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,884 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:51,987 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:51,987 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:51,987 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:51,988 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,003 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,103 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,104 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,104 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,119 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,340 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,356 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,458 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,458 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,458 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,458 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,577 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,710 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,812 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,812 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,813 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,931 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:52,931 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:52,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:52,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:52,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:53,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:53,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:53,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:53,050 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:53,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:53,163 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:57:53,163 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:57:53,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:57:53,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:57:53,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:03,984 - INFO - Epoch 32/150 - Train Loss: 0.259914, Val Loss: 0.259862
2025-08-07 10:58:11,941 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:11,941 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:11,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:11,942 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:11,962 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,060 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,060 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,075 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,178 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,179 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,179 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,194 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,297 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,297 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,297 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,298 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,414 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,414 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,414 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,414 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,430 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,531 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,531 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,531 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,531 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,547 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,650 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,650 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,651 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,651 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,666 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,767 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,767 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,768 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,768 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,786 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,884 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:12,884 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:12,885 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:12,885 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:12,903 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,001 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,001 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,002 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,002 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,017 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,118 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,118 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,119 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,119 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,137 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,235 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,235 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,236 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,236 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,352 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,352 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,352 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,353 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,368 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,472 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,588 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,588 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,589 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,604 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,705 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,705 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,706 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,706 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,722 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,822 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,822 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,823 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,823 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,939 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:13,939 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:13,940 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:13,940 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:13,958 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,056 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,056 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,057 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,057 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,072 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,173 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,173 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,174 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,174 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,189 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,290 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,290 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,291 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,291 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,407 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,407 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,408 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,408 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,423 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,524 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,524 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,525 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,525 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,543 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,641 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,641 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,642 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,642 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,758 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,758 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,759 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,759 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,875 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,876 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,876 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,891 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:14,992 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:14,992 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:14,992 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:14,993 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,011 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,109 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,109 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,109 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,125 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,225 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,226 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,226 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,226 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,244 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,343 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,343 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,361 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,460 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,460 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,460 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,461 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,577 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,577 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,577 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,811 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,811 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,829 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,927 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:15,927 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:15,928 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:15,928 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:15,943 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,044 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,044 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,045 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,045 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,060 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,161 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,161 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,162 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,162 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,177 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,295 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,396 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,396 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,513 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,627 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,627 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,627 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,627 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,645 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,744 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,744 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,744 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,744 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,760 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,861 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,861 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,861 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,861 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,876 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,977 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:16,977 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:16,978 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:16,978 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:16,993 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,094 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,094 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,095 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,095 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,110 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,211 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,211 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,212 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,212 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,227 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,328 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,328 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,329 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,329 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,344 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,445 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,445 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,446 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,446 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,464 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,562 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,562 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,563 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,563 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,679 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,679 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,679 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,680 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,698 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,796 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,796 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,796 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,797 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,812 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,913 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:17,913 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:17,913 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:17,913 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:17,931 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,030 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,030 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,030 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,030 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,049 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,147 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,147 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,147 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,148 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,266 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,266 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,282 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,385 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,385 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,386 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,401 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,502 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,502 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,503 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,518 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,620 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,639 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,855 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,870 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,973 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:18,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:18,974 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:18,974 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:18,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,090 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,090 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,091 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,091 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,207 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,207 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,208 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,208 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,227 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,324 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,325 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,325 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,345 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,442 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,461 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,562 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,562 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,563 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,563 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,578 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,680 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,680 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,681 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,681 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,696 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,798 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,798 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,814 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,917 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:19,917 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:19,917 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:19,918 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:19,932 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,035 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,035 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,036 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,036 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,153 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,153 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,154 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,154 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,169 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,271 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,271 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,272 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,272 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,287 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,389 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,389 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,390 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,390 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,405 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,508 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,508 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,508 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,626 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,626 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,626 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,627 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,642 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,743 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,743 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,743 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,743 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,857 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:20,857 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:20,857 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:20,858 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:20,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:31,184 - INFO - Epoch 33/150 - Train Loss: 0.252211, Val Loss: 0.252425
2025-08-07 10:58:31,223 - INFO - New best model saved with Val Loss: 0.252425
2025-08-07 10:58:39,291 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,291 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,292 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,292 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,311 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,409 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,409 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,409 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,428 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,527 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,542 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,646 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,662 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,763 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,763 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,764 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,764 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,779 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,881 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,896 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:39,997 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:39,997 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:39,997 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:39,998 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,130 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,231 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,231 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,246 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,347 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,348 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,464 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,465 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,465 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,483 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,581 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,582 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,582 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,582 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,598 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,698 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,698 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,699 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,714 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,815 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,815 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,816 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,831 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,932 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:40,932 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:40,933 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:40,933 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:40,948 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,050 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,050 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,167 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,401 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,401 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,517 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,517 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,518 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,518 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,533 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,634 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,635 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,635 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,751 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,751 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,752 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,770 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,887 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:41,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:41,985 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:41,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:41,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,001 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,102 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,102 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,336 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,336 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,337 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,337 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,352 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,454 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,454 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,570 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,570 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,571 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,571 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,684 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,684 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,685 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,685 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,703 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,801 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,801 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,802 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,802 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,918 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:42,918 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:42,919 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:42,919 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:42,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,035 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,035 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,036 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,036 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,152 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,152 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,153 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,153 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,171 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,269 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,269 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,270 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,270 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,386 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,387 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,405 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,503 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,503 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,504 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,620 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,870 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:43,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:43,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:43,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:43,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,106 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,204 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,205 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,324 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,324 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,325 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,325 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,441 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,441 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,442 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,442 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,462 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,558 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,558 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,559 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,559 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,789 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,789 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,790 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,790 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,805 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,906 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:44,906 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:44,907 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:44,907 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:44,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,023 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,023 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,023 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,024 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,039 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,140 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,140 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,141 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,141 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,159 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,257 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,257 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,257 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,258 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,275 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,374 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,374 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,374 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,375 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,392 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,491 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,491 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,491 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,491 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,509 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,608 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,608 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,608 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,608 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,623 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,724 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,725 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,725 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,725 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,743 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,841 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,841 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,842 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,842 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,860 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,958 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:45,958 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:45,959 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:45,959 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:45,977 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,075 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,075 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,076 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,076 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,091 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,192 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,192 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,193 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,193 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,211 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,309 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,309 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,310 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,310 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,325 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,426 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,426 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,427 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,427 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,445 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,543 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,543 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,543 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,544 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,562 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,660 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,660 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,660 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,661 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,676 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,777 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,777 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,777 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,777 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,796 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,894 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:46,894 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:46,894 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:46,895 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:46,912 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,011 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,011 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,011 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,029 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,128 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,128 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,128 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,128 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,143 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,245 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,245 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,245 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,245 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,260 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,361 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,361 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,362 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,362 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,377 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,478 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,479 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,479 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,479 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,497 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,595 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,595 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,596 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,596 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,614 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,712 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,712 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,713 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,713 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,731 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,832 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,832 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,833 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,833 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,848 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,949 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:47,949 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:47,950 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:47,950 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:47,968 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:48,066 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:48,066 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:48,066 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:48,067 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:48,084 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:48,180 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:58:48,180 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:58:48,180 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:58:48,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:48,195 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:58:58,928 - INFO - Epoch 34/150 - Train Loss: 0.256122, Val Loss: 0.254114
2025-08-07 10:59:06,780 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:06,780 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:06,781 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:06,781 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:06,798 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:06,897 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:06,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:06,898 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:06,898 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:06,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,015 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,015 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,015 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,015 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,033 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,134 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,134 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,135 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,135 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,150 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,251 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,251 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,252 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,252 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,267 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,368 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,368 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,369 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,369 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,384 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,485 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,485 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,486 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,486 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,501 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,602 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,602 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,603 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,603 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,618 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,719 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,720 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,720 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,720 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,738 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,836 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,837 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,837 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,837 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,855 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,953 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:07,953 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:07,954 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:07,954 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:07,972 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,070 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,070 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,071 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,071 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,089 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,187 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,187 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,188 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,188 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,203 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,304 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,304 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,305 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,305 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,323 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,421 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,421 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,422 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,422 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,440 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,538 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,538 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,539 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,539 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,554 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,655 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,655 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,772 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,772 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,773 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,773 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,788 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,891 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:08,891 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:08,891 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:08,892 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:08,907 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,008 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,008 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,009 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,009 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,027 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,125 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,125 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,126 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,126 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,141 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,242 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,242 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,243 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,243 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,258 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,359 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,359 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,360 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,360 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,378 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,473 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,473 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,474 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,474 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,492 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,590 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,590 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,591 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,591 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,609 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,707 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,707 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,708 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,723 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,824 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,824 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,825 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,825 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,840 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,941 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:09,941 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:09,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:09,942 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:09,957 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,058 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,058 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,058 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,059 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,175 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,175 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,175 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,175 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,193 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,292 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,292 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,293 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,293 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,409 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,409 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,409 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,425 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,527 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,545 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,643 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,661 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,760 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,760 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,760 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,761 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,778 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,877 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,877 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,877 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,877 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:10,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:10,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:10,994 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:10,994 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,009 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,110 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,111 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,129 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,227 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,227 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,228 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,243 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,344 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,344 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,345 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,461 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,462 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,480 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,581 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,581 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,581 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,582 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,597 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,698 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,698 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,698 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,698 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,716 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,815 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,815 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,815 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,815 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,931 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:11,932 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:11,932 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:11,932 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:11,950 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,048 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,049 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,064 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,165 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,165 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,166 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,166 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,181 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,283 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,283 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,301 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,400 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,400 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,418 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,516 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,517 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,517 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,517 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,633 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,634 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,634 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,634 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,649 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,750 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,750 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,751 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,751 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,766 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,867 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,867 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,868 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,868 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,886 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:12,984 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:12,984 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:12,985 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:12,985 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,003 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,120 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,218 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,218 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,351 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,569 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,569 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,570 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,587 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,689 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,689 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,689 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,689 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,705 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,806 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,821 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:13,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:13,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:13,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:13,941 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,042 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,042 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,043 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,043 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,058 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,159 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,159 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,160 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,160 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,175 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,297 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,510 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,510 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,511 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,511 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,526 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,631 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,631 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,632 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,749 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,750 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,750 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,766 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,868 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,868 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,884 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:14,986 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:14,986 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:14,987 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:14,987 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,002 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:15,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:15,105 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:15,105 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,120 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:15,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:15,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:15,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,340 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:15,341 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:15,341 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:15,341 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,357 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,459 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:15,459 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:15,459 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:15,460 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,475 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,577 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:15,577 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:15,578 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:15,578 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,593 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,691 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:15,691 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:15,692 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:15,692 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:15,707 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:26,437 - INFO - Epoch 35/150 - Train Loss: 0.252927, Val Loss: 0.239130
2025-08-07 10:59:26,463 - INFO - New best model saved with Val Loss: 0.239130
2025-08-07 10:59:34,366 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:34,366 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:34,366 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:34,367 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,383 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,483 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:34,483 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:34,484 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:34,484 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,502 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,598 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:34,598 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:34,598 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:34,598 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,616 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,714 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:34,715 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:34,715 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:34,715 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,734 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,832 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:34,832 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:34,832 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:34,833 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,848 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,949 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:34,949 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:34,949 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:34,949 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:34,967 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,066 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,066 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,066 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,067 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,084 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,183 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,183 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,183 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,183 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,202 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,300 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,300 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,300 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,300 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,319 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,419 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,419 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,420 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,420 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,435 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,536 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,536 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,537 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,537 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,552 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,653 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,653 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,654 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,654 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,672 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,770 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,771 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,771 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,771 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,789 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,887 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:35,887 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:35,888 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:35,888 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:35,903 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,004 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,004 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,005 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,005 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,023 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,124 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,124 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,124 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,140 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,241 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,241 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,241 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,242 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,261 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,358 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,358 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,358 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,358 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,374 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,479 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,479 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,479 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,480 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,495 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,597 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,597 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,598 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,598 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,613 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,715 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,715 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,716 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,716 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,731 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,833 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,834 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,834 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,834 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,849 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,952 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:36,952 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:36,952 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:36,953 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:36,968 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,070 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,070 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,071 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,071 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,086 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,188 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,188 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,189 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,189 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,204 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,306 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,307 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,307 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,307 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,425 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,425 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,425 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,425 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,441 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,543 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,543 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,544 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,544 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,559 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,661 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,661 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,662 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,662 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,677 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,779 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,779 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,780 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,780 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,795 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,897 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:37,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:37,898 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:37,898 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:37,913 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,016 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,016 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,016 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,016 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,032 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,134 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,134 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,135 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,135 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,150 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,252 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,252 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,253 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,253 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,268 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,370 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,370 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,371 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,371 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,386 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,488 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,489 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,489 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,489 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,504 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,607 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,607 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,607 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,608 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,623 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,725 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,725 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,726 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,726 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,741 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,843 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,843 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,844 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,844 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,859 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,961 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:38,962 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:38,962 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:38,962 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:38,977 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,079 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,079 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,080 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,080 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,095 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,197 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,198 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,198 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,198 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,213 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,316 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,316 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,316 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,316 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,332 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,434 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,434 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,434 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,435 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,552 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,552 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,553 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,553 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,568 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,670 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,670 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,671 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,671 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,686 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,789 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,789 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,789 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,789 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,805 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,907 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:39,907 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:39,907 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:39,908 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:39,923 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,025 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,025 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,026 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,026 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,041 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,143 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,143 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,144 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,144 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,159 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,261 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,262 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,262 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,262 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,277 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,380 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,380 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,381 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,381 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,396 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,498 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,498 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,499 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,499 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,514 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,616 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,616 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,617 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,617 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,632 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,735 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,735 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,735 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,735 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,751 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,853 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,853 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,869 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:40,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:40,972 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:40,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:40,987 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,089 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,089 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,090 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,090 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,105 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,207 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,208 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,208 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,208 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,326 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,326 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,326 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,326 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,341 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,444 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,444 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,444 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,445 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,460 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,562 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,562 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,563 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,563 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,578 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,680 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,680 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,681 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,681 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,696 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,800 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,800 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,917 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:41,917 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:41,918 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:41,918 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:41,933 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,035 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,035 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,036 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,036 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,153 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,153 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,154 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,154 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,169 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,268 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,268 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,268 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,268 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,284 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,386 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,387 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,402 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,504 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,504 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,505 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,505 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,520 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,622 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,622 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,623 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,623 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,740 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,741 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,741 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,741 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,756 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,859 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,859 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,859 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,859 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,874 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,977 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:42,977 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:42,977 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:42,978 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:42,993 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:43,095 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:43,095 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:43,095 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:43,096 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:43,111 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:43,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:43,213 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:43,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:43,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:43,229 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:43,327 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 10:59:43,327 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 10:59:43,328 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 10:59:43,328 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:43,343 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 10:59:54,106 - INFO - Epoch 36/150 - Train Loss: 0.252351, Val Loss: 0.260743
2025-08-07 11:00:02,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,105 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,105 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,339 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,339 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,573 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,573 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,689 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,690 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,690 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,807 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,807 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,825 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,926 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:02,926 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:02,927 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:02,927 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:02,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,043 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,043 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,044 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,044 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,062 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,160 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,160 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,161 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,161 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,277 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,277 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,278 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,278 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,296 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,394 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,394 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,395 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,410 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,628 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,629 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,745 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,745 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,746 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,746 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,764 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,862 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,862 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,862 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,863 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,881 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,979 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:03,979 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:03,979 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:03,979 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:03,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,096 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,096 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,096 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,096 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,114 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,214 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,215 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,215 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,230 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,331 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,332 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,332 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,448 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,448 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,449 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,449 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,467 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,568 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,568 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,569 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,584 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,685 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,685 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,686 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,686 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,701 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,802 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,802 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,803 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,803 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,821 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,919 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:04,919 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:04,920 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:04,920 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:04,938 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,036 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,036 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,037 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,037 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,052 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,153 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,153 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,154 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,154 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,270 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,270 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,271 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,271 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,286 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,387 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,387 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,388 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,388 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,406 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,504 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,504 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,505 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,505 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,621 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,621 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,622 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,622 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,637 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,738 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,738 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,739 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,739 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,757 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,857 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,857 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,858 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,858 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,974 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:05,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:05,975 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:05,975 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:05,992 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,091 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,091 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,091 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,092 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,109 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,211 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,226 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,327 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,327 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,328 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,328 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,346 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,444 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,444 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,445 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,445 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,463 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,564 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,564 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,681 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,681 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,701 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,802 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,802 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,803 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,803 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,818 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:06,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:06,921 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:06,921 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:06,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,038 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,038 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,157 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,157 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,158 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,291 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,394 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,511 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,511 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,512 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,527 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,630 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,645 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,748 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,748 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,749 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,749 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,765 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,867 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,867 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,867 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,882 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:07,985 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:07,985 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:07,985 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:07,985 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,103 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,119 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,457 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,457 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,458 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,458 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,473 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,575 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,575 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,576 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,694 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,710 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,812 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,812 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,813 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:08,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:08,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:08,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:08,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,048 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,048 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,049 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,064 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,167 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,285 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,285 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,286 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,301 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,403 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,521 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,522 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,522 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,522 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,537 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,640 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,640 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,758 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,758 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,759 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,759 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,774 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,876 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,876 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,877 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,877 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,892 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:09,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:09,995 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:09,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:09,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,010 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,113 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,113 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,113 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,129 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,247 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,349 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,349 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,350 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,350 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,365 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,467 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,467 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,483 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,586 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,586 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,586 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,704 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,704 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,704 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,705 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,720 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,822 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,822 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,823 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,823 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,940 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:10,940 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:10,941 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:10,941 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:10,956 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:11,054 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:11,054 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:11,055 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:11,055 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:11,070 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:21,508 - INFO - Epoch 37/150 - Train Loss: 0.246726, Val Loss: 0.250859
2025-08-07 11:00:29,366 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:29,366 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:29,366 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:29,367 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,383 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,486 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:29,486 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:29,487 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:29,487 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,505 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,603 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:29,603 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:29,604 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:29,604 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,622 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,722 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:29,723 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:29,723 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:29,723 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,738 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,842 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:29,842 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:29,843 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:29,843 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,858 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,959 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:29,959 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:29,960 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:29,960 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:29,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,076 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,076 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,077 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,077 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,096 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,193 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,193 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,193 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,194 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,213 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,313 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,313 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,314 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,314 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,329 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,431 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,432 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,432 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,447 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,546 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,546 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,547 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,547 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,562 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,665 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,665 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,665 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,665 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,681 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,784 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,784 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,785 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,785 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,903 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:30,903 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:30,903 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:30,903 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:30,919 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,021 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,021 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,022 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,022 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,037 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,139 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,139 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,140 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,140 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,155 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,257 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,257 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,258 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,258 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,273 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,375 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,375 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,376 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,376 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,391 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,494 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,494 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,494 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,509 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,612 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,612 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,613 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,613 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,628 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,730 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,730 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,731 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,731 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,746 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,848 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,848 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,849 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,849 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,864 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:31,967 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:31,967 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:31,967 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:31,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,085 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,085 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,086 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,086 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,102 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,203 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,203 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,204 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,204 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,219 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,321 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,337 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,440 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,440 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,441 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,441 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,456 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,558 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,558 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,559 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,559 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,574 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,676 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,676 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,677 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,677 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,692 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,795 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,795 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,795 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,795 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,811 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,913 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:32,913 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:32,913 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:32,914 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:32,929 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,031 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,031 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,032 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,032 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,047 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,149 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,149 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,150 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,150 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,267 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,267 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,268 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,268 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,284 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,385 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,386 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,401 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,504 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,504 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,504 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,505 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,520 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,622 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,622 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,623 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,623 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,740 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,740 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,741 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,741 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,756 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,858 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,858 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,859 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,859 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,875 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,977 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:33,977 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:33,977 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:33,977 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:33,992 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,095 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,095 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,096 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,096 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,111 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,213 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,229 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,331 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,332 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,332 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,347 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,449 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,449 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,450 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,450 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,465 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,567 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,567 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,568 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,568 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,583 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,686 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,686 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,686 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,687 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,702 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,804 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,804 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,805 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,805 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,820 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:34,922 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:34,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:34,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:34,938 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,040 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,041 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,041 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,159 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,174 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,277 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,277 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,278 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,293 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,396 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,411 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,513 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,513 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,514 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,514 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,631 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,632 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,647 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,750 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,750 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,750 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,765 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,868 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,868 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,869 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,884 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:35,986 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:35,986 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:35,987 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:35,987 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,002 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,103 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,104 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,104 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,119 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,458 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,458 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,458 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,458 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,474 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,576 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,710 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,812 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,812 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,813 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,813 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:36,931 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:36,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:36,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:36,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,049 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,183 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,285 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,285 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,286 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,301 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,404 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,404 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,405 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,522 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,522 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,522 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,523 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,538 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,640 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,758 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,758 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,759 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,759 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,774 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,876 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,876 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,877 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,877 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,892 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:37,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:37,995 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:37,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:37,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,010 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,108 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:38,109 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:38,109 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:38,109 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,128 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,225 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:38,226 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:38,226 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:38,226 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,241 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:38,340 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:38,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:38,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:38,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:48,707 - INFO - Epoch 38/150 - Train Loss: 0.245277, Val Loss: 0.231215
2025-08-07 11:00:48,733 - INFO - New best model saved with Val Loss: 0.231215
2025-08-07 11:00:56,342 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:56,342 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:56,343 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:56,343 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,460 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:56,460 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:56,461 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:56,461 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,479 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,577 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:56,577 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:56,578 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:56,578 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,596 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,694 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:56,694 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:56,695 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:56,695 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,713 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,811 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:56,811 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:56,812 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:56,812 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,830 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,928 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:56,928 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:56,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:56,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:56,947 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,045 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,045 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,046 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,046 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,064 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,162 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,162 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,163 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,163 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,178 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,279 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,279 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,280 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,280 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,396 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,397 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,397 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,397 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,415 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,513 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,513 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,514 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,514 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,532 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,630 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,630 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,631 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,631 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,646 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,747 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,748 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,748 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,748 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,766 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,864 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,865 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,865 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:57,984 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:57,984 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:57,985 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:57,985 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,117 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,218 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,218 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,452 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,452 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,453 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,453 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,468 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,571 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,571 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,572 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,572 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,688 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,688 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,689 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,689 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,707 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,805 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,806 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,806 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,821 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,922 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:58,922 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:58,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:58,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:58,941 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,039 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,039 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,040 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,055 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,175 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,295 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,645 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,762 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,863 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,863 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:00:59,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:00:59,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:00:59,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:00:59,980 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,000 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,097 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,097 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,097 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,117 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,337 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,337 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,338 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,338 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,353 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,455 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,455 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,574 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,574 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,575 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,692 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,692 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,693 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,811 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,811 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,928 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:00,928 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:00,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:00,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:00,944 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,046 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,165 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,165 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,165 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,165 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,181 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,402 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,402 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,403 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,403 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,418 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,639 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,639 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,639 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,639 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,655 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,757 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,757 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,757 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,758 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,875 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,876 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,876 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,891 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:01,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:01,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:01,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:01,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,012 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,115 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,115 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,116 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,116 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,131 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,234 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,234 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,235 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,235 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,352 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,352 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,353 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,353 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,368 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,470 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,471 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,471 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,589 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,589 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,589 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,605 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,707 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,707 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,708 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,723 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,825 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,825 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,826 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,826 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,841 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,941 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:02,941 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:02,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:02,942 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:02,957 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,060 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,060 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,075 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,177 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,178 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,178 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,178 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,193 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,296 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,296 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,296 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,297 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,312 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,414 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,414 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,415 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,415 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,430 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,532 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,532 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,533 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,533 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,548 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,650 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,650 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,651 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,651 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,666 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,769 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,769 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,769 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,770 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,784 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,887 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:03,887 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:03,888 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:03,888 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:03,903 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,005 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,005 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,006 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,006 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,021 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,123 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,123 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,124 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,124 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,139 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,242 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,242 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,242 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,242 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,258 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,360 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,360 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,361 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,361 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,376 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,478 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,478 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,479 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,479 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,494 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,596 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,596 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,597 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,597 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,612 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,715 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,715 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,715 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,715 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,730 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,833 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,833 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,833 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,834 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,849 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,951 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:04,951 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:04,952 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:04,952 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:04,967 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:05,069 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:05,069 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:05,070 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:05,070 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:05,085 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:05,188 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:05,188 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:05,188 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:05,188 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:05,203 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:05,301 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:05,302 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:05,302 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:05,302 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:05,317 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:15,927 - INFO - Epoch 39/150 - Train Loss: 0.240495, Val Loss: 0.248638
2025-08-07 11:01:23,541 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:23,541 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:23,542 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:23,542 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,559 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,659 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:23,659 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:23,659 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:23,660 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,678 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,776 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:23,776 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:23,777 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:23,777 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,795 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,893 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:23,893 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:23,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:23,894 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:23,912 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,010 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,010 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,010 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,010 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,028 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,126 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,127 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,127 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,127 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,143 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,246 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,247 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,247 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,247 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,262 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,363 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,363 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,364 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,364 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,382 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,480 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,480 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,481 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,481 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,496 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,597 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,597 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,598 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,598 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,613 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,714 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,714 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,715 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,715 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,733 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,831 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,831 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,832 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,832 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,847 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,948 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:24,948 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:24,949 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:24,949 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:24,967 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,065 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,065 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,066 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,066 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,084 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,182 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,182 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,183 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,183 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,198 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,299 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,299 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,300 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,300 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,318 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,416 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,416 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,417 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,417 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,435 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,533 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,533 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,534 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,534 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,549 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,650 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,650 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,651 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,651 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,666 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,767 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,767 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,768 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,768 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,783 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,884 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:25,884 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:25,885 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:25,885 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:25,902 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,001 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,001 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,001 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,002 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,017 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,118 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,118 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,118 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,118 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,136 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,237 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,237 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,238 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,238 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,253 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,354 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,354 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,355 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,355 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,373 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,588 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,588 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,589 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,604 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,705 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,705 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,706 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,706 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,721 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,822 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,822 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,823 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,823 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,942 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:26,942 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:26,942 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:26,943 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:26,958 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,059 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,059 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,176 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,176 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,176 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,194 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,295 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,295 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,296 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,296 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,311 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,412 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,412 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,413 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,413 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,432 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,529 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,529 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,530 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,530 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,549 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,647 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,666 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,763 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,763 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,764 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,764 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,783 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,881 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,901 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:27,997 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:27,997 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:27,998 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:27,998 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,018 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,115 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,115 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,135 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,247 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,465 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,465 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,485 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,582 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,700 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,715 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,816 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,816 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,817 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,836 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,937 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:28,937 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:28,938 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:28,938 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:28,953 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,173 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,174 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,174 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,174 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,189 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,292 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,292 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,293 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,293 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,410 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,410 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,411 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,411 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,426 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,528 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,528 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,529 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,529 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,544 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,646 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,647 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,662 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,765 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,765 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,766 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,766 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,781 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,883 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:29,883 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:29,884 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:29,884 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:29,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,001 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,002 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,002 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,002 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,017 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,120 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,120 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,120 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,121 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,136 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,238 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,238 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,239 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,239 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,356 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,356 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,357 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,357 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,372 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,474 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,475 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,475 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,475 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,490 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,593 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,593 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,593 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,593 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,609 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,711 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,711 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,712 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,712 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,727 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,829 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,829 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,830 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,830 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,845 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,948 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:30,948 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:30,948 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:30,948 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:30,963 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,066 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,066 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,067 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,067 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,082 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,180 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,180 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,200 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,297 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,297 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,298 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,298 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,317 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,414 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,414 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,415 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,415 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,430 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,531 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,531 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,532 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,532 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,551 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,648 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,648 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,649 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,649 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,664 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,765 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,765 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,765 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,765 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,781 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,882 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,882 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,882 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,882 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,897 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:31,998 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:31,999 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:31,999 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:31,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,014 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,115 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:32,115 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:32,116 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:32,116 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,135 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,232 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:32,232 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:32,233 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:32,233 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,252 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,349 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:32,349 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:32,350 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:32,350 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,365 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,463 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:32,463 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:32,464 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:32,464 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:32,479 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:43,188 - INFO - Epoch 40/150 - Train Loss: 0.242985, Val Loss: 0.232438
2025-08-07 11:01:51,033 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,034 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,034 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,053 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,150 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,150 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,151 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,151 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,270 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,270 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,271 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,271 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,286 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,390 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,390 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,390 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,391 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,406 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,507 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,507 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,507 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,507 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,623 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,623 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,624 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,624 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,639 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,740 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,740 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,741 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,741 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,759 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,857 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,857 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,858 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,858 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,876 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,974 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:51,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:51,975 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:51,975 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:51,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,091 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,091 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,092 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,092 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,107 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,208 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,208 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,209 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,209 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,227 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,325 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,325 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,326 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,326 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,341 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,442 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,442 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,443 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,443 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,458 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,559 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,559 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,559 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,560 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,575 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,676 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,676 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,676 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,676 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,793 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,793 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,909 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:52,909 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:52,910 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:52,910 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:52,926 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,026 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,027 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,027 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,027 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,143 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,143 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,144 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,144 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,162 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,260 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,260 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,261 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,261 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,377 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,377 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,378 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,378 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,393 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,494 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,494 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,495 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,495 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,510 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,611 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,611 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,612 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,612 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,630 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,728 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,728 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,729 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,746 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,845 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,845 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,845 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,861 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,962 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:53,962 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:53,962 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:53,962 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:53,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,078 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,079 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,079 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,079 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,094 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,195 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,196 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,196 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,196 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,214 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,315 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,315 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,316 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,316 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,331 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,432 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,432 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,432 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,433 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,549 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,549 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,549 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,550 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,567 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,666 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,666 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,666 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,667 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,684 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,783 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,783 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,783 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,783 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,899 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:54,900 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:54,900 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:54,900 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:54,918 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,016 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,016 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,017 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,017 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,032 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,133 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,133 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,134 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,134 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,152 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,250 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,250 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,251 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,251 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,269 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,367 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,367 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,368 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,368 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,383 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,484 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,484 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,484 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,484 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,499 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,601 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,601 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,601 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,601 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,620 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,717 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,717 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,718 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,718 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,733 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,834 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,834 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,835 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,835 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,853 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,954 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:55,954 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:55,954 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:55,955 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:55,970 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,071 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,071 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,071 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,071 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,091 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,187 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,188 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,188 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,188 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,203 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,304 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,304 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,305 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,305 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,325 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,421 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,421 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,422 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,422 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,445 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,538 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,539 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,539 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,539 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,559 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,655 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,655 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,656 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,675 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,772 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,772 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,773 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,773 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,788 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,889 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:56,889 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:56,890 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:56,890 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:56,910 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,006 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,006 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,007 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,007 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,120 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,120 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,121 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,121 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,139 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,237 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,237 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,238 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,238 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,256 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,354 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,354 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,355 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,355 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,370 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,588 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,588 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,589 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,607 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,705 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,705 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,706 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,706 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,724 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,822 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,822 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,823 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,823 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,838 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,939 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:57,939 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:57,940 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:57,940 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:57,957 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,056 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,056 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,057 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,173 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,173 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,173 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,173 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,189 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,290 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,290 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,290 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,290 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,306 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,407 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,407 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,407 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,426 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,523 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,524 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,524 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,524 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,539 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,640 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,640 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,641 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,641 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,757 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,757 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,758 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,758 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,776 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,874 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:58,988 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:58,988 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:58,989 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:58,989 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,105 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,105 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,106 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,355 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,459 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,459 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,460 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,460 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,475 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,576 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,576 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,577 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,577 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,592 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,694 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,713 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,810 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,811 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,830 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:01:59,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:01:59,924 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:01:59,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:01:59,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:10,710 - INFO - Epoch 41/150 - Train Loss: 0.239731, Val Loss: 0.232626
2025-08-07 11:02:18,157 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,158 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,158 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,178 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,395 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,395 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,395 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,396 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,411 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,512 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,648 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,764 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,863 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,863 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,881 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:18,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:18,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:18,981 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:18,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,097 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,097 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,097 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,113 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,214 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,229 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,330 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,331 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,349 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,448 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,467 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,583 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,698 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,915 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:19,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:19,916 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:19,916 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:19,931 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,048 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,149 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,149 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,150 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,150 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,383 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,384 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,384 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,402 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,500 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,501 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,501 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,617 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,617 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,618 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,618 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,636 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,855 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,873 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:20,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:20,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:20,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:20,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,088 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,104 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,205 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,205 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,224 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,327 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,327 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,328 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,328 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,343 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,445 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,445 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,446 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,446 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,461 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,563 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,563 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,564 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,564 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,579 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,681 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,698 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,800 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,800 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,800 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,801 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,816 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,918 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:21,918 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:21,919 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:21,919 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:21,934 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,037 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,037 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,037 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,037 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,052 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,156 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,270 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,270 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,271 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,271 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,286 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,388 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,388 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,389 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,389 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,404 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,506 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,507 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,507 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,507 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,522 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,621 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,621 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,621 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,621 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,641 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,738 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,738 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,855 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,855 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,855 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,874 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:22,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:22,972 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:22,972 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:22,992 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,088 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,089 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,089 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,104 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,202 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,203 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,203 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,203 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,221 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,319 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,320 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,320 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,320 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,338 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,436 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,436 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,437 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,437 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,455 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,553 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,553 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,554 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,554 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,572 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,670 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,670 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,671 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,671 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,687 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,787 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,788 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,788 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,788 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,806 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,904 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:23,904 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:23,905 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:23,905 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:23,923 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,021 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,021 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,022 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,022 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,037 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,138 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,138 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,139 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,139 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,157 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,255 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,255 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,256 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,256 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,271 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,372 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,372 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,373 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,373 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,388 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,489 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,490 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,490 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,490 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,505 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,606 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,606 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,607 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,607 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,622 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,723 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,723 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,724 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,724 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,739 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,840 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,840 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,841 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,841 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,856 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,957 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:24,957 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:24,958 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:24,958 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:24,973 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,074 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,074 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,075 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,075 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,093 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,191 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,191 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,192 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,192 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,210 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,308 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,308 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,308 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,309 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,326 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,425 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,425 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,425 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,425 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,443 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,541 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,542 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,542 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,542 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,560 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,658 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,658 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,659 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,659 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,677 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,775 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,775 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,776 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,776 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,791 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,892 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:25,892 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:25,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:25,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:25,908 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,009 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,009 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,010 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,010 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,025 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,126 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,126 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,127 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,127 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,142 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,244 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,262 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,360 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,360 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,360 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,361 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,378 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,477 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,477 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,477 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,478 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,496 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,594 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,594 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,594 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,594 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,612 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,711 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,711 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,711 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,711 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,727 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,827 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,828 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,828 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,828 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,844 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:26,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:26,945 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:26,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:26,963 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:27,058 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:27,058 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:27,059 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:27,059 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:27,074 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:37,739 - INFO - Epoch 42/150 - Train Loss: 0.241386, Val Loss: 0.225929
2025-08-07 11:02:37,765 - INFO - New best model saved with Val Loss: 0.225929
2025-08-07 11:02:45,578 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:45,578 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:45,579 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:45,579 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,595 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,698 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:45,698 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:45,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:45,699 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,714 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,815 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:45,815 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:45,816 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:45,816 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,831 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,932 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:45,932 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:45,933 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:45,933 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:45,951 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,050 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,050 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,068 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,167 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,182 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,398 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,398 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,398 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,398 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,515 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,515 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,515 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,515 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,534 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,632 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,632 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,632 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,632 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,650 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,749 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,749 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,749 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,750 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,768 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,866 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,866 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,867 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,867 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:46,983 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:46,983 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:46,984 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:46,984 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,002 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,100 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,100 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,101 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,101 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,217 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,217 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,218 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,218 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,233 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,334 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,334 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,335 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,335 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,451 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,451 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,452 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,452 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,470 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,568 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,568 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,569 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,569 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,587 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,685 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,685 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,686 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,686 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,704 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,805 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,805 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,805 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,805 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,820 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:47,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:47,925 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:47,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:47,940 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,042 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,042 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,042 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,042 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,058 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,159 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,159 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,175 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,276 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,276 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,277 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,277 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,297 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,393 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,393 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,394 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,510 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,510 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,510 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,511 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,530 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,628 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,629 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,644 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,743 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,743 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,744 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,744 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,759 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,861 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,861 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,862 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,862 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,877 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:48,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:48,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:48,981 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:48,995 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,098 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,098 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,099 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,099 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,115 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,217 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,217 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,217 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,217 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,233 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,335 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,335 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,336 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,336 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,351 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,453 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,453 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,454 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,454 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,469 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,572 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,572 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,572 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,572 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,588 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,706 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,808 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,808 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,809 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,809 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,824 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,926 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:49,927 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:49,927 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:49,927 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:49,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,045 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,045 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,045 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,046 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,060 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,163 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,163 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,164 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,179 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,282 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,282 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,282 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,283 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,298 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,400 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,400 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,401 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,401 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,416 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,518 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,518 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,519 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,519 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,534 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,636 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,637 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,637 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,652 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,755 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,755 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,771 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,873 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,873 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,874 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,874 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,889 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:50,991 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:50,991 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:50,992 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:50,992 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,110 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,110 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,110 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,110 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,125 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,228 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,229 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,243 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,346 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,346 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,347 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,347 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,362 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,464 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,464 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,465 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,480 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,583 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,599 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,701 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,701 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,819 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,820 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,820 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,835 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,937 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:51,937 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:51,938 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:51,938 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:51,953 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,174 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,174 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,174 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,174 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,189 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,292 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,292 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,292 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,293 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,410 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,410 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,411 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,411 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,426 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,527 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,527 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,528 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,528 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,547 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,644 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,644 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,645 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,645 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,664 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,761 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,761 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,762 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,762 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,878 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,878 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,879 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,879 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,898 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:52,998 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:52,998 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:52,999 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:52,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,014 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,117 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,117 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,133 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,235 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,235 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,235 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,236 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,353 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,353 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,354 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,354 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,369 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,472 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,472 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,472 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,487 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,590 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,590 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,590 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,590 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,606 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,708 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,708 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,709 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,709 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,724 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,826 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,826 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,827 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,827 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,842 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:53,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:53,945 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:53,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:53,960 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,063 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:54,063 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:54,063 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:54,063 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,181 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:54,181 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:54,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:54,182 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,197 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,299 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:54,299 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:54,300 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:54,300 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,315 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,417 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:54,417 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:54,418 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:54,418 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,433 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,531 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:02:54,531 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:02:54,532 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:02:54,532 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:02:54,547 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:05,275 - INFO - Epoch 43/150 - Train Loss: 0.241968, Val Loss: 0.230486
2025-08-07 11:03:12,960 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:12,960 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:12,961 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:12,961 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:12,980 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,078 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,078 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,078 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,078 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,094 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,197 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,198 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,198 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,198 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,213 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,314 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,315 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,315 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,315 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,333 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,431 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,432 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,432 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,432 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,551 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,551 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,552 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,552 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,567 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,668 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,668 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,669 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,669 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,687 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,785 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,785 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,786 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,786 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,801 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,902 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:13,902 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:13,903 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:13,903 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:13,918 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,019 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,019 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,019 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,020 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,035 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,136 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,136 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,136 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,136 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,154 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,253 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,253 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,253 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,253 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,271 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,369 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,370 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,370 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,370 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,386 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,489 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,489 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,490 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,490 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,505 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,609 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,609 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,610 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,610 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,625 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,726 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,726 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,727 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,727 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,745 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,843 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,843 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,843 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,844 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,859 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,960 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:14,960 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:14,960 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:14,960 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:14,976 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,077 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,077 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,077 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,078 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,093 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,196 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,196 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,197 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,197 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,212 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,318 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,318 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,333 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,436 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,436 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,436 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,436 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,452 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,554 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,554 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,555 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,555 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,570 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,688 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,790 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,791 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,791 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,791 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,806 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,909 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:15,909 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:15,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:15,910 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:15,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,027 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,027 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,028 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,028 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,043 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,145 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,145 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,146 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,146 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,161 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,264 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,264 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,264 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,265 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,281 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,382 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,500 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,501 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,501 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,516 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,619 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,619 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,855 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,855 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,856 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,856 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,871 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,973 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:16,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:16,974 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:16,974 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:16,989 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,092 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,092 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,092 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,210 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,210 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,226 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,328 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,328 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,329 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,329 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,344 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,446 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,446 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,447 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,447 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,462 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,564 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,683 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,683 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,683 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,683 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,699 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,801 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,801 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,802 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,802 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,919 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:17,919 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:17,920 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:17,920 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:17,935 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,037 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,037 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,038 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,038 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,053 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,156 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,156 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,274 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,275 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,290 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,408 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,510 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,510 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,511 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,511 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,526 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,629 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,644 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,747 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,747 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,748 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,763 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,865 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,865 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,866 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,866 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,881 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,983 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:18,983 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:18,984 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:18,984 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:18,999 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,117 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,220 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,236 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,338 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,338 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,338 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,339 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,574 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,574 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,575 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,575 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,693 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,693 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,693 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,811 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,811 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,812 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,812 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,827 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,929 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:19,929 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:19,930 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:19,930 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:19,945 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,048 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,048 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,165 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,166 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,166 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,181 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,284 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,285 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,285 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,402 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,402 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,403 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,403 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,418 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,521 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,521 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,537 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,639 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,639 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,639 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,640 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,655 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,757 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,757 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,758 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,758 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,773 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,875 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,876 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,876 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,891 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:20,993 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:20,993 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:20,994 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:20,994 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,009 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,112 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,112 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,230 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,230 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,230 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,230 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,245 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,466 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,466 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,467 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,467 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,482 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,584 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,584 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,600 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,703 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,703 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,820 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,820 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,821 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,821 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,836 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,934 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:21,934 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:21,935 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:21,935 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:21,950 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:32,611 - INFO - Epoch 44/150 - Train Loss: 0.234483, Val Loss: 0.225402
2025-08-07 11:03:32,655 - INFO - New best model saved with Val Loss: 0.225402
2025-08-07 11:03:40,465 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:40,466 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:40,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:40,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,583 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:40,583 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:40,584 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:40,584 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,602 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:40,701 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:40,701 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:40,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:40,818 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:40,818 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:40,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,834 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,935 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:40,935 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:40,935 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:40,935 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:40,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,054 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,055 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,055 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,070 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,171 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,172 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,172 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,172 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,187 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,288 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,288 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,289 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,289 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,307 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,405 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,405 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,406 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,406 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,421 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,522 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,522 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,523 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,523 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,538 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,639 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,639 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,640 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,640 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,655 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,756 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,756 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,757 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,757 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,775 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,873 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,873 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,874 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,874 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,892 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:41,987 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:41,987 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:41,988 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:41,988 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,006 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,104 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,104 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,105 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,105 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,123 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,221 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,240 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,338 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,338 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,339 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,339 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,357 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,455 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,455 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,473 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,572 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,572 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,572 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,573 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,689 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,689 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,690 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,690 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,806 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,806 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,807 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,807 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,822 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,923 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:42,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:42,923 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:42,923 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:42,939 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,040 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,040 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,040 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,058 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,157 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,175 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,274 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,274 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,391 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,391 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,392 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,392 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,410 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,508 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,509 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,509 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,524 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,625 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,625 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,626 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,626 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,641 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,742 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,742 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,742 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,743 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,760 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,859 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,859 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,859 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,859 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,877 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,978 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:43,978 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:43,979 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:43,979 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:43,994 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,095 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,095 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,096 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,096 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,111 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,212 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,212 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,213 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,213 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,231 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,329 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,329 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,330 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,330 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,345 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,463 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,564 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,564 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,565 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,565 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,580 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,681 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,681 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,682 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,697 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,798 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,798 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,818 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,915 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:44,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:44,915 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:44,915 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:44,935 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,032 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,032 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,032 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,047 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,148 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,148 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,149 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,149 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,164 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,265 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,265 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,266 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,266 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,382 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,402 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,499 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,499 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,500 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,500 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,616 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,616 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,616 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,616 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,632 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,733 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,733 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,733 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,733 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,849 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,850 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,850 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,850 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,870 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,966 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:45,966 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:45,967 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:45,967 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:45,982 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,083 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,083 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,084 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,084 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,103 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,200 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,200 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,201 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,201 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,220 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,317 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,317 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,318 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,318 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,337 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,434 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,434 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,435 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,435 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,450 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,551 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,551 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,551 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,552 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,571 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,672 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,688 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,790 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,790 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,791 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,791 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,806 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:46,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:46,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:46,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:46,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,026 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,027 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,027 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,027 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,042 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,144 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,145 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,145 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,145 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,160 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,263 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,263 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,263 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,263 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,279 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,377 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,377 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,377 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,378 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,397 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,494 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,494 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,494 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,494 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,510 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,610 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,611 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,611 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,611 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,631 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,727 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,728 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,728 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,728 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,748 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,844 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,844 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,845 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,865 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,965 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:47,966 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:47,966 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:47,966 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:47,981 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,084 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,084 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,084 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,084 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,100 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,202 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,202 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,202 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,203 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,218 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,320 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,320 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,321 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,321 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,336 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,438 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,438 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,454 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,556 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,556 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,557 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,557 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,572 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,674 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,675 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,675 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,675 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,690 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,793 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,793 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,793 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,793 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,809 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,911 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:48,911 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:48,912 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:48,912 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:48,927 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,029 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:49,029 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:49,030 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:49,030 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,045 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,147 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:49,147 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:49,148 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:49,148 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,163 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,265 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:49,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:49,266 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:49,266 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,281 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,379 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:03:49,380 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:03:49,380 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:03:49,380 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:03:49,395 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:00,073 - INFO - Epoch 45/150 - Train Loss: 0.228923, Val Loss: 0.225562
2025-08-07 11:04:07,896 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:07,896 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:07,897 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:07,897 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:07,916 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,013 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,013 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,014 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,014 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,032 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,128 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,128 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,129 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,129 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,147 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,245 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,245 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,246 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,246 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,264 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,365 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,365 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,365 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,366 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,381 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,482 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,482 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,482 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,483 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,498 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,599 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,599 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,599 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,599 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,615 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,716 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,716 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,716 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,716 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,732 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,832 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,832 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,833 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,833 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,848 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,949 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:08,949 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:08,950 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:08,950 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:08,965 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,066 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,066 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,067 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,067 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,085 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,183 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,183 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,184 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,184 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,202 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,300 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,300 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,301 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,301 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,319 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,417 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,417 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,418 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,418 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,433 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,534 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,534 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,535 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,535 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,550 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,651 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,651 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,652 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,652 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,667 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,768 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,768 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,769 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,769 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,784 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,885 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:09,885 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:09,886 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:09,886 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:09,901 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,002 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,002 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,002 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,003 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,018 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,119 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,119 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,119 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,119 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,135 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,236 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,236 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,236 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,236 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,352 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,352 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,353 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,353 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,371 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,469 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,469 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,470 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,470 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,485 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,589 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,589 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,590 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,590 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,605 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,706 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,706 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,707 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,707 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,725 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,823 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,823 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,824 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,824 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,839 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,940 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:10,940 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:10,941 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:10,941 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:10,959 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,057 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,057 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,058 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,058 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,076 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,176 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,177 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,177 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,177 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,192 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,297 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,298 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,298 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,298 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,313 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,416 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,416 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,416 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,416 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,432 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,534 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,534 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,535 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,535 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,550 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,652 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,652 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,653 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,653 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,770 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,771 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,771 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,771 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,787 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,889 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:11,889 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:11,889 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:11,889 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:11,905 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,007 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,007 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,008 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,008 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,023 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,125 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,125 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,126 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,126 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,141 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,244 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,259 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,362 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,362 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,362 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,362 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,378 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,480 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,480 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,481 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,481 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,496 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,598 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,598 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,599 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,599 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,614 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,716 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,717 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,717 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,717 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,733 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,835 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,835 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,835 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,835 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,851 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,953 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:12,953 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:12,954 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:12,954 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:12,969 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,071 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,071 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,072 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,072 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,087 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,189 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,189 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,190 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,190 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,205 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,307 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,308 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,308 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,308 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,324 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,426 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,426 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,426 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,427 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,442 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,544 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,544 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,545 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,545 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,560 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,662 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,662 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,663 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,663 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,678 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,780 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,780 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,781 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,781 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,796 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,898 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:13,898 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:13,899 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:13,899 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:13,914 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,017 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,017 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,017 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,017 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,033 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,135 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,135 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,136 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,136 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,151 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,253 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,253 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,254 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,254 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,269 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,371 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,371 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,372 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,372 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,387 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,490 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,490 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,491 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,491 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,506 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,608 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,608 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,609 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,609 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,624 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,726 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,726 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,727 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,727 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,742 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,844 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,844 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,845 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,845 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,860 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,963 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:14,963 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:14,963 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:14,963 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:14,978 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,081 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,081 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,081 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,082 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,097 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,199 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,199 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,200 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,200 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,215 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,317 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,317 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,318 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,318 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,333 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,435 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,436 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,436 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,436 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,451 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,554 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,554 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,554 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,554 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,570 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,672 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,688 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,790 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,790 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,791 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,791 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,806 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,908 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:15,908 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:15,909 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:15,909 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:15,924 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,026 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,026 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,027 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,027 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,042 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,141 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,141 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,142 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,142 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,157 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,259 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,259 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,260 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,260 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,275 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,377 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,378 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,378 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,378 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,393 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,496 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,496 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,496 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,496 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,512 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,614 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,614 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,615 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,615 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,630 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,732 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,733 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,733 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,733 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,748 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,846 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:16,847 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:16,847 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:16,847 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:16,862 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:27,522 - INFO - Epoch 46/150 - Train Loss: 0.230366, Val Loss: 0.233873
2025-08-07 11:04:35,547 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:35,547 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:35,548 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:35,548 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,564 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,667 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:35,667 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:35,668 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:35,668 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,683 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,784 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:35,784 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:35,785 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:35,785 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,803 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,901 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:35,901 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:35,901 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:35,902 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:35,917 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,018 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,018 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,019 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,019 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,034 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,135 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,135 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,135 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,136 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,154 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,252 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,252 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,252 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,253 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,268 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,369 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,369 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,369 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,369 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,387 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,488 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,489 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,489 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,489 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,504 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,605 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,605 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,606 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,606 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,621 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,722 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,722 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,723 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,723 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,741 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,839 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,839 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,840 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,840 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,858 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,956 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:36,956 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:36,957 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:36,957 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:36,975 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,073 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,073 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,074 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,074 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,092 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,190 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,190 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,191 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,191 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,209 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,307 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,307 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,308 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,308 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,326 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,424 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,424 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,425 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,425 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,443 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,541 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,541 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,542 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,542 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,560 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,658 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,658 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,659 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,659 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,775 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,775 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,776 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,776 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,794 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,892 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:37,892 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:37,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:37,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:37,908 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,009 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,009 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,010 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,010 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,025 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,126 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,126 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,127 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,127 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,145 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,240 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,240 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,241 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,241 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,259 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,357 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,357 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,358 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,358 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,373 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,474 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,474 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,475 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,475 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,493 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,591 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,591 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,592 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,592 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,610 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,708 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,708 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,709 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,709 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,724 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,825 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,825 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,826 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,826 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,841 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,942 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:38,942 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:38,943 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:38,943 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:38,958 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,059 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,059 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,060 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,060 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,176 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,176 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,177 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,177 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,195 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,293 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,293 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,294 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,294 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,312 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,410 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,410 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,411 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,411 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,429 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,527 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,527 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,528 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,543 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,644 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,644 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,645 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,660 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,761 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,761 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,761 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,761 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,878 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,878 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,878 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,878 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:39,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:39,995 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:39,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:39,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,013 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,114 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,114 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,115 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,115 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,130 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,232 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,232 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,248 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,349 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,349 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,349 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,365 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,466 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,466 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,482 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,582 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,583 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,583 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,603 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,700 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,700 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,719 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,816 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,816 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,817 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,817 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,832 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:40,933 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:40,934 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:40,934 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:40,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,050 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,050 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,051 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,051 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,187 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,289 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,289 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,289 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,289 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,305 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,407 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,407 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,407 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,408 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,422 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,525 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,525 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,526 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,526 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,541 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,643 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,761 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,761 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,762 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,762 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,777 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,879 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,880 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,880 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,896 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:41,998 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:41,998 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:41,998 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:41,999 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,014 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,116 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,116 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,117 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,117 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,132 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,234 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,234 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,235 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,235 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,352 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,352 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,353 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,353 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,368 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,471 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,471 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,471 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,471 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,486 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,589 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,589 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,589 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,590 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,605 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,707 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,707 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,708 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,708 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,723 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,825 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,826 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,826 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,826 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,841 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,944 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:42,944 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:42,945 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:42,945 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:42,960 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,062 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,062 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,063 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,063 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,078 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,180 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,181 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,196 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,299 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,299 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,299 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,299 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,314 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,417 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,417 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,418 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,418 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,433 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,535 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,535 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,536 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,536 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,551 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,649 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,649 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,650 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,650 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,665 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,767 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,767 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,768 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,768 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,783 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,886 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:43,886 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:43,886 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:43,886 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:43,902 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,004 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:44,004 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:44,004 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:44,005 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,019 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,122 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:44,122 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:44,123 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:44,123 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,138 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,240 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:44,240 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:44,241 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:44,241 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,256 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,358 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:44,359 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:44,359 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:44,359 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,374 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,472 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:04:44,473 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:04:44,473 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:04:44,473 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:44,488 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:04:55,139 - INFO - Epoch 47/150 - Train Loss: 0.228316, Val Loss: 0.227269
2025-08-07 11:05:02,914 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:02,915 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:02,915 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:02,915 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:02,932 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,032 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,149 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,149 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,150 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,150 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,168 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,386 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,386 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,386 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,386 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,402 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,503 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,503 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,503 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,504 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,521 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,620 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,620 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,620 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,737 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,737 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,854 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,854 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,854 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,854 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,971 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:03,971 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:03,971 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:03,971 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:03,987 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,087 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,088 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,088 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,088 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,104 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,204 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,205 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,205 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,205 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,223 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,321 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,321 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,322 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,322 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,340 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,438 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,439 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,439 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,439 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,457 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,555 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,555 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,556 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,556 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,571 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,672 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,672 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,673 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,673 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,691 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,789 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,789 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,790 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,790 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,805 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,906 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:04,906 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:04,907 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:04,907 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:04,925 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,023 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,023 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,024 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,024 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,039 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,140 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,140 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,141 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,141 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,156 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,257 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,257 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,258 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,258 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,276 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,374 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,374 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,374 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,375 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,392 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,491 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,491 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,491 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,491 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,506 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,608 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,608 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,608 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,608 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,626 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,724 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,725 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,725 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,725 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,740 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,841 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,841 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,842 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,842 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,860 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,958 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:05,958 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:05,959 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:05,959 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:05,974 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,075 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,075 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,076 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,076 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,094 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,192 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,192 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,193 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,193 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,211 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,309 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,309 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,310 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,310 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,328 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,426 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,426 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,427 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,427 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,442 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,543 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,543 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,544 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,544 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,562 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,660 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,660 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,661 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,661 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,676 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,777 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,777 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,778 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,778 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,793 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,894 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:06,894 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:06,895 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:06,895 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:06,910 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,011 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,011 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,012 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,029 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,130 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,130 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,131 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,131 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,146 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,247 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,247 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,248 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,248 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,263 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,364 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,364 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,365 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,365 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,380 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,481 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,481 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,482 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,482 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,500 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,598 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,598 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,599 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,599 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,617 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,715 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,715 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,716 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,716 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,734 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,832 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,832 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,832 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,833 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,851 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,951 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:07,951 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:07,952 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:07,952 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:07,967 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,068 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,068 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,069 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,069 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,089 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,185 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,185 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,186 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,186 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,205 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,302 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,302 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,303 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,303 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,322 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,419 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,419 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,420 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,420 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,439 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,536 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,536 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,537 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,537 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,552 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,653 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,653 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,653 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,653 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,673 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,774 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,774 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,774 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,775 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,790 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,892 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:08,892 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:08,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:08,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:08,908 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,010 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,010 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,011 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,011 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,129 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,129 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,129 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,129 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,145 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,247 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,247 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,248 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,248 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,263 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,361 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,361 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,362 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,362 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,381 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,478 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,478 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,478 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,479 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,498 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,599 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,599 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,600 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,600 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,615 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,717 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,718 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,718 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,718 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,734 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,836 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,836 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,837 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,837 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,852 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,954 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:09,954 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:09,955 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:09,955 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:09,970 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,072 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,072 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,073 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,073 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,088 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,190 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,190 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,191 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,191 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,206 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,309 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,309 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,309 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,310 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,325 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,427 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,427 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,428 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,428 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,443 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,541 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,541 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,542 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,542 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,561 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,658 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,658 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,659 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,659 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,678 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,775 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,775 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,776 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,776 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,791 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,892 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:10,892 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:10,893 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:10,893 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:10,912 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,009 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,009 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,010 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,010 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,029 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,126 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,126 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,127 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,127 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,146 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,243 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,243 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,243 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,244 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,263 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,360 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,360 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,360 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,360 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,375 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,476 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,477 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,477 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,477 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,497 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,593 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,593 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,594 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,594 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,609 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,710 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,710 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,711 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,711 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,730 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,824 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:11,824 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:11,825 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:11,825 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:11,840 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:22,480 - INFO - Epoch 48/150 - Train Loss: 0.227476, Val Loss: 0.219586
2025-08-07 11:05:22,522 - INFO - New best model saved with Val Loss: 0.219586
2025-08-07 11:05:30,420 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:30,421 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:30,421 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:30,421 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,441 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,538 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:30,538 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:30,538 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:30,539 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,554 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,655 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:30,655 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:30,655 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:30,656 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,674 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,772 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:30,772 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:30,772 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:30,772 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,790 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,891 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:30,891 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:30,891 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:30,891 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:30,907 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,008 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,008 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,008 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,008 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,026 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,125 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,125 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,125 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,125 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,141 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,241 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,242 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,242 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,242 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,260 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,358 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,358 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,359 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,359 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,377 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,475 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,475 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,476 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,476 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,494 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,595 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,595 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,596 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,596 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,611 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,712 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,712 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,713 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,713 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,728 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,829 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,829 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,829 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,830 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,848 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,946 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:31,946 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:31,946 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:31,947 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:31,965 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,063 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,063 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,064 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,064 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,083 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,181 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,181 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,181 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,181 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,199 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,296 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,296 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,297 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,297 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,315 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,415 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,416 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,416 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,416 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,431 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,532 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,532 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,533 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,533 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,548 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,649 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,649 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,650 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,650 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,668 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,766 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,766 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,767 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,767 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,883 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:32,883 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:32,884 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:32,884 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:32,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,000 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,000 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,001 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,001 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,016 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,117 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,117 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,118 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,118 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,135 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,234 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,234 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,234 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,234 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,351 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,351 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,351 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,351 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,366 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,469 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,484 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,601 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,702 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,818 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,819 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,819 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,837 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,935 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:33,936 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:33,936 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:33,936 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:33,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,052 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,053 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,053 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,053 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,068 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,169 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,169 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,170 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,170 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,286 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,287 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,305 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,403 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,419 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,653 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,754 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,770 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,871 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,889 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:34,988 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:34,988 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:34,988 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:34,989 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,004 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,105 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,105 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,105 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,105 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,123 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,221 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,222 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,222 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,237 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,338 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,338 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,339 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,339 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,354 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,455 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,455 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,471 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,572 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,572 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,573 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,573 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,591 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,689 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,689 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,690 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,690 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,806 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,806 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,807 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,807 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,825 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,923 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:35,923 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:35,924 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:35,924 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:35,942 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,040 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,040 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,041 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,041 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,056 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,157 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,157 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,173 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,274 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,274 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,293 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,391 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,391 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,391 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,391 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,409 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,508 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,508 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,508 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,523 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,624 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,624 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,625 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,625 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,640 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,741 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,741 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,742 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,742 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,760 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,861 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,861 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,861 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,862 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,877 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,978 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:36,978 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:36,978 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:36,978 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:36,994 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,094 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,095 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,095 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,095 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,110 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,211 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,212 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,212 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,212 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,230 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,329 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,329 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,329 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,329 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,448 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,448 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,449 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,449 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,464 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,585 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,683 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,683 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,702 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,800 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,800 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,916 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:37,916 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:37,917 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:37,917 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:37,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,033 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,034 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,034 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,053 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,154 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,154 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,155 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,155 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,170 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,272 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,272 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,273 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,273 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,288 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,390 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,390 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,391 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,391 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,406 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,509 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,509 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,509 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,524 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,627 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,627 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,627 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,628 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,643 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,745 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,745 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,746 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,746 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,761 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,864 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,981 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:38,982 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:38,982 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:38,982 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:38,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:39,100 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:39,100 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:39,100 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:39,101 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:39,116 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:39,218 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:39,218 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:39,219 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:39,219 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:39,234 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:39,332 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:39,332 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:39,333 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:39,333 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:39,348 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:49,913 - INFO - Epoch 49/150 - Train Loss: 0.233397, Val Loss: 0.237789
2025-08-07 11:05:57,695 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:57,696 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:57,696 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:57,696 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:57,716 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:57,813 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:57,813 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:57,814 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:57,814 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:57,832 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:57,930 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:57,930 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:57,931 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:57,931 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:57,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,048 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,048 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,164 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,164 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,164 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,165 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,180 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,281 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,281 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,281 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,282 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,300 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,401 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,401 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,402 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,402 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,417 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,518 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,518 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,518 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,519 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,534 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,635 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,635 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,636 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,636 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,651 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,752 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,752 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,752 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,753 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,771 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,869 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,869 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,869 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,870 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,885 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:58,986 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:58,986 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:58,986 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:58,986 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,004 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,103 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,103 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,103 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,103 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,121 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,238 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,340 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,340 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,341 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,356 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,457 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,457 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,473 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,574 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,574 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,691 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,808 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,808 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:05:59,925 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:05:59,925 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:05:59,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:05:59,940 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,041 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,041 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,042 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,042 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,057 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,177 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,276 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,411 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,512 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,512 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,513 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,513 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,528 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,629 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,629 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,630 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,630 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,648 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,765 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,863 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,863 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,864 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,864 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,879 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,980 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:00,980 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:00,981 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:00,981 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:00,997 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,097 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,097 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,098 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,098 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,113 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,214 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,214 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,215 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,215 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,233 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,331 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,331 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,332 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,332 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,350 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,448 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,448 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,449 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,449 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,467 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,583 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,682 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,682 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,682 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,683 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,701 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,799 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,799 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,799 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,799 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,815 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,916 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:01,916 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:01,916 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:01,916 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:01,931 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,032 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,033 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,033 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,033 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,051 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,149 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,149 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,150 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,150 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,165 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,266 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,266 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,267 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,267 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,285 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,383 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,384 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,384 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,399 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,500 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,500 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,501 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,501 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,519 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,617 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,617 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,617 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,618 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,633 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,734 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,734 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,734 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,734 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,750 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,851 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,851 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,851 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,851 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,867 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,967 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:02,968 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:02,968 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:02,968 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:02,983 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,084 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,084 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,085 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,085 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,100 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,201 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,201 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,202 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,202 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,217 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,318 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,318 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,319 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,319 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,334 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,435 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,435 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,436 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,436 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,455 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,552 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,552 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,553 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,553 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,572 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,673 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,673 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,674 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,674 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,689 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,792 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,792 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,792 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,792 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,808 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,910 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:03,910 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:03,910 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:03,911 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:03,925 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,028 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,028 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,029 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,029 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,044 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,146 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,146 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,147 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,147 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,162 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,264 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,264 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,265 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,265 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,280 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,382 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,383 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,383 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,383 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,398 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,501 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,501 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,502 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,502 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,517 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,619 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,619 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,620 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,620 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,635 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,737 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,737 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,738 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,738 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,753 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,855 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,856 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,856 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,856 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,872 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,974 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:04,974 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:04,975 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:04,975 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:04,990 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,092 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,093 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,093 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,093 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,108 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,211 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,211 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,211 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,211 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,227 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,329 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,329 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,329 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,330 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,345 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,448 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,448 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,463 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,565 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,565 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,566 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,566 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,581 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,683 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,683 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,684 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,684 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,699 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,802 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,802 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,802 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,802 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,817 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,920 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:05,920 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:05,920 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:05,920 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:05,936 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,038 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:06,038 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:06,039 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:06,039 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,156 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:06,156 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:06,157 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:06,157 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,172 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,274 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:06,274 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:06,275 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:06,275 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,290 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:06,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:06,393 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:06,393 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,408 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,508 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:06,508 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:06,509 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:06,509 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,524 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,623 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:06,623 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:06,623 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:06,623 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:06,638 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:17,061 - INFO - Epoch 50/150 - Train Loss: 0.225265, Val Loss: 0.220611
2025-08-07 11:06:25,113 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,113 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,114 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,114 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,134 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,231 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,231 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,232 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,232 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,250 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,348 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,348 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,349 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,367 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,468 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,468 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,468 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,468 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,484 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,585 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,585 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,585 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,603 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,702 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,720 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,821 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,821 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,821 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,821 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,837 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,938 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:25,938 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:25,939 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:25,939 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:25,958 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,055 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,172 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,172 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,173 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,173 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,191 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,292 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,292 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,293 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,293 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,409 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,409 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,410 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,410 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,425 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,526 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,526 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,527 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,527 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,545 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,643 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,643 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,644 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,644 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,659 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,760 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,760 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,761 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,761 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,779 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,877 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,877 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,878 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,878 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,893 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:26,994 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:26,994 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:26,995 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:26,995 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,010 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,112 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,229 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,229 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,246 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,345 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,345 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,345 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,346 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,364 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,462 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,462 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,462 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,462 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,478 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,578 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,579 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,579 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,579 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,597 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,699 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,699 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,699 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,699 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,715 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,816 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,816 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,817 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,817 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,835 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,933 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:27,933 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:27,934 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:27,934 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:27,949 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,050 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,050 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,051 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,051 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,066 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,167 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,167 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,168 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,168 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,186 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,285 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,285 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,286 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,286 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,304 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,404 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,405 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,405 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,405 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,420 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,521 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,521 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,522 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,522 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,541 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,638 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,638 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,639 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,639 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,658 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,755 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,755 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,756 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,756 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,771 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,872 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,872 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,873 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,873 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,888 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:28,989 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:28,989 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:28,990 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:28,990 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,009 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,106 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,106 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,107 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,126 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,223 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,223 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,243 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,340 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,360 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,477 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,711 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,828 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,928 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:29,929 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:29,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:29,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:29,944 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,047 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,063 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,165 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,165 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,165 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,166 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,181 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,283 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,299 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,401 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,401 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,402 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,402 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,417 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,519 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,520 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,520 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,535 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,638 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,654 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,756 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,756 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,756 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,756 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,874 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,874 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,874 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:30,992 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:30,992 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:30,993 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:30,993 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,008 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,110 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,110 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,111 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,111 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,126 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,228 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,228 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,229 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,229 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,245 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,346 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,347 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,347 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,347 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,362 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,465 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,465 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,465 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,465 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,481 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,583 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,583 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,583 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,584 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,599 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,701 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,701 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,701 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,702 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,717 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,819 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,819 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,820 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,820 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,835 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,937 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:31,937 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:31,938 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:31,938 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:31,953 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,055 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,056 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,056 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,056 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,071 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,174 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,174 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,174 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,174 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,189 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,292 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,292 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,292 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,293 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,308 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,410 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,410 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,411 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,411 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,426 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,528 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,529 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,529 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,529 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,544 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,646 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,647 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,647 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,647 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,662 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,765 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,765 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,766 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,766 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,781 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,883 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:32,884 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:32,884 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:32,884 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:32,899 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,002 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,002 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,002 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,003 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,017 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,120 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,120 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,120 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,121 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,136 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,238 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,238 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,239 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,239 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,254 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,356 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,356 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,357 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,357 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,372 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,474 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,474 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,475 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,475 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,490 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,592 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,592 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,593 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,593 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,608 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,711 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,711 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,711 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,711 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,727 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,829 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,829 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,829 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,829 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,844 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,947 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:33,947 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:33,948 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:33,948 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:33,963 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:34,061 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:34,061 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:34,062 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:34,062 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:34,077 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:44,458 - INFO - Epoch 51/150 - Train Loss: 0.220820, Val Loss: 0.218207
2025-08-07 11:06:44,484 - INFO - New best model saved with Val Loss: 0.218207
2025-08-07 11:06:51,929 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:51,929 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:51,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:51,930 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:51,946 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,049 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,049 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,049 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,050 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,065 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,166 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,166 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,167 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,167 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,185 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,286 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,286 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,287 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,287 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,302 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,403 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,403 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,404 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,404 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,422 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,539 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,637 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,637 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,638 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,638 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,656 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,754 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,754 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,755 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,755 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,773 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,871 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,871 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,872 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,872 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:52,988 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:52,988 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:52,989 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:52,989 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,007 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,105 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,105 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,106 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,106 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,124 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,222 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,222 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,223 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,223 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,241 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,339 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,339 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,340 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,340 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,358 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,457 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,457 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,573 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,573 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,574 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,589 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,690 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,690 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,691 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,691 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,709 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,807 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,807 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,808 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,808 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,823 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,924 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:53,924 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:53,925 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:53,925 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:53,943 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,041 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,041 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,042 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,042 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,057 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,158 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,158 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,159 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,159 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,177 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,275 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,275 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,275 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,276 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,294 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,392 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,392 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,392 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,392 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,408 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,509 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,509 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,509 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,509 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,527 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,625 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,626 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,626 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,626 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,644 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,742 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,743 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,743 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,743 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,758 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,859 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,859 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,860 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,860 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,875 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,979 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:54,979 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:54,980 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:54,980 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:54,995 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,096 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,096 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,097 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,097 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,115 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,213 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,213 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,214 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,214 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,232 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,330 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,330 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,330 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,331 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,346 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,447 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,447 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,447 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,447 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,462 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,563 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,563 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,564 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,564 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,582 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,680 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,680 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,681 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,681 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,699 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,797 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,797 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,798 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,798 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,816 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,917 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:55,917 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:55,918 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:55,918 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:55,933 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,034 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,034 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,034 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,035 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,054 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,155 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,155 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,156 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,156 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,171 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,273 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,273 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,274 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,274 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,289 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,391 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,391 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,392 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,392 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,407 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,509 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,510 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,510 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,510 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,525 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,628 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,628 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,628 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,629 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,644 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,746 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,746 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,747 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,747 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,762 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,864 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,864 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,865 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,865 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,880 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,982 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:56,983 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:56,983 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:56,983 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:56,998 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,101 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,101 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,102 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,102 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,117 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,219 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,219 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,220 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,220 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,235 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,337 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,337 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,338 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,338 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,353 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,456 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,456 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,456 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,456 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,472 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,574 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,574 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,574 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,575 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,590 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,692 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,692 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,693 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,693 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,708 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,810 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,810 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,811 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,811 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,826 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,929 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:57,929 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:57,929 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:57,929 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:57,945 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,047 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,047 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,047 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,048 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,062 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,165 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,165 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,166 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,166 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,181 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,283 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,284 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,284 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,284 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,299 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,402 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,402 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,402 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,403 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,417 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,520 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,520 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,521 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,521 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,536 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,638 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,638 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,639 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,639 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,654 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,756 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,756 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,757 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,757 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,772 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,875 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,875 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,875 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,875 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,890 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:58,993 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:58,993 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:58,993 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:58,993 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,009 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,111 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,111 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,112 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,112 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,127 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,229 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,229 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,230 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,230 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,245 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,347 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,347 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,348 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,348 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,363 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,466 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,466 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,466 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,466 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,482 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,584 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,584 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,584 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,585 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,600 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,702 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,702 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,703 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,703 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,718 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,820 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,820 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,821 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,821 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,836 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,938 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:06:59,938 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:06:59,939 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:06:59,939 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:06:59,954 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,057 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,057 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,057 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,057 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,072 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,175 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,175 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,175 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,175 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,191 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,293 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,293 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,294 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,294 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,309 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,411 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,411 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,412 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,412 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,427 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,529 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,529 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,530 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,530 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,546 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,648 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,648 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,648 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,648 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,664 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,766 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,766 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,766 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,767 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,782 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,880 - INFO - [33m data.shape: torch.Size([6, 1, 3, 10000]) [0m
2025-08-07 11:07:00,880 - INFO - [33m targets.shape: torch.Size([6, 1, 10000]) [0m
2025-08-07 11:07:00,880 - INFO - [33m data.shape: torch.Size([6, 10000, 3]) [0m
2025-08-07 11:07:00,881 - INFO - [33m targets.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 11:07:00,895 - INFO - [33m outputs.shape: torch.Size([6, 10000, 1]) [0m
2025-08-07 12:31:20,543 - INFO - args.exp_name : Test
2025-08-07 12:31:20,544 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 250,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-07 12:31:20,544 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-07 12:31:20,987 - INFO - Total trainable parameters: 713921
2025-08-07 12:31:21,334 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-07 12:31:21,335 - INFO - Staring training for 250 epochs
2025-08-07 12:31:51,680 - INFO - Epoch 1/250 - Train Loss: 0.872728, Val Loss: 0.770381
2025-08-07 12:31:51,747 - INFO - New best model saved with Val Loss: 0.770381
2025-08-07 12:32:19,603 - INFO - Epoch 2/250 - Train Loss: 0.746029, Val Loss: 0.714486
2025-08-07 12:32:19,631 - INFO - New best model saved with Val Loss: 0.714486
2025-08-07 12:32:47,536 - INFO - Epoch 3/250 - Train Loss: 0.689046, Val Loss: 0.652508
2025-08-07 12:32:47,563 - INFO - New best model saved with Val Loss: 0.652508
2025-08-07 12:33:15,472 - INFO - Epoch 4/250 - Train Loss: 0.596089, Val Loss: 0.517790
2025-08-07 12:33:15,501 - INFO - New best model saved with Val Loss: 0.517790
2025-08-07 12:33:43,664 - INFO - Epoch 5/250 - Train Loss: 0.487988, Val Loss: 0.471622
2025-08-07 12:33:43,692 - INFO - New best model saved with Val Loss: 0.471622
2025-08-07 12:34:11,681 - INFO - Epoch 6/250 - Train Loss: 0.457196, Val Loss: 0.443875
2025-08-07 12:34:11,710 - INFO - New best model saved with Val Loss: 0.443875
2025-08-07 12:34:39,887 - INFO - Epoch 7/250 - Train Loss: 0.438555, Val Loss: 0.427619
2025-08-07 12:34:39,915 - INFO - New best model saved with Val Loss: 0.427619
2025-08-07 12:35:07,858 - INFO - Epoch 8/250 - Train Loss: 0.426537, Val Loss: 0.443644
2025-08-07 12:35:35,797 - INFO - Epoch 9/250 - Train Loss: 0.420910, Val Loss: 0.407189
2025-08-07 12:35:35,825 - INFO - New best model saved with Val Loss: 0.407189
2025-08-07 12:36:03,854 - INFO - Epoch 10/250 - Train Loss: 0.405058, Val Loss: 0.395317
2025-08-07 12:36:03,882 - INFO - New best model saved with Val Loss: 0.395317
2025-08-07 12:36:31,832 - INFO - Epoch 11/250 - Train Loss: 0.396889, Val Loss: 0.394301
2025-08-07 12:36:31,860 - INFO - New best model saved with Val Loss: 0.394301
2025-08-07 12:36:59,946 - INFO - Epoch 12/250 - Train Loss: 0.393854, Val Loss: 0.398666
2025-08-07 12:37:27,441 - INFO - Epoch 13/250 - Train Loss: 0.393448, Val Loss: 0.395053
2025-08-07 12:37:55,180 - INFO - Epoch 14/250 - Train Loss: 0.393088, Val Loss: 0.382051
2025-08-07 12:37:55,208 - INFO - New best model saved with Val Loss: 0.382051
2025-08-07 12:38:22,789 - INFO - Epoch 15/250 - Train Loss: 0.380370, Val Loss: 0.376395
2025-08-07 12:38:22,816 - INFO - New best model saved with Val Loss: 0.376395
2025-08-07 12:38:50,606 - INFO - Epoch 16/250 - Train Loss: 0.384243, Val Loss: 0.382050
2025-08-07 12:39:18,474 - INFO - Epoch 17/250 - Train Loss: 0.377425, Val Loss: 0.366214
2025-08-07 12:39:18,516 - INFO - New best model saved with Val Loss: 0.366214
2025-08-07 12:39:46,321 - INFO - Epoch 18/250 - Train Loss: 0.371412, Val Loss: 0.371318
2025-08-07 12:40:13,711 - INFO - Epoch 19/250 - Train Loss: 0.363831, Val Loss: 0.358968
2025-08-07 12:40:13,749 - INFO - New best model saved with Val Loss: 0.358968
2025-08-07 12:40:41,573 - INFO - Epoch 20/250 - Train Loss: 0.355873, Val Loss: 0.345916
2025-08-07 12:40:41,600 - INFO - New best model saved with Val Loss: 0.345916
2025-08-07 12:41:09,856 - INFO - Epoch 21/250 - Train Loss: 0.348938, Val Loss: 0.328994
2025-08-07 12:41:09,899 - INFO - New best model saved with Val Loss: 0.328994
2025-08-07 12:41:37,883 - INFO - Epoch 22/250 - Train Loss: 0.328250, Val Loss: 0.317762
2025-08-07 12:41:37,910 - INFO - New best model saved with Val Loss: 0.317762
2025-08-07 12:42:05,696 - INFO - Epoch 23/250 - Train Loss: 0.309963, Val Loss: 0.297027
2025-08-07 12:42:05,724 - INFO - New best model saved with Val Loss: 0.297027
2025-08-07 12:42:33,341 - INFO - Epoch 24/250 - Train Loss: 0.306142, Val Loss: 0.289150
2025-08-07 12:42:33,368 - INFO - New best model saved with Val Loss: 0.289150
2025-08-07 12:43:01,197 - INFO - Epoch 25/250 - Train Loss: 0.298667, Val Loss: 0.288754
2025-08-07 12:43:01,224 - INFO - New best model saved with Val Loss: 0.288754
2025-08-07 12:43:29,135 - INFO - Epoch 26/250 - Train Loss: 0.292320, Val Loss: 0.282417
2025-08-07 12:43:29,163 - INFO - New best model saved with Val Loss: 0.282417
2025-08-07 12:43:56,985 - INFO - Epoch 27/250 - Train Loss: 0.286816, Val Loss: 0.280205
2025-08-07 12:43:57,013 - INFO - New best model saved with Val Loss: 0.280205
2025-08-07 12:44:24,337 - INFO - Epoch 28/250 - Train Loss: 0.281554, Val Loss: 0.275352
2025-08-07 12:44:24,365 - INFO - New best model saved with Val Loss: 0.275352
2025-08-07 12:44:52,143 - INFO - Epoch 29/250 - Train Loss: 0.273313, Val Loss: 0.259936
2025-08-07 12:44:52,171 - INFO - New best model saved with Val Loss: 0.259936
2025-08-07 12:45:19,758 - INFO - Epoch 30/250 - Train Loss: 0.264080, Val Loss: 0.253437
2025-08-07 12:45:19,785 - INFO - New best model saved with Val Loss: 0.253437
2025-08-07 12:45:47,673 - INFO - Epoch 31/250 - Train Loss: 0.259967, Val Loss: 0.255636
2025-08-07 12:46:15,475 - INFO - Epoch 32/250 - Train Loss: 0.257382, Val Loss: 0.256045
2025-08-07 12:46:43,743 - INFO - Epoch 33/250 - Train Loss: 0.252600, Val Loss: 0.253996
2025-08-07 12:47:11,888 - INFO - Epoch 34/250 - Train Loss: 0.256595, Val Loss: 0.255327
2025-08-07 12:47:39,447 - INFO - Epoch 35/250 - Train Loss: 0.252030, Val Loss: 0.235432
2025-08-07 12:47:39,475 - INFO - New best model saved with Val Loss: 0.235432
2025-08-07 12:48:07,481 - INFO - Epoch 36/250 - Train Loss: 0.250305, Val Loss: 0.243129
2025-08-07 12:48:35,098 - INFO - Epoch 37/250 - Train Loss: 0.243904, Val Loss: 0.244168
2025-08-07 12:49:02,611 - INFO - Epoch 38/250 - Train Loss: 0.244118, Val Loss: 0.228261
2025-08-07 12:49:02,638 - INFO - New best model saved with Val Loss: 0.228261
2025-08-07 12:49:30,360 - INFO - Epoch 39/250 - Train Loss: 0.239221, Val Loss: 0.248252
2025-08-07 12:49:58,196 - INFO - Epoch 40/250 - Train Loss: 0.240437, Val Loss: 0.230236
2025-08-07 12:50:26,505 - INFO - Epoch 41/250 - Train Loss: 0.237910, Val Loss: 0.234242
2025-08-07 12:50:53,977 - INFO - Epoch 42/250 - Train Loss: 0.239524, Val Loss: 0.225113
2025-08-07 12:50:54,004 - INFO - New best model saved with Val Loss: 0.225113
2025-08-07 12:51:21,961 - INFO - Epoch 43/250 - Train Loss: 0.235790, Val Loss: 0.231976
2025-08-07 12:51:49,806 - INFO - Epoch 44/250 - Train Loss: 0.232867, Val Loss: 0.226040
2025-08-07 12:52:17,442 - INFO - Epoch 45/250 - Train Loss: 0.232822, Val Loss: 0.230853
2025-08-07 12:52:44,634 - INFO - Epoch 46/250 - Train Loss: 0.232508, Val Loss: 0.234469
2025-08-07 12:53:12,352 - INFO - Epoch 47/250 - Train Loss: 0.228633, Val Loss: 0.230019
2025-08-07 12:53:40,078 - INFO - Epoch 48/250 - Train Loss: 0.230986, Val Loss: 0.226691
2025-08-07 12:54:07,898 - INFO - Epoch 49/250 - Train Loss: 0.228577, Val Loss: 0.230252
2025-08-07 12:54:35,981 - INFO - Epoch 50/250 - Train Loss: 0.225610, Val Loss: 0.224138
2025-08-07 12:54:36,010 - INFO - New best model saved with Val Loss: 0.224138
2025-08-07 12:55:03,634 - INFO - Epoch 51/250 - Train Loss: 0.226096, Val Loss: 0.220608
2025-08-07 12:55:03,661 - INFO - New best model saved with Val Loss: 0.220608
2025-08-07 12:55:31,646 - INFO - Epoch 52/250 - Train Loss: 0.220978, Val Loss: 0.229232
2025-08-07 12:55:59,674 - INFO - Epoch 53/250 - Train Loss: 0.224083, Val Loss: 0.214109
2025-08-07 12:55:59,701 - INFO - New best model saved with Val Loss: 0.214109
2025-08-07 12:56:27,269 - INFO - Epoch 54/250 - Train Loss: 0.219357, Val Loss: 0.213314
2025-08-07 12:56:27,295 - INFO - New best model saved with Val Loss: 0.213314
2025-08-07 12:56:54,840 - INFO - Epoch 55/250 - Train Loss: 0.213263, Val Loss: 0.210136
2025-08-07 12:56:54,867 - INFO - New best model saved with Val Loss: 0.210136
2025-08-07 12:57:22,617 - INFO - Epoch 56/250 - Train Loss: 0.211504, Val Loss: 0.208160
2025-08-07 12:57:22,644 - INFO - New best model saved with Val Loss: 0.208160
2025-08-07 12:57:50,590 - INFO - Epoch 57/250 - Train Loss: 0.210533, Val Loss: 0.201559
2025-08-07 12:57:50,617 - INFO - New best model saved with Val Loss: 0.201559
2025-08-07 12:58:18,525 - INFO - Epoch 58/250 - Train Loss: 0.212218, Val Loss: 0.210462
2025-08-07 12:58:46,511 - INFO - Epoch 59/250 - Train Loss: 0.213248, Val Loss: 0.202650
2025-08-07 12:59:14,289 - INFO - Epoch 60/250 - Train Loss: 0.206235, Val Loss: 0.199456
2025-08-07 12:59:14,317 - INFO - New best model saved with Val Loss: 0.199456
2025-08-07 12:59:42,403 - INFO - Epoch 61/250 - Train Loss: 0.207568, Val Loss: 0.199422
2025-08-07 12:59:42,429 - INFO - New best model saved with Val Loss: 0.199422
2025-08-07 13:00:10,263 - INFO - Epoch 62/250 - Train Loss: 0.208362, Val Loss: 0.208728
2025-08-07 13:00:38,170 - INFO - Epoch 63/250 - Train Loss: 0.204394, Val Loss: 0.201039
2025-08-07 13:01:05,773 - INFO - Epoch 64/250 - Train Loss: 0.208318, Val Loss: 0.198614
2025-08-07 13:01:05,819 - INFO - New best model saved with Val Loss: 0.198614
2025-08-07 13:01:33,148 - INFO - Epoch 65/250 - Train Loss: 0.202805, Val Loss: 0.199201
2025-08-07 13:02:00,923 - INFO - Epoch 66/250 - Train Loss: 0.201434, Val Loss: 0.198030
2025-08-07 13:02:00,950 - INFO - New best model saved with Val Loss: 0.198030
2025-08-07 13:02:28,969 - INFO - Epoch 67/250 - Train Loss: 0.203481, Val Loss: 0.191895
2025-08-07 13:02:28,996 - INFO - New best model saved with Val Loss: 0.191895
2025-08-07 13:02:56,383 - INFO - Epoch 68/250 - Train Loss: 0.203677, Val Loss: 0.199056
2025-08-07 13:03:24,201 - INFO - Epoch 69/250 - Train Loss: 0.202387, Val Loss: 0.186813
2025-08-07 13:03:24,228 - INFO - New best model saved with Val Loss: 0.186813
2025-08-07 13:03:52,038 - INFO - Epoch 70/250 - Train Loss: 0.198160, Val Loss: 0.192520
2025-08-07 13:04:20,061 - INFO - Epoch 71/250 - Train Loss: 0.199944, Val Loss: 0.184624
2025-08-07 13:04:20,088 - INFO - New best model saved with Val Loss: 0.184624
2025-08-07 13:04:47,461 - INFO - Epoch 72/250 - Train Loss: 0.197394, Val Loss: 0.186144
2025-08-07 13:05:15,381 - INFO - Epoch 73/250 - Train Loss: 0.196352, Val Loss: 0.181895
2025-08-07 13:05:15,409 - INFO - New best model saved with Val Loss: 0.181895
2025-08-07 13:05:42,910 - INFO - Epoch 74/250 - Train Loss: 0.193869, Val Loss: 0.180310
2025-08-07 13:05:42,937 - INFO - New best model saved with Val Loss: 0.180310
2025-08-07 13:06:10,719 - INFO - Epoch 75/250 - Train Loss: 0.200038, Val Loss: 0.186844
2025-08-07 13:06:38,694 - INFO - Epoch 76/250 - Train Loss: 0.192535, Val Loss: 0.191764
2025-08-07 13:07:06,436 - INFO - Epoch 77/250 - Train Loss: 0.194147, Val Loss: 0.196323
2025-08-07 13:07:34,079 - INFO - Epoch 78/250 - Train Loss: 0.196658, Val Loss: 0.189077
2025-08-07 13:08:01,671 - INFO - Epoch 79/250 - Train Loss: 0.193587, Val Loss: 0.184888
2025-08-07 13:08:29,241 - INFO - Epoch 80/250 - Train Loss: 0.190023, Val Loss: 0.187345
2025-08-07 13:08:56,841 - INFO - Epoch 81/250 - Train Loss: 0.190995, Val Loss: 0.200955
2025-08-07 13:09:24,291 - INFO - Epoch 82/250 - Train Loss: 0.193073, Val Loss: 0.175856
2025-08-07 13:09:24,319 - INFO - New best model saved with Val Loss: 0.175856
2025-08-07 13:09:52,130 - INFO - Epoch 83/250 - Train Loss: 0.187177, Val Loss: 0.173618
2025-08-07 13:09:52,179 - INFO - New best model saved with Val Loss: 0.173618
2025-08-07 13:10:20,120 - INFO - Epoch 84/250 - Train Loss: 0.190742, Val Loss: 0.185113
2025-08-07 13:10:48,048 - INFO - Epoch 85/250 - Train Loss: 0.189131, Val Loss: 0.186732
2025-08-07 13:11:15,973 - INFO - Epoch 86/250 - Train Loss: 0.187560, Val Loss: 0.182538
2025-08-07 13:11:43,428 - INFO - Epoch 87/250 - Train Loss: 0.185677, Val Loss: 0.179216
2025-08-07 13:12:10,950 - INFO - Epoch 88/250 - Train Loss: 0.187251, Val Loss: 0.177919
2025-08-07 13:12:38,688 - INFO - Epoch 89/250 - Train Loss: 0.186919, Val Loss: 0.176347
2025-08-07 13:13:06,283 - INFO - Epoch 90/250 - Train Loss: 0.187990, Val Loss: 0.177680
2025-08-07 13:13:34,004 - INFO - Epoch 91/250 - Train Loss: 0.186254, Val Loss: 0.184298
2025-08-07 13:14:01,778 - INFO - Epoch 92/250 - Train Loss: 0.185842, Val Loss: 0.180589
2025-08-07 13:14:29,512 - INFO - Epoch 93/250 - Train Loss: 0.189019, Val Loss: 0.185677
2025-08-07 13:14:57,373 - INFO - Epoch 94/250 - Train Loss: 0.180291, Val Loss: 0.173412
2025-08-07 13:14:57,411 - INFO - New best model saved with Val Loss: 0.173412
2025-08-07 13:15:25,294 - INFO - Epoch 95/250 - Train Loss: 0.181950, Val Loss: 0.173773
2025-08-07 13:15:52,786 - INFO - Epoch 96/250 - Train Loss: 0.181616, Val Loss: 0.173494
2025-08-07 13:16:20,537 - INFO - Epoch 97/250 - Train Loss: 0.180635, Val Loss: 0.173400
2025-08-07 13:16:20,564 - INFO - New best model saved with Val Loss: 0.173400
2025-08-07 13:16:48,404 - INFO - Epoch 98/250 - Train Loss: 0.180529, Val Loss: 0.166746
2025-08-07 13:16:48,431 - INFO - New best model saved with Val Loss: 0.166746
2025-08-07 13:17:16,107 - INFO - Epoch 99/250 - Train Loss: 0.177881, Val Loss: 0.169999
2025-08-07 13:17:43,582 - INFO - Epoch 100/250 - Train Loss: 0.181925, Val Loss: 0.178844
2025-08-07 13:18:11,227 - INFO - Epoch 101/250 - Train Loss: 0.179741, Val Loss: 0.173282
2025-08-07 13:18:38,971 - INFO - Epoch 102/250 - Train Loss: 0.175484, Val Loss: 0.166298
2025-08-07 13:18:38,998 - INFO - New best model saved with Val Loss: 0.166298
2025-08-07 13:19:06,811 - INFO - Epoch 103/250 - Train Loss: 0.182369, Val Loss: 0.180797
2025-08-07 13:19:34,055 - INFO - Epoch 104/250 - Train Loss: 0.175286, Val Loss: 0.178063
2025-08-07 13:20:01,703 - INFO - Epoch 105/250 - Train Loss: 0.179769, Val Loss: 0.176597
2025-08-07 13:20:29,374 - INFO - Epoch 106/250 - Train Loss: 0.178734, Val Loss: 0.171249
2025-08-07 13:20:57,031 - INFO - Epoch 107/250 - Train Loss: 0.175057, Val Loss: 0.169115
2025-08-07 13:21:24,574 - INFO - Epoch 108/250 - Train Loss: 0.171155, Val Loss: 0.161660
2025-08-07 13:21:24,601 - INFO - New best model saved with Val Loss: 0.161660
2025-08-07 13:21:52,362 - INFO - Epoch 109/250 - Train Loss: 0.168656, Val Loss: 0.156935
2025-08-07 13:21:52,390 - INFO - New best model saved with Val Loss: 0.156935
2025-08-07 13:22:19,823 - INFO - Epoch 110/250 - Train Loss: 0.174492, Val Loss: 0.171248
2025-08-07 13:22:47,765 - INFO - Epoch 111/250 - Train Loss: 0.173698, Val Loss: 0.157079
2025-08-07 13:23:15,429 - INFO - Epoch 112/250 - Train Loss: 0.173057, Val Loss: 0.171179
2025-08-07 13:23:43,237 - INFO - Epoch 113/250 - Train Loss: 0.171933, Val Loss: 0.158344
2025-08-07 13:24:11,156 - INFO - Epoch 114/250 - Train Loss: 0.168685, Val Loss: 0.160595
2025-08-07 13:24:38,710 - INFO - Epoch 115/250 - Train Loss: 0.172755, Val Loss: 0.163555
2025-08-07 13:25:06,239 - INFO - Epoch 116/250 - Train Loss: 0.168799, Val Loss: 0.160622
2025-08-07 13:25:33,874 - INFO - Epoch 117/250 - Train Loss: 0.167079, Val Loss: 0.155232
2025-08-07 13:25:33,901 - INFO - New best model saved with Val Loss: 0.155232
2025-08-07 13:26:01,533 - INFO - Epoch 118/250 - Train Loss: 0.164205, Val Loss: 0.167679
2025-08-07 13:26:29,407 - INFO - Epoch 119/250 - Train Loss: 0.169456, Val Loss: 0.159380
2025-08-07 13:26:57,174 - INFO - Epoch 120/250 - Train Loss: 0.166856, Val Loss: 0.155844
2025-08-07 13:27:25,325 - INFO - Epoch 121/250 - Train Loss: 0.162645, Val Loss: 0.150523
2025-08-07 13:27:25,352 - INFO - New best model saved with Val Loss: 0.150523
2025-08-07 13:27:52,990 - INFO - Epoch 122/250 - Train Loss: 0.160670, Val Loss: 0.156735
2025-08-07 13:28:20,547 - INFO - Epoch 123/250 - Train Loss: 0.166765, Val Loss: 0.157434
2025-08-07 13:28:48,118 - INFO - Epoch 124/250 - Train Loss: 0.162084, Val Loss: 0.152554
2025-08-07 13:29:15,420 - INFO - Epoch 125/250 - Train Loss: 0.161687, Val Loss: 0.164457
2025-08-07 13:29:43,170 - INFO - Epoch 126/250 - Train Loss: 0.167346, Val Loss: 0.153950
2025-08-07 13:30:10,364 - INFO - Epoch 127/250 - Train Loss: 0.161249, Val Loss: 0.151141
2025-08-07 13:30:38,210 - INFO - Epoch 128/250 - Train Loss: 0.161787, Val Loss: 0.153222
2025-08-07 13:31:06,324 - INFO - Epoch 129/250 - Train Loss: 0.159798, Val Loss: 0.158385
2025-08-07 13:31:33,973 - INFO - Epoch 130/250 - Train Loss: 0.160324, Val Loss: 0.153991
2025-08-07 13:32:01,720 - INFO - Epoch 131/250 - Train Loss: 0.161151, Val Loss: 0.157029
2025-08-07 13:32:29,465 - INFO - Epoch 132/250 - Train Loss: 0.165424, Val Loss: 0.153071
2025-08-07 13:32:57,100 - INFO - Epoch 133/250 - Train Loss: 0.162374, Val Loss: 0.159798
2025-08-07 13:33:24,946 - INFO - Epoch 134/250 - Train Loss: 0.159582, Val Loss: 0.149246
2025-08-07 13:33:24,973 - INFO - New best model saved with Val Loss: 0.149246
2025-08-07 13:33:52,650 - INFO - Epoch 135/250 - Train Loss: 0.160795, Val Loss: 0.154453
2025-08-07 13:34:20,341 - INFO - Epoch 136/250 - Train Loss: 0.159031, Val Loss: 0.147768
2025-08-07 13:34:20,369 - INFO - New best model saved with Val Loss: 0.147768
2025-08-07 13:34:47,873 - INFO - Epoch 137/250 - Train Loss: 0.157372, Val Loss: 0.150005
2025-08-07 13:35:15,713 - INFO - Epoch 138/250 - Train Loss: 0.158123, Val Loss: 0.150963
2025-08-07 13:35:43,517 - INFO - Epoch 139/250 - Train Loss: 0.157200, Val Loss: 0.146379
2025-08-07 13:35:43,544 - INFO - New best model saved with Val Loss: 0.146379
2025-08-07 13:36:11,426 - INFO - Epoch 140/250 - Train Loss: 0.162747, Val Loss: 0.161523
2025-08-07 13:36:39,121 - INFO - Epoch 141/250 - Train Loss: 0.159889, Val Loss: 0.150652
2025-08-07 13:37:06,759 - INFO - Epoch 142/250 - Train Loss: 0.152182, Val Loss: 0.154791
2025-08-07 13:37:34,287 - INFO - Epoch 143/250 - Train Loss: 0.157511, Val Loss: 0.150151
2025-08-07 13:38:01,909 - INFO - Epoch 144/250 - Train Loss: 0.149904, Val Loss: 0.138871
2025-08-07 13:38:01,937 - INFO - New best model saved with Val Loss: 0.138871
2025-08-07 13:38:29,301 - INFO - Epoch 145/250 - Train Loss: 0.149150, Val Loss: 0.141733
2025-08-07 13:38:57,214 - INFO - Epoch 146/250 - Train Loss: 0.153972, Val Loss: 0.141633
2025-08-07 13:39:25,106 - INFO - Epoch 147/250 - Train Loss: 0.152560, Val Loss: 0.154813
2025-08-07 13:39:52,972 - INFO - Epoch 148/250 - Train Loss: 0.153007, Val Loss: 0.153307
2025-08-07 13:40:20,697 - INFO - Epoch 149/250 - Train Loss: 0.152381, Val Loss: 0.146191
2025-08-07 13:40:48,849 - INFO - Epoch 150/250 - Train Loss: 0.148153, Val Loss: 0.138824
2025-08-07 13:40:48,878 - INFO - New best model saved with Val Loss: 0.138824
2025-08-07 13:41:16,660 - INFO - Epoch 151/250 - Train Loss: 0.151300, Val Loss: 0.144002
2025-08-07 13:41:44,506 - INFO - Epoch 152/250 - Train Loss: 0.153793, Val Loss: 0.139023
2025-08-07 13:42:12,060 - INFO - Epoch 153/250 - Train Loss: 0.150693, Val Loss: 0.140308
2025-08-07 13:42:39,936 - INFO - Epoch 154/250 - Train Loss: 0.148611, Val Loss: 0.135089
2025-08-07 13:42:39,977 - INFO - New best model saved with Val Loss: 0.135089
2025-08-07 13:43:07,806 - INFO - Epoch 155/250 - Train Loss: 0.145707, Val Loss: 0.140128
2025-08-07 13:43:35,512 - INFO - Epoch 156/250 - Train Loss: 0.146245, Val Loss: 0.141314
2025-08-07 13:44:03,158 - INFO - Epoch 157/250 - Train Loss: 0.147358, Val Loss: 0.134220
2025-08-07 13:44:03,185 - INFO - New best model saved with Val Loss: 0.134220
2025-08-07 13:44:30,611 - INFO - Epoch 158/250 - Train Loss: 0.143281, Val Loss: 0.135098
2025-08-07 13:44:58,245 - INFO - Epoch 159/250 - Train Loss: 0.148299, Val Loss: 0.137263
2025-08-07 13:45:25,667 - INFO - Epoch 160/250 - Train Loss: 0.146410, Val Loss: 0.134446
2025-08-07 13:45:53,564 - INFO - Epoch 161/250 - Train Loss: 0.144705, Val Loss: 0.135788
2025-08-07 13:46:21,200 - INFO - Epoch 162/250 - Train Loss: 0.144747, Val Loss: 0.135834
2025-08-07 13:46:48,874 - INFO - Epoch 163/250 - Train Loss: 0.146522, Val Loss: 0.139827
2025-08-07 13:47:16,523 - INFO - Epoch 164/250 - Train Loss: 0.142900, Val Loss: 0.127780
2025-08-07 13:47:16,550 - INFO - New best model saved with Val Loss: 0.127780
2025-08-07 13:47:44,693 - INFO - Epoch 165/250 - Train Loss: 0.142264, Val Loss: 0.129596
2025-08-07 13:48:12,483 - INFO - Epoch 166/250 - Train Loss: 0.145080, Val Loss: 0.133667
2025-08-07 13:48:40,110 - INFO - Epoch 167/250 - Train Loss: 0.141947, Val Loss: 0.132304
2025-08-07 13:49:07,599 - INFO - Epoch 168/250 - Train Loss: 0.139957, Val Loss: 0.132276
2025-08-07 13:49:35,305 - INFO - Epoch 169/250 - Train Loss: 0.144116, Val Loss: 0.130024
2025-08-07 13:50:02,708 - INFO - Epoch 170/250 - Train Loss: 0.144596, Val Loss: 0.132473
2025-08-07 13:50:30,700 - INFO - Epoch 171/250 - Train Loss: 0.142819, Val Loss: 0.138971
2025-08-07 13:50:58,432 - INFO - Epoch 172/250 - Train Loss: 0.142516, Val Loss: 0.132976
2025-08-07 13:51:26,475 - INFO - Epoch 173/250 - Train Loss: 0.140567, Val Loss: 0.132563
2025-08-07 13:51:54,424 - INFO - Epoch 174/250 - Train Loss: 0.139166, Val Loss: 0.126799
2025-08-07 13:51:54,455 - INFO - New best model saved with Val Loss: 0.126799
2025-08-07 13:52:22,206 - INFO - Epoch 175/250 - Train Loss: 0.141426, Val Loss: 0.128235
2025-08-07 13:52:49,844 - INFO - Epoch 176/250 - Train Loss: 0.143162, Val Loss: 0.128409
2025-08-07 13:53:17,838 - INFO - Epoch 177/250 - Train Loss: 0.140666, Val Loss: 0.127992
2025-08-07 13:53:45,495 - INFO - Epoch 178/250 - Train Loss: 0.140237, Val Loss: 0.129122
2025-08-07 13:54:13,363 - INFO - Epoch 179/250 - Train Loss: 0.140182, Val Loss: 0.129297
2025-08-07 13:54:41,396 - INFO - Epoch 180/250 - Train Loss: 0.136339, Val Loss: 0.128332
2025-08-07 13:55:09,190 - INFO - Epoch 181/250 - Train Loss: 0.137606, Val Loss: 0.124978
2025-08-07 13:55:09,219 - INFO - New best model saved with Val Loss: 0.124978
2025-08-07 13:55:36,477 - INFO - Epoch 182/250 - Train Loss: 0.138859, Val Loss: 0.123988
2025-08-07 13:55:36,507 - INFO - New best model saved with Val Loss: 0.123988
2025-08-07 13:56:04,181 - INFO - Epoch 183/250 - Train Loss: 0.138321, Val Loss: 0.127182
2025-08-07 13:56:31,743 - INFO - Epoch 184/250 - Train Loss: 0.139849, Val Loss: 0.129735
2025-08-07 13:56:59,560 - INFO - Epoch 185/250 - Train Loss: 0.136841, Val Loss: 0.123367
2025-08-07 13:56:59,588 - INFO - New best model saved with Val Loss: 0.123367
2025-08-07 13:57:27,364 - INFO - Epoch 186/250 - Train Loss: 0.136067, Val Loss: 0.127303
2025-08-07 13:57:54,975 - INFO - Epoch 187/250 - Train Loss: 0.140616, Val Loss: 0.126781
2025-08-07 13:58:22,573 - INFO - Epoch 188/250 - Train Loss: 0.134588, Val Loss: 0.123389
2025-08-07 13:58:50,052 - INFO - Epoch 189/250 - Train Loss: 0.131937, Val Loss: 0.129374
2025-08-07 13:59:17,949 - INFO - Epoch 190/250 - Train Loss: 0.135142, Val Loss: 0.121500
2025-08-07 13:59:17,978 - INFO - New best model saved with Val Loss: 0.121500
2025-08-07 13:59:45,767 - INFO - Epoch 191/250 - Train Loss: 0.135453, Val Loss: 0.129886
2025-08-07 14:00:13,570 - INFO - Epoch 192/250 - Train Loss: 0.135631, Val Loss: 0.124803
2025-08-07 14:00:41,265 - INFO - Epoch 193/250 - Train Loss: 0.134608, Val Loss: 0.123943
2025-08-07 14:01:09,158 - INFO - Epoch 194/250 - Train Loss: 0.132268, Val Loss: 0.123879
2025-08-07 14:01:37,131 - INFO - Epoch 195/250 - Train Loss: 0.132972, Val Loss: 0.121266
2025-08-07 14:01:37,161 - INFO - New best model saved with Val Loss: 0.121266
2025-08-07 14:02:05,110 - INFO - Epoch 196/250 - Train Loss: 0.131494, Val Loss: 0.127721
2025-08-07 14:02:32,560 - INFO - Epoch 197/250 - Train Loss: 0.131516, Val Loss: 0.128478
2025-08-07 14:03:00,304 - INFO - Epoch 198/250 - Train Loss: 0.133192, Val Loss: 0.122601
2025-08-07 14:03:28,351 - INFO - Epoch 199/250 - Train Loss: 0.134851, Val Loss: 0.123138
2025-08-07 14:03:56,138 - INFO - Epoch 200/250 - Train Loss: 0.134242, Val Loss: 0.123035
2025-08-07 14:04:23,989 - INFO - Epoch 201/250 - Train Loss: 0.135432, Val Loss: 0.121324
2025-08-07 14:04:51,710 - INFO - Epoch 202/250 - Train Loss: 0.130963, Val Loss: 0.118877
2025-08-07 14:04:51,737 - INFO - New best model saved with Val Loss: 0.118877
2025-08-07 14:05:19,445 - INFO - Epoch 203/250 - Train Loss: 0.131485, Val Loss: 0.117424
2025-08-07 14:05:19,473 - INFO - New best model saved with Val Loss: 0.117424
2025-08-07 14:05:47,072 - INFO - Epoch 204/250 - Train Loss: 0.129512, Val Loss: 0.120244
2025-08-07 14:06:14,704 - INFO - Epoch 205/250 - Train Loss: 0.128558, Val Loss: 0.116045
2025-08-07 14:06:14,733 - INFO - New best model saved with Val Loss: 0.116045
2025-08-07 14:06:42,544 - INFO - Epoch 206/250 - Train Loss: 0.131819, Val Loss: 0.127993
2025-08-07 14:07:09,946 - INFO - Epoch 207/250 - Train Loss: 0.129251, Val Loss: 0.120874
2025-08-07 14:07:37,756 - INFO - Epoch 208/250 - Train Loss: 0.127869, Val Loss: 0.113275
2025-08-07 14:07:37,783 - INFO - New best model saved with Val Loss: 0.113275
2025-08-07 14:08:05,396 - INFO - Epoch 209/250 - Train Loss: 0.128083, Val Loss: 0.120083
2025-08-07 14:08:33,045 - INFO - Epoch 210/250 - Train Loss: 0.127141, Val Loss: 0.117420
2025-08-07 14:09:01,217 - INFO - Epoch 211/250 - Train Loss: 0.128891, Val Loss: 0.115652
2025-08-07 14:09:28,875 - INFO - Epoch 212/250 - Train Loss: 0.127649, Val Loss: 0.128877
2025-08-07 14:09:56,455 - INFO - Epoch 213/250 - Train Loss: 0.126796, Val Loss: 0.115074
2025-08-07 14:10:24,194 - INFO - Epoch 214/250 - Train Loss: 0.128188, Val Loss: 0.114962
2025-08-07 14:10:51,603 - INFO - Epoch 215/250 - Train Loss: 0.126337, Val Loss: 0.113053
2025-08-07 14:10:51,630 - INFO - New best model saved with Val Loss: 0.113053
2025-08-07 14:11:19,130 - INFO - Epoch 216/250 - Train Loss: 0.127049, Val Loss: 0.118670
2025-08-07 14:11:47,117 - INFO - Epoch 217/250 - Train Loss: 0.127406, Val Loss: 0.117103
2025-08-07 14:12:14,820 - INFO - Epoch 218/250 - Train Loss: 0.124674, Val Loss: 0.115676
2025-08-07 14:12:42,185 - INFO - Epoch 219/250 - Train Loss: 0.128378, Val Loss: 0.111655
2025-08-07 14:12:42,212 - INFO - New best model saved with Val Loss: 0.111655
2025-08-07 14:13:09,705 - INFO - Epoch 220/250 - Train Loss: 0.125507, Val Loss: 0.114866
2025-08-07 14:13:37,399 - INFO - Epoch 221/250 - Train Loss: 0.124956, Val Loss: 0.109239
2025-08-07 14:13:37,426 - INFO - New best model saved with Val Loss: 0.109239
2025-08-07 14:14:05,114 - INFO - Epoch 222/250 - Train Loss: 0.125700, Val Loss: 0.120121
2025-08-07 14:14:32,793 - INFO - Epoch 223/250 - Train Loss: 0.125587, Val Loss: 0.119131
2025-08-07 14:15:00,505 - INFO - Epoch 224/250 - Train Loss: 0.124797, Val Loss: 0.113481
2025-08-07 14:15:28,160 - INFO - Epoch 225/250 - Train Loss: 0.122059, Val Loss: 0.117155
2025-08-07 14:15:56,191 - INFO - Epoch 226/250 - Train Loss: 0.122069, Val Loss: 0.109217
2025-08-07 14:15:56,219 - INFO - New best model saved with Val Loss: 0.109217
2025-08-07 14:16:23,944 - INFO - Epoch 227/250 - Train Loss: 0.124182, Val Loss: 0.107093
2025-08-07 14:16:23,971 - INFO - New best model saved with Val Loss: 0.107093
2025-08-07 14:16:51,486 - INFO - Epoch 228/250 - Train Loss: 0.119701, Val Loss: 0.114031
2025-08-07 14:17:18,928 - INFO - Epoch 229/250 - Train Loss: 0.120069, Val Loss: 0.107871
2025-08-07 14:17:46,709 - INFO - Epoch 230/250 - Train Loss: 0.119205, Val Loss: 0.105766
2025-08-07 14:17:46,737 - INFO - New best model saved with Val Loss: 0.105766
2025-08-07 14:18:14,007 - INFO - Epoch 231/250 - Train Loss: 0.119419, Val Loss: 0.107379
2025-08-07 14:18:41,466 - INFO - Epoch 232/250 - Train Loss: 0.121568, Val Loss: 0.106961
2025-08-07 14:19:09,169 - INFO - Epoch 233/250 - Train Loss: 0.121038, Val Loss: 0.110325
2025-08-07 14:19:37,375 - INFO - Epoch 234/250 - Train Loss: 0.117780, Val Loss: 0.107698
2025-08-07 14:20:05,109 - INFO - Epoch 235/250 - Train Loss: 0.120716, Val Loss: 0.105343
2025-08-07 14:20:05,136 - INFO - New best model saved with Val Loss: 0.105343
2025-08-07 14:20:32,714 - INFO - Epoch 236/250 - Train Loss: 0.120579, Val Loss: 0.114214
2025-08-07 14:21:00,783 - INFO - Epoch 237/250 - Train Loss: 0.118971, Val Loss: 0.109054
2025-08-07 14:21:28,647 - INFO - Epoch 238/250 - Train Loss: 0.117510, Val Loss: 0.108141
2025-08-07 14:21:56,597 - INFO - Epoch 239/250 - Train Loss: 0.117988, Val Loss: 0.106967
2025-08-07 14:22:24,303 - INFO - Epoch 240/250 - Train Loss: 0.116194, Val Loss: 0.106344
2025-08-07 14:22:51,802 - INFO - Epoch 241/250 - Train Loss: 0.120214, Val Loss: 0.114813
2025-08-07 14:23:19,559 - INFO - Epoch 242/250 - Train Loss: 0.120993, Val Loss: 0.109975
2025-08-07 14:23:47,388 - INFO - Epoch 243/250 - Train Loss: 0.118218, Val Loss: 0.103367
2025-08-07 14:23:47,415 - INFO - New best model saved with Val Loss: 0.103367
2025-08-07 14:24:14,973 - INFO - Epoch 244/250 - Train Loss: 0.117287, Val Loss: 0.105865
2025-08-07 14:24:42,398 - INFO - Epoch 245/250 - Train Loss: 0.116927, Val Loss: 0.107732
2025-08-07 14:25:09,920 - INFO - Epoch 246/250 - Train Loss: 0.116347, Val Loss: 0.111433
2025-08-07 14:25:37,298 - INFO - Epoch 247/250 - Train Loss: 0.116235, Val Loss: 0.102590
2025-08-07 14:25:37,328 - INFO - New best model saved with Val Loss: 0.102590
2025-08-07 14:26:04,792 - INFO - Epoch 248/250 - Train Loss: 0.118991, Val Loss: 0.111419
2025-08-07 14:26:32,561 - INFO - Epoch 249/250 - Train Loss: 0.117437, Val Loss: 0.110517
2025-08-07 14:27:00,599 - INFO - Epoch 250/250 - Train Loss: 0.116672, Val Loss: 0.116488
2025-08-07 14:27:00,794 - INFO - Final model saved to experiments/Test/final_model.pth
2025-08-07 14:27:00,808 - INFO - Testing the final model
2025-08-07 14:27:10,629 - INFO - Total MSE across all processes: 13.122313499450684
2025-08-07 14:27:10,634 - INFO - mean value for all_targets: {tmp}
2025-08-07 14:27:10,640 - INFO - Test MSE: 0.115108, Test MAE: 0.190951, Max AE: 26.911041, Test R2: 0.8916
2025-08-07 14:27:10,640 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-07 14:27:10,640 - INFO - Total inference time:  0.28s for 114 samples
2025-08-07 14:27:10,660 - INFO - Testing the best model
2025-08-07 14:27:19,231 - INFO - Total MSE across all processes: 11.86176872253418
2025-08-07 14:27:19,234 - INFO - mean value for all_targets: {tmp}
2025-08-07 14:27:19,240 - INFO - Test MSE: 0.104051, Test MAE: 0.186295, Max AE: 26.980894, Test R2: 0.9021
2025-08-07 14:27:19,240 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-07 14:27:19,240 - INFO - Total inference time:  0.28s for 114 samples
2025-08-07 18:53:54,111 - INFO - args.exp_name : Test
2025-08-07 18:53:54,112 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-07 18:53:54,112 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-07 18:53:54,589 - INFO - Total trainable parameters: 713921
2025-08-07 18:53:54,947 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-07 18:53:54,948 - INFO - Staring training for 1000 epochs
2025-08-07 18:54:22,603 - INFO - Epoch 1/1000 - Train Loss: 0.872068, Val Loss: 0.769350
2025-08-07 18:54:22,650 - INFO - New best model saved with Val Loss: 0.769350
2025-08-07 18:54:49,410 - INFO - Epoch 2/1000 - Train Loss: 0.745479, Val Loss: 0.716564
2025-08-07 18:54:49,431 - INFO - New best model saved with Val Loss: 0.716564
2025-08-07 18:55:13,932 - INFO - Epoch 3/1000 - Train Loss: 0.688537, Val Loss: 0.648317
2025-08-07 18:55:13,966 - INFO - New best model saved with Val Loss: 0.648317
2025-08-07 18:55:38,247 - INFO - Epoch 4/1000 - Train Loss: 0.592505, Val Loss: 0.522496
2025-08-07 18:55:38,269 - INFO - New best model saved with Val Loss: 0.522496
2025-08-07 18:56:02,629 - INFO - Epoch 5/1000 - Train Loss: 0.485806, Val Loss: 0.468122
2025-08-07 18:56:02,650 - INFO - New best model saved with Val Loss: 0.468122
2025-08-07 18:56:27,014 - INFO - Epoch 6/1000 - Train Loss: 0.458963, Val Loss: 0.452188
2025-08-07 18:56:27,035 - INFO - New best model saved with Val Loss: 0.452188
2025-08-07 18:56:51,303 - INFO - Epoch 7/1000 - Train Loss: 0.438410, Val Loss: 0.424061
2025-08-07 18:56:51,324 - INFO - New best model saved with Val Loss: 0.424061
2025-08-07 18:57:15,341 - INFO - Epoch 8/1000 - Train Loss: 0.427005, Val Loss: 0.426281
2025-08-07 18:57:39,619 - INFO - Epoch 9/1000 - Train Loss: 0.418697, Val Loss: 0.408864
2025-08-07 18:57:39,640 - INFO - New best model saved with Val Loss: 0.408864
2025-08-07 18:58:03,932 - INFO - Epoch 10/1000 - Train Loss: 0.407012, Val Loss: 0.403224
2025-08-07 18:58:03,953 - INFO - New best model saved with Val Loss: 0.403224
2025-08-07 18:58:28,553 - INFO - Epoch 11/1000 - Train Loss: 0.401429, Val Loss: 0.403475
2025-08-07 18:58:52,847 - INFO - Epoch 12/1000 - Train Loss: 0.393588, Val Loss: 0.399000
2025-08-07 18:58:52,884 - INFO - New best model saved with Val Loss: 0.399000
2025-08-07 18:59:17,154 - INFO - Epoch 13/1000 - Train Loss: 0.391261, Val Loss: 0.390037
2025-08-07 18:59:17,175 - INFO - New best model saved with Val Loss: 0.390037
2025-08-07 18:59:41,412 - INFO - Epoch 14/1000 - Train Loss: 0.395312, Val Loss: 0.379477
2025-08-07 18:59:41,434 - INFO - New best model saved with Val Loss: 0.379477
2025-08-07 19:00:05,651 - INFO - Epoch 15/1000 - Train Loss: 0.382580, Val Loss: 0.376339
2025-08-07 19:00:05,672 - INFO - New best model saved with Val Loss: 0.376339
2025-08-07 19:00:30,026 - INFO - Epoch 16/1000 - Train Loss: 0.378712, Val Loss: 0.384692
2025-08-07 19:00:54,151 - INFO - Epoch 17/1000 - Train Loss: 0.376918, Val Loss: 0.368021
2025-08-07 19:00:54,172 - INFO - New best model saved with Val Loss: 0.368021
2025-08-07 19:01:18,303 - INFO - Epoch 18/1000 - Train Loss: 0.367722, Val Loss: 0.358435
2025-08-07 19:01:18,324 - INFO - New best model saved with Val Loss: 0.358435
2025-08-07 19:01:42,799 - INFO - Epoch 19/1000 - Train Loss: 0.354541, Val Loss: 0.346365
2025-08-07 19:01:42,820 - INFO - New best model saved with Val Loss: 0.346365
2025-08-07 19:02:07,070 - INFO - Epoch 20/1000 - Train Loss: 0.347017, Val Loss: 0.340778
2025-08-07 19:02:07,091 - INFO - New best model saved with Val Loss: 0.340778
2025-08-07 19:02:31,524 - INFO - Epoch 21/1000 - Train Loss: 0.330183, Val Loss: 0.316436
2025-08-07 19:02:31,545 - INFO - New best model saved with Val Loss: 0.316436
2025-08-07 19:02:55,603 - INFO - Epoch 22/1000 - Train Loss: 0.325603, Val Loss: 0.318754
2025-08-07 19:03:20,032 - INFO - Epoch 23/1000 - Train Loss: 0.307702, Val Loss: 0.293929
2025-08-07 19:03:20,053 - INFO - New best model saved with Val Loss: 0.293929
2025-08-07 19:03:44,301 - INFO - Epoch 24/1000 - Train Loss: 0.306396, Val Loss: 0.306673
2025-08-07 19:04:08,573 - INFO - Epoch 25/1000 - Train Loss: 0.306879, Val Loss: 0.290387
2025-08-07 19:04:08,594 - INFO - New best model saved with Val Loss: 0.290387
2025-08-07 19:04:32,889 - INFO - Epoch 26/1000 - Train Loss: 0.291754, Val Loss: 0.278166
2025-08-07 19:04:32,910 - INFO - New best model saved with Val Loss: 0.278166
2025-08-07 19:04:57,146 - INFO - Epoch 27/1000 - Train Loss: 0.284545, Val Loss: 0.276351
2025-08-07 19:04:57,167 - INFO - New best model saved with Val Loss: 0.276351
2025-08-07 19:05:21,517 - INFO - Epoch 28/1000 - Train Loss: 0.279916, Val Loss: 0.281842
2025-08-07 19:05:45,919 - INFO - Epoch 29/1000 - Train Loss: 0.272210, Val Loss: 0.262212
2025-08-07 19:05:45,940 - INFO - New best model saved with Val Loss: 0.262212
2025-08-07 19:06:10,223 - INFO - Epoch 30/1000 - Train Loss: 0.263505, Val Loss: 0.254954
2025-08-07 19:06:10,244 - INFO - New best model saved with Val Loss: 0.254954
2025-08-07 19:06:34,608 - INFO - Epoch 31/1000 - Train Loss: 0.260322, Val Loss: 0.256993
2025-08-07 19:06:58,767 - INFO - Epoch 32/1000 - Train Loss: 0.259914, Val Loss: 0.259862
2025-08-07 19:07:23,118 - INFO - Epoch 33/1000 - Train Loss: 0.252211, Val Loss: 0.252425
2025-08-07 19:07:23,139 - INFO - New best model saved with Val Loss: 0.252425
2025-08-07 19:07:47,403 - INFO - Epoch 34/1000 - Train Loss: 0.256122, Val Loss: 0.254114
2025-08-07 19:08:11,589 - INFO - Epoch 35/1000 - Train Loss: 0.252927, Val Loss: 0.239130
2025-08-07 19:08:11,611 - INFO - New best model saved with Val Loss: 0.239130
2025-08-07 19:08:35,933 - INFO - Epoch 36/1000 - Train Loss: 0.252351, Val Loss: 0.260743
2025-08-07 19:08:59,933 - INFO - Epoch 37/1000 - Train Loss: 0.246726, Val Loss: 0.250859
2025-08-07 19:09:24,241 - INFO - Epoch 38/1000 - Train Loss: 0.245277, Val Loss: 0.231215
2025-08-07 19:09:24,262 - INFO - New best model saved with Val Loss: 0.231215
2025-08-07 19:09:48,439 - INFO - Epoch 39/1000 - Train Loss: 0.240495, Val Loss: 0.248638
2025-08-07 19:10:12,814 - INFO - Epoch 40/1000 - Train Loss: 0.242985, Val Loss: 0.232438
2025-08-07 19:10:37,493 - INFO - Epoch 41/1000 - Train Loss: 0.239731, Val Loss: 0.232626
2025-08-07 19:11:01,878 - INFO - Epoch 42/1000 - Train Loss: 0.241386, Val Loss: 0.225929
2025-08-07 19:11:01,899 - INFO - New best model saved with Val Loss: 0.225929
2025-08-07 19:11:26,142 - INFO - Epoch 43/1000 - Train Loss: 0.241968, Val Loss: 0.230486
2025-08-07 19:11:50,242 - INFO - Epoch 44/1000 - Train Loss: 0.234483, Val Loss: 0.225402
2025-08-07 19:11:50,263 - INFO - New best model saved with Val Loss: 0.225402
2025-08-07 19:12:14,603 - INFO - Epoch 45/1000 - Train Loss: 0.228923, Val Loss: 0.225562
2025-08-07 19:12:38,956 - INFO - Epoch 46/1000 - Train Loss: 0.230366, Val Loss: 0.233873
2025-08-07 19:13:03,153 - INFO - Epoch 47/1000 - Train Loss: 0.228316, Val Loss: 0.227269
2025-08-07 19:13:27,564 - INFO - Epoch 48/1000 - Train Loss: 0.227476, Val Loss: 0.219586
2025-08-07 19:13:27,585 - INFO - New best model saved with Val Loss: 0.219586
2025-08-07 19:13:51,909 - INFO - Epoch 49/1000 - Train Loss: 0.233397, Val Loss: 0.237789
2025-08-07 19:14:16,286 - INFO - Epoch 50/1000 - Train Loss: 0.225265, Val Loss: 0.220611
2025-08-07 19:14:40,882 - INFO - Epoch 51/1000 - Train Loss: 0.220820, Val Loss: 0.218207
2025-08-07 19:14:40,902 - INFO - New best model saved with Val Loss: 0.218207
2025-08-07 19:15:05,144 - INFO - Epoch 52/1000 - Train Loss: 0.223154, Val Loss: 0.221003
2025-08-07 19:15:29,366 - INFO - Epoch 53/1000 - Train Loss: 0.223501, Val Loss: 0.224970
2025-08-07 19:15:53,685 - INFO - Epoch 54/1000 - Train Loss: 0.219195, Val Loss: 0.213364
2025-08-07 19:15:53,706 - INFO - New best model saved with Val Loss: 0.213364
2025-08-07 19:16:17,883 - INFO - Epoch 55/1000 - Train Loss: 0.215412, Val Loss: 0.211194
2025-08-07 19:16:17,904 - INFO - New best model saved with Val Loss: 0.211194
2025-08-07 19:16:42,200 - INFO - Epoch 56/1000 - Train Loss: 0.212411, Val Loss: 0.215128
2025-08-07 19:17:06,358 - INFO - Epoch 57/1000 - Train Loss: 0.214222, Val Loss: 0.208523
2025-08-07 19:17:06,379 - INFO - New best model saved with Val Loss: 0.208523
2025-08-07 19:17:30,759 - INFO - Epoch 58/1000 - Train Loss: 0.211405, Val Loss: 0.205888
2025-08-07 19:17:30,780 - INFO - New best model saved with Val Loss: 0.205888
2025-08-07 19:17:54,941 - INFO - Epoch 59/1000 - Train Loss: 0.209567, Val Loss: 0.200661
2025-08-07 19:17:54,963 - INFO - New best model saved with Val Loss: 0.200661
2025-08-07 19:18:19,352 - INFO - Epoch 60/1000 - Train Loss: 0.209154, Val Loss: 0.200884
2025-08-07 19:18:43,876 - INFO - Epoch 61/1000 - Train Loss: 0.206137, Val Loss: 0.198217
2025-08-07 19:18:43,897 - INFO - New best model saved with Val Loss: 0.198217
2025-08-07 19:19:08,219 - INFO - Epoch 62/1000 - Train Loss: 0.206694, Val Loss: 0.194944
2025-08-07 19:19:08,249 - INFO - New best model saved with Val Loss: 0.194944
2025-08-07 19:19:32,692 - INFO - Epoch 63/1000 - Train Loss: 0.205650, Val Loss: 0.197715
2025-08-07 19:19:57,074 - INFO - Epoch 64/1000 - Train Loss: 0.207678, Val Loss: 0.195446
2025-08-07 19:20:21,441 - INFO - Epoch 65/1000 - Train Loss: 0.200153, Val Loss: 0.198568
2025-08-07 19:20:45,791 - INFO - Epoch 66/1000 - Train Loss: 0.203122, Val Loss: 0.194978
2025-08-07 19:21:09,935 - INFO - Epoch 67/1000 - Train Loss: 0.203508, Val Loss: 0.196799
2025-08-07 19:21:34,261 - INFO - Epoch 68/1000 - Train Loss: 0.205424, Val Loss: 0.206140
2025-08-07 19:21:58,496 - INFO - Epoch 69/1000 - Train Loss: 0.203181, Val Loss: 0.187797
2025-08-07 19:21:58,532 - INFO - New best model saved with Val Loss: 0.187797
2025-08-07 19:22:22,760 - INFO - Epoch 70/1000 - Train Loss: 0.200170, Val Loss: 0.191455
2025-08-07 19:22:47,005 - INFO - Epoch 71/1000 - Train Loss: 0.196233, Val Loss: 0.186080
2025-08-07 19:22:47,026 - INFO - New best model saved with Val Loss: 0.186080
2025-08-07 19:23:11,303 - INFO - Epoch 72/1000 - Train Loss: 0.195286, Val Loss: 0.186776
2025-08-07 19:23:35,429 - INFO - Epoch 73/1000 - Train Loss: 0.195153, Val Loss: 0.182175
2025-08-07 19:23:35,450 - INFO - New best model saved with Val Loss: 0.182175
2025-08-07 19:23:59,580 - INFO - Epoch 74/1000 - Train Loss: 0.195511, Val Loss: 0.182834
2025-08-07 19:24:23,728 - INFO - Epoch 75/1000 - Train Loss: 0.199592, Val Loss: 0.190301
2025-08-07 19:24:47,850 - INFO - Epoch 76/1000 - Train Loss: 0.194324, Val Loss: 0.197822
2025-08-07 19:25:12,021 - INFO - Epoch 77/1000 - Train Loss: 0.199458, Val Loss: 0.199141
2025-08-07 19:25:36,193 - INFO - Epoch 78/1000 - Train Loss: 0.197017, Val Loss: 0.184923
2025-08-07 19:26:00,393 - INFO - Epoch 79/1000 - Train Loss: 0.192839, Val Loss: 0.184655
2025-08-07 19:26:24,547 - INFO - Epoch 80/1000 - Train Loss: 0.190746, Val Loss: 0.190271
2025-08-07 19:26:49,465 - INFO - Epoch 81/1000 - Train Loss: 0.191849, Val Loss: 0.191104
2025-08-07 19:27:14,455 - INFO - Epoch 82/1000 - Train Loss: 0.189747, Val Loss: 0.178996
2025-08-07 19:27:14,476 - INFO - New best model saved with Val Loss: 0.178996
2025-08-07 19:27:39,493 - INFO - Epoch 83/1000 - Train Loss: 0.188345, Val Loss: 0.176183
2025-08-07 19:27:39,515 - INFO - New best model saved with Val Loss: 0.176183
2025-08-07 19:28:04,436 - INFO - Epoch 84/1000 - Train Loss: 0.192180, Val Loss: 0.185372
2025-08-07 19:28:29,304 - INFO - Epoch 85/1000 - Train Loss: 0.189303, Val Loss: 0.194449
2025-08-07 19:28:53,945 - INFO - Epoch 86/1000 - Train Loss: 0.186917, Val Loss: 0.183183
2025-08-07 19:29:18,692 - INFO - Epoch 87/1000 - Train Loss: 0.185146, Val Loss: 0.183197
2025-08-07 19:29:43,362 - INFO - Epoch 88/1000 - Train Loss: 0.186084, Val Loss: 0.175725
2025-08-07 19:29:43,401 - INFO - New best model saved with Val Loss: 0.175725
2025-08-07 19:30:08,173 - INFO - Epoch 89/1000 - Train Loss: 0.187088, Val Loss: 0.189543
2025-08-07 19:30:32,817 - INFO - Epoch 90/1000 - Train Loss: 0.189485, Val Loss: 0.178224
2025-08-07 19:30:57,517 - INFO - Epoch 91/1000 - Train Loss: 0.183455, Val Loss: 0.180333
2025-08-07 19:31:22,137 - INFO - Epoch 92/1000 - Train Loss: 0.184146, Val Loss: 0.183906
2025-08-07 19:31:46,810 - INFO - Epoch 93/1000 - Train Loss: 0.186063, Val Loss: 0.181676
2025-08-07 19:32:11,480 - INFO - Epoch 94/1000 - Train Loss: 0.183661, Val Loss: 0.179708
2025-08-07 19:32:36,022 - INFO - Epoch 95/1000 - Train Loss: 0.183942, Val Loss: 0.176540
2025-08-07 19:33:00,703 - INFO - Epoch 96/1000 - Train Loss: 0.181054, Val Loss: 0.172707
2025-08-07 19:33:00,724 - INFO - New best model saved with Val Loss: 0.172707
2025-08-07 19:33:25,421 - INFO - Epoch 97/1000 - Train Loss: 0.180399, Val Loss: 0.173814
2025-08-07 19:33:50,097 - INFO - Epoch 98/1000 - Train Loss: 0.178592, Val Loss: 0.166492
2025-08-07 19:33:50,118 - INFO - New best model saved with Val Loss: 0.166492
2025-08-07 19:34:14,926 - INFO - Epoch 99/1000 - Train Loss: 0.177670, Val Loss: 0.171852
2025-08-07 19:34:39,408 - INFO - Epoch 100/1000 - Train Loss: 0.181234, Val Loss: 0.175583
2025-08-07 19:35:04,239 - INFO - Epoch 101/1000 - Train Loss: 0.179490, Val Loss: 0.179793
2025-08-07 19:35:28,888 - INFO - Epoch 102/1000 - Train Loss: 0.177598, Val Loss: 0.164603
2025-08-07 19:35:28,910 - INFO - New best model saved with Val Loss: 0.164603
2025-08-07 19:35:53,439 - INFO - Epoch 103/1000 - Train Loss: 0.178640, Val Loss: 0.181982
2025-08-07 19:36:17,975 - INFO - Epoch 104/1000 - Train Loss: 0.176309, Val Loss: 0.181852
2025-08-07 19:36:42,609 - INFO - Epoch 105/1000 - Train Loss: 0.180897, Val Loss: 0.177299
2025-08-07 19:37:07,136 - INFO - Epoch 106/1000 - Train Loss: 0.179040, Val Loss: 0.165377
2025-08-07 19:37:31,531 - INFO - Epoch 107/1000 - Train Loss: 0.173381, Val Loss: 0.168956
2025-08-07 19:37:56,033 - INFO - Epoch 108/1000 - Train Loss: 0.172095, Val Loss: 0.163081
2025-08-07 19:37:56,054 - INFO - New best model saved with Val Loss: 0.163081
2025-08-07 19:38:20,463 - INFO - Epoch 109/1000 - Train Loss: 0.169216, Val Loss: 0.169113
2025-08-07 19:38:44,815 - INFO - Epoch 110/1000 - Train Loss: 0.176655, Val Loss: 0.165690
2025-08-07 19:39:09,259 - INFO - Epoch 111/1000 - Train Loss: 0.172141, Val Loss: 0.159002
2025-08-07 19:39:09,279 - INFO - New best model saved with Val Loss: 0.159002
2025-08-07 19:39:33,749 - INFO - Epoch 112/1000 - Train Loss: 0.173571, Val Loss: 0.173640
2025-08-07 19:39:58,343 - INFO - Epoch 113/1000 - Train Loss: 0.172781, Val Loss: 0.161565
2025-08-07 19:40:23,135 - INFO - Epoch 114/1000 - Train Loss: 0.172374, Val Loss: 0.171271
2025-08-07 19:40:47,688 - INFO - Epoch 115/1000 - Train Loss: 0.171168, Val Loss: 0.160468
2025-08-07 19:41:12,204 - INFO - Epoch 116/1000 - Train Loss: 0.166332, Val Loss: 0.155077
2025-08-07 19:41:12,226 - INFO - New best model saved with Val Loss: 0.155077
2025-08-07 19:41:36,811 - INFO - Epoch 117/1000 - Train Loss: 0.165436, Val Loss: 0.157119
2025-08-07 19:42:01,351 - INFO - Epoch 118/1000 - Train Loss: 0.163929, Val Loss: 0.159562
2025-08-07 19:42:26,099 - INFO - Epoch 119/1000 - Train Loss: 0.168356, Val Loss: 0.161949
2025-08-07 19:42:50,660 - INFO - Epoch 120/1000 - Train Loss: 0.166788, Val Loss: 0.154398
2025-08-07 19:42:50,681 - INFO - New best model saved with Val Loss: 0.154398
2025-08-07 19:43:15,334 - INFO - Epoch 121/1000 - Train Loss: 0.162244, Val Loss: 0.150711
2025-08-07 19:43:15,356 - INFO - New best model saved with Val Loss: 0.150711
2025-08-07 19:43:39,771 - INFO - Epoch 122/1000 - Train Loss: 0.158850, Val Loss: 0.150054
2025-08-07 19:43:39,793 - INFO - New best model saved with Val Loss: 0.150054
2025-08-07 19:44:04,519 - INFO - Epoch 123/1000 - Train Loss: 0.170679, Val Loss: 0.159278
2025-08-07 19:44:29,041 - INFO - Epoch 124/1000 - Train Loss: 0.160835, Val Loss: 0.152577
2025-08-07 19:44:53,638 - INFO - Epoch 125/1000 - Train Loss: 0.161872, Val Loss: 0.157168
2025-08-07 19:45:18,132 - INFO - Epoch 126/1000 - Train Loss: 0.165437, Val Loss: 0.153369
2025-08-07 19:45:42,914 - INFO - Epoch 127/1000 - Train Loss: 0.159813, Val Loss: 0.150373
2025-08-07 19:46:07,584 - INFO - Epoch 128/1000 - Train Loss: 0.161131, Val Loss: 0.150933
2025-08-07 19:46:32,237 - INFO - Epoch 129/1000 - Train Loss: 0.160642, Val Loss: 0.160845
2025-08-07 19:46:56,824 - INFO - Epoch 130/1000 - Train Loss: 0.160146, Val Loss: 0.155659
2025-08-07 19:47:21,578 - INFO - Epoch 131/1000 - Train Loss: 0.161632, Val Loss: 0.159349
2025-08-07 19:47:46,063 - INFO - Epoch 132/1000 - Train Loss: 0.164878, Val Loss: 0.150162
2025-08-07 19:48:10,563 - INFO - Epoch 133/1000 - Train Loss: 0.164414, Val Loss: 0.167430
2025-08-07 19:48:35,101 - INFO - Epoch 134/1000 - Train Loss: 0.160516, Val Loss: 0.148146
2025-08-07 19:48:35,122 - INFO - New best model saved with Val Loss: 0.148146
2025-08-07 19:48:59,695 - INFO - Epoch 135/1000 - Train Loss: 0.157060, Val Loss: 0.151168
2025-08-07 19:49:24,277 - INFO - Epoch 136/1000 - Train Loss: 0.159533, Val Loss: 0.144103
2025-08-07 19:49:24,299 - INFO - New best model saved with Val Loss: 0.144103
2025-08-07 19:49:48,834 - INFO - Epoch 137/1000 - Train Loss: 0.155061, Val Loss: 0.152792
2025-08-07 19:50:13,489 - INFO - Epoch 138/1000 - Train Loss: 0.161747, Val Loss: 0.150713
2025-08-07 19:50:37,956 - INFO - Epoch 139/1000 - Train Loss: 0.154549, Val Loss: 0.140968
2025-08-07 19:50:37,977 - INFO - New best model saved with Val Loss: 0.140968
2025-08-07 19:51:02,475 - INFO - Epoch 140/1000 - Train Loss: 0.158802, Val Loss: 0.144840
2025-08-07 19:51:27,023 - INFO - Epoch 141/1000 - Train Loss: 0.158589, Val Loss: 0.151697
2025-08-07 19:51:51,373 - INFO - Epoch 142/1000 - Train Loss: 0.155259, Val Loss: 0.144603
2025-08-07 19:52:15,946 - INFO - Epoch 143/1000 - Train Loss: 0.155255, Val Loss: 0.148407
2025-08-07 19:52:40,534 - INFO - Epoch 144/1000 - Train Loss: 0.151368, Val Loss: 0.141648
2025-08-07 19:53:04,991 - INFO - Epoch 145/1000 - Train Loss: 0.151896, Val Loss: 0.149863
2025-08-07 19:53:29,408 - INFO - Epoch 146/1000 - Train Loss: 0.153192, Val Loss: 0.141245
2025-08-07 19:53:53,956 - INFO - Epoch 147/1000 - Train Loss: 0.152055, Val Loss: 0.145929
2025-08-07 19:54:18,736 - INFO - Epoch 148/1000 - Train Loss: 0.151063, Val Loss: 0.143439
2025-08-07 19:54:43,483 - INFO - Epoch 149/1000 - Train Loss: 0.153522, Val Loss: 0.140571
2025-08-07 19:54:43,506 - INFO - New best model saved with Val Loss: 0.140571
2025-08-07 19:55:07,983 - INFO - Epoch 150/1000 - Train Loss: 0.147661, Val Loss: 0.139233
2025-08-07 19:55:08,004 - INFO - New best model saved with Val Loss: 0.139233
2025-08-07 19:55:32,918 - INFO - Epoch 151/1000 - Train Loss: 0.148063, Val Loss: 0.144798
2025-08-07 19:55:57,446 - INFO - Epoch 152/1000 - Train Loss: 0.149773, Val Loss: 0.138053
2025-08-07 19:55:57,466 - INFO - New best model saved with Val Loss: 0.138053
2025-08-07 19:56:21,953 - INFO - Epoch 153/1000 - Train Loss: 0.149486, Val Loss: 0.136843
2025-08-07 19:56:21,973 - INFO - New best model saved with Val Loss: 0.136843
2025-08-07 19:56:46,326 - INFO - Epoch 154/1000 - Train Loss: 0.148952, Val Loss: 0.143380
2025-08-07 19:57:10,854 - INFO - Epoch 155/1000 - Train Loss: 0.148906, Val Loss: 0.144883
2025-08-07 19:57:35,612 - INFO - Epoch 156/1000 - Train Loss: 0.145624, Val Loss: 0.137123
2025-08-07 19:58:00,235 - INFO - Epoch 157/1000 - Train Loss: 0.147540, Val Loss: 0.134930
2025-08-07 19:58:00,256 - INFO - New best model saved with Val Loss: 0.134930
2025-08-07 19:58:24,727 - INFO - Epoch 158/1000 - Train Loss: 0.143556, Val Loss: 0.134991
2025-08-07 19:58:49,328 - INFO - Epoch 159/1000 - Train Loss: 0.147974, Val Loss: 0.137077
2025-08-07 19:59:13,819 - INFO - Epoch 160/1000 - Train Loss: 0.146649, Val Loss: 0.134592
2025-08-07 19:59:13,840 - INFO - New best model saved with Val Loss: 0.134592
2025-08-07 19:59:38,620 - INFO - Epoch 161/1000 - Train Loss: 0.144164, Val Loss: 0.135864
2025-08-07 20:00:03,237 - INFO - Epoch 162/1000 - Train Loss: 0.142911, Val Loss: 0.132198
2025-08-07 20:00:03,258 - INFO - New best model saved with Val Loss: 0.132198
2025-08-07 20:00:27,865 - INFO - Epoch 163/1000 - Train Loss: 0.143745, Val Loss: 0.133344
2025-08-07 20:00:52,500 - INFO - Epoch 164/1000 - Train Loss: 0.142226, Val Loss: 0.129564
2025-08-07 20:00:52,521 - INFO - New best model saved with Val Loss: 0.129564
2025-08-07 20:01:17,190 - INFO - Epoch 165/1000 - Train Loss: 0.143931, Val Loss: 0.129371
2025-08-07 20:01:17,211 - INFO - New best model saved with Val Loss: 0.129371
2025-08-07 20:01:41,799 - INFO - Epoch 166/1000 - Train Loss: 0.144468, Val Loss: 0.132772
2025-08-07 20:02:06,457 - INFO - Epoch 167/1000 - Train Loss: 0.142000, Val Loss: 0.128685
2025-08-07 20:02:06,478 - INFO - New best model saved with Val Loss: 0.128685
2025-08-07 20:02:31,172 - INFO - Epoch 168/1000 - Train Loss: 0.139711, Val Loss: 0.135944
2025-08-07 20:02:55,812 - INFO - Epoch 169/1000 - Train Loss: 0.143313, Val Loss: 0.130672
2025-08-07 20:03:20,805 - INFO - Epoch 170/1000 - Train Loss: 0.143258, Val Loss: 0.128367
2025-08-07 20:03:20,826 - INFO - New best model saved with Val Loss: 0.128367
2025-08-07 20:03:45,984 - INFO - Epoch 171/1000 - Train Loss: 0.142462, Val Loss: 0.143785
2025-08-07 20:04:10,501 - INFO - Epoch 172/1000 - Train Loss: 0.141850, Val Loss: 0.131503
2025-08-07 20:04:35,149 - INFO - Epoch 173/1000 - Train Loss: 0.140497, Val Loss: 0.128525
2025-08-07 20:04:59,771 - INFO - Epoch 174/1000 - Train Loss: 0.139128, Val Loss: 0.129772
2025-08-07 20:05:24,300 - INFO - Epoch 175/1000 - Train Loss: 0.140351, Val Loss: 0.129535
2025-08-07 20:05:48,847 - INFO - Epoch 176/1000 - Train Loss: 0.140671, Val Loss: 0.132726
2025-08-07 20:06:13,433 - INFO - Epoch 177/1000 - Train Loss: 0.138930, Val Loss: 0.136885
2025-08-07 20:06:37,968 - INFO - Epoch 178/1000 - Train Loss: 0.141781, Val Loss: 0.130491
2025-08-07 20:07:02,550 - INFO - Epoch 179/1000 - Train Loss: 0.140052, Val Loss: 0.130469
2025-08-07 20:07:27,065 - INFO - Epoch 180/1000 - Train Loss: 0.137576, Val Loss: 0.130499
2025-08-07 20:07:51,811 - INFO - Epoch 181/1000 - Train Loss: 0.136678, Val Loss: 0.122694
2025-08-07 20:07:51,832 - INFO - New best model saved with Val Loss: 0.122694
2025-08-07 20:08:16,410 - INFO - Epoch 182/1000 - Train Loss: 0.138213, Val Loss: 0.126678
2025-08-07 20:08:41,049 - INFO - Epoch 183/1000 - Train Loss: 0.137572, Val Loss: 0.125232
2025-08-07 20:09:05,695 - INFO - Epoch 184/1000 - Train Loss: 0.137132, Val Loss: 0.132765
2025-08-07 20:09:30,307 - INFO - Epoch 185/1000 - Train Loss: 0.134590, Val Loss: 0.122115
2025-08-07 20:09:30,328 - INFO - New best model saved with Val Loss: 0.122115
2025-08-07 20:09:54,847 - INFO - Epoch 186/1000 - Train Loss: 0.134296, Val Loss: 0.126494
2025-08-07 20:10:19,372 - INFO - Epoch 187/1000 - Train Loss: 0.138908, Val Loss: 0.130005
2025-08-07 20:10:43,813 - INFO - Epoch 188/1000 - Train Loss: 0.134917, Val Loss: 0.121701
2025-08-07 20:10:43,835 - INFO - New best model saved with Val Loss: 0.121701
2025-08-07 20:11:08,371 - INFO - Epoch 189/1000 - Train Loss: 0.133014, Val Loss: 0.127242
2025-08-07 20:11:33,068 - INFO - Epoch 190/1000 - Train Loss: 0.133025, Val Loss: 0.121628
2025-08-07 20:11:33,089 - INFO - New best model saved with Val Loss: 0.121628
2025-08-07 20:11:58,022 - INFO - Epoch 191/1000 - Train Loss: 0.131969, Val Loss: 0.132350
2025-08-07 20:12:22,611 - INFO - Epoch 192/1000 - Train Loss: 0.133764, Val Loss: 0.119290
2025-08-07 20:12:22,633 - INFO - New best model saved with Val Loss: 0.119290
2025-08-07 20:12:47,205 - INFO - Epoch 193/1000 - Train Loss: 0.130635, Val Loss: 0.118611
2025-08-07 20:12:47,226 - INFO - New best model saved with Val Loss: 0.118611
2025-08-07 20:13:11,682 - INFO - Epoch 194/1000 - Train Loss: 0.130001, Val Loss: 0.121341
2025-08-07 20:13:36,360 - INFO - Epoch 195/1000 - Train Loss: 0.132253, Val Loss: 0.121257
2025-08-07 20:14:00,994 - INFO - Epoch 196/1000 - Train Loss: 0.129982, Val Loss: 0.123225
2025-08-07 20:14:25,663 - INFO - Epoch 197/1000 - Train Loss: 0.129803, Val Loss: 0.121967
2025-08-07 20:14:50,228 - INFO - Epoch 198/1000 - Train Loss: 0.131890, Val Loss: 0.119408
2025-08-07 20:15:14,844 - INFO - Epoch 199/1000 - Train Loss: 0.132119, Val Loss: 0.117506
2025-08-07 20:15:14,865 - INFO - New best model saved with Val Loss: 0.117506
2025-08-07 20:15:39,307 - INFO - Epoch 200/1000 - Train Loss: 0.131929, Val Loss: 0.124837
2025-08-07 20:16:03,919 - INFO - Epoch 201/1000 - Train Loss: 0.132604, Val Loss: 0.120796
2025-08-07 20:16:28,631 - INFO - Epoch 202/1000 - Train Loss: 0.129908, Val Loss: 0.117737
2025-08-07 20:16:53,230 - INFO - Epoch 203/1000 - Train Loss: 0.129818, Val Loss: 0.114294
2025-08-07 20:16:53,251 - INFO - New best model saved with Val Loss: 0.114294
2025-08-07 20:17:17,892 - INFO - Epoch 204/1000 - Train Loss: 0.130257, Val Loss: 0.118700
2025-08-07 20:17:42,510 - INFO - Epoch 205/1000 - Train Loss: 0.127440, Val Loss: 0.117234
2025-08-07 20:18:06,975 - INFO - Epoch 206/1000 - Train Loss: 0.128551, Val Loss: 0.115957
2025-08-07 20:18:31,518 - INFO - Epoch 207/1000 - Train Loss: 0.126651, Val Loss: 0.116539
2025-08-07 20:18:56,205 - INFO - Epoch 208/1000 - Train Loss: 0.126376, Val Loss: 0.113773
2025-08-07 20:18:56,226 - INFO - New best model saved with Val Loss: 0.113773
2025-08-07 20:19:20,799 - INFO - Epoch 209/1000 - Train Loss: 0.126037, Val Loss: 0.117269
2025-08-07 20:19:45,399 - INFO - Epoch 210/1000 - Train Loss: 0.126789, Val Loss: 0.117842
2025-08-07 20:20:10,198 - INFO - Epoch 211/1000 - Train Loss: 0.125500, Val Loss: 0.113181
2025-08-07 20:20:10,219 - INFO - New best model saved with Val Loss: 0.113181
2025-08-07 20:20:35,083 - INFO - Epoch 212/1000 - Train Loss: 0.125646, Val Loss: 0.114412
2025-08-07 20:21:00,040 - INFO - Epoch 213/1000 - Train Loss: 0.123581, Val Loss: 0.117511
2025-08-07 20:21:24,589 - INFO - Epoch 214/1000 - Train Loss: 0.126764, Val Loss: 0.119811
2025-08-07 20:21:49,822 - INFO - Epoch 215/1000 - Train Loss: 0.126599, Val Loss: 0.123806
2025-08-07 20:22:14,286 - INFO - Epoch 216/1000 - Train Loss: 0.126023, Val Loss: 0.112121
2025-08-07 20:22:14,323 - INFO - New best model saved with Val Loss: 0.112121
2025-08-07 20:22:38,490 - INFO - Epoch 217/1000 - Train Loss: 0.123806, Val Loss: 0.112792
2025-08-07 20:23:02,633 - INFO - Epoch 218/1000 - Train Loss: 0.122562, Val Loss: 0.110993
2025-08-07 20:23:02,654 - INFO - New best model saved with Val Loss: 0.110993
2025-08-07 20:23:26,991 - INFO - Epoch 219/1000 - Train Loss: 0.128397, Val Loss: 0.112604
2025-08-07 20:23:51,086 - INFO - Epoch 220/1000 - Train Loss: 0.122515, Val Loss: 0.114080
2025-08-07 20:24:15,344 - INFO - Epoch 221/1000 - Train Loss: 0.122454, Val Loss: 0.108559
2025-08-07 20:24:15,365 - INFO - New best model saved with Val Loss: 0.108559
2025-08-07 20:24:39,583 - INFO - Epoch 222/1000 - Train Loss: 0.123594, Val Loss: 0.111817
2025-08-07 20:25:03,963 - INFO - Epoch 223/1000 - Train Loss: 0.122480, Val Loss: 0.111575
2025-08-07 20:25:30,272 - INFO - Epoch 224/1000 - Train Loss: 0.121053, Val Loss: 0.110385
2025-08-07 20:25:54,585 - INFO - Epoch 225/1000 - Train Loss: 0.119982, Val Loss: 0.111687
2025-08-07 20:26:18,898 - INFO - Epoch 226/1000 - Train Loss: 0.119545, Val Loss: 0.108789
2025-08-07 20:26:43,048 - INFO - Epoch 227/1000 - Train Loss: 0.117906, Val Loss: 0.106811
2025-08-07 20:26:43,069 - INFO - New best model saved with Val Loss: 0.106811
2025-08-07 20:27:07,294 - INFO - Epoch 228/1000 - Train Loss: 0.116798, Val Loss: 0.107477
2025-08-07 20:27:31,440 - INFO - Epoch 229/1000 - Train Loss: 0.119047, Val Loss: 0.109601
2025-08-07 20:27:55,613 - INFO - Epoch 230/1000 - Train Loss: 0.118893, Val Loss: 0.105392
2025-08-07 20:27:55,634 - INFO - New best model saved with Val Loss: 0.105392
2025-08-07 20:28:20,116 - INFO - Epoch 231/1000 - Train Loss: 0.117128, Val Loss: 0.104836
2025-08-07 20:28:20,138 - INFO - New best model saved with Val Loss: 0.104836
2025-08-07 20:28:44,426 - INFO - Epoch 232/1000 - Train Loss: 0.118796, Val Loss: 0.106649
2025-08-07 20:29:08,856 - INFO - Epoch 233/1000 - Train Loss: 0.116792, Val Loss: 0.104175
2025-08-07 20:29:08,877 - INFO - New best model saved with Val Loss: 0.104175
2025-08-07 20:29:33,169 - INFO - Epoch 234/1000 - Train Loss: 0.114867, Val Loss: 0.102068
2025-08-07 20:29:33,189 - INFO - New best model saved with Val Loss: 0.102068
2025-08-07 20:29:57,361 - INFO - Epoch 235/1000 - Train Loss: 0.114859, Val Loss: 0.102877
2025-08-07 20:30:21,568 - INFO - Epoch 236/1000 - Train Loss: 0.116571, Val Loss: 0.115372
2025-08-07 20:30:45,842 - INFO - Epoch 237/1000 - Train Loss: 0.116054, Val Loss: 0.100775
2025-08-07 20:30:45,864 - INFO - New best model saved with Val Loss: 0.100775
2025-08-07 20:31:10,106 - INFO - Epoch 238/1000 - Train Loss: 0.116476, Val Loss: 0.108786
2025-08-07 20:31:34,605 - INFO - Epoch 239/1000 - Train Loss: 0.114686, Val Loss: 0.103371
2025-08-07 20:31:59,413 - INFO - Epoch 240/1000 - Train Loss: 0.113947, Val Loss: 0.104217
2025-08-07 20:32:24,447 - INFO - Epoch 241/1000 - Train Loss: 0.115471, Val Loss: 0.102068
2025-08-07 20:32:49,319 - INFO - Epoch 242/1000 - Train Loss: 0.115056, Val Loss: 0.106218
2025-08-07 20:33:14,107 - INFO - Epoch 243/1000 - Train Loss: 0.113273, Val Loss: 0.102385
2025-08-07 20:33:38,780 - INFO - Epoch 244/1000 - Train Loss: 0.114501, Val Loss: 0.099588
2025-08-07 20:33:38,802 - INFO - New best model saved with Val Loss: 0.099588
2025-08-07 20:34:03,679 - INFO - Epoch 245/1000 - Train Loss: 0.113075, Val Loss: 0.098664
2025-08-07 20:34:03,700 - INFO - New best model saved with Val Loss: 0.098664
2025-08-07 20:34:28,433 - INFO - Epoch 246/1000 - Train Loss: 0.111593, Val Loss: 0.098988
2025-08-07 20:34:53,090 - INFO - Epoch 247/1000 - Train Loss: 0.110894, Val Loss: 0.098372
2025-08-07 20:34:53,111 - INFO - New best model saved with Val Loss: 0.098372
2025-08-07 20:35:17,799 - INFO - Epoch 248/1000 - Train Loss: 0.111913, Val Loss: 0.103513
2025-08-07 20:35:42,325 - INFO - Epoch 249/1000 - Train Loss: 0.113317, Val Loss: 0.101707
2025-08-07 20:36:06,957 - INFO - Epoch 250/1000 - Train Loss: 0.112771, Val Loss: 0.103553
2025-08-07 20:36:31,668 - INFO - Epoch 251/1000 - Train Loss: 0.112059, Val Loss: 0.102294
2025-08-07 20:36:56,180 - INFO - Epoch 252/1000 - Train Loss: 0.111628, Val Loss: 0.100313
2025-08-07 20:37:20,880 - INFO - Epoch 253/1000 - Train Loss: 0.111174, Val Loss: 0.098254
2025-08-07 20:37:20,902 - INFO - New best model saved with Val Loss: 0.098254
2025-08-07 20:37:45,667 - INFO - Epoch 254/1000 - Train Loss: 0.111045, Val Loss: 0.100872
2025-08-07 20:38:10,473 - INFO - Epoch 255/1000 - Train Loss: 0.112134, Val Loss: 0.099737
2025-08-07 20:38:35,126 - INFO - Epoch 256/1000 - Train Loss: 0.110729, Val Loss: 0.097905
2025-08-07 20:38:35,148 - INFO - New best model saved with Val Loss: 0.097905
2025-08-07 20:38:59,633 - INFO - Epoch 257/1000 - Train Loss: 0.109269, Val Loss: 0.096479
2025-08-07 20:38:59,655 - INFO - New best model saved with Val Loss: 0.096479
2025-08-07 20:39:24,355 - INFO - Epoch 258/1000 - Train Loss: 0.108617, Val Loss: 0.099272
2025-08-07 20:39:48,915 - INFO - Epoch 259/1000 - Train Loss: 0.109703, Val Loss: 0.102167
2025-08-07 20:40:13,451 - INFO - Epoch 260/1000 - Train Loss: 0.110573, Val Loss: 0.100644
2025-08-07 20:40:38,245 - INFO - Epoch 261/1000 - Train Loss: 0.108208, Val Loss: 0.095574
2025-08-07 20:40:38,268 - INFO - New best model saved with Val Loss: 0.095574
2025-08-07 20:41:02,794 - INFO - Epoch 262/1000 - Train Loss: 0.109046, Val Loss: 0.101602
2025-08-07 20:41:28,375 - INFO - Epoch 263/1000 - Train Loss: 0.110924, Val Loss: 0.104020
2025-08-07 20:41:52,829 - INFO - Epoch 264/1000 - Train Loss: 0.111873, Val Loss: 0.098226
2025-08-07 20:42:17,340 - INFO - Epoch 265/1000 - Train Loss: 0.107282, Val Loss: 0.093919
2025-08-07 20:42:17,361 - INFO - New best model saved with Val Loss: 0.093919
2025-08-07 20:42:41,944 - INFO - Epoch 266/1000 - Train Loss: 0.107213, Val Loss: 0.095453
2025-08-07 20:43:06,576 - INFO - Epoch 267/1000 - Train Loss: 0.107379, Val Loss: 0.101065
2025-08-07 20:43:31,218 - INFO - Epoch 268/1000 - Train Loss: 0.108055, Val Loss: 0.093559
2025-08-07 20:43:31,240 - INFO - New best model saved with Val Loss: 0.093559
2025-08-07 20:43:55,752 - INFO - Epoch 269/1000 - Train Loss: 0.107291, Val Loss: 0.096452
2025-08-07 20:44:20,399 - INFO - Epoch 270/1000 - Train Loss: 0.107250, Val Loss: 0.092704
2025-08-07 20:44:20,420 - INFO - New best model saved with Val Loss: 0.092704
2025-08-07 20:44:45,191 - INFO - Epoch 271/1000 - Train Loss: 0.105959, Val Loss: 0.098419
2025-08-07 20:45:09,755 - INFO - Epoch 272/1000 - Train Loss: 0.106057, Val Loss: 0.094891
2025-08-07 20:45:34,365 - INFO - Epoch 273/1000 - Train Loss: 0.107221, Val Loss: 0.094532
2025-08-07 20:45:59,159 - INFO - Epoch 274/1000 - Train Loss: 0.108771, Val Loss: 0.100156
2025-08-07 20:46:23,963 - INFO - Epoch 275/1000 - Train Loss: 0.106536, Val Loss: 0.099120
2025-08-07 20:46:48,997 - INFO - Epoch 276/1000 - Train Loss: 0.106518, Val Loss: 0.095078
2025-08-07 20:47:13,854 - INFO - Epoch 277/1000 - Train Loss: 0.108080, Val Loss: 0.104779
2025-08-07 20:47:38,295 - INFO - Epoch 278/1000 - Train Loss: 0.105901, Val Loss: 0.094648
2025-08-07 20:48:02,884 - INFO - Epoch 279/1000 - Train Loss: 0.104965, Val Loss: 0.092272
2025-08-07 20:48:02,907 - INFO - New best model saved with Val Loss: 0.092272
2025-08-07 20:48:27,553 - INFO - Epoch 280/1000 - Train Loss: 0.103991, Val Loss: 0.095813
2025-08-07 20:48:52,461 - INFO - Epoch 281/1000 - Train Loss: 0.106445, Val Loss: 0.094082
2025-08-07 20:49:17,054 - INFO - Epoch 282/1000 - Train Loss: 0.105361, Val Loss: 0.094196
2025-08-07 20:49:41,648 - INFO - Epoch 283/1000 - Train Loss: 0.104670, Val Loss: 0.095914
2025-08-07 20:50:06,242 - INFO - Epoch 284/1000 - Train Loss: 0.104242, Val Loss: 0.093265
2025-08-07 20:50:30,947 - INFO - Epoch 285/1000 - Train Loss: 0.106801, Val Loss: 0.095035
2025-08-07 20:50:55,592 - INFO - Epoch 286/1000 - Train Loss: 0.104130, Val Loss: 0.097310
2025-08-07 20:51:20,223 - INFO - Epoch 287/1000 - Train Loss: 0.104353, Val Loss: 0.090971
2025-08-07 20:51:20,244 - INFO - New best model saved with Val Loss: 0.090971
2025-08-07 20:51:45,048 - INFO - Epoch 288/1000 - Train Loss: 0.103706, Val Loss: 0.093344
2025-08-07 20:52:09,706 - INFO - Epoch 289/1000 - Train Loss: 0.103590, Val Loss: 0.090646
2025-08-07 20:52:09,727 - INFO - New best model saved with Val Loss: 0.090646
2025-08-07 20:52:34,440 - INFO - Epoch 290/1000 - Train Loss: 0.102674, Val Loss: 0.092878
2025-08-07 20:52:59,338 - INFO - Epoch 291/1000 - Train Loss: 0.104971, Val Loss: 0.102879
2025-08-07 20:53:24,166 - INFO - Epoch 292/1000 - Train Loss: 0.106112, Val Loss: 0.089669
2025-08-07 20:53:24,187 - INFO - New best model saved with Val Loss: 0.089669
2025-08-07 20:53:48,672 - INFO - Epoch 293/1000 - Train Loss: 0.102550, Val Loss: 0.095973
2025-08-07 20:54:13,038 - INFO - Epoch 294/1000 - Train Loss: 0.104417, Val Loss: 0.089588
2025-08-07 20:54:13,060 - INFO - New best model saved with Val Loss: 0.089588
2025-08-07 20:54:37,631 - INFO - Epoch 295/1000 - Train Loss: 0.101500, Val Loss: 0.095766
2025-08-07 20:55:02,304 - INFO - Epoch 296/1000 - Train Loss: 0.101782, Val Loss: 0.089489
2025-08-07 20:55:02,325 - INFO - New best model saved with Val Loss: 0.089489
2025-08-07 20:55:26,994 - INFO - Epoch 297/1000 - Train Loss: 0.101439, Val Loss: 0.092607
2025-08-07 20:55:51,566 - INFO - Epoch 298/1000 - Train Loss: 0.102230, Val Loss: 0.090740
2025-08-07 20:56:16,145 - INFO - Epoch 299/1000 - Train Loss: 0.100274, Val Loss: 0.091097
2025-08-07 20:56:40,681 - INFO - Epoch 300/1000 - Train Loss: 0.101984, Val Loss: 0.090787
2025-08-07 20:57:05,420 - INFO - Epoch 301/1000 - Train Loss: 0.103521, Val Loss: 0.088429
2025-08-07 20:57:05,460 - INFO - New best model saved with Val Loss: 0.088429
2025-08-07 20:57:30,014 - INFO - Epoch 302/1000 - Train Loss: 0.102512, Val Loss: 0.086332
2025-08-07 20:57:30,035 - INFO - New best model saved with Val Loss: 0.086332
2025-08-07 20:57:54,564 - INFO - Epoch 303/1000 - Train Loss: 0.100479, Val Loss: 0.088080
2025-08-07 20:58:18,971 - INFO - Epoch 304/1000 - Train Loss: 0.101202, Val Loss: 0.093941
2025-08-07 20:58:43,471 - INFO - Epoch 305/1000 - Train Loss: 0.101837, Val Loss: 0.087759
2025-08-07 20:59:08,094 - INFO - Epoch 306/1000 - Train Loss: 0.099872, Val Loss: 0.088499
2025-08-07 20:59:32,735 - INFO - Epoch 307/1000 - Train Loss: 0.103112, Val Loss: 0.091760
2025-08-07 20:59:57,295 - INFO - Epoch 308/1000 - Train Loss: 0.100589, Val Loss: 0.094309
2025-08-07 21:00:21,954 - INFO - Epoch 309/1000 - Train Loss: 0.101364, Val Loss: 0.088857
2025-08-07 21:00:46,570 - INFO - Epoch 310/1000 - Train Loss: 0.103020, Val Loss: 0.093920
2025-08-07 21:01:11,441 - INFO - Epoch 311/1000 - Train Loss: 0.103217, Val Loss: 0.087604
2025-08-07 21:01:36,215 - INFO - Epoch 312/1000 - Train Loss: 0.100490, Val Loss: 0.089335
2025-08-07 21:02:00,775 - INFO - Epoch 313/1000 - Train Loss: 0.101165, Val Loss: 0.088410
2025-08-07 21:02:25,352 - INFO - Epoch 314/1000 - Train Loss: 0.099929, Val Loss: 0.088331
2025-08-07 21:02:50,015 - INFO - Epoch 315/1000 - Train Loss: 0.098248, Val Loss: 0.087178
2025-08-07 21:03:14,565 - INFO - Epoch 316/1000 - Train Loss: 0.099628, Val Loss: 0.087028
2025-08-07 21:03:39,365 - INFO - Epoch 317/1000 - Train Loss: 0.101223, Val Loss: 0.091950
2025-08-07 21:04:04,007 - INFO - Epoch 318/1000 - Train Loss: 0.101672, Val Loss: 0.091134
2025-08-07 21:04:28,706 - INFO - Epoch 319/1000 - Train Loss: 0.097733, Val Loss: 0.086553
2025-08-07 21:04:53,155 - INFO - Epoch 320/1000 - Train Loss: 0.099630, Val Loss: 0.087830
2025-08-07 21:05:17,744 - INFO - Epoch 321/1000 - Train Loss: 0.099323, Val Loss: 0.088601
2025-08-07 21:05:42,213 - INFO - Epoch 322/1000 - Train Loss: 0.098296, Val Loss: 0.087784
2025-08-07 21:06:06,819 - INFO - Epoch 323/1000 - Train Loss: 0.100007, Val Loss: 0.089748
2025-08-07 21:06:31,298 - INFO - Epoch 324/1000 - Train Loss: 0.098817, Val Loss: 0.085936
2025-08-07 21:06:31,321 - INFO - New best model saved with Val Loss: 0.085936
2025-08-07 21:06:55,884 - INFO - Epoch 325/1000 - Train Loss: 0.098222, Val Loss: 0.086085
2025-08-07 21:07:20,521 - INFO - Epoch 326/1000 - Train Loss: 0.098663, Val Loss: 0.084823
2025-08-07 21:07:20,542 - INFO - New best model saved with Val Loss: 0.084823
2025-08-07 21:07:44,994 - INFO - Epoch 327/1000 - Train Loss: 0.098015, Val Loss: 0.086550
2025-08-07 21:08:09,789 - INFO - Epoch 328/1000 - Train Loss: 0.100051, Val Loss: 0.086423
2025-08-07 21:08:34,621 - INFO - Epoch 329/1000 - Train Loss: 0.098038, Val Loss: 0.086314
2025-08-07 21:08:59,351 - INFO - Epoch 330/1000 - Train Loss: 0.097692, Val Loss: 0.086605
2025-08-07 21:09:24,279 - INFO - Epoch 331/1000 - Train Loss: 0.097659, Val Loss: 0.086496
2025-08-07 21:09:48,886 - INFO - Epoch 332/1000 - Train Loss: 0.096939, Val Loss: 0.088632
2025-08-07 21:10:13,492 - INFO - Epoch 333/1000 - Train Loss: 0.098102, Val Loss: 0.086302
2025-08-07 21:10:37,899 - INFO - Epoch 334/1000 - Train Loss: 0.096524, Val Loss: 0.087489
2025-08-07 21:11:02,338 - INFO - Epoch 335/1000 - Train Loss: 0.096059, Val Loss: 0.084035
2025-08-07 21:11:02,378 - INFO - New best model saved with Val Loss: 0.084035
2025-08-07 21:11:27,074 - INFO - Epoch 336/1000 - Train Loss: 0.096054, Val Loss: 0.083223
2025-08-07 21:11:27,095 - INFO - New best model saved with Val Loss: 0.083223
2025-08-07 21:11:51,650 - INFO - Epoch 337/1000 - Train Loss: 0.096046, Val Loss: 0.087490
2025-08-07 21:12:16,128 - INFO - Epoch 338/1000 - Train Loss: 0.098125, Val Loss: 0.084882
2025-08-07 21:12:40,809 - INFO - Epoch 339/1000 - Train Loss: 0.094915, Val Loss: 0.085699
2025-08-07 21:13:05,404 - INFO - Epoch 340/1000 - Train Loss: 0.097145, Val Loss: 0.089816
2025-08-07 21:13:30,356 - INFO - Epoch 341/1000 - Train Loss: 0.097216, Val Loss: 0.088356
2025-08-07 21:13:54,959 - INFO - Epoch 342/1000 - Train Loss: 0.097817, Val Loss: 0.084989
2025-08-07 21:14:19,652 - INFO - Epoch 343/1000 - Train Loss: 0.094321, Val Loss: 0.083557
2025-08-07 21:14:44,396 - INFO - Epoch 344/1000 - Train Loss: 0.093277, Val Loss: 0.085192
2025-08-07 21:15:08,987 - INFO - Epoch 345/1000 - Train Loss: 0.098530, Val Loss: 0.085221
2025-08-07 21:15:33,524 - INFO - Epoch 346/1000 - Train Loss: 0.096157, Val Loss: 0.083828
2025-08-07 21:15:58,207 - INFO - Epoch 347/1000 - Train Loss: 0.094935, Val Loss: 0.084987
2025-08-07 21:16:22,680 - INFO - Epoch 348/1000 - Train Loss: 0.097227, Val Loss: 0.084211
2025-08-07 21:16:47,280 - INFO - Epoch 349/1000 - Train Loss: 0.096407, Val Loss: 0.089440
2025-08-07 21:17:11,829 - INFO - Epoch 350/1000 - Train Loss: 0.095907, Val Loss: 0.087768
2025-08-07 21:17:36,617 - INFO - Epoch 351/1000 - Train Loss: 0.097726, Val Loss: 0.087162
2025-08-07 21:18:01,179 - INFO - Epoch 352/1000 - Train Loss: 0.095021, Val Loss: 0.083436
2025-08-07 21:18:25,897 - INFO - Epoch 353/1000 - Train Loss: 0.094135, Val Loss: 0.081540
2025-08-07 21:18:25,920 - INFO - New best model saved with Val Loss: 0.081540
2025-08-07 21:18:50,455 - INFO - Epoch 354/1000 - Train Loss: 0.093600, Val Loss: 0.083080
2025-08-07 21:19:15,031 - INFO - Epoch 355/1000 - Train Loss: 0.094944, Val Loss: 0.081069
2025-08-07 21:19:15,052 - INFO - New best model saved with Val Loss: 0.081069
2025-08-07 21:19:39,643 - INFO - Epoch 356/1000 - Train Loss: 0.092763, Val Loss: 0.081421
2025-08-07 21:20:04,201 - INFO - Epoch 357/1000 - Train Loss: 0.092901, Val Loss: 0.079631
2025-08-07 21:20:04,223 - INFO - New best model saved with Val Loss: 0.079631
2025-08-07 21:20:28,925 - INFO - Epoch 358/1000 - Train Loss: 0.094284, Val Loss: 0.082160
2025-08-07 21:20:54,326 - INFO - Epoch 359/1000 - Train Loss: 0.093684, Val Loss: 0.083981
2025-08-07 21:21:18,442 - INFO - Epoch 360/1000 - Train Loss: 0.092588, Val Loss: 0.079228
2025-08-07 21:21:18,463 - INFO - New best model saved with Val Loss: 0.079228
2025-08-07 21:21:42,977 - INFO - Epoch 361/1000 - Train Loss: 0.092104, Val Loss: 0.082369
2025-08-07 21:22:07,199 - INFO - Epoch 362/1000 - Train Loss: 0.093284, Val Loss: 0.084192
2025-08-07 21:22:31,554 - INFO - Epoch 363/1000 - Train Loss: 0.092890, Val Loss: 0.080079
2025-08-07 21:22:55,893 - INFO - Epoch 364/1000 - Train Loss: 0.096456, Val Loss: 0.086270
2025-08-07 21:23:20,270 - INFO - Epoch 365/1000 - Train Loss: 0.094511, Val Loss: 0.088389
2025-08-07 21:23:44,621 - INFO - Epoch 366/1000 - Train Loss: 0.095456, Val Loss: 0.083927
2025-08-07 21:24:09,026 - INFO - Epoch 367/1000 - Train Loss: 0.094847, Val Loss: 0.083260
2025-08-07 21:24:33,188 - INFO - Epoch 368/1000 - Train Loss: 0.092961, Val Loss: 0.083949
2025-08-07 21:24:57,488 - INFO - Epoch 369/1000 - Train Loss: 0.092879, Val Loss: 0.082548
2025-08-07 21:25:21,704 - INFO - Epoch 370/1000 - Train Loss: 0.093125, Val Loss: 0.084104
2025-08-07 21:25:46,092 - INFO - Epoch 371/1000 - Train Loss: 0.093679, Val Loss: 0.083533
2025-08-07 21:26:10,351 - INFO - Epoch 372/1000 - Train Loss: 0.094813, Val Loss: 0.083295
2025-08-07 21:26:34,337 - INFO - Epoch 373/1000 - Train Loss: 0.092623, Val Loss: 0.083438
2025-08-07 21:26:58,414 - INFO - Epoch 374/1000 - Train Loss: 0.091931, Val Loss: 0.079167
2025-08-07 21:26:58,444 - INFO - New best model saved with Val Loss: 0.079167
2025-08-07 21:27:22,586 - INFO - Epoch 375/1000 - Train Loss: 0.090765, Val Loss: 0.082145
2025-08-07 21:27:46,815 - INFO - Epoch 376/1000 - Train Loss: 0.092093, Val Loss: 0.084426
2025-08-07 21:28:10,902 - INFO - Epoch 377/1000 - Train Loss: 0.097600, Val Loss: 0.084032
2025-08-07 21:28:35,068 - INFO - Epoch 378/1000 - Train Loss: 0.093900, Val Loss: 0.084675
2025-08-07 21:28:59,113 - INFO - Epoch 379/1000 - Train Loss: 0.091423, Val Loss: 0.081785
2025-08-07 21:29:23,236 - INFO - Epoch 380/1000 - Train Loss: 0.093070, Val Loss: 0.078691
2025-08-07 21:29:23,257 - INFO - New best model saved with Val Loss: 0.078691
2025-08-07 21:29:47,676 - INFO - Epoch 381/1000 - Train Loss: 0.090915, Val Loss: 0.080970
2025-08-07 21:30:12,301 - INFO - Epoch 382/1000 - Train Loss: 0.092611, Val Loss: 0.084965
2025-08-07 21:30:37,398 - INFO - Epoch 383/1000 - Train Loss: 0.090919, Val Loss: 0.082770
2025-08-07 21:31:01,674 - INFO - Epoch 384/1000 - Train Loss: 0.092925, Val Loss: 0.081228
2025-08-07 21:31:25,790 - INFO - Epoch 385/1000 - Train Loss: 0.090790, Val Loss: 0.079588
2025-08-07 21:31:49,804 - INFO - Epoch 386/1000 - Train Loss: 0.091695, Val Loss: 0.079856
2025-08-07 21:32:13,966 - INFO - Epoch 387/1000 - Train Loss: 0.090105, Val Loss: 0.080994
2025-08-07 21:32:38,456 - INFO - Epoch 388/1000 - Train Loss: 0.091198, Val Loss: 0.088498
2025-08-07 21:33:03,169 - INFO - Epoch 389/1000 - Train Loss: 0.091585, Val Loss: 0.081649
2025-08-07 21:33:27,346 - INFO - Epoch 390/1000 - Train Loss: 0.089577, Val Loss: 0.078327
2025-08-07 21:33:27,379 - INFO - New best model saved with Val Loss: 0.078327
2025-08-07 21:33:51,708 - INFO - Epoch 391/1000 - Train Loss: 0.089534, Val Loss: 0.081258
2025-08-07 21:34:15,957 - INFO - Epoch 392/1000 - Train Loss: 0.089215, Val Loss: 0.078168
2025-08-07 21:34:15,978 - INFO - New best model saved with Val Loss: 0.078168
2025-08-07 21:34:40,253 - INFO - Epoch 393/1000 - Train Loss: 0.091306, Val Loss: 0.085728
2025-08-07 21:35:04,468 - INFO - Epoch 394/1000 - Train Loss: 0.092111, Val Loss: 0.080968
2025-08-07 21:35:28,647 - INFO - Epoch 395/1000 - Train Loss: 0.091753, Val Loss: 0.078016
2025-08-07 21:35:28,668 - INFO - New best model saved with Val Loss: 0.078016
2025-08-07 21:35:52,942 - INFO - Epoch 396/1000 - Train Loss: 0.091617, Val Loss: 0.079050
2025-08-07 21:36:17,302 - INFO - Epoch 397/1000 - Train Loss: 0.089399, Val Loss: 0.079889
2025-08-07 21:36:41,474 - INFO - Epoch 398/1000 - Train Loss: 0.090331, Val Loss: 0.084008
2025-08-07 21:37:05,697 - INFO - Epoch 399/1000 - Train Loss: 0.091146, Val Loss: 0.082162
2025-08-07 21:37:29,725 - INFO - Epoch 400/1000 - Train Loss: 0.091620, Val Loss: 0.083108
2025-08-07 21:37:54,182 - INFO - Epoch 401/1000 - Train Loss: 0.091087, Val Loss: 0.081238
2025-08-07 21:38:18,424 - INFO - Epoch 402/1000 - Train Loss: 0.091479, Val Loss: 0.080047
2025-08-07 21:38:42,472 - INFO - Epoch 403/1000 - Train Loss: 0.089567, Val Loss: 0.081203
2025-08-07 21:39:06,695 - INFO - Epoch 404/1000 - Train Loss: 0.091681, Val Loss: 0.083480
2025-08-07 21:39:30,849 - INFO - Epoch 405/1000 - Train Loss: 0.090375, Val Loss: 0.076628
2025-08-07 21:39:30,870 - INFO - New best model saved with Val Loss: 0.076628
2025-08-07 21:39:55,094 - INFO - Epoch 406/1000 - Train Loss: 0.088327, Val Loss: 0.079399
2025-08-07 21:40:19,155 - INFO - Epoch 407/1000 - Train Loss: 0.088945, Val Loss: 0.083440
2025-08-07 21:40:43,333 - INFO - Epoch 408/1000 - Train Loss: 0.091906, Val Loss: 0.078500
2025-08-07 21:41:07,509 - INFO - Epoch 409/1000 - Train Loss: 0.087970, Val Loss: 0.077221
2025-08-07 21:41:31,603 - INFO - Epoch 410/1000 - Train Loss: 0.088593, Val Loss: 0.077597
2025-08-07 21:41:56,279 - INFO - Epoch 411/1000 - Train Loss: 0.088463, Val Loss: 0.079797
2025-08-07 21:42:20,617 - INFO - Epoch 412/1000 - Train Loss: 0.089358, Val Loss: 0.077001
2025-08-07 21:42:44,893 - INFO - Epoch 413/1000 - Train Loss: 0.088643, Val Loss: 0.076812
2025-08-07 21:43:09,327 - INFO - Epoch 414/1000 - Train Loss: 0.089113, Val Loss: 0.078659
2025-08-07 21:43:33,637 - INFO - Epoch 415/1000 - Train Loss: 0.088885, Val Loss: 0.082171
2025-08-07 21:43:57,959 - INFO - Epoch 416/1000 - Train Loss: 0.088105, Val Loss: 0.075952
2025-08-07 21:43:57,981 - INFO - New best model saved with Val Loss: 0.075952
2025-08-07 21:44:22,219 - INFO - Epoch 417/1000 - Train Loss: 0.088194, Val Loss: 0.080588
2025-08-07 21:44:46,542 - INFO - Epoch 418/1000 - Train Loss: 0.089130, Val Loss: 0.077785
2025-08-07 21:45:10,699 - INFO - Epoch 419/1000 - Train Loss: 0.088119, Val Loss: 0.076386
2025-08-07 21:45:34,833 - INFO - Epoch 420/1000 - Train Loss: 0.087803, Val Loss: 0.075971
2025-08-07 21:45:59,400 - INFO - Epoch 421/1000 - Train Loss: 0.088471, Val Loss: 0.079948
2025-08-07 21:46:23,757 - INFO - Epoch 422/1000 - Train Loss: 0.089126, Val Loss: 0.083976
2025-08-07 21:46:48,117 - INFO - Epoch 423/1000 - Train Loss: 0.088945, Val Loss: 0.075002
2025-08-07 21:46:48,139 - INFO - New best model saved with Val Loss: 0.075002
2025-08-07 21:47:12,455 - INFO - Epoch 424/1000 - Train Loss: 0.088554, Val Loss: 0.076317
2025-08-07 21:47:36,862 - INFO - Epoch 425/1000 - Train Loss: 0.088960, Val Loss: 0.080686
2025-08-07 21:48:01,210 - INFO - Epoch 426/1000 - Train Loss: 0.091440, Val Loss: 0.080306
2025-08-07 21:48:25,634 - INFO - Epoch 427/1000 - Train Loss: 0.086501, Val Loss: 0.077195
2025-08-07 21:48:49,759 - INFO - Epoch 428/1000 - Train Loss: 0.086789, Val Loss: 0.076372
2025-08-07 21:49:14,085 - INFO - Epoch 429/1000 - Train Loss: 0.088012, Val Loss: 0.079008
2025-08-07 21:49:38,291 - INFO - Epoch 430/1000 - Train Loss: 0.088518, Val Loss: 0.077190
2025-08-07 21:50:02,734 - INFO - Epoch 431/1000 - Train Loss: 0.087837, Val Loss: 0.074757
2025-08-07 21:50:02,756 - INFO - New best model saved with Val Loss: 0.074757
2025-08-07 21:50:27,000 - INFO - Epoch 432/1000 - Train Loss: 0.087112, Val Loss: 0.079275
2025-08-07 21:50:51,305 - INFO - Epoch 433/1000 - Train Loss: 0.087537, Val Loss: 0.076233
2025-08-07 21:51:15,810 - INFO - Epoch 434/1000 - Train Loss: 0.086471, Val Loss: 0.076456
2025-08-07 21:51:40,505 - INFO - Epoch 435/1000 - Train Loss: 0.087491, Val Loss: 0.075808
2025-08-07 21:52:04,971 - INFO - Epoch 436/1000 - Train Loss: 0.087506, Val Loss: 0.074358
2025-08-07 21:52:05,005 - INFO - New best model saved with Val Loss: 0.074358
2025-08-07 21:52:29,562 - INFO - Epoch 437/1000 - Train Loss: 0.085844, Val Loss: 0.076134
2025-08-07 21:52:53,998 - INFO - Epoch 438/1000 - Train Loss: 0.087140, Val Loss: 0.076959
2025-08-07 21:53:18,188 - INFO - Epoch 439/1000 - Train Loss: 0.086789, Val Loss: 0.077307
2025-08-07 21:53:42,546 - INFO - Epoch 440/1000 - Train Loss: 0.087068, Val Loss: 0.076025
2025-08-07 21:54:06,970 - INFO - Epoch 441/1000 - Train Loss: 0.087610, Val Loss: 0.080113
2025-08-07 21:54:31,380 - INFO - Epoch 442/1000 - Train Loss: 0.086419, Val Loss: 0.076299
2025-08-07 21:54:55,432 - INFO - Epoch 443/1000 - Train Loss: 0.086893, Val Loss: 0.074507
2025-08-07 21:55:19,671 - INFO - Epoch 444/1000 - Train Loss: 0.085492, Val Loss: 0.077651
2025-08-07 21:55:43,948 - INFO - Epoch 445/1000 - Train Loss: 0.086839, Val Loss: 0.081074
2025-08-07 21:56:08,376 - INFO - Epoch 446/1000 - Train Loss: 0.086652, Val Loss: 0.076872
2025-08-07 21:56:32,733 - INFO - Epoch 447/1000 - Train Loss: 0.086344, Val Loss: 0.077630
2025-08-07 21:56:56,905 - INFO - Epoch 448/1000 - Train Loss: 0.087237, Val Loss: 0.078503
2025-08-07 21:57:21,121 - INFO - Epoch 449/1000 - Train Loss: 0.086679, Val Loss: 0.073295
2025-08-07 21:57:21,142 - INFO - New best model saved with Val Loss: 0.073295
2025-08-07 21:57:45,416 - INFO - Epoch 450/1000 - Train Loss: 0.084297, Val Loss: 0.076024
2025-08-07 21:58:09,554 - INFO - Epoch 451/1000 - Train Loss: 0.085806, Val Loss: 0.075336
2025-08-07 21:58:33,878 - INFO - Epoch 452/1000 - Train Loss: 0.087329, Val Loss: 0.074854
2025-08-07 21:58:58,124 - INFO - Epoch 453/1000 - Train Loss: 0.086005, Val Loss: 0.073903
2025-08-07 21:59:22,381 - INFO - Epoch 454/1000 - Train Loss: 0.086267, Val Loss: 0.083857
2025-08-07 21:59:46,713 - INFO - Epoch 455/1000 - Train Loss: 0.087402, Val Loss: 0.073665
2025-08-07 22:00:11,062 - INFO - Epoch 456/1000 - Train Loss: 0.084980, Val Loss: 0.074344
2025-08-07 22:00:35,277 - INFO - Epoch 457/1000 - Train Loss: 0.085617, Val Loss: 0.074344
2025-08-07 22:00:59,494 - INFO - Epoch 458/1000 - Train Loss: 0.085498, Val Loss: 0.075338
2025-08-07 22:01:23,885 - INFO - Epoch 459/1000 - Train Loss: 0.084165, Val Loss: 0.074585
2025-08-07 22:01:48,260 - INFO - Epoch 460/1000 - Train Loss: 0.084834, Val Loss: 0.074947
2025-08-07 22:02:12,819 - INFO - Epoch 461/1000 - Train Loss: 0.084901, Val Loss: 0.076042
2025-08-07 22:02:37,138 - INFO - Epoch 462/1000 - Train Loss: 0.085386, Val Loss: 0.076309
2025-08-07 22:03:01,338 - INFO - Epoch 463/1000 - Train Loss: 0.085812, Val Loss: 0.073640
2025-08-07 22:03:25,686 - INFO - Epoch 464/1000 - Train Loss: 0.086303, Val Loss: 0.074070
2025-08-07 22:03:50,065 - INFO - Epoch 465/1000 - Train Loss: 0.083754, Val Loss: 0.078500
2025-08-07 22:04:14,427 - INFO - Epoch 466/1000 - Train Loss: 0.086524, Val Loss: 0.073664
2025-08-07 22:04:38,755 - INFO - Epoch 467/1000 - Train Loss: 0.083327, Val Loss: 0.072088
2025-08-07 22:04:38,777 - INFO - New best model saved with Val Loss: 0.072088
2025-08-07 22:05:03,231 - INFO - Epoch 468/1000 - Train Loss: 0.084745, Val Loss: 0.074052
2025-08-07 22:05:27,529 - INFO - Epoch 469/1000 - Train Loss: 0.085351, Val Loss: 0.071608
2025-08-07 22:05:27,550 - INFO - New best model saved with Val Loss: 0.071608
2025-08-07 22:05:51,825 - INFO - Epoch 470/1000 - Train Loss: 0.085583, Val Loss: 0.077043
2025-08-07 22:06:16,210 - INFO - Epoch 471/1000 - Train Loss: 0.085199, Val Loss: 0.073779
2025-08-07 22:06:40,647 - INFO - Epoch 472/1000 - Train Loss: 0.085009, Val Loss: 0.071460
2025-08-07 22:06:40,668 - INFO - New best model saved with Val Loss: 0.071460
2025-08-07 22:07:04,890 - INFO - Epoch 473/1000 - Train Loss: 0.083730, Val Loss: 0.073208
2025-08-07 22:07:29,177 - INFO - Epoch 474/1000 - Train Loss: 0.084519, Val Loss: 0.074165
2025-08-07 22:07:53,396 - INFO - Epoch 475/1000 - Train Loss: 0.083733, Val Loss: 0.073943
2025-08-07 22:08:17,723 - INFO - Epoch 476/1000 - Train Loss: 0.082944, Val Loss: 0.073524
2025-08-07 22:08:41,901 - INFO - Epoch 477/1000 - Train Loss: 0.083902, Val Loss: 0.073004
2025-08-07 22:09:06,112 - INFO - Epoch 478/1000 - Train Loss: 0.083791, Val Loss: 0.072568
2025-08-07 22:09:30,310 - INFO - Epoch 479/1000 - Train Loss: 0.083259, Val Loss: 0.072971
2025-08-07 22:09:54,375 - INFO - Epoch 480/1000 - Train Loss: 0.081530, Val Loss: 0.074465
2025-08-07 22:10:18,769 - INFO - Epoch 481/1000 - Train Loss: 0.083200, Val Loss: 0.074731
2025-08-07 22:10:43,153 - INFO - Epoch 482/1000 - Train Loss: 0.083709, Val Loss: 0.074500
2025-08-07 22:11:07,467 - INFO - Epoch 483/1000 - Train Loss: 0.083655, Val Loss: 0.072229
2025-08-07 22:11:31,646 - INFO - Epoch 484/1000 - Train Loss: 0.083674, Val Loss: 0.073132
2025-08-07 22:11:56,009 - INFO - Epoch 485/1000 - Train Loss: 0.082766, Val Loss: 0.073171
2025-08-07 22:12:20,310 - INFO - Epoch 486/1000 - Train Loss: 0.082534, Val Loss: 0.072637
2025-08-07 22:12:44,739 - INFO - Epoch 487/1000 - Train Loss: 0.082054, Val Loss: 0.071121
2025-08-07 22:12:44,761 - INFO - New best model saved with Val Loss: 0.071121
2025-08-07 22:13:09,311 - INFO - Epoch 488/1000 - Train Loss: 0.082318, Val Loss: 0.076915
2025-08-07 22:13:33,638 - INFO - Epoch 489/1000 - Train Loss: 0.084941, Val Loss: 0.075889
2025-08-07 22:13:58,261 - INFO - Epoch 490/1000 - Train Loss: 0.081753, Val Loss: 0.072029
2025-08-07 22:14:22,900 - INFO - Epoch 491/1000 - Train Loss: 0.081699, Val Loss: 0.073852
2025-08-07 22:14:47,358 - INFO - Epoch 492/1000 - Train Loss: 0.083458, Val Loss: 0.074986
2025-08-07 22:15:11,741 - INFO - Epoch 493/1000 - Train Loss: 0.083950, Val Loss: 0.071396
2025-08-07 22:15:36,056 - INFO - Epoch 494/1000 - Train Loss: 0.083286, Val Loss: 0.071489
2025-08-07 22:16:00,374 - INFO - Epoch 495/1000 - Train Loss: 0.082145, Val Loss: 0.069898
2025-08-07 22:16:00,395 - INFO - New best model saved with Val Loss: 0.069898
2025-08-07 22:16:24,566 - INFO - Epoch 496/1000 - Train Loss: 0.082385, Val Loss: 0.070740
2025-08-07 22:16:48,824 - INFO - Epoch 497/1000 - Train Loss: 0.081707, Val Loss: 0.072098
2025-08-07 22:17:13,075 - INFO - Epoch 498/1000 - Train Loss: 0.083462, Val Loss: 0.071646
2025-08-07 22:17:37,519 - INFO - Epoch 499/1000 - Train Loss: 0.081288, Val Loss: 0.073055
2025-08-07 22:18:01,917 - INFO - Epoch 500/1000 - Train Loss: 0.081937, Val Loss: 0.070405
2025-08-07 22:18:26,559 - INFO - Epoch 501/1000 - Train Loss: 0.081676, Val Loss: 0.073381
2025-08-07 22:18:50,818 - INFO - Epoch 502/1000 - Train Loss: 0.082968, Val Loss: 0.070496
2025-08-07 22:19:14,838 - INFO - Epoch 503/1000 - Train Loss: 0.082810, Val Loss: 0.070216
2025-08-07 22:19:39,222 - INFO - Epoch 504/1000 - Train Loss: 0.080582, Val Loss: 0.072633
2025-08-07 22:20:03,490 - INFO - Epoch 505/1000 - Train Loss: 0.079818, Val Loss: 0.073113
2025-08-07 22:20:27,824 - INFO - Epoch 506/1000 - Train Loss: 0.080854, Val Loss: 0.070212
2025-08-07 22:20:52,266 - INFO - Epoch 507/1000 - Train Loss: 0.082381, Val Loss: 0.074213
2025-08-07 22:21:16,441 - INFO - Epoch 508/1000 - Train Loss: 0.081084, Val Loss: 0.072896
2025-08-07 22:21:40,605 - INFO - Epoch 509/1000 - Train Loss: 0.081117, Val Loss: 0.070471
2025-08-07 22:22:05,027 - INFO - Epoch 510/1000 - Train Loss: 0.080474, Val Loss: 0.069756
2025-08-07 22:22:05,049 - INFO - New best model saved with Val Loss: 0.069756
2025-08-07 22:22:29,741 - INFO - Epoch 511/1000 - Train Loss: 0.080318, Val Loss: 0.070777
2025-08-07 22:22:54,246 - INFO - Epoch 512/1000 - Train Loss: 0.081079, Val Loss: 0.072000
2025-08-07 22:23:18,535 - INFO - Epoch 513/1000 - Train Loss: 0.080466, Val Loss: 0.074096
2025-08-07 22:23:42,807 - INFO - Epoch 514/1000 - Train Loss: 0.080730, Val Loss: 0.073837
2025-08-07 22:24:06,829 - INFO - Epoch 515/1000 - Train Loss: 0.080863, Val Loss: 0.073152
2025-08-07 22:24:31,030 - INFO - Epoch 516/1000 - Train Loss: 0.080591, Val Loss: 0.072805
2025-08-07 22:24:55,307 - INFO - Epoch 517/1000 - Train Loss: 0.081287, Val Loss: 0.072285
2025-08-07 22:25:19,709 - INFO - Epoch 518/1000 - Train Loss: 0.080311, Val Loss: 0.072767
2025-08-07 22:25:44,007 - INFO - Epoch 519/1000 - Train Loss: 0.080382, Val Loss: 0.070497
2025-08-07 22:26:08,258 - INFO - Epoch 520/1000 - Train Loss: 0.082514, Val Loss: 0.072179
2025-08-07 22:26:32,807 - INFO - Epoch 521/1000 - Train Loss: 0.081060, Val Loss: 0.071835
2025-08-07 22:26:57,235 - INFO - Epoch 522/1000 - Train Loss: 0.080223, Val Loss: 0.069830
2025-08-07 22:27:21,370 - INFO - Epoch 523/1000 - Train Loss: 0.079599, Val Loss: 0.071201
2025-08-07 22:27:45,669 - INFO - Epoch 524/1000 - Train Loss: 0.081661, Val Loss: 0.072749
2025-08-07 22:28:09,791 - INFO - Epoch 525/1000 - Train Loss: 0.078889, Val Loss: 0.068965
2025-08-07 22:28:09,813 - INFO - New best model saved with Val Loss: 0.068965
2025-08-07 22:28:34,045 - INFO - Epoch 526/1000 - Train Loss: 0.078629, Val Loss: 0.072540
2025-08-07 22:28:58,422 - INFO - Epoch 527/1000 - Train Loss: 0.079019, Val Loss: 0.071186
2025-08-07 22:29:22,658 - INFO - Epoch 528/1000 - Train Loss: 0.080139, Val Loss: 0.069574
2025-08-07 22:29:46,748 - INFO - Epoch 529/1000 - Train Loss: 0.080829, Val Loss: 0.069414
2025-08-07 22:30:10,968 - INFO - Epoch 530/1000 - Train Loss: 0.080333, Val Loss: 0.071118
2025-08-07 22:30:35,649 - INFO - Epoch 531/1000 - Train Loss: 0.079686, Val Loss: 0.069265
2025-08-07 22:30:59,986 - INFO - Epoch 532/1000 - Train Loss: 0.079513, Val Loss: 0.072186
2025-08-07 22:31:24,360 - INFO - Epoch 533/1000 - Train Loss: 0.079010, Val Loss: 0.071120
2025-08-07 22:31:48,835 - INFO - Epoch 534/1000 - Train Loss: 0.078850, Val Loss: 0.070406
2025-08-07 22:32:13,271 - INFO - Epoch 535/1000 - Train Loss: 0.079701, Val Loss: 0.071983
2025-08-07 22:32:37,720 - INFO - Epoch 536/1000 - Train Loss: 0.079855, Val Loss: 0.070049
2025-08-07 22:33:01,973 - INFO - Epoch 537/1000 - Train Loss: 0.079044, Val Loss: 0.070098
2025-08-07 22:33:26,258 - INFO - Epoch 538/1000 - Train Loss: 0.079243, Val Loss: 0.070610
2025-08-07 22:33:50,545 - INFO - Epoch 539/1000 - Train Loss: 0.078868, Val Loss: 0.068391
2025-08-07 22:33:50,568 - INFO - New best model saved with Val Loss: 0.068391
2025-08-07 22:34:14,892 - INFO - Epoch 540/1000 - Train Loss: 0.078790, Val Loss: 0.068899
2025-08-07 22:34:39,571 - INFO - Epoch 541/1000 - Train Loss: 0.078538, Val Loss: 0.067231
2025-08-07 22:34:39,592 - INFO - New best model saved with Val Loss: 0.067231
2025-08-07 22:35:03,939 - INFO - Epoch 542/1000 - Train Loss: 0.077250, Val Loss: 0.067500
2025-08-07 22:35:28,004 - INFO - Epoch 543/1000 - Train Loss: 0.078331, Val Loss: 0.070953
2025-08-07 22:35:52,212 - INFO - Epoch 544/1000 - Train Loss: 0.078813, Val Loss: 0.068425
2025-08-07 22:36:16,630 - INFO - Epoch 545/1000 - Train Loss: 0.078913, Val Loss: 0.072207
2025-08-07 22:36:40,872 - INFO - Epoch 546/1000 - Train Loss: 0.077766, Val Loss: 0.068129
2025-08-07 22:37:05,239 - INFO - Epoch 547/1000 - Train Loss: 0.077653, Val Loss: 0.068598
2025-08-07 22:37:29,501 - INFO - Epoch 548/1000 - Train Loss: 0.079021, Val Loss: 0.067843
2025-08-07 22:37:53,712 - INFO - Epoch 549/1000 - Train Loss: 0.079070, Val Loss: 0.073763
2025-08-07 22:38:18,061 - INFO - Epoch 550/1000 - Train Loss: 0.080374, Val Loss: 0.069448
2025-08-07 22:38:42,450 - INFO - Epoch 551/1000 - Train Loss: 0.077513, Val Loss: 0.069415
2025-08-07 22:39:06,643 - INFO - Epoch 552/1000 - Train Loss: 0.077530, Val Loss: 0.069570
2025-08-07 22:39:31,018 - INFO - Epoch 553/1000 - Train Loss: 0.078626, Val Loss: 0.071548
2025-08-07 22:39:55,251 - INFO - Epoch 554/1000 - Train Loss: 0.077205, Val Loss: 0.069737
2025-08-07 22:40:19,728 - INFO - Epoch 555/1000 - Train Loss: 0.078721, Val Loss: 0.068779
2025-08-07 22:40:44,045 - INFO - Epoch 556/1000 - Train Loss: 0.077970, Val Loss: 0.068253
2025-08-07 22:41:08,202 - INFO - Epoch 557/1000 - Train Loss: 0.079930, Val Loss: 0.067359
2025-08-07 22:41:32,676 - INFO - Epoch 558/1000 - Train Loss: 0.076698, Val Loss: 0.066573
2025-08-07 22:41:32,709 - INFO - New best model saved with Val Loss: 0.066573
2025-08-07 22:41:57,155 - INFO - Epoch 559/1000 - Train Loss: 0.079138, Val Loss: 0.078236
2025-08-07 22:42:21,352 - INFO - Epoch 560/1000 - Train Loss: 0.079652, Val Loss: 0.071255
2025-08-07 22:42:45,717 - INFO - Epoch 561/1000 - Train Loss: 0.077161, Val Loss: 0.069045
2025-08-07 22:43:09,976 - INFO - Epoch 562/1000 - Train Loss: 0.077146, Val Loss: 0.068783
2025-08-07 22:43:33,986 - INFO - Epoch 563/1000 - Train Loss: 0.076319, Val Loss: 0.066279
2025-08-07 22:43:34,007 - INFO - New best model saved with Val Loss: 0.066279
2025-08-07 22:43:58,325 - INFO - Epoch 564/1000 - Train Loss: 0.077347, Val Loss: 0.070036
2025-08-07 22:44:22,539 - INFO - Epoch 565/1000 - Train Loss: 0.077456, Val Loss: 0.067659
2025-08-07 22:44:46,670 - INFO - Epoch 566/1000 - Train Loss: 0.076546, Val Loss: 0.068167
2025-08-07 22:45:11,021 - INFO - Epoch 567/1000 - Train Loss: 0.077910, Val Loss: 0.068773
2025-08-07 22:45:35,243 - INFO - Epoch 568/1000 - Train Loss: 0.077253, Val Loss: 0.069618
2025-08-07 22:45:59,603 - INFO - Epoch 569/1000 - Train Loss: 0.076729, Val Loss: 0.069108
2025-08-07 22:46:23,918 - INFO - Epoch 570/1000 - Train Loss: 0.076496, Val Loss: 0.068318
2025-08-07 22:46:48,446 - INFO - Epoch 571/1000 - Train Loss: 0.076264, Val Loss: 0.068362
2025-08-07 22:47:12,543 - INFO - Epoch 572/1000 - Train Loss: 0.076434, Val Loss: 0.068952
2025-08-07 22:47:36,896 - INFO - Epoch 573/1000 - Train Loss: 0.077259, Val Loss: 0.070067
2025-08-07 22:48:01,031 - INFO - Epoch 574/1000 - Train Loss: 0.077185, Val Loss: 0.067267
2025-08-07 22:48:25,179 - INFO - Epoch 575/1000 - Train Loss: 0.076068, Val Loss: 0.070546
2025-08-07 22:48:49,614 - INFO - Epoch 576/1000 - Train Loss: 0.075844, Val Loss: 0.070316
2025-08-07 22:49:14,062 - INFO - Epoch 577/1000 - Train Loss: 0.076558, Val Loss: 0.068012
2025-08-07 22:49:38,058 - INFO - Epoch 578/1000 - Train Loss: 0.076814, Val Loss: 0.069425
2025-08-07 22:50:02,389 - INFO - Epoch 579/1000 - Train Loss: 0.077532, Val Loss: 0.070478
2025-08-07 22:50:26,574 - INFO - Epoch 580/1000 - Train Loss: 0.077288, Val Loss: 0.067166
2025-08-07 22:50:50,974 - INFO - Epoch 581/1000 - Train Loss: 0.077147, Val Loss: 0.067436
2025-08-07 22:51:15,243 - INFO - Epoch 582/1000 - Train Loss: 0.075864, Val Loss: 0.068557
2025-08-07 22:51:39,537 - INFO - Epoch 583/1000 - Train Loss: 0.075786, Val Loss: 0.065879
2025-08-07 22:51:39,559 - INFO - New best model saved with Val Loss: 0.065879
2025-08-07 22:52:03,846 - INFO - Epoch 584/1000 - Train Loss: 0.075914, Val Loss: 0.066716
2025-08-07 22:52:28,367 - INFO - Epoch 585/1000 - Train Loss: 0.075181, Val Loss: 0.067539
2025-08-07 22:52:52,556 - INFO - Epoch 586/1000 - Train Loss: 0.076465, Val Loss: 0.069343
2025-08-07 22:53:16,912 - INFO - Epoch 587/1000 - Train Loss: 0.076218, Val Loss: 0.066810
2025-08-07 22:53:41,211 - INFO - Epoch 588/1000 - Train Loss: 0.076718, Val Loss: 0.069315
2025-08-07 22:54:05,432 - INFO - Epoch 589/1000 - Train Loss: 0.075670, Val Loss: 0.066144
2025-08-07 22:54:29,499 - INFO - Epoch 590/1000 - Train Loss: 0.075142, Val Loss: 0.065094
2025-08-07 22:54:29,520 - INFO - New best model saved with Val Loss: 0.065094
2025-08-07 22:54:54,009 - INFO - Epoch 591/1000 - Train Loss: 0.075049, Val Loss: 0.066496
2025-08-07 22:55:18,309 - INFO - Epoch 592/1000 - Train Loss: 0.075382, Val Loss: 0.066576
2025-08-07 22:55:42,537 - INFO - Epoch 593/1000 - Train Loss: 0.076132, Val Loss: 0.064789
2025-08-07 22:55:42,558 - INFO - New best model saved with Val Loss: 0.064789
2025-08-07 22:56:06,867 - INFO - Epoch 594/1000 - Train Loss: 0.074618, Val Loss: 0.068435
2025-08-07 22:56:31,596 - INFO - Epoch 595/1000 - Train Loss: 0.075488, Val Loss: 0.066685
2025-08-07 22:56:56,014 - INFO - Epoch 596/1000 - Train Loss: 0.074693, Val Loss: 0.069665
2025-08-07 22:57:20,290 - INFO - Epoch 597/1000 - Train Loss: 0.077431, Val Loss: 0.066426
2025-08-07 22:57:44,999 - INFO - Epoch 598/1000 - Train Loss: 0.075120, Val Loss: 0.069555
2025-08-07 22:58:09,230 - INFO - Epoch 599/1000 - Train Loss: 0.075337, Val Loss: 0.064866
2025-08-07 22:58:33,524 - INFO - Epoch 600/1000 - Train Loss: 0.075020, Val Loss: 0.065096
2025-08-07 22:58:57,846 - INFO - Epoch 601/1000 - Train Loss: 0.076427, Val Loss: 0.071633
2025-08-07 22:59:22,030 - INFO - Epoch 602/1000 - Train Loss: 0.076476, Val Loss: 0.067175
2025-08-07 22:59:46,209 - INFO - Epoch 603/1000 - Train Loss: 0.075106, Val Loss: 0.066031
2025-08-07 23:00:10,534 - INFO - Epoch 604/1000 - Train Loss: 0.077566, Val Loss: 0.066697
2025-08-07 23:00:34,709 - INFO - Epoch 605/1000 - Train Loss: 0.075414, Val Loss: 0.066208
2025-08-07 23:00:59,028 - INFO - Epoch 606/1000 - Train Loss: 0.074809, Val Loss: 0.065186
2025-08-07 23:01:23,213 - INFO - Epoch 607/1000 - Train Loss: 0.075852, Val Loss: 0.067563
2025-08-07 23:01:47,437 - INFO - Epoch 608/1000 - Train Loss: 0.075597, Val Loss: 0.064213
2025-08-07 23:01:47,459 - INFO - New best model saved with Val Loss: 0.064213
2025-08-07 23:02:11,942 - INFO - Epoch 609/1000 - Train Loss: 0.074966, Val Loss: 0.067616
2025-08-07 23:02:36,195 - INFO - Epoch 610/1000 - Train Loss: 0.074930, Val Loss: 0.065469
2025-08-07 23:03:00,744 - INFO - Epoch 611/1000 - Train Loss: 0.074512, Val Loss: 0.065651
2025-08-07 23:03:25,122 - INFO - Epoch 612/1000 - Train Loss: 0.074753, Val Loss: 0.064562
2025-08-07 23:03:49,511 - INFO - Epoch 613/1000 - Train Loss: 0.075169, Val Loss: 0.067151
2025-08-07 23:04:13,748 - INFO - Epoch 614/1000 - Train Loss: 0.073651, Val Loss: 0.066262
2025-08-07 23:04:38,052 - INFO - Epoch 615/1000 - Train Loss: 0.074158, Val Loss: 0.065183
2025-08-07 23:05:02,306 - INFO - Epoch 616/1000 - Train Loss: 0.074291, Val Loss: 0.067521
2025-08-07 23:05:26,650 - INFO - Epoch 617/1000 - Train Loss: 0.074101, Val Loss: 0.066350
2025-08-07 23:05:50,843 - INFO - Epoch 618/1000 - Train Loss: 0.074249, Val Loss: 0.065451
2025-08-07 23:06:15,387 - INFO - Epoch 619/1000 - Train Loss: 0.074344, Val Loss: 0.063735
2025-08-07 23:06:15,427 - INFO - New best model saved with Val Loss: 0.063735
2025-08-07 23:06:39,955 - INFO - Epoch 620/1000 - Train Loss: 0.073983, Val Loss: 0.064727
2025-08-07 23:07:04,511 - INFO - Epoch 621/1000 - Train Loss: 0.073736, Val Loss: 0.066393
2025-08-07 23:07:28,783 - INFO - Epoch 622/1000 - Train Loss: 0.073522, Val Loss: 0.064584
2025-08-07 23:07:53,049 - INFO - Epoch 623/1000 - Train Loss: 0.074309, Val Loss: 0.064896
2025-08-07 23:08:17,429 - INFO - Epoch 624/1000 - Train Loss: 0.073456, Val Loss: 0.065596
2025-08-07 23:08:41,754 - INFO - Epoch 625/1000 - Train Loss: 0.075081, Val Loss: 0.067454
2025-08-07 23:09:05,749 - INFO - Epoch 626/1000 - Train Loss: 0.073612, Val Loss: 0.062426
2025-08-07 23:09:05,785 - INFO - New best model saved with Val Loss: 0.062426
2025-08-07 23:09:29,906 - INFO - Epoch 627/1000 - Train Loss: 0.073120, Val Loss: 0.066311
2025-08-07 23:09:54,116 - INFO - Epoch 628/1000 - Train Loss: 0.074737, Val Loss: 0.069855
2025-08-07 23:10:18,368 - INFO - Epoch 629/1000 - Train Loss: 0.073682, Val Loss: 0.064645
2025-08-07 23:10:42,535 - INFO - Epoch 630/1000 - Train Loss: 0.073482, Val Loss: 0.065522
2025-08-07 23:11:06,937 - INFO - Epoch 631/1000 - Train Loss: 0.072979, Val Loss: 0.066389
2025-08-07 23:11:31,187 - INFO - Epoch 632/1000 - Train Loss: 0.075363, Val Loss: 0.065785
2025-08-07 23:11:55,542 - INFO - Epoch 633/1000 - Train Loss: 0.072496, Val Loss: 0.067246
2025-08-07 23:12:20,020 - INFO - Epoch 634/1000 - Train Loss: 0.073595, Val Loss: 0.063690
2025-08-07 23:12:44,430 - INFO - Epoch 635/1000 - Train Loss: 0.072940, Val Loss: 0.065668
2025-08-07 23:13:08,753 - INFO - Epoch 636/1000 - Train Loss: 0.074706, Val Loss: 0.066921
2025-08-07 23:13:32,836 - INFO - Epoch 637/1000 - Train Loss: 0.075803, Val Loss: 0.064339
2025-08-07 23:13:56,920 - INFO - Epoch 638/1000 - Train Loss: 0.072078, Val Loss: 0.065640
2025-08-07 23:14:21,175 - INFO - Epoch 639/1000 - Train Loss: 0.073071, Val Loss: 0.063344
2025-08-07 23:14:45,640 - INFO - Epoch 640/1000 - Train Loss: 0.072694, Val Loss: 0.066389
2025-08-07 23:15:10,205 - INFO - Epoch 641/1000 - Train Loss: 0.073020, Val Loss: 0.065388
2025-08-07 23:15:34,433 - INFO - Epoch 642/1000 - Train Loss: 0.071674, Val Loss: 0.063402
2025-08-07 23:15:58,633 - INFO - Epoch 643/1000 - Train Loss: 0.072862, Val Loss: 0.067379
2025-08-07 23:16:22,783 - INFO - Epoch 644/1000 - Train Loss: 0.073311, Val Loss: 0.066639
2025-08-07 23:16:47,113 - INFO - Epoch 645/1000 - Train Loss: 0.074357, Val Loss: 0.064752
2025-08-07 23:17:11,415 - INFO - Epoch 646/1000 - Train Loss: 0.075451, Val Loss: 0.064624
2025-08-07 23:17:35,663 - INFO - Epoch 647/1000 - Train Loss: 0.073072, Val Loss: 0.065530
2025-08-07 23:18:00,008 - INFO - Epoch 648/1000 - Train Loss: 0.073672, Val Loss: 0.066022
2025-08-07 23:18:24,184 - INFO - Epoch 649/1000 - Train Loss: 0.073118, Val Loss: 0.067555
2025-08-07 23:18:48,513 - INFO - Epoch 650/1000 - Train Loss: 0.071577, Val Loss: 0.067114
2025-08-07 23:19:12,743 - INFO - Epoch 651/1000 - Train Loss: 0.072256, Val Loss: 0.064951
2025-08-07 23:19:37,161 - INFO - Epoch 652/1000 - Train Loss: 0.072256, Val Loss: 0.064655
2025-08-07 23:20:01,769 - INFO - Epoch 653/1000 - Train Loss: 0.072686, Val Loss: 0.062779
2025-08-07 23:20:26,014 - INFO - Epoch 654/1000 - Train Loss: 0.071908, Val Loss: 0.063659
2025-08-07 23:20:50,269 - INFO - Epoch 655/1000 - Train Loss: 0.073518, Val Loss: 0.066287
2025-08-07 23:21:14,455 - INFO - Epoch 656/1000 - Train Loss: 0.072947, Val Loss: 0.061383
2025-08-07 23:21:14,477 - INFO - New best model saved with Val Loss: 0.061383
2025-08-07 23:21:38,684 - INFO - Epoch 657/1000 - Train Loss: 0.071605, Val Loss: 0.064273
2025-08-07 23:22:03,021 - INFO - Epoch 658/1000 - Train Loss: 0.071530, Val Loss: 0.064640
2025-08-07 23:22:27,292 - INFO - Epoch 659/1000 - Train Loss: 0.070154, Val Loss: 0.065263
2025-08-07 23:22:51,390 - INFO - Epoch 660/1000 - Train Loss: 0.071954, Val Loss: 0.062703
2025-08-07 23:23:16,124 - INFO - Epoch 661/1000 - Train Loss: 0.072122, Val Loss: 0.065107
2025-08-07 23:23:40,417 - INFO - Epoch 662/1000 - Train Loss: 0.073485, Val Loss: 0.062383
2025-08-07 23:24:04,739 - INFO - Epoch 663/1000 - Train Loss: 0.071414, Val Loss: 0.064774
2025-08-07 23:24:29,196 - INFO - Epoch 664/1000 - Train Loss: 0.071116, Val Loss: 0.067331
2025-08-07 23:24:53,448 - INFO - Epoch 665/1000 - Train Loss: 0.073403, Val Loss: 0.062819
2025-08-07 23:25:17,597 - INFO - Epoch 666/1000 - Train Loss: 0.073118, Val Loss: 0.064171
2025-08-07 23:25:41,869 - INFO - Epoch 667/1000 - Train Loss: 0.072154, Val Loss: 0.064059
2025-08-07 23:26:06,132 - INFO - Epoch 668/1000 - Train Loss: 0.071188, Val Loss: 0.061102
2025-08-07 23:26:06,154 - INFO - New best model saved with Val Loss: 0.061102
2025-08-07 23:26:30,308 - INFO - Epoch 669/1000 - Train Loss: 0.071328, Val Loss: 0.064582
2025-08-07 23:26:54,603 - INFO - Epoch 670/1000 - Train Loss: 0.073366, Val Loss: 0.064597
2025-08-07 23:27:19,030 - INFO - Epoch 671/1000 - Train Loss: 0.071965, Val Loss: 0.065306
2025-08-07 23:27:43,448 - INFO - Epoch 672/1000 - Train Loss: 0.072116, Val Loss: 0.064759
2025-08-07 23:28:07,533 - INFO - Epoch 673/1000 - Train Loss: 0.072878, Val Loss: 0.063012
2025-08-07 23:28:31,922 - INFO - Epoch 674/1000 - Train Loss: 0.072199, Val Loss: 0.066729
2025-08-07 23:28:56,255 - INFO - Epoch 675/1000 - Train Loss: 0.071437, Val Loss: 0.062523
2025-08-07 23:29:20,491 - INFO - Epoch 676/1000 - Train Loss: 0.071645, Val Loss: 0.062446
2025-08-07 23:29:44,731 - INFO - Epoch 677/1000 - Train Loss: 0.071100, Val Loss: 0.063878
2025-08-07 23:30:09,070 - INFO - Epoch 678/1000 - Train Loss: 0.071758, Val Loss: 0.065597
2025-08-07 23:30:33,331 - INFO - Epoch 679/1000 - Train Loss: 0.070617, Val Loss: 0.064491
2025-08-07 23:30:57,735 - INFO - Epoch 680/1000 - Train Loss: 0.071359, Val Loss: 0.063808
2025-08-07 23:31:22,124 - INFO - Epoch 681/1000 - Train Loss: 0.072590, Val Loss: 0.064979
2025-08-07 23:31:46,384 - INFO - Epoch 682/1000 - Train Loss: 0.071947, Val Loss: 0.066532
2025-08-07 23:32:10,602 - INFO - Epoch 683/1000 - Train Loss: 0.071250, Val Loss: 0.063504
2025-08-07 23:32:34,977 - INFO - Epoch 684/1000 - Train Loss: 0.071260, Val Loss: 0.062362
2025-08-07 23:32:59,519 - INFO - Epoch 685/1000 - Train Loss: 0.071408, Val Loss: 0.064983
2025-08-07 23:33:23,672 - INFO - Epoch 686/1000 - Train Loss: 0.070048, Val Loss: 0.064689
2025-08-07 23:33:47,953 - INFO - Epoch 687/1000 - Train Loss: 0.070891, Val Loss: 0.062027
2025-08-07 23:34:12,050 - INFO - Epoch 688/1000 - Train Loss: 0.071101, Val Loss: 0.061883
2025-08-07 23:34:36,365 - INFO - Epoch 689/1000 - Train Loss: 0.070977, Val Loss: 0.067188
2025-08-07 23:35:00,735 - INFO - Epoch 690/1000 - Train Loss: 0.072300, Val Loss: 0.063284
2025-08-07 23:35:25,124 - INFO - Epoch 691/1000 - Train Loss: 0.070839, Val Loss: 0.062930
2025-08-07 23:35:49,568 - INFO - Epoch 692/1000 - Train Loss: 0.071470, Val Loss: 0.064211
2025-08-07 23:36:13,670 - INFO - Epoch 693/1000 - Train Loss: 0.071269, Val Loss: 0.063164
2025-08-07 23:36:38,144 - INFO - Epoch 694/1000 - Train Loss: 0.070518, Val Loss: 0.063475
2025-08-07 23:37:02,562 - INFO - Epoch 695/1000 - Train Loss: 0.071412, Val Loss: 0.066300
2025-08-07 23:37:26,879 - INFO - Epoch 696/1000 - Train Loss: 0.071251, Val Loss: 0.061571
2025-08-07 23:37:50,997 - INFO - Epoch 697/1000 - Train Loss: 0.071407, Val Loss: 0.066630
2025-08-07 23:38:15,250 - INFO - Epoch 698/1000 - Train Loss: 0.071056, Val Loss: 0.062477
2025-08-07 23:38:39,431 - INFO - Epoch 699/1000 - Train Loss: 0.071637, Val Loss: 0.064129
2025-08-07 23:39:03,686 - INFO - Epoch 700/1000 - Train Loss: 0.070474, Val Loss: 0.060896
2025-08-07 23:39:03,708 - INFO - New best model saved with Val Loss: 0.060896
2025-08-07 23:39:28,140 - INFO - Epoch 701/1000 - Train Loss: 0.069068, Val Loss: 0.061268
2025-08-07 23:39:52,455 - INFO - Epoch 702/1000 - Train Loss: 0.070457, Val Loss: 0.066547
2025-08-07 23:40:16,668 - INFO - Epoch 703/1000 - Train Loss: 0.072985, Val Loss: 0.064892
2025-08-07 23:40:41,006 - INFO - Epoch 704/1000 - Train Loss: 0.070951, Val Loss: 0.064904
2025-08-07 23:41:05,355 - INFO - Epoch 705/1000 - Train Loss: 0.071578, Val Loss: 0.068298
2025-08-07 23:41:29,879 - INFO - Epoch 706/1000 - Train Loss: 0.070737, Val Loss: 0.063730
2025-08-07 23:41:53,994 - INFO - Epoch 707/1000 - Train Loss: 0.070932, Val Loss: 0.063275
2025-08-07 23:42:18,216 - INFO - Epoch 708/1000 - Train Loss: 0.069669, Val Loss: 0.061245
2025-08-07 23:42:42,563 - INFO - Epoch 709/1000 - Train Loss: 0.069358, Val Loss: 0.060137
2025-08-07 23:42:42,585 - INFO - New best model saved with Val Loss: 0.060137
2025-08-07 23:43:06,780 - INFO - Epoch 710/1000 - Train Loss: 0.068867, Val Loss: 0.061219
2025-08-07 23:43:31,623 - INFO - Epoch 711/1000 - Train Loss: 0.071541, Val Loss: 0.061391
2025-08-07 23:43:56,155 - INFO - Epoch 712/1000 - Train Loss: 0.070932, Val Loss: 0.061563
2025-08-07 23:44:20,442 - INFO - Epoch 713/1000 - Train Loss: 0.070842, Val Loss: 0.064679
2025-08-07 23:44:44,796 - INFO - Epoch 714/1000 - Train Loss: 0.071267, Val Loss: 0.061829
2025-08-07 23:45:08,965 - INFO - Epoch 715/1000 - Train Loss: 0.071207, Val Loss: 0.062887
2025-08-07 23:45:33,329 - INFO - Epoch 716/1000 - Train Loss: 0.069881, Val Loss: 0.062804
2025-08-07 23:45:57,513 - INFO - Epoch 717/1000 - Train Loss: 0.069472, Val Loss: 0.061044
2025-08-07 23:46:21,662 - INFO - Epoch 718/1000 - Train Loss: 0.070117, Val Loss: 0.063512
2025-08-07 23:46:45,838 - INFO - Epoch 719/1000 - Train Loss: 0.068605, Val Loss: 0.061066
2025-08-07 23:47:10,070 - INFO - Epoch 720/1000 - Train Loss: 0.069342, Val Loss: 0.060070
2025-08-07 23:47:10,092 - INFO - New best model saved with Val Loss: 0.060070
2025-08-07 23:47:34,645 - INFO - Epoch 721/1000 - Train Loss: 0.070107, Val Loss: 0.061838
2025-08-07 23:47:58,831 - INFO - Epoch 722/1000 - Train Loss: 0.068476, Val Loss: 0.062434
2025-08-07 23:48:23,117 - INFO - Epoch 723/1000 - Train Loss: 0.068748, Val Loss: 0.063221
2025-08-07 23:48:47,471 - INFO - Epoch 724/1000 - Train Loss: 0.070268, Val Loss: 0.060211
2025-08-07 23:49:11,768 - INFO - Epoch 725/1000 - Train Loss: 0.069979, Val Loss: 0.066382
2025-08-07 23:49:36,114 - INFO - Epoch 726/1000 - Train Loss: 0.070012, Val Loss: 0.064496
2025-08-07 23:50:00,527 - INFO - Epoch 727/1000 - Train Loss: 0.070158, Val Loss: 0.061217
2025-08-07 23:50:24,786 - INFO - Epoch 728/1000 - Train Loss: 0.069489, Val Loss: 0.062828
2025-08-07 23:50:48,992 - INFO - Epoch 729/1000 - Train Loss: 0.068854, Val Loss: 0.060387
2025-08-07 23:51:13,195 - INFO - Epoch 730/1000 - Train Loss: 0.068163, Val Loss: 0.061194
2025-08-07 23:51:37,908 - INFO - Epoch 731/1000 - Train Loss: 0.069544, Val Loss: 0.059708
2025-08-07 23:51:37,929 - INFO - New best model saved with Val Loss: 0.059708
2025-08-07 23:52:02,277 - INFO - Epoch 732/1000 - Train Loss: 0.069052, Val Loss: 0.065468
2025-08-07 23:52:26,647 - INFO - Epoch 733/1000 - Train Loss: 0.070281, Val Loss: 0.063218
2025-08-07 23:52:51,028 - INFO - Epoch 734/1000 - Train Loss: 0.069662, Val Loss: 0.060408
2025-08-07 23:53:15,407 - INFO - Epoch 735/1000 - Train Loss: 0.068770, Val Loss: 0.062030
2025-08-07 23:53:39,796 - INFO - Epoch 736/1000 - Train Loss: 0.069408, Val Loss: 0.061114
2025-08-07 23:54:04,025 - INFO - Epoch 737/1000 - Train Loss: 0.066960, Val Loss: 0.062570
2025-08-07 23:54:28,290 - INFO - Epoch 738/1000 - Train Loss: 0.068741, Val Loss: 0.062723
2025-08-07 23:54:52,586 - INFO - Epoch 739/1000 - Train Loss: 0.069146, Val Loss: 0.061846
2025-08-07 23:55:16,630 - INFO - Epoch 740/1000 - Train Loss: 0.068924, Val Loss: 0.062883
2025-08-07 23:55:41,048 - INFO - Epoch 741/1000 - Train Loss: 0.068271, Val Loss: 0.062388
2025-08-07 23:56:05,278 - INFO - Epoch 742/1000 - Train Loss: 0.068499, Val Loss: 0.060384
2025-08-07 23:56:29,496 - INFO - Epoch 743/1000 - Train Loss: 0.069963, Val Loss: 0.063535
2025-08-07 23:56:53,687 - INFO - Epoch 744/1000 - Train Loss: 0.070950, Val Loss: 0.063186
2025-08-07 23:57:18,065 - INFO - Epoch 745/1000 - Train Loss: 0.070151, Val Loss: 0.060921
2025-08-07 23:57:42,318 - INFO - Epoch 746/1000 - Train Loss: 0.067760, Val Loss: 0.059566
2025-08-07 23:57:42,340 - INFO - New best model saved with Val Loss: 0.059566
2025-08-07 23:58:06,526 - INFO - Epoch 747/1000 - Train Loss: 0.068241, Val Loss: 0.061836
2025-08-07 23:58:30,725 - INFO - Epoch 748/1000 - Train Loss: 0.067971, Val Loss: 0.061942
2025-08-07 23:58:55,047 - INFO - Epoch 749/1000 - Train Loss: 0.068599, Val Loss: 0.061139
2025-08-07 23:59:19,268 - INFO - Epoch 750/1000 - Train Loss: 0.068031, Val Loss: 0.060718
2025-08-07 23:59:43,756 - INFO - Epoch 751/1000 - Train Loss: 0.069062, Val Loss: 0.063261
2025-08-08 00:00:08,088 - INFO - Epoch 752/1000 - Train Loss: 0.069900, Val Loss: 0.063665
2025-08-08 00:00:32,253 - INFO - Epoch 753/1000 - Train Loss: 0.069114, Val Loss: 0.063680
2025-08-08 00:00:56,423 - INFO - Epoch 754/1000 - Train Loss: 0.067867, Val Loss: 0.060110
2025-08-08 00:01:20,567 - INFO - Epoch 755/1000 - Train Loss: 0.066587, Val Loss: 0.063552
2025-08-08 00:01:44,840 - INFO - Epoch 756/1000 - Train Loss: 0.068258, Val Loss: 0.061510
2025-08-08 00:02:08,990 - INFO - Epoch 757/1000 - Train Loss: 0.069266, Val Loss: 0.062894
2025-08-08 00:02:33,047 - INFO - Epoch 758/1000 - Train Loss: 0.067285, Val Loss: 0.061303
2025-08-08 00:02:57,368 - INFO - Epoch 759/1000 - Train Loss: 0.068815, Val Loss: 0.063174
2025-08-08 00:03:21,728 - INFO - Epoch 760/1000 - Train Loss: 0.067709, Val Loss: 0.063748
2025-08-08 00:03:46,356 - INFO - Epoch 761/1000 - Train Loss: 0.069241, Val Loss: 0.060617
2025-08-08 00:04:10,578 - INFO - Epoch 762/1000 - Train Loss: 0.070079, Val Loss: 0.062052
2025-08-08 00:04:34,953 - INFO - Epoch 763/1000 - Train Loss: 0.068706, Val Loss: 0.060579
2025-08-08 00:04:59,118 - INFO - Epoch 764/1000 - Train Loss: 0.069046, Val Loss: 0.060949
2025-08-08 00:05:23,229 - INFO - Epoch 765/1000 - Train Loss: 0.069655, Val Loss: 0.060164
2025-08-08 00:05:47,412 - INFO - Epoch 766/1000 - Train Loss: 0.067854, Val Loss: 0.060989
2025-08-08 00:06:11,749 - INFO - Epoch 767/1000 - Train Loss: 0.066588, Val Loss: 0.062518
2025-08-08 00:06:35,963 - INFO - Epoch 768/1000 - Train Loss: 0.067349, Val Loss: 0.061693
2025-08-08 00:07:00,693 - INFO - Epoch 769/1000 - Train Loss: 0.068170, Val Loss: 0.062531
2025-08-08 00:07:25,267 - INFO - Epoch 770/1000 - Train Loss: 0.068177, Val Loss: 0.060102
2025-08-08 00:07:49,787 - INFO - Epoch 771/1000 - Train Loss: 0.068183, Val Loss: 0.059572
2025-08-08 00:08:13,997 - INFO - Epoch 772/1000 - Train Loss: 0.067525, Val Loss: 0.060024
2025-08-08 00:08:38,372 - INFO - Epoch 773/1000 - Train Loss: 0.067882, Val Loss: 0.061981
2025-08-08 00:09:02,703 - INFO - Epoch 774/1000 - Train Loss: 0.069250, Val Loss: 0.061007
2025-08-08 00:09:27,104 - INFO - Epoch 775/1000 - Train Loss: 0.067997, Val Loss: 0.063269
2025-08-08 00:09:51,305 - INFO - Epoch 776/1000 - Train Loss: 0.068381, Val Loss: 0.062048
2025-08-08 00:10:15,681 - INFO - Epoch 777/1000 - Train Loss: 0.069000, Val Loss: 0.059421
2025-08-08 00:10:15,719 - INFO - New best model saved with Val Loss: 0.059421
2025-08-08 00:10:39,780 - INFO - Epoch 778/1000 - Train Loss: 0.067703, Val Loss: 0.060086
2025-08-08 00:11:03,753 - INFO - Epoch 779/1000 - Train Loss: 0.066080, Val Loss: 0.058992
2025-08-08 00:11:03,774 - INFO - New best model saved with Val Loss: 0.058992
2025-08-08 00:11:28,286 - INFO - Epoch 780/1000 - Train Loss: 0.068216, Val Loss: 0.061962
2025-08-08 00:11:52,808 - INFO - Epoch 781/1000 - Train Loss: 0.068127, Val Loss: 0.061468
2025-08-08 00:12:17,202 - INFO - Epoch 782/1000 - Train Loss: 0.067861, Val Loss: 0.061156
2025-08-08 00:12:41,606 - INFO - Epoch 783/1000 - Train Loss: 0.068345, Val Loss: 0.059999
2025-08-08 00:13:06,093 - INFO - Epoch 784/1000 - Train Loss: 0.066302, Val Loss: 0.058520
2025-08-08 00:13:06,114 - INFO - New best model saved with Val Loss: 0.058520
2025-08-08 00:13:30,431 - INFO - Epoch 785/1000 - Train Loss: 0.066798, Val Loss: 0.059702
2025-08-08 00:13:54,838 - INFO - Epoch 786/1000 - Train Loss: 0.067044, Val Loss: 0.057638
2025-08-08 00:13:54,858 - INFO - New best model saved with Val Loss: 0.057638
2025-08-08 00:14:19,052 - INFO - Epoch 787/1000 - Train Loss: 0.066915, Val Loss: 0.061291
2025-08-08 00:14:43,334 - INFO - Epoch 788/1000 - Train Loss: 0.066941, Val Loss: 0.058547
2025-08-08 00:15:07,560 - INFO - Epoch 789/1000 - Train Loss: 0.066523, Val Loss: 0.059644
2025-08-08 00:15:31,958 - INFO - Epoch 790/1000 - Train Loss: 0.066446, Val Loss: 0.059440
2025-08-08 00:15:56,610 - INFO - Epoch 791/1000 - Train Loss: 0.066777, Val Loss: 0.061322
2025-08-08 00:16:20,988 - INFO - Epoch 792/1000 - Train Loss: 0.067625, Val Loss: 0.060242
2025-08-08 00:16:45,269 - INFO - Epoch 793/1000 - Train Loss: 0.065679, Val Loss: 0.060286
2025-08-08 00:17:09,432 - INFO - Epoch 794/1000 - Train Loss: 0.066938, Val Loss: 0.062130
2025-08-08 00:17:33,818 - INFO - Epoch 795/1000 - Train Loss: 0.067596, Val Loss: 0.061864
2025-08-08 00:17:58,124 - INFO - Epoch 796/1000 - Train Loss: 0.068240, Val Loss: 0.060909
2025-08-08 00:18:22,460 - INFO - Epoch 797/1000 - Train Loss: 0.066690, Val Loss: 0.060626
2025-08-08 00:18:46,751 - INFO - Epoch 798/1000 - Train Loss: 0.065981, Val Loss: 0.058549
2025-08-08 00:19:11,046 - INFO - Epoch 799/1000 - Train Loss: 0.066862, Val Loss: 0.063448
2025-08-08 00:19:35,233 - INFO - Epoch 800/1000 - Train Loss: 0.067536, Val Loss: 0.060484
2025-08-08 00:19:59,516 - INFO - Epoch 801/1000 - Train Loss: 0.067279, Val Loss: 0.059755
2025-08-08 00:20:23,729 - INFO - Epoch 802/1000 - Train Loss: 0.066459, Val Loss: 0.061589
2025-08-08 00:20:47,867 - INFO - Epoch 803/1000 - Train Loss: 0.068225, Val Loss: 0.061344
2025-08-08 00:21:12,113 - INFO - Epoch 804/1000 - Train Loss: 0.067498, Val Loss: 0.057444
2025-08-08 00:21:12,134 - INFO - New best model saved with Val Loss: 0.057444
2025-08-08 00:21:36,247 - INFO - Epoch 805/1000 - Train Loss: 0.066371, Val Loss: 0.059196
2025-08-08 00:22:00,601 - INFO - Epoch 806/1000 - Train Loss: 0.066677, Val Loss: 0.058464
2025-08-08 00:22:24,958 - INFO - Epoch 807/1000 - Train Loss: 0.067324, Val Loss: 0.062060
2025-08-08 00:22:49,108 - INFO - Epoch 808/1000 - Train Loss: 0.065506, Val Loss: 0.060004
2025-08-08 00:23:13,438 - INFO - Epoch 809/1000 - Train Loss: 0.066807, Val Loss: 0.061342
2025-08-08 00:23:37,654 - INFO - Epoch 810/1000 - Train Loss: 0.065554, Val Loss: 0.058156
2025-08-08 00:24:02,028 - INFO - Epoch 811/1000 - Train Loss: 0.064921, Val Loss: 0.057263
2025-08-08 00:24:02,049 - INFO - New best model saved with Val Loss: 0.057263
2025-08-08 00:24:26,468 - INFO - Epoch 812/1000 - Train Loss: 0.065737, Val Loss: 0.058986
2025-08-08 00:24:50,749 - INFO - Epoch 813/1000 - Train Loss: 0.065823, Val Loss: 0.060497
2025-08-08 00:25:14,828 - INFO - Epoch 814/1000 - Train Loss: 0.065791, Val Loss: 0.059022
2025-08-08 00:25:38,832 - INFO - Epoch 815/1000 - Train Loss: 0.066876, Val Loss: 0.059054
2025-08-08 00:26:03,143 - INFO - Epoch 816/1000 - Train Loss: 0.066220, Val Loss: 0.060112
2025-08-08 00:26:27,448 - INFO - Epoch 817/1000 - Train Loss: 0.065540, Val Loss: 0.060898
2025-08-08 00:26:51,719 - INFO - Epoch 818/1000 - Train Loss: 0.065476, Val Loss: 0.058721
2025-08-08 00:27:15,978 - INFO - Epoch 819/1000 - Train Loss: 0.065466, Val Loss: 0.059658
2025-08-08 00:27:40,417 - INFO - Epoch 820/1000 - Train Loss: 0.065812, Val Loss: 0.058519
2025-08-08 00:28:04,933 - INFO - Epoch 821/1000 - Train Loss: 0.063084, Val Loss: 0.056026
2025-08-08 00:28:04,976 - INFO - New best model saved with Val Loss: 0.056026
2025-08-08 00:28:29,405 - INFO - Epoch 822/1000 - Train Loss: 0.064660, Val Loss: 0.057064
2025-08-08 00:28:53,617 - INFO - Epoch 823/1000 - Train Loss: 0.066003, Val Loss: 0.058933
2025-08-08 00:29:18,004 - INFO - Epoch 824/1000 - Train Loss: 0.066675, Val Loss: 0.058224
2025-08-08 00:29:42,441 - INFO - Epoch 825/1000 - Train Loss: 0.063525, Val Loss: 0.058023
2025-08-08 00:30:06,625 - INFO - Epoch 826/1000 - Train Loss: 0.064309, Val Loss: 0.056532
2025-08-08 00:30:31,020 - INFO - Epoch 827/1000 - Train Loss: 0.065087, Val Loss: 0.058926
2025-08-08 00:30:55,514 - INFO - Epoch 828/1000 - Train Loss: 0.066602, Val Loss: 0.059960
2025-08-08 00:31:19,772 - INFO - Epoch 829/1000 - Train Loss: 0.064868, Val Loss: 0.058809
2025-08-08 00:31:43,993 - INFO - Epoch 830/1000 - Train Loss: 0.064755, Val Loss: 0.058368
2025-08-08 00:32:08,471 - INFO - Epoch 831/1000 - Train Loss: 0.067704, Val Loss: 0.060031
2025-08-08 00:32:32,772 - INFO - Epoch 832/1000 - Train Loss: 0.066523, Val Loss: 0.056461
2025-08-08 00:32:57,265 - INFO - Epoch 833/1000 - Train Loss: 0.066317, Val Loss: 0.058830
2025-08-08 00:33:21,737 - INFO - Epoch 834/1000 - Train Loss: 0.066239, Val Loss: 0.056700
2025-08-08 00:33:46,188 - INFO - Epoch 835/1000 - Train Loss: 0.066908, Val Loss: 0.063100
2025-08-08 00:34:10,200 - INFO - Epoch 836/1000 - Train Loss: 0.066246, Val Loss: 0.059673
2025-08-08 00:34:34,133 - INFO - Epoch 837/1000 - Train Loss: 0.065052, Val Loss: 0.062253
2025-08-08 00:34:58,337 - INFO - Epoch 838/1000 - Train Loss: 0.064854, Val Loss: 0.061327
2025-08-08 00:35:22,582 - INFO - Epoch 839/1000 - Train Loss: 0.065875, Val Loss: 0.059068
2025-08-08 00:35:46,981 - INFO - Epoch 840/1000 - Train Loss: 0.065464, Val Loss: 0.056639
2025-08-08 00:36:11,402 - INFO - Epoch 841/1000 - Train Loss: 0.065375, Val Loss: 0.057572
2025-08-08 00:36:35,754 - INFO - Epoch 842/1000 - Train Loss: 0.064316, Val Loss: 0.055727
2025-08-08 00:36:35,775 - INFO - New best model saved with Val Loss: 0.055727
2025-08-08 00:37:00,085 - INFO - Epoch 843/1000 - Train Loss: 0.064841, Val Loss: 0.058343
2025-08-08 00:37:24,416 - INFO - Epoch 844/1000 - Train Loss: 0.064857, Val Loss: 0.056982
2025-08-08 00:37:48,687 - INFO - Epoch 845/1000 - Train Loss: 0.064546, Val Loss: 0.059766
2025-08-08 00:38:13,003 - INFO - Epoch 846/1000 - Train Loss: 0.064578, Val Loss: 0.057022
2025-08-08 00:38:37,224 - INFO - Epoch 847/1000 - Train Loss: 0.064523, Val Loss: 0.057874
2025-08-08 00:39:01,518 - INFO - Epoch 848/1000 - Train Loss: 0.065242, Val Loss: 0.056903
2025-08-08 00:39:25,935 - INFO - Epoch 849/1000 - Train Loss: 0.066119, Val Loss: 0.065254
2025-08-08 00:39:50,495 - INFO - Epoch 850/1000 - Train Loss: 0.065520, Val Loss: 0.057438
2025-08-08 00:40:14,684 - INFO - Epoch 851/1000 - Train Loss: 0.063411, Val Loss: 0.055417
2025-08-08 00:40:14,706 - INFO - New best model saved with Val Loss: 0.055417
2025-08-08 00:40:39,019 - INFO - Epoch 852/1000 - Train Loss: 0.064505, Val Loss: 0.058993
2025-08-08 00:41:03,035 - INFO - Epoch 853/1000 - Train Loss: 0.064508, Val Loss: 0.059299
2025-08-08 00:41:27,221 - INFO - Epoch 854/1000 - Train Loss: 0.065035, Val Loss: 0.056361
2025-08-08 00:41:51,573 - INFO - Epoch 855/1000 - Train Loss: 0.063948, Val Loss: 0.056742
2025-08-08 00:42:15,873 - INFO - Epoch 856/1000 - Train Loss: 0.065410, Val Loss: 0.057582
2025-08-08 00:42:40,122 - INFO - Epoch 857/1000 - Train Loss: 0.065454, Val Loss: 0.059228
2025-08-08 00:43:04,433 - INFO - Epoch 858/1000 - Train Loss: 0.065019, Val Loss: 0.058394
2025-08-08 00:43:28,707 - INFO - Epoch 859/1000 - Train Loss: 0.065683, Val Loss: 0.061445
2025-08-08 00:43:53,121 - INFO - Epoch 860/1000 - Train Loss: 0.064000, Val Loss: 0.055754
2025-08-08 00:44:17,567 - INFO - Epoch 861/1000 - Train Loss: 0.063858, Val Loss: 0.056677
2025-08-08 00:44:42,108 - INFO - Epoch 862/1000 - Train Loss: 0.063893, Val Loss: 0.057229
2025-08-08 00:45:06,446 - INFO - Epoch 863/1000 - Train Loss: 0.063840, Val Loss: 0.056590
2025-08-08 00:45:30,622 - INFO - Epoch 864/1000 - Train Loss: 0.063491, Val Loss: 0.059770
2025-08-08 00:45:54,816 - INFO - Epoch 865/1000 - Train Loss: 0.066591, Val Loss: 0.056304
2025-08-08 00:46:19,037 - INFO - Epoch 866/1000 - Train Loss: 0.064035, Val Loss: 0.057414
2025-08-08 00:46:43,442 - INFO - Epoch 867/1000 - Train Loss: 0.063245, Val Loss: 0.055911
2025-08-08 00:47:07,664 - INFO - Epoch 868/1000 - Train Loss: 0.064770, Val Loss: 0.059752
2025-08-08 00:47:31,934 - INFO - Epoch 869/1000 - Train Loss: 0.064195, Val Loss: 0.058035
2025-08-08 00:47:56,380 - INFO - Epoch 870/1000 - Train Loss: 0.062661, Val Loss: 0.055400
2025-08-08 00:47:56,401 - INFO - New best model saved with Val Loss: 0.055400
2025-08-08 00:48:20,757 - INFO - Epoch 871/1000 - Train Loss: 0.063893, Val Loss: 0.056117
2025-08-08 00:48:44,963 - INFO - Epoch 872/1000 - Train Loss: 0.063547, Val Loss: 0.057506
2025-08-08 00:49:09,355 - INFO - Epoch 873/1000 - Train Loss: 0.063671, Val Loss: 0.056552
2025-08-08 00:49:33,643 - INFO - Epoch 874/1000 - Train Loss: 0.063367, Val Loss: 0.055098
2025-08-08 00:49:33,664 - INFO - New best model saved with Val Loss: 0.055098
2025-08-08 00:49:58,010 - INFO - Epoch 875/1000 - Train Loss: 0.063068, Val Loss: 0.057149
2025-08-08 00:50:22,408 - INFO - Epoch 876/1000 - Train Loss: 0.065168, Val Loss: 0.056651
2025-08-08 00:50:46,811 - INFO - Epoch 877/1000 - Train Loss: 0.062448, Val Loss: 0.055802
2025-08-08 00:51:10,993 - INFO - Epoch 878/1000 - Train Loss: 0.063466, Val Loss: 0.060802
2025-08-08 00:51:35,186 - INFO - Epoch 879/1000 - Train Loss: 0.066642, Val Loss: 0.059273
2025-08-08 00:51:59,500 - INFO - Epoch 880/1000 - Train Loss: 0.063606, Val Loss: 0.056653
2025-08-08 00:52:24,032 - INFO - Epoch 881/1000 - Train Loss: 0.063118, Val Loss: 0.056132
2025-08-08 00:52:48,215 - INFO - Epoch 882/1000 - Train Loss: 0.064508, Val Loss: 0.059683
2025-08-08 00:53:12,453 - INFO - Epoch 883/1000 - Train Loss: 0.064911, Val Loss: 0.057440
2025-08-08 00:53:36,867 - INFO - Epoch 884/1000 - Train Loss: 0.063530, Val Loss: 0.057740
2025-08-08 00:54:01,360 - INFO - Epoch 885/1000 - Train Loss: 0.063367, Val Loss: 0.061464
2025-08-08 00:54:25,920 - INFO - Epoch 886/1000 - Train Loss: 0.064117, Val Loss: 0.057567
2025-08-08 00:54:50,403 - INFO - Epoch 887/1000 - Train Loss: 0.063163, Val Loss: 0.056231
2025-08-08 00:55:14,754 - INFO - Epoch 888/1000 - Train Loss: 0.062437, Val Loss: 0.058633
2025-08-08 00:55:38,985 - INFO - Epoch 889/1000 - Train Loss: 0.063648, Val Loss: 0.056615
2025-08-08 00:56:03,305 - INFO - Epoch 890/1000 - Train Loss: 0.063771, Val Loss: 0.056641
2025-08-08 00:56:27,697 - INFO - Epoch 891/1000 - Train Loss: 0.064689, Val Loss: 0.059637
2025-08-08 00:56:52,095 - INFO - Epoch 892/1000 - Train Loss: 0.064805, Val Loss: 0.055792
2025-08-08 00:57:16,372 - INFO - Epoch 893/1000 - Train Loss: 0.062504, Val Loss: 0.055722
2025-08-08 00:57:40,625 - INFO - Epoch 894/1000 - Train Loss: 0.061664, Val Loss: 0.054488
2025-08-08 00:57:40,646 - INFO - New best model saved with Val Loss: 0.054488
2025-08-08 00:58:04,899 - INFO - Epoch 895/1000 - Train Loss: 0.063166, Val Loss: 0.057121
2025-08-08 00:58:29,435 - INFO - Epoch 896/1000 - Train Loss: 0.062755, Val Loss: 0.057380
2025-08-08 00:58:53,496 - INFO - Epoch 897/1000 - Train Loss: 0.064500, Val Loss: 0.057160
2025-08-08 00:59:17,797 - INFO - Epoch 898/1000 - Train Loss: 0.062004, Val Loss: 0.056553
2025-08-08 00:59:42,039 - INFO - Epoch 899/1000 - Train Loss: 0.062478, Val Loss: 0.055471
2025-08-08 01:00:06,395 - INFO - Epoch 900/1000 - Train Loss: 0.062450, Val Loss: 0.056458
2025-08-08 01:00:30,734 - INFO - Epoch 901/1000 - Train Loss: 0.062803, Val Loss: 0.054574
2025-08-08 01:00:55,014 - INFO - Epoch 902/1000 - Train Loss: 0.062466, Val Loss: 0.057584
2025-08-08 01:01:19,320 - INFO - Epoch 903/1000 - Train Loss: 0.061848, Val Loss: 0.055726
2025-08-08 01:01:43,561 - INFO - Epoch 904/1000 - Train Loss: 0.063213, Val Loss: 0.054746
2025-08-08 01:02:07,701 - INFO - Epoch 905/1000 - Train Loss: 0.063486, Val Loss: 0.056486
2025-08-08 01:02:32,103 - INFO - Epoch 906/1000 - Train Loss: 0.063840, Val Loss: 0.056060
2025-08-08 01:02:56,301 - INFO - Epoch 907/1000 - Train Loss: 0.062714, Val Loss: 0.057803
2025-08-08 01:03:20,776 - INFO - Epoch 908/1000 - Train Loss: 0.063061, Val Loss: 0.056022
2025-08-08 01:03:45,038 - INFO - Epoch 909/1000 - Train Loss: 0.062594, Val Loss: 0.056436
2025-08-08 01:04:09,306 - INFO - Epoch 910/1000 - Train Loss: 0.062312, Val Loss: 0.055566
2025-08-08 01:04:33,618 - INFO - Epoch 911/1000 - Train Loss: 0.062344, Val Loss: 0.054747
2025-08-08 01:04:57,816 - INFO - Epoch 912/1000 - Train Loss: 0.062325, Val Loss: 0.058727
2025-08-08 01:05:22,027 - INFO - Epoch 913/1000 - Train Loss: 0.063189, Val Loss: 0.054671
2025-08-08 01:05:46,389 - INFO - Epoch 914/1000 - Train Loss: 0.062198, Val Loss: 0.055140
2025-08-08 01:06:10,832 - INFO - Epoch 915/1000 - Train Loss: 0.063932, Val Loss: 0.058304
2025-08-08 01:06:35,233 - INFO - Epoch 916/1000 - Train Loss: 0.061976, Val Loss: 0.055289
2025-08-08 01:06:59,574 - INFO - Epoch 917/1000 - Train Loss: 0.062030, Val Loss: 0.055201
2025-08-08 01:07:23,839 - INFO - Epoch 918/1000 - Train Loss: 0.064150, Val Loss: 0.055002
2025-08-08 01:07:48,149 - INFO - Epoch 919/1000 - Train Loss: 0.063367, Val Loss: 0.054694
2025-08-08 01:08:12,479 - INFO - Epoch 920/1000 - Train Loss: 0.061765, Val Loss: 0.056751
2025-08-08 01:08:36,926 - INFO - Epoch 921/1000 - Train Loss: 0.062450, Val Loss: 0.057398
2025-08-08 01:09:01,124 - INFO - Epoch 922/1000 - Train Loss: 0.062175, Val Loss: 0.053846
2025-08-08 01:09:01,145 - INFO - New best model saved with Val Loss: 0.053846
2025-08-08 01:09:25,401 - INFO - Epoch 923/1000 - Train Loss: 0.061761, Val Loss: 0.054571
2025-08-08 01:09:49,641 - INFO - Epoch 924/1000 - Train Loss: 0.062597, Val Loss: 0.056667
2025-08-08 01:10:13,925 - INFO - Epoch 925/1000 - Train Loss: 0.061564, Val Loss: 0.055489
2025-08-08 01:10:38,060 - INFO - Epoch 926/1000 - Train Loss: 0.064563, Val Loss: 0.056601
2025-08-08 01:11:02,198 - INFO - Epoch 927/1000 - Train Loss: 0.064664, Val Loss: 0.059039
2025-08-08 01:11:26,562 - INFO - Epoch 928/1000 - Train Loss: 0.061523, Val Loss: 0.052686
2025-08-08 01:11:26,583 - INFO - New best model saved with Val Loss: 0.052686
2025-08-08 01:11:50,925 - INFO - Epoch 929/1000 - Train Loss: 0.063932, Val Loss: 0.056034
2025-08-08 01:12:15,283 - INFO - Epoch 930/1000 - Train Loss: 0.061651, Val Loss: 0.053627
2025-08-08 01:12:39,573 - INFO - Epoch 931/1000 - Train Loss: 0.063021, Val Loss: 0.054662
2025-08-08 01:13:03,868 - INFO - Epoch 932/1000 - Train Loss: 0.061851, Val Loss: 0.056031
2025-08-08 01:13:28,184 - INFO - Epoch 933/1000 - Train Loss: 0.061819, Val Loss: 0.054876
2025-08-08 01:13:52,522 - INFO - Epoch 934/1000 - Train Loss: 0.061722, Val Loss: 0.053997
2025-08-08 01:14:16,714 - INFO - Epoch 935/1000 - Train Loss: 0.061604, Val Loss: 0.056103
2025-08-08 01:14:41,063 - INFO - Epoch 936/1000 - Train Loss: 0.061653, Val Loss: 0.058852
2025-08-08 01:15:05,253 - INFO - Epoch 937/1000 - Train Loss: 0.062751, Val Loss: 0.056760
2025-08-08 01:15:29,419 - INFO - Epoch 938/1000 - Train Loss: 0.061796, Val Loss: 0.053525
2025-08-08 01:15:53,798 - INFO - Epoch 939/1000 - Train Loss: 0.062753, Val Loss: 0.055565
2025-08-08 01:16:18,115 - INFO - Epoch 940/1000 - Train Loss: 0.060293, Val Loss: 0.054013
2025-08-08 01:16:42,461 - INFO - Epoch 941/1000 - Train Loss: 0.062079, Val Loss: 0.058056
2025-08-08 01:17:07,096 - INFO - Epoch 942/1000 - Train Loss: 0.062618, Val Loss: 0.054160
2025-08-08 01:17:31,634 - INFO - Epoch 943/1000 - Train Loss: 0.062599, Val Loss: 0.064112
2025-08-08 01:17:55,998 - INFO - Epoch 944/1000 - Train Loss: 0.064109, Val Loss: 0.055370
2025-08-08 01:18:20,194 - INFO - Epoch 945/1000 - Train Loss: 0.060770, Val Loss: 0.055885
2025-08-08 01:18:44,519 - INFO - Epoch 946/1000 - Train Loss: 0.061792, Val Loss: 0.055143
2025-08-08 01:19:08,777 - INFO - Epoch 947/1000 - Train Loss: 0.061879, Val Loss: 0.053862
2025-08-08 01:19:33,026 - INFO - Epoch 948/1000 - Train Loss: 0.061694, Val Loss: 0.057975
2025-08-08 01:19:57,248 - INFO - Epoch 949/1000 - Train Loss: 0.063783, Val Loss: 0.053674
2025-08-08 01:20:21,584 - INFO - Epoch 950/1000 - Train Loss: 0.061950, Val Loss: 0.056955
2025-08-08 01:20:45,950 - INFO - Epoch 951/1000 - Train Loss: 0.061621, Val Loss: 0.055497
2025-08-08 01:21:10,238 - INFO - Epoch 952/1000 - Train Loss: 0.062110, Val Loss: 0.053081
2025-08-08 01:21:34,484 - INFO - Epoch 953/1000 - Train Loss: 0.062003, Val Loss: 0.051940
2025-08-08 01:21:34,506 - INFO - New best model saved with Val Loss: 0.051940
2025-08-08 01:21:58,742 - INFO - Epoch 954/1000 - Train Loss: 0.061549, Val Loss: 0.052891
2025-08-08 01:22:23,020 - INFO - Epoch 955/1000 - Train Loss: 0.062029, Val Loss: 0.058221
2025-08-08 01:22:47,404 - INFO - Epoch 956/1000 - Train Loss: 0.060685, Val Loss: 0.054459
2025-08-08 01:23:11,581 - INFO - Epoch 957/1000 - Train Loss: 0.061361, Val Loss: 0.055308
2025-08-08 01:23:35,635 - INFO - Epoch 958/1000 - Train Loss: 0.061863, Val Loss: 0.054842
2025-08-08 01:23:59,696 - INFO - Epoch 959/1000 - Train Loss: 0.061781, Val Loss: 0.055582
2025-08-08 01:24:24,032 - INFO - Epoch 960/1000 - Train Loss: 0.062816, Val Loss: 0.054538
2025-08-08 01:24:48,419 - INFO - Epoch 961/1000 - Train Loss: 0.060375, Val Loss: 0.052319
2025-08-08 01:25:12,596 - INFO - Epoch 962/1000 - Train Loss: 0.060109, Val Loss: 0.053756
2025-08-08 01:25:36,891 - INFO - Epoch 963/1000 - Train Loss: 0.060566, Val Loss: 0.060554
2025-08-08 01:26:01,393 - INFO - Epoch 964/1000 - Train Loss: 0.061951, Val Loss: 0.053638
2025-08-08 01:26:25,772 - INFO - Epoch 965/1000 - Train Loss: 0.060712, Val Loss: 0.054762
2025-08-08 01:26:50,030 - INFO - Epoch 966/1000 - Train Loss: 0.060120, Val Loss: 0.053158
2025-08-08 01:27:14,229 - INFO - Epoch 967/1000 - Train Loss: 0.062482, Val Loss: 0.055573
2025-08-08 01:27:38,535 - INFO - Epoch 968/1000 - Train Loss: 0.061504, Val Loss: 0.055232
2025-08-08 01:28:02,690 - INFO - Epoch 969/1000 - Train Loss: 0.062087, Val Loss: 0.054970
2025-08-08 01:28:27,164 - INFO - Epoch 970/1000 - Train Loss: 0.060761, Val Loss: 0.054559
2025-08-08 01:28:51,470 - INFO - Epoch 971/1000 - Train Loss: 0.060852, Val Loss: 0.053144
2025-08-08 01:29:15,711 - INFO - Epoch 972/1000 - Train Loss: 0.060384, Val Loss: 0.054069
2025-08-08 01:29:39,802 - INFO - Epoch 973/1000 - Train Loss: 0.060645, Val Loss: 0.054249
2025-08-08 01:30:04,013 - INFO - Epoch 974/1000 - Train Loss: 0.060657, Val Loss: 0.053473
2025-08-08 01:30:28,485 - INFO - Epoch 975/1000 - Train Loss: 0.060453, Val Loss: 0.054061
2025-08-08 01:30:52,690 - INFO - Epoch 976/1000 - Train Loss: 0.061106, Val Loss: 0.055404
2025-08-08 01:31:17,025 - INFO - Epoch 977/1000 - Train Loss: 0.060593, Val Loss: 0.052595
2025-08-08 01:31:41,345 - INFO - Epoch 978/1000 - Train Loss: 0.061891, Val Loss: 0.053468
2025-08-08 01:32:05,573 - INFO - Epoch 979/1000 - Train Loss: 0.060465, Val Loss: 0.054676
2025-08-08 01:32:29,854 - INFO - Epoch 980/1000 - Train Loss: 0.061917, Val Loss: 0.054762
2025-08-08 01:32:54,176 - INFO - Epoch 981/1000 - Train Loss: 0.060289, Val Loss: 0.053632
2025-08-08 01:33:18,488 - INFO - Epoch 982/1000 - Train Loss: 0.059813, Val Loss: 0.055700
2025-08-08 01:33:42,637 - INFO - Epoch 983/1000 - Train Loss: 0.061148, Val Loss: 0.053889
2025-08-08 01:34:06,860 - INFO - Epoch 984/1000 - Train Loss: 0.061875, Val Loss: 0.058208
2025-08-08 01:34:31,260 - INFO - Epoch 985/1000 - Train Loss: 0.061237, Val Loss: 0.056390
2025-08-08 01:34:55,577 - INFO - Epoch 986/1000 - Train Loss: 0.060251, Val Loss: 0.053908
2025-08-08 01:35:19,797 - INFO - Epoch 987/1000 - Train Loss: 0.059564, Val Loss: 0.055854
2025-08-08 01:35:44,216 - INFO - Epoch 988/1000 - Train Loss: 0.060045, Val Loss: 0.055910
2025-08-08 01:36:08,374 - INFO - Epoch 989/1000 - Train Loss: 0.060395, Val Loss: 0.053873
2025-08-08 01:36:32,616 - INFO - Epoch 990/1000 - Train Loss: 0.059963, Val Loss: 0.053590
2025-08-08 01:36:56,941 - INFO - Epoch 991/1000 - Train Loss: 0.059950, Val Loss: 0.055522
2025-08-08 01:37:21,197 - INFO - Epoch 992/1000 - Train Loss: 0.060230, Val Loss: 0.053966
2025-08-08 01:37:45,485 - INFO - Epoch 993/1000 - Train Loss: 0.059773, Val Loss: 0.054535
2025-08-08 01:38:09,767 - INFO - Epoch 994/1000 - Train Loss: 0.059611, Val Loss: 0.053434
2025-08-08 01:38:34,199 - INFO - Epoch 995/1000 - Train Loss: 0.060511, Val Loss: 0.057529
2025-08-08 01:38:58,411 - INFO - Epoch 996/1000 - Train Loss: 0.061030, Val Loss: 0.055662
2025-08-08 01:39:22,687 - INFO - Epoch 997/1000 - Train Loss: 0.060572, Val Loss: 0.057155
2025-08-08 01:39:47,092 - INFO - Epoch 998/1000 - Train Loss: 0.060432, Val Loss: 0.056629
2025-08-08 01:40:11,668 - INFO - Epoch 999/1000 - Train Loss: 0.062060, Val Loss: 0.056020
2025-08-08 01:40:36,160 - INFO - Epoch 1000/1000 - Train Loss: 0.060677, Val Loss: 0.056887
2025-08-08 01:40:36,535 - INFO - Final model saved to experiments/Test/final_model.pth
2025-08-08 01:40:36,540 - INFO - Testing the final model
2025-08-08 01:40:45,949 - INFO - Total MSE across all processes: 6.5942487716674805
2025-08-08 01:40:45,952 - INFO - mean value for all_targets: {tmp}
2025-08-08 01:40:45,958 - INFO - Test MSE: 0.057844, Test MAE: 0.134749, Max AE: 26.842327, Test R2: 0.9456
2025-08-08 01:40:45,958 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-08 01:40:45,958 - INFO - Total inference time:  0.18s for 114 samples
2025-08-08 01:40:45,983 - INFO - Testing the best model
2025-08-08 01:40:54,221 - INFO - Total MSE across all processes: 6.301454544067383
2025-08-08 01:40:54,224 - INFO - mean value for all_targets: {tmp}
2025-08-08 01:40:54,229 - INFO - Test MSE: 0.055276, Test MAE: 0.134337, Max AE: 26.824375, Test R2: 0.9480
2025-08-08 01:40:54,229 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-08 01:40:54,229 - INFO - Total inference time:  0.18s for 114 samples
2025-08-15 11:00:28,365 - INFO - args.exp_name : Test
2025-08-15 11:00:28,431 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:00:28,431 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:03:27,864 - INFO - args.exp_name : Test
2025-08-15 11:03:27,867 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:03:27,867 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:05:04,668 - INFO - args.exp_name : Test
2025-08-15 11:05:04,671 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:05:04,671 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:08:13,535 - INFO - args.exp_name : Test
2025-08-15 11:08:13,538 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:08:13,538 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:08:14,161 - INFO - Total trainable parameters: 15042450
2025-08-15 11:08:14,527 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 11:08:14,528 - INFO - Staring training for 1000 epochs
2025-08-15 11:10:18,082 - INFO - args.exp_name : Test
2025-08-15 11:10:18,084 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:10:18,084 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:10:18,659 - INFO - Total trainable parameters: 15042450
2025-08-15 11:10:18,940 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 11:10:18,942 - INFO - Staring training for 1000 epochs
2025-08-15 11:15:39,235 - INFO - args.exp_name : Test
2025-08-15 11:15:39,239 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:15:39,240 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:15:39,610 - INFO - Total trainable parameters: 2441034
2025-08-15 11:15:39,890 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 11:15:39,891 - INFO - Staring training for 1000 epochs
2025-08-15 11:16:36,951 - INFO - args.exp_name : Test
2025-08-15 11:16:36,956 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 11:16:36,956 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 11:16:37,336 - INFO - Total trainable parameters: 2441034
2025-08-15 11:16:37,614 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 11:16:37,615 - INFO - Staring training for 1000 epochs
2025-08-15 12:03:46,528 - INFO - args.exp_name : Test
2025-08-15 12:03:46,532 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:03:46,533 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:03:47,018 - INFO - Total trainable parameters: 2441034
2025-08-15 12:03:47,432 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:03:47,433 - INFO - Staring training for 1000 epochs
2025-08-15 12:07:34,446 - INFO - args.exp_name : Test
2025-08-15 12:07:34,450 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:07:34,450 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:07:35,173 - INFO - Total trainable parameters: 2441034
2025-08-15 12:07:35,646 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:07:35,650 - INFO - Staring training for 1000 epochs
2025-08-15 12:13:08,065 - INFO - args.exp_name : Test
2025-08-15 12:13:08,137 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:13:08,137 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:13:08,624 - INFO - Total trainable parameters: 2441034
2025-08-15 12:13:09,026 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:13:09,027 - INFO - Staring training for 1000 epochs
2025-08-15 12:18:58,407 - INFO - args.exp_name : Test
2025-08-15 12:18:58,456 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:18:58,456 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:18:58,912 - INFO - Total trainable parameters: 2441034
2025-08-15 12:18:59,211 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:18:59,212 - INFO - Staring training for 1000 epochs
2025-08-15 12:22:30,443 - INFO - args.exp_name : Test
2025-08-15 12:22:30,448 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:22:30,448 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:22:30,880 - INFO - Total trainable parameters: 2447946
2025-08-15 12:22:31,158 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:22:31,159 - INFO - Staring training for 1000 epochs
2025-08-15 12:30:21,320 - INFO - args.exp_name : Test
2025-08-15 12:30:21,325 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:30:21,325 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:30:21,777 - INFO - Total trainable parameters: 2447946
2025-08-15 12:30:22,058 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:30:22,059 - INFO - Staring training for 1000 epochs
2025-08-15 12:31:24,851 - INFO - args.exp_name : Test
2025-08-15 12:31:24,856 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:31:24,856 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:33:10,384 - INFO - args.exp_name : Test
2025-08-15 12:33:10,402 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:33:10,402 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:35:48,123 - INFO - args.exp_name : Test
2025-08-15 12:35:48,128 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:35:48,128 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:37:09,201 - INFO - args.exp_name : Test
2025-08-15 12:37:09,206 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:37:09,206 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:37:09,256 - INFO - [35m n_hidden: 128 [0m
2025-08-15 12:37:09,652 - INFO - Total trainable parameters: 2447946
2025-08-15 12:37:09,926 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:37:09,927 - INFO - Staring training for 1000 epochs
2025-08-15 12:42:18,181 - INFO - args.exp_name : Test
2025-08-15 12:42:18,216 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:42:18,216 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:42:18,265 - INFO - [35m n_hidden: 128 [0m
2025-08-15 12:42:18,678 - INFO - Total trainable parameters: 2447946
2025-08-15 12:42:18,951 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:42:18,952 - INFO - Staring training for 1000 epochs
2025-08-15 12:44:43,960 - INFO - args.exp_name : Test
2025-08-15 12:44:43,964 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:44:44,058 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:44:44,107 - INFO - [35m n_hidden: 128 [0m
2025-08-15 12:44:44,502 - INFO - Total trainable parameters: 2447946
2025-08-15 12:44:44,779 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:44:44,779 - INFO - Staring training for 1000 epochs
2025-08-15 12:46:19,593 - INFO - args.exp_name : Test
2025-08-15 12:46:19,597 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:46:19,597 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:46:19,657 - INFO - [35m n_hidden: 128 [0m
2025-08-15 12:47:16,807 - INFO - args.exp_name : Test
2025-08-15 12:47:16,811 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 12:47:16,811 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 12:47:16,861 - INFO - [35m n_hidden: 128 [0m
2025-08-15 12:47:17,279 - INFO - Total trainable parameters: 2447818
2025-08-15 12:47:17,553 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 12:47:17,554 - INFO - Staring training for 1000 epochs
2025-08-15 14:28:48,899 - INFO - args.exp_name : Test
2025-08-15 14:28:48,918 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:28:48,918 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:28:49,396 - INFO - Total trainable parameters: 2447946
2025-08-15 14:28:49,788 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:28:49,789 - INFO - Staring training for 1000 epochs
2025-08-15 14:28:56,892 - INFO - [35m x.shape: torch.Size([6, 9996, 256]) [0m
2025-08-15 14:28:56,896 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:31:23,255 - INFO - args.exp_name : Test
2025-08-15 14:31:23,272 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:31:23,272 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:31:23,291 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:31:23,291 - INFO - [35m n_output: 128 [0m
2025-08-15 14:31:23,724 - INFO - Total trainable parameters: 2447946
2025-08-15 14:31:23,999 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:31:24,000 - INFO - Staring training for 1000 epochs
2025-08-15 14:31:30,886 - INFO - [35m x.shape: torch.Size([6, 9996, 256]) [0m
2025-08-15 14:31:30,886 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:33:29,120 - INFO - args.exp_name : Test
2025-08-15 14:33:29,143 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:33:29,143 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:33:29,162 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:33:29,162 - INFO - [35m n_output: 128 [0m
2025-08-15 14:33:29,577 - INFO - Total trainable parameters: 2447946
2025-08-15 14:33:29,851 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:33:29,855 - INFO - Staring training for 1000 epochs
2025-08-15 14:35:33,946 - INFO - args.exp_name : Test
2025-08-15 14:35:33,950 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:35:33,950 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:35:33,969 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:35:33,969 - INFO - [35m n_output: 128 [0m
2025-08-15 14:35:34,401 - INFO - Total trainable parameters: 2447946
2025-08-15 14:35:34,688 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:35:34,689 - INFO - Staring training for 1000 epochs
2025-08-15 14:37:23,249 - INFO - args.exp_name : Test
2025-08-15 14:37:23,265 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:37:23,265 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:37:23,283 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:37:23,284 - INFO - [35m n_output: 128 [0m
2025-08-15 14:37:23,701 - INFO - Total trainable parameters: 2447946
2025-08-15 14:37:23,975 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:37:23,976 - INFO - Staring training for 1000 epochs
2025-08-15 14:39:14,859 - INFO - args.exp_name : Test
2025-08-15 14:39:14,863 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:39:14,863 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:39:14,883 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:39:14,883 - INFO - [35m n_output: 128 [0m
2025-08-15 14:39:15,316 - INFO - Total trainable parameters: 2447946
2025-08-15 14:39:15,589 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:39:15,590 - INFO - Staring training for 1000 epochs
2025-08-15 14:41:59,848 - INFO - args.exp_name : Test
2025-08-15 14:41:59,852 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:41:59,852 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:41:59,871 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:41:59,871 - INFO - [35m n_output: 128 [0m
2025-08-15 14:42:00,300 - INFO - Total trainable parameters: 2447946
2025-08-15 14:42:00,590 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:42:00,591 - INFO - Staring training for 1000 epochs
2025-08-15 14:42:07,335 - INFO - [35m x.conv1: torch.Size([6, 256, 9998, 38]) [0m
2025-08-15 14:42:07,339 - INFO - [35m x.conv2: torch.Size([6, 256, 9996, 36]) [0m
2025-08-15 14:48:26,012 - INFO - args.exp_name : Test
2025-08-15 14:48:26,035 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:48:26,038 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:49:06,027 - INFO - args.exp_name : Test
2025-08-15 14:49:06,031 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:49:06,031 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:49:06,049 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:49:06,049 - INFO - [35m n_output: 128 [0m
2025-08-15 14:49:06,482 - INFO - Total trainable parameters: 2447946
2025-08-15 14:49:06,774 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:49:06,778 - INFO - Staring training for 1000 epochs
2025-08-15 14:49:13,719 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:49:13,723 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:12,148 - INFO - args.exp_name : Test
2025-08-15 14:52:12,152 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:52:12,152 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:52:12,171 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:52:12,171 - INFO - [35m n_output: 128 [0m
2025-08-15 14:52:12,581 - INFO - Total trainable parameters: 2447690
2025-08-15 14:52:12,859 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:52:12,860 - INFO - Staring training for 1000 epochs
2025-08-15 14:52:19,921 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:19,925 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:19,926 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:19,927 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:19,927 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:19,927 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:21,559 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:21,559 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:21,560 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:21,560 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:21,560 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:21,560 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:23,023 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:23,023 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:23,023 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:23,024 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:23,024 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:23,027 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:24,411 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:24,411 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:24,411 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:24,412 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:24,412 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:24,412 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:25,798 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:25,799 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:25,799 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:25,799 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:25,799 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:25,799 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:27,188 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:27,188 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:27,189 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:27,189 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:27,189 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:27,189 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:28,581 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:28,581 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:28,582 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:28,582 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:28,582 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:28,582 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:29,969 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:29,969 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:29,970 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:29,970 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:29,970 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:29,970 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:31,360 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:31,360 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:31,361 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:31,361 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:31,361 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:31,361 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:32,754 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:32,754 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:32,755 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:32,755 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:32,755 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:32,755 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:34,143 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:34,143 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:34,143 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:34,143 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:34,144 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:34,144 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:35,531 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:35,532 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:35,532 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:35,532 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:35,532 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:35,532 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:36,923 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:36,923 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:36,924 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:36,924 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:36,924 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:36,924 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:38,315 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:38,315 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:38,316 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:38,316 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:38,316 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:38,316 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:39,703 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:39,704 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:39,704 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:39,704 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:39,705 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:39,705 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:41,097 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:41,097 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:41,098 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:41,098 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:41,098 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:41,098 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:42,493 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:42,493 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:42,494 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:42,494 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:42,494 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:42,494 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:43,883 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:43,884 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:43,884 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:43,884 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:43,884 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:43,884 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:45,276 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:45,276 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:45,276 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:45,277 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:45,277 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:45,277 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:46,669 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:46,669 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:46,670 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:46,670 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:46,670 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:46,670 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:48,059 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:48,060 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:48,060 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:48,060 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:48,060 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:48,061 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:49,449 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:49,450 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:49,450 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:49,450 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:49,450 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:49,451 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:50,843 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:50,843 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:50,844 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:50,844 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:50,844 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:50,844 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:52,238 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:52,239 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:52,239 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:52,239 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:52,240 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:52,240 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:53,629 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:53,630 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:53,630 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:53,630 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:53,630 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:53,630 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:55,023 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:55,023 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:55,024 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:55,024 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:55,024 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:55,024 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:56,418 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:56,419 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:56,419 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:56,419 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:56,419 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:56,420 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:57,811 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:57,812 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:57,812 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:57,812 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:57,812 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:57,813 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:52:59,204 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:59,204 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:52:59,205 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:52:59,205 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:52:59,205 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:52:59,205 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:00,598 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:00,598 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:00,599 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:00,599 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:00,599 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:00,599 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:01,993 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:01,993 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:01,994 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:01,994 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:01,994 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:01,994 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:03,393 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:03,393 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:03,393 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:03,393 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:03,394 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:03,394 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:04,787 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:04,788 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:04,788 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:04,788 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:04,788 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:04,788 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:06,180 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:06,180 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:06,181 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:06,181 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:06,181 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:06,181 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:07,576 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:07,577 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:07,577 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:07,577 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:07,577 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:07,577 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:08,974 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:08,975 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:08,975 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:08,975 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:08,975 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:08,976 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:10,371 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:10,371 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:10,372 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:10,372 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:10,372 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:10,372 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:11,765 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:11,765 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:11,766 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:11,766 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:11,766 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:11,766 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:13,165 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:13,166 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:13,166 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:13,166 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:13,166 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:13,167 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:14,559 - INFO - [35m x.conv1: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:14,559 - INFO - [35m x.conv2: torch.Size([6, 256, 10000, 40]) [0m
2025-08-15 14:53:14,560 - INFO - [35m x.conv3: torch.Size([6, 128, 10000, 40]) [0m
2025-08-15 14:53:14,560 - INFO - [35m x.max: torch.Size([6, 128, 10000]) [0m
2025-08-15 14:53:14,560 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:14,560 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:48,117 - INFO - args.exp_name : Test
2025-08-15 14:53:48,121 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:53:48,121 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:53:48,139 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:53:48,139 - INFO - [35m n_output: 128 [0m
2025-08-15 14:53:48,573 - INFO - Total trainable parameters: 2447690
2025-08-15 14:53:48,848 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:53:48,852 - INFO - Staring training for 1000 epochs
2025-08-15 14:53:56,090 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:56,092 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:57,683 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:57,683 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:53:59,151 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:53:59,152 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:00,548 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:00,548 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:01,940 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:01,940 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:03,332 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:03,332 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:04,724 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:04,724 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:06,125 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:06,126 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:07,519 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:07,520 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:08,913 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:08,913 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:10,308 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:10,308 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:11,700 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:11,701 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:13,095 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:13,096 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:14,491 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:14,491 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:15,885 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:15,885 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:17,281 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:17,281 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:18,678 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:18,678 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:20,071 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:20,071 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:21,466 - INFO - [35m x.shape: torch.Size([6, 10000, 128]) [0m
2025-08-15 14:54:21,466 - INFO - [35m self.placeholder: torch.Size([128]) [0m
2025-08-15 14:54:52,244 - INFO - args.exp_name : Test
2025-08-15 14:54:52,248 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-15 14:54:52,248 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-15 14:54:52,267 - INFO - [35m n_hidden: 256 [0m
2025-08-15 14:54:52,268 - INFO - [35m n_output: 128 [0m
2025-08-15 14:54:52,696 - INFO - Total trainable parameters: 2447690
2025-08-15 14:54:52,977 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-15 14:54:52,980 - INFO - Staring training for 1000 epochs
2025-08-15 14:57:03,238 - INFO - Epoch 1/1000 - Train Loss: 1.061845, Val Loss: 1.042250
2025-08-15 14:57:03,291 - INFO - New best model saved with Val Loss: 1.042250
2025-08-15 14:59:12,978 - INFO - Epoch 2/1000 - Train Loss: 1.007209, Val Loss: 0.992495
2025-08-15 14:59:13,014 - INFO - New best model saved with Val Loss: 0.992495
2025-08-15 15:01:22,744 - INFO - Epoch 3/1000 - Train Loss: 0.966305, Val Loss: 0.975856
2025-08-15 15:01:22,779 - INFO - New best model saved with Val Loss: 0.975856
2025-08-15 15:03:32,336 - INFO - Epoch 4/1000 - Train Loss: 0.927951, Val Loss: 0.957859
2025-08-15 15:03:32,371 - INFO - New best model saved with Val Loss: 0.957859
2025-08-15 15:05:41,696 - INFO - Epoch 5/1000 - Train Loss: 0.895549, Val Loss: 0.961393
2025-08-15 15:07:51,116 - INFO - Epoch 6/1000 - Train Loss: 0.866772, Val Loss: 0.861157
2025-08-15 15:07:51,170 - INFO - New best model saved with Val Loss: 0.861157
2025-08-15 15:10:00,851 - INFO - Epoch 7/1000 - Train Loss: 0.836236, Val Loss: 0.843428
2025-08-15 15:10:00,898 - INFO - New best model saved with Val Loss: 0.843428
2025-08-15 15:12:10,119 - INFO - Epoch 8/1000 - Train Loss: 0.816422, Val Loss: 0.825426
2025-08-15 15:12:10,154 - INFO - New best model saved with Val Loss: 0.825426
2025-08-15 15:14:19,497 - INFO - Epoch 9/1000 - Train Loss: 0.797396, Val Loss: 0.811997
2025-08-15 15:14:19,532 - INFO - New best model saved with Val Loss: 0.811997
2025-08-15 15:16:29,046 - INFO - Epoch 10/1000 - Train Loss: 0.768123, Val Loss: 0.784734
2025-08-15 15:16:29,099 - INFO - New best model saved with Val Loss: 0.784734
2025-08-15 15:18:39,188 - INFO - Epoch 11/1000 - Train Loss: 0.747217, Val Loss: 0.750572
2025-08-15 15:18:39,224 - INFO - New best model saved with Val Loss: 0.750572
2025-08-15 15:20:48,725 - INFO - Epoch 12/1000 - Train Loss: 0.724724, Val Loss: 0.740398
2025-08-15 15:20:48,760 - INFO - New best model saved with Val Loss: 0.740398
2025-08-15 15:22:58,560 - INFO - Epoch 13/1000 - Train Loss: 0.703800, Val Loss: 0.707053
2025-08-15 15:22:58,595 - INFO - New best model saved with Val Loss: 0.707053
2025-08-15 15:25:08,453 - INFO - Epoch 14/1000 - Train Loss: 0.680973, Val Loss: 0.676201
2025-08-15 15:25:08,500 - INFO - New best model saved with Val Loss: 0.676201
2025-08-15 15:27:17,937 - INFO - Epoch 15/1000 - Train Loss: 0.662914, Val Loss: 0.681979
2025-08-15 15:29:27,201 - INFO - Epoch 16/1000 - Train Loss: 0.650879, Val Loss: 0.651146
2025-08-15 15:29:27,252 - INFO - New best model saved with Val Loss: 0.651146
2025-08-15 15:31:36,575 - INFO - Epoch 17/1000 - Train Loss: 0.631791, Val Loss: 0.637939
2025-08-15 15:31:36,611 - INFO - New best model saved with Val Loss: 0.637939
2025-08-15 15:33:45,805 - INFO - Epoch 18/1000 - Train Loss: 0.612644, Val Loss: 0.634868
2025-08-15 15:33:45,856 - INFO - New best model saved with Val Loss: 0.634868
2025-08-15 15:35:55,331 - INFO - Epoch 19/1000 - Train Loss: 0.599625, Val Loss: 0.608375
2025-08-15 15:35:55,366 - INFO - New best model saved with Val Loss: 0.608375
2025-08-15 15:38:04,613 - INFO - Epoch 20/1000 - Train Loss: 0.586782, Val Loss: 0.580520
2025-08-15 15:38:04,648 - INFO - New best model saved with Val Loss: 0.580520
2025-08-15 15:40:14,142 - INFO - Epoch 21/1000 - Train Loss: 0.570070, Val Loss: 0.570453
2025-08-15 15:40:14,178 - INFO - New best model saved with Val Loss: 0.570453
2025-08-15 15:42:23,543 - INFO - Epoch 22/1000 - Train Loss: 0.561610, Val Loss: 0.559984
2025-08-15 15:42:23,577 - INFO - New best model saved with Val Loss: 0.559984
2025-08-15 15:44:32,900 - INFO - Epoch 23/1000 - Train Loss: 0.548593, Val Loss: 0.560192
2025-08-15 15:46:42,466 - INFO - Epoch 24/1000 - Train Loss: 0.536694, Val Loss: 0.545711
2025-08-15 15:46:42,500 - INFO - New best model saved with Val Loss: 0.545711
2025-08-15 15:48:51,685 - INFO - Epoch 25/1000 - Train Loss: 0.533180, Val Loss: 0.545818
2025-08-15 15:51:01,105 - INFO - Epoch 26/1000 - Train Loss: 0.523922, Val Loss: 0.519712
2025-08-15 15:51:01,150 - INFO - New best model saved with Val Loss: 0.519712
2025-08-15 15:53:10,508 - INFO - Epoch 27/1000 - Train Loss: 0.518568, Val Loss: 0.540604
2025-08-15 15:55:19,942 - INFO - Epoch 28/1000 - Train Loss: 0.507561, Val Loss: 0.501023
2025-08-15 15:55:19,990 - INFO - New best model saved with Val Loss: 0.501023
2025-08-15 15:57:29,653 - INFO - Epoch 29/1000 - Train Loss: 0.496379, Val Loss: 0.517174
2025-08-15 15:59:38,944 - INFO - Epoch 30/1000 - Train Loss: 0.493592, Val Loss: 0.503207
2025-08-15 16:01:48,725 - INFO - Epoch 31/1000 - Train Loss: 0.489199, Val Loss: 0.497476
2025-08-15 16:01:48,760 - INFO - New best model saved with Val Loss: 0.497476
2025-08-15 16:03:58,082 - INFO - Epoch 32/1000 - Train Loss: 0.484660, Val Loss: 0.501163
2025-08-15 16:06:07,263 - INFO - Epoch 33/1000 - Train Loss: 0.481098, Val Loss: 0.479052
2025-08-15 16:06:07,300 - INFO - New best model saved with Val Loss: 0.479052
2025-08-15 16:08:16,638 - INFO - Epoch 34/1000 - Train Loss: 0.478007, Val Loss: 0.487085
2025-08-15 16:10:26,015 - INFO - Epoch 35/1000 - Train Loss: 0.474787, Val Loss: 0.474051
2025-08-15 16:10:26,050 - INFO - New best model saved with Val Loss: 0.474051
2025-08-15 16:12:35,649 - INFO - Epoch 36/1000 - Train Loss: 0.470776, Val Loss: 0.475691
2025-08-15 16:14:45,012 - INFO - Epoch 37/1000 - Train Loss: 0.463691, Val Loss: 0.464340
2025-08-15 16:14:45,059 - INFO - New best model saved with Val Loss: 0.464340
2025-08-15 16:16:54,752 - INFO - Epoch 38/1000 - Train Loss: 0.462252, Val Loss: 0.459982
2025-08-15 16:16:54,785 - INFO - New best model saved with Val Loss: 0.459982
2025-08-15 16:19:04,537 - INFO - Epoch 39/1000 - Train Loss: 0.454682, Val Loss: 0.459450
2025-08-15 16:19:04,571 - INFO - New best model saved with Val Loss: 0.459450
2025-08-15 16:21:14,264 - INFO - Epoch 40/1000 - Train Loss: 0.456164, Val Loss: 0.450428
2025-08-15 16:21:14,297 - INFO - New best model saved with Val Loss: 0.450428
2025-08-15 16:23:23,861 - INFO - Epoch 41/1000 - Train Loss: 0.450730, Val Loss: 0.456072
2025-08-15 16:25:33,098 - INFO - Epoch 42/1000 - Train Loss: 0.451396, Val Loss: 0.458593
2025-08-15 16:27:42,296 - INFO - Epoch 43/1000 - Train Loss: 0.450727, Val Loss: 0.472760
2025-08-15 16:29:51,858 - INFO - Epoch 44/1000 - Train Loss: 0.447335, Val Loss: 0.454549
2025-08-15 16:32:01,268 - INFO - Epoch 45/1000 - Train Loss: 0.443226, Val Loss: 0.454590
2025-08-15 16:34:10,473 - INFO - Epoch 46/1000 - Train Loss: 0.443339, Val Loss: 0.448700
2025-08-15 16:34:10,507 - INFO - New best model saved with Val Loss: 0.448700
2025-08-15 16:36:19,857 - INFO - Epoch 47/1000 - Train Loss: 0.439617, Val Loss: 0.446430
2025-08-15 16:36:19,891 - INFO - New best model saved with Val Loss: 0.446430
2025-08-15 16:38:29,769 - INFO - Epoch 48/1000 - Train Loss: 0.438525, Val Loss: 0.443076
2025-08-15 16:38:29,803 - INFO - New best model saved with Val Loss: 0.443076
2025-08-15 16:40:39,084 - INFO - Epoch 49/1000 - Train Loss: 0.439274, Val Loss: 0.442498
2025-08-15 16:40:39,119 - INFO - New best model saved with Val Loss: 0.442498
2025-08-15 16:42:48,920 - INFO - Epoch 50/1000 - Train Loss: 0.434698, Val Loss: 0.445812
2025-08-15 16:44:58,638 - INFO - Epoch 51/1000 - Train Loss: 0.433392, Val Loss: 0.432888
2025-08-15 16:44:58,674 - INFO - New best model saved with Val Loss: 0.432888
2025-08-15 16:47:08,495 - INFO - Epoch 52/1000 - Train Loss: 0.434056, Val Loss: 0.437818
2025-08-15 16:49:17,965 - INFO - Epoch 53/1000 - Train Loss: 0.430170, Val Loss: 0.442719
2025-08-15 16:51:27,732 - INFO - Epoch 54/1000 - Train Loss: 0.429430, Val Loss: 0.432382
2025-08-15 16:51:27,785 - INFO - New best model saved with Val Loss: 0.432382
2025-08-15 16:53:37,308 - INFO - Epoch 55/1000 - Train Loss: 0.426897, Val Loss: 0.432180
2025-08-15 16:53:37,344 - INFO - New best model saved with Val Loss: 0.432180
2025-08-15 16:55:47,449 - INFO - Epoch 56/1000 - Train Loss: 0.430977, Val Loss: 0.437320
2025-08-15 16:57:57,574 - INFO - Epoch 57/1000 - Train Loss: 0.427176, Val Loss: 0.429477
2025-08-15 16:57:57,608 - INFO - New best model saved with Val Loss: 0.429477
2025-08-15 17:00:07,617 - INFO - Epoch 58/1000 - Train Loss: 0.425953, Val Loss: 0.444852
2025-08-15 17:02:17,254 - INFO - Epoch 59/1000 - Train Loss: 0.422501, Val Loss: 0.433828
2025-08-15 17:04:26,801 - INFO - Epoch 60/1000 - Train Loss: 0.423844, Val Loss: 0.432729
2025-08-15 17:06:36,461 - INFO - Epoch 61/1000 - Train Loss: 0.423887, Val Loss: 0.439188
2025-08-15 17:08:46,078 - INFO - Epoch 62/1000 - Train Loss: 0.418961, Val Loss: 0.417976
2025-08-15 17:08:46,112 - INFO - New best model saved with Val Loss: 0.417976
2025-08-15 17:10:56,101 - INFO - Epoch 63/1000 - Train Loss: 0.421637, Val Loss: 0.423602
2025-08-15 17:13:05,813 - INFO - Epoch 64/1000 - Train Loss: 0.416422, Val Loss: 0.417280
2025-08-15 17:13:05,849 - INFO - New best model saved with Val Loss: 0.417280
2025-08-15 17:15:15,342 - INFO - Epoch 65/1000 - Train Loss: 0.413462, Val Loss: 0.419120
2025-08-15 17:17:24,790 - INFO - Epoch 66/1000 - Train Loss: 0.417971, Val Loss: 0.422954
2025-08-15 17:19:34,514 - INFO - Epoch 67/1000 - Train Loss: 0.413641, Val Loss: 0.428947
2025-08-15 17:21:44,098 - INFO - Epoch 68/1000 - Train Loss: 0.413417, Val Loss: 0.417556
2025-08-15 17:23:53,849 - INFO - Epoch 69/1000 - Train Loss: 0.415027, Val Loss: 0.421659
2025-08-15 17:26:03,483 - INFO - Epoch 70/1000 - Train Loss: 0.412723, Val Loss: 0.422521
2025-08-15 17:28:13,329 - INFO - Epoch 71/1000 - Train Loss: 0.414092, Val Loss: 0.433709
2025-08-15 17:30:22,494 - INFO - Epoch 72/1000 - Train Loss: 0.411620, Val Loss: 0.424055
2025-08-15 17:32:31,736 - INFO - Epoch 73/1000 - Train Loss: 0.409821, Val Loss: 0.415900
2025-08-15 17:32:31,781 - INFO - New best model saved with Val Loss: 0.415900
2025-08-15 17:34:41,336 - INFO - Epoch 74/1000 - Train Loss: 0.409953, Val Loss: 0.410656
2025-08-15 17:34:41,371 - INFO - New best model saved with Val Loss: 0.410656
2025-08-15 17:36:50,839 - INFO - Epoch 75/1000 - Train Loss: 0.412325, Val Loss: 0.418251
2025-08-15 17:39:00,445 - INFO - Epoch 76/1000 - Train Loss: 0.408789, Val Loss: 0.417373
2025-08-15 17:41:09,958 - INFO - Epoch 77/1000 - Train Loss: 0.411251, Val Loss: 0.430891
2025-08-15 17:43:19,449 - INFO - Epoch 78/1000 - Train Loss: 0.413660, Val Loss: 0.427612
2025-08-15 17:45:28,864 - INFO - Epoch 79/1000 - Train Loss: 0.406886, Val Loss: 0.420515
2025-08-15 17:47:37,987 - INFO - Epoch 80/1000 - Train Loss: 0.404929, Val Loss: 0.420635
2025-08-15 17:49:47,607 - INFO - Epoch 81/1000 - Train Loss: 0.405585, Val Loss: 0.410537
2025-08-15 17:49:47,641 - INFO - New best model saved with Val Loss: 0.410537
2025-08-15 17:51:56,819 - INFO - Epoch 82/1000 - Train Loss: 0.405475, Val Loss: 0.408891
2025-08-15 17:51:56,854 - INFO - New best model saved with Val Loss: 0.408891
2025-08-15 17:54:05,998 - INFO - Epoch 83/1000 - Train Loss: 0.404614, Val Loss: 0.417702
2025-08-15 17:56:15,038 - INFO - Epoch 84/1000 - Train Loss: 0.404626, Val Loss: 0.412698
2025-08-15 17:58:24,359 - INFO - Epoch 85/1000 - Train Loss: 0.406970, Val Loss: 0.415756
2025-08-15 18:00:33,949 - INFO - Epoch 86/1000 - Train Loss: 0.406671, Val Loss: 0.415742
2025-08-15 18:02:43,709 - INFO - Epoch 87/1000 - Train Loss: 0.403943, Val Loss: 0.412735
2025-08-15 18:04:52,705 - INFO - Epoch 88/1000 - Train Loss: 0.401051, Val Loss: 0.408071
2025-08-15 18:04:52,741 - INFO - New best model saved with Val Loss: 0.408071
2025-08-15 18:07:02,176 - INFO - Epoch 89/1000 - Train Loss: 0.402492, Val Loss: 0.405601
2025-08-15 18:07:02,210 - INFO - New best model saved with Val Loss: 0.405601
2025-08-15 18:09:11,548 - INFO - Epoch 90/1000 - Train Loss: 0.401855, Val Loss: 0.411405
2025-08-15 18:11:20,706 - INFO - Epoch 91/1000 - Train Loss: 0.402182, Val Loss: 0.401354
2025-08-15 18:11:20,742 - INFO - New best model saved with Val Loss: 0.401354
2025-08-15 18:13:30,399 - INFO - Epoch 92/1000 - Train Loss: 0.400449, Val Loss: 0.418445
2025-08-15 18:15:39,400 - INFO - Epoch 93/1000 - Train Loss: 0.402811, Val Loss: 0.407600
2025-08-15 18:17:48,683 - INFO - Epoch 94/1000 - Train Loss: 0.399474, Val Loss: 0.405892
2025-08-15 18:19:57,599 - INFO - Epoch 95/1000 - Train Loss: 0.404895, Val Loss: 0.408637
2025-08-15 18:22:06,944 - INFO - Epoch 96/1000 - Train Loss: 0.395870, Val Loss: 0.410958
2025-08-15 18:24:16,271 - INFO - Epoch 97/1000 - Train Loss: 0.399389, Val Loss: 0.412252
2025-08-15 18:26:25,516 - INFO - Epoch 98/1000 - Train Loss: 0.396469, Val Loss: 0.408065
2025-08-15 18:28:35,042 - INFO - Epoch 99/1000 - Train Loss: 0.397191, Val Loss: 0.412673
2025-08-15 18:30:44,339 - INFO - Epoch 100/1000 - Train Loss: 0.398704, Val Loss: 0.403323
2025-08-15 18:32:53,931 - INFO - Epoch 101/1000 - Train Loss: 0.395089, Val Loss: 0.405569
2025-08-15 18:35:03,037 - INFO - Epoch 102/1000 - Train Loss: 0.399686, Val Loss: 0.412430
2025-08-15 18:37:12,498 - INFO - Epoch 103/1000 - Train Loss: 0.396860, Val Loss: 0.397821
2025-08-15 18:37:12,544 - INFO - New best model saved with Val Loss: 0.397821
2025-08-15 18:39:21,755 - INFO - Epoch 104/1000 - Train Loss: 0.397441, Val Loss: 0.406808
2025-08-15 18:41:30,879 - INFO - Epoch 105/1000 - Train Loss: 0.394527, Val Loss: 0.402398
2025-08-15 18:43:40,296 - INFO - Epoch 106/1000 - Train Loss: 0.394556, Val Loss: 0.425856
2025-08-15 18:45:49,858 - INFO - Epoch 107/1000 - Train Loss: 0.393553, Val Loss: 0.403930
2025-08-15 18:47:59,141 - INFO - Epoch 108/1000 - Train Loss: 0.394351, Val Loss: 0.417031
2025-08-15 18:50:08,124 - INFO - Epoch 109/1000 - Train Loss: 0.392840, Val Loss: 0.416401
2025-08-15 18:52:17,390 - INFO - Epoch 110/1000 - Train Loss: 0.391829, Val Loss: 0.425288
2025-08-15 18:54:26,825 - INFO - Epoch 111/1000 - Train Loss: 0.395333, Val Loss: 0.397942
2025-08-15 18:56:36,373 - INFO - Epoch 112/1000 - Train Loss: 0.390255, Val Loss: 0.410785
2025-08-15 18:58:45,861 - INFO - Epoch 113/1000 - Train Loss: 0.393023, Val Loss: 0.402688
2025-08-15 19:00:55,133 - INFO - Epoch 114/1000 - Train Loss: 0.392461, Val Loss: 0.428565
2025-08-15 19:03:04,481 - INFO - Epoch 115/1000 - Train Loss: 0.391935, Val Loss: 0.399744
2025-08-15 19:05:14,010 - INFO - Epoch 116/1000 - Train Loss: 0.390394, Val Loss: 0.402626
2025-08-15 19:07:23,322 - INFO - Epoch 117/1000 - Train Loss: 0.387276, Val Loss: 0.405462
2025-08-15 19:09:32,930 - INFO - Epoch 118/1000 - Train Loss: 0.386152, Val Loss: 0.398537
2025-08-15 19:11:42,107 - INFO - Epoch 119/1000 - Train Loss: 0.388566, Val Loss: 0.403210
2025-08-15 19:13:51,829 - INFO - Epoch 120/1000 - Train Loss: 0.388612, Val Loss: 0.396902
2025-08-15 19:13:51,899 - INFO - New best model saved with Val Loss: 0.396902
2025-08-15 19:16:01,937 - INFO - Epoch 121/1000 - Train Loss: 0.386451, Val Loss: 0.398271
2025-08-15 19:18:11,264 - INFO - Epoch 122/1000 - Train Loss: 0.389630, Val Loss: 0.398627
2025-08-15 19:20:20,808 - INFO - Epoch 123/1000 - Train Loss: 0.389052, Val Loss: 0.405601
2025-08-15 19:22:30,228 - INFO - Epoch 124/1000 - Train Loss: 0.387023, Val Loss: 0.399823
2025-08-15 19:24:39,893 - INFO - Epoch 125/1000 - Train Loss: 0.384805, Val Loss: 0.415988
2025-08-15 19:26:49,394 - INFO - Epoch 126/1000 - Train Loss: 0.383455, Val Loss: 0.408953
2025-08-15 19:28:58,932 - INFO - Epoch 127/1000 - Train Loss: 0.383263, Val Loss: 0.395408
2025-08-15 19:28:58,967 - INFO - New best model saved with Val Loss: 0.395408
2025-08-15 19:31:08,175 - INFO - Epoch 128/1000 - Train Loss: 0.383599, Val Loss: 0.422478
2025-08-15 19:33:17,392 - INFO - Epoch 129/1000 - Train Loss: 0.386555, Val Loss: 0.392718
2025-08-15 19:33:17,444 - INFO - New best model saved with Val Loss: 0.392718
2025-08-15 19:35:26,917 - INFO - Epoch 130/1000 - Train Loss: 0.380673, Val Loss: 0.395000
2025-08-15 19:37:36,116 - INFO - Epoch 131/1000 - Train Loss: 0.384188, Val Loss: 0.398167
2025-08-15 19:39:45,511 - INFO - Epoch 132/1000 - Train Loss: 0.384984, Val Loss: 0.400497
2025-08-15 19:41:54,715 - INFO - Epoch 133/1000 - Train Loss: 0.382609, Val Loss: 0.404070
2025-08-15 19:44:04,056 - INFO - Epoch 134/1000 - Train Loss: 0.385631, Val Loss: 0.397809
2025-08-15 19:46:13,487 - INFO - Epoch 135/1000 - Train Loss: 0.384691, Val Loss: 0.391575
2025-08-15 19:46:13,523 - INFO - New best model saved with Val Loss: 0.391575
2025-08-15 19:48:22,713 - INFO - Epoch 136/1000 - Train Loss: 0.383119, Val Loss: 0.394351
2025-08-15 19:50:32,287 - INFO - Epoch 137/1000 - Train Loss: 0.380001, Val Loss: 0.396122
2025-08-15 19:52:41,824 - INFO - Epoch 138/1000 - Train Loss: 0.379587, Val Loss: 0.397067
2025-08-15 19:54:51,121 - INFO - Epoch 139/1000 - Train Loss: 0.379743, Val Loss: 0.398014
2025-08-15 19:57:00,423 - INFO - Epoch 140/1000 - Train Loss: 0.379218, Val Loss: 0.398119
2025-08-15 19:59:10,454 - INFO - Epoch 141/1000 - Train Loss: 0.379770, Val Loss: 0.405607
2025-08-15 20:01:19,527 - INFO - Epoch 142/1000 - Train Loss: 0.380646, Val Loss: 0.388721
2025-08-15 20:01:19,562 - INFO - New best model saved with Val Loss: 0.388721
2025-08-15 20:03:28,533 - INFO - Epoch 143/1000 - Train Loss: 0.378493, Val Loss: 0.398411
2025-08-15 20:05:37,847 - INFO - Epoch 144/1000 - Train Loss: 0.375584, Val Loss: 0.389316
2025-08-15 20:07:47,198 - INFO - Epoch 145/1000 - Train Loss: 0.376612, Val Loss: 0.397808
2025-08-15 20:09:57,202 - INFO - Epoch 146/1000 - Train Loss: 0.378972, Val Loss: 0.386248
2025-08-15 20:09:57,237 - INFO - New best model saved with Val Loss: 0.386248
2025-08-15 20:12:06,813 - INFO - Epoch 147/1000 - Train Loss: 0.376828, Val Loss: 0.385332
2025-08-15 20:12:06,859 - INFO - New best model saved with Val Loss: 0.385332
2025-08-15 20:14:15,978 - INFO - Epoch 148/1000 - Train Loss: 0.374883, Val Loss: 0.389809
2025-08-15 20:16:25,317 - INFO - Epoch 149/1000 - Train Loss: 0.376184, Val Loss: 0.396006
2025-08-15 20:18:34,498 - INFO - Epoch 150/1000 - Train Loss: 0.377857, Val Loss: 0.403778
2025-08-15 20:20:43,887 - INFO - Epoch 151/1000 - Train Loss: 0.377261, Val Loss: 0.392484
2025-08-15 20:22:53,583 - INFO - Epoch 152/1000 - Train Loss: 0.373514, Val Loss: 0.384211
2025-08-15 20:22:53,618 - INFO - New best model saved with Val Loss: 0.384211
2025-08-15 20:25:03,051 - INFO - Epoch 153/1000 - Train Loss: 0.373345, Val Loss: 0.393886
2025-08-15 20:27:12,181 - INFO - Epoch 154/1000 - Train Loss: 0.376419, Val Loss: 0.383398
2025-08-15 20:27:12,215 - INFO - New best model saved with Val Loss: 0.383398
2025-08-15 20:29:21,622 - INFO - Epoch 155/1000 - Train Loss: 0.374716, Val Loss: 0.386027
2025-08-15 20:31:31,002 - INFO - Epoch 156/1000 - Train Loss: 0.373727, Val Loss: 0.395222
2025-08-15 20:33:40,543 - INFO - Epoch 157/1000 - Train Loss: 0.371389, Val Loss: 0.379989
2025-08-15 20:33:40,578 - INFO - New best model saved with Val Loss: 0.379989
2025-08-15 20:35:49,989 - INFO - Epoch 158/1000 - Train Loss: 0.370843, Val Loss: 0.410057
2025-08-15 20:37:59,448 - INFO - Epoch 159/1000 - Train Loss: 0.369587, Val Loss: 0.392528
2025-08-15 20:40:08,937 - INFO - Epoch 160/1000 - Train Loss: 0.371411, Val Loss: 0.393278
2025-08-15 20:42:18,633 - INFO - Epoch 161/1000 - Train Loss: 0.371119, Val Loss: 0.386212
2025-08-15 20:44:27,785 - INFO - Epoch 162/1000 - Train Loss: 0.370250, Val Loss: 0.391394
2025-08-15 20:46:37,490 - INFO - Epoch 163/1000 - Train Loss: 0.368808, Val Loss: 0.383856
2025-08-15 20:48:47,278 - INFO - Epoch 164/1000 - Train Loss: 0.368441, Val Loss: 0.392335
2025-08-15 20:50:56,593 - INFO - Epoch 165/1000 - Train Loss: 0.370799, Val Loss: 0.404751
2025-08-15 20:53:06,102 - INFO - Epoch 166/1000 - Train Loss: 0.373489, Val Loss: 0.392870
2025-08-15 20:55:15,546 - INFO - Epoch 167/1000 - Train Loss: 0.367504, Val Loss: 0.382223
2025-08-15 20:57:24,648 - INFO - Epoch 168/1000 - Train Loss: 0.368907, Val Loss: 0.379716
2025-08-15 20:57:24,684 - INFO - New best model saved with Val Loss: 0.379716
2025-08-15 20:59:34,292 - INFO - Epoch 169/1000 - Train Loss: 0.366180, Val Loss: 0.377213
2025-08-15 20:59:34,326 - INFO - New best model saved with Val Loss: 0.377213
2025-08-15 21:01:43,557 - INFO - Epoch 170/1000 - Train Loss: 0.366607, Val Loss: 0.384058
2025-08-15 21:03:53,026 - INFO - Epoch 171/1000 - Train Loss: 0.365427, Val Loss: 0.387471
2025-08-15 21:06:02,086 - INFO - Epoch 172/1000 - Train Loss: 0.366498, Val Loss: 0.381041
2025-08-15 21:08:11,276 - INFO - Epoch 173/1000 - Train Loss: 0.367206, Val Loss: 0.375143
2025-08-15 21:08:11,311 - INFO - New best model saved with Val Loss: 0.375143
2025-08-15 21:10:20,601 - INFO - Epoch 174/1000 - Train Loss: 0.362379, Val Loss: 0.385797
2025-08-15 21:12:30,197 - INFO - Epoch 175/1000 - Train Loss: 0.365352, Val Loss: 0.379934
2025-08-15 21:14:39,544 - INFO - Epoch 176/1000 - Train Loss: 0.362179, Val Loss: 0.375936
2025-08-15 21:16:48,985 - INFO - Epoch 177/1000 - Train Loss: 0.364800, Val Loss: 0.386313
2025-08-15 21:18:58,511 - INFO - Epoch 178/1000 - Train Loss: 0.363434, Val Loss: 0.385398
2025-08-15 21:21:07,645 - INFO - Epoch 179/1000 - Train Loss: 0.361741, Val Loss: 0.382437
2025-08-15 21:23:17,140 - INFO - Epoch 180/1000 - Train Loss: 0.359199, Val Loss: 0.385024
2025-08-15 21:25:26,419 - INFO - Epoch 181/1000 - Train Loss: 0.361527, Val Loss: 0.380285
2025-08-15 21:27:35,492 - INFO - Epoch 182/1000 - Train Loss: 0.364855, Val Loss: 0.376806
2025-08-15 21:29:44,510 - INFO - Epoch 183/1000 - Train Loss: 0.363199, Val Loss: 0.385382
2025-08-15 21:31:53,750 - INFO - Epoch 184/1000 - Train Loss: 0.359083, Val Loss: 0.378885
2025-08-15 21:34:03,266 - INFO - Epoch 185/1000 - Train Loss: 0.358055, Val Loss: 0.387123
2025-08-15 21:36:12,726 - INFO - Epoch 186/1000 - Train Loss: 0.357913, Val Loss: 0.373677
2025-08-15 21:36:12,782 - INFO - New best model saved with Val Loss: 0.373677
2025-08-15 21:38:22,291 - INFO - Epoch 187/1000 - Train Loss: 0.358576, Val Loss: 0.387916
2025-08-15 21:40:31,658 - INFO - Epoch 188/1000 - Train Loss: 0.357192, Val Loss: 0.385665
2025-08-15 21:42:41,088 - INFO - Epoch 189/1000 - Train Loss: 0.356565, Val Loss: 0.378487
2025-08-15 21:44:50,735 - INFO - Epoch 190/1000 - Train Loss: 0.357096, Val Loss: 0.391294
2025-08-15 21:47:00,529 - INFO - Epoch 191/1000 - Train Loss: 0.356734, Val Loss: 0.379139
2025-08-15 21:49:10,479 - INFO - Epoch 192/1000 - Train Loss: 0.355556, Val Loss: 0.375662
2025-08-15 21:51:19,900 - INFO - Epoch 193/1000 - Train Loss: 0.357322, Val Loss: 0.385126
2025-08-15 21:53:29,136 - INFO - Epoch 194/1000 - Train Loss: 0.353995, Val Loss: 0.368809
2025-08-15 21:53:29,171 - INFO - New best model saved with Val Loss: 0.368809
2025-08-15 21:55:38,635 - INFO - Epoch 195/1000 - Train Loss: 0.355491, Val Loss: 0.374876
2025-08-15 21:57:47,789 - INFO - Epoch 196/1000 - Train Loss: 0.352812, Val Loss: 0.378413
2025-08-15 21:59:57,615 - INFO - Epoch 197/1000 - Train Loss: 0.352602, Val Loss: 0.365797
2025-08-15 21:59:57,651 - INFO - New best model saved with Val Loss: 0.365797
2025-08-15 22:02:07,284 - INFO - Epoch 198/1000 - Train Loss: 0.352454, Val Loss: 0.368095
2025-08-15 22:04:16,830 - INFO - Epoch 199/1000 - Train Loss: 0.352806, Val Loss: 0.363637
2025-08-15 22:04:16,865 - INFO - New best model saved with Val Loss: 0.363637
2025-08-15 22:06:26,650 - INFO - Epoch 200/1000 - Train Loss: 0.351533, Val Loss: 0.370833
2025-08-15 22:08:36,087 - INFO - Epoch 201/1000 - Train Loss: 0.351263, Val Loss: 0.367436
2025-08-15 22:10:45,585 - INFO - Epoch 202/1000 - Train Loss: 0.351022, Val Loss: 0.375827
2025-08-15 22:12:55,078 - INFO - Epoch 203/1000 - Train Loss: 0.350189, Val Loss: 0.366549
2025-08-15 22:15:04,586 - INFO - Epoch 204/1000 - Train Loss: 0.348571, Val Loss: 0.378953
2025-08-15 22:17:13,908 - INFO - Epoch 205/1000 - Train Loss: 0.347964, Val Loss: 0.368552
2025-08-15 22:19:23,624 - INFO - Epoch 206/1000 - Train Loss: 0.348595, Val Loss: 0.381870
2025-08-15 22:21:33,750 - INFO - Epoch 207/1000 - Train Loss: 0.351558, Val Loss: 0.365405
2025-08-15 22:23:43,104 - INFO - Epoch 208/1000 - Train Loss: 0.347984, Val Loss: 0.400949
2025-08-15 22:25:52,441 - INFO - Epoch 209/1000 - Train Loss: 0.349232, Val Loss: 0.374059
2025-08-15 22:28:01,916 - INFO - Epoch 210/1000 - Train Loss: 0.348067, Val Loss: 0.372159
2025-08-15 22:30:11,572 - INFO - Epoch 211/1000 - Train Loss: 0.348757, Val Loss: 0.376116
2025-08-15 22:32:20,792 - INFO - Epoch 212/1000 - Train Loss: 0.346088, Val Loss: 0.369179
2025-08-15 22:34:29,754 - INFO - Epoch 213/1000 - Train Loss: 0.348316, Val Loss: 0.375306
2025-08-15 22:36:38,947 - INFO - Epoch 214/1000 - Train Loss: 0.347684, Val Loss: 0.368808
2025-08-15 22:38:47,919 - INFO - Epoch 215/1000 - Train Loss: 0.348961, Val Loss: 0.364650
2025-08-15 22:40:56,987 - INFO - Epoch 216/1000 - Train Loss: 0.347560, Val Loss: 0.393608
2025-08-15 22:43:06,302 - INFO - Epoch 217/1000 - Train Loss: 0.346308, Val Loss: 0.372629
2025-08-15 22:45:15,592 - INFO - Epoch 218/1000 - Train Loss: 0.341945, Val Loss: 0.375026
2025-08-15 22:47:24,757 - INFO - Epoch 219/1000 - Train Loss: 0.342277, Val Loss: 0.381006
2025-08-15 22:49:34,109 - INFO - Epoch 220/1000 - Train Loss: 0.343497, Val Loss: 0.357888
2025-08-15 22:49:34,178 - INFO - New best model saved with Val Loss: 0.357888
2025-08-15 22:51:44,106 - INFO - Epoch 221/1000 - Train Loss: 0.346452, Val Loss: 0.378278
2025-08-15 22:53:53,513 - INFO - Epoch 222/1000 - Train Loss: 0.343630, Val Loss: 0.384882
2025-08-15 22:56:02,872 - INFO - Epoch 223/1000 - Train Loss: 0.341520, Val Loss: 0.361373
2025-08-15 22:58:12,170 - INFO - Epoch 224/1000 - Train Loss: 0.340437, Val Loss: 0.367152
2025-08-15 23:00:21,465 - INFO - Epoch 225/1000 - Train Loss: 0.342573, Val Loss: 0.372447
2025-08-15 23:02:30,640 - INFO - Epoch 226/1000 - Train Loss: 0.344343, Val Loss: 0.378750
2025-08-15 23:04:40,097 - INFO - Epoch 227/1000 - Train Loss: 0.343006, Val Loss: 0.376196
2025-08-15 23:06:49,500 - INFO - Epoch 228/1000 - Train Loss: 0.343126, Val Loss: 0.369272
2025-08-15 23:08:58,954 - INFO - Epoch 229/1000 - Train Loss: 0.343783, Val Loss: 0.376331
2025-08-15 23:11:08,007 - INFO - Epoch 230/1000 - Train Loss: 0.341821, Val Loss: 0.362804
2025-08-15 23:13:17,532 - INFO - Epoch 231/1000 - Train Loss: 0.342382, Val Loss: 0.370750
2025-08-15 23:15:26,787 - INFO - Epoch 232/1000 - Train Loss: 0.340249, Val Loss: 0.370163
2025-08-15 23:17:36,138 - INFO - Epoch 233/1000 - Train Loss: 0.341412, Val Loss: 0.373756
2025-08-15 23:19:45,332 - INFO - Epoch 234/1000 - Train Loss: 0.340712, Val Loss: 0.364166
2025-08-15 23:21:54,603 - INFO - Epoch 235/1000 - Train Loss: 0.340941, Val Loss: 0.357332
2025-08-15 23:21:54,641 - INFO - New best model saved with Val Loss: 0.357332
2025-08-15 23:24:03,827 - INFO - Epoch 236/1000 - Train Loss: 0.341696, Val Loss: 0.363492
2025-08-15 23:26:13,053 - INFO - Epoch 237/1000 - Train Loss: 0.338510, Val Loss: 0.356352
2025-08-15 23:26:13,088 - INFO - New best model saved with Val Loss: 0.356352
2025-08-15 23:28:22,300 - INFO - Epoch 238/1000 - Train Loss: 0.341430, Val Loss: 0.389783
2025-08-15 23:30:31,512 - INFO - Epoch 239/1000 - Train Loss: 0.337799, Val Loss: 0.368427
2025-08-15 23:32:40,759 - INFO - Epoch 240/1000 - Train Loss: 0.338166, Val Loss: 0.360934
2025-08-15 23:34:50,136 - INFO - Epoch 241/1000 - Train Loss: 0.338130, Val Loss: 0.360477
2025-08-15 23:36:59,505 - INFO - Epoch 242/1000 - Train Loss: 0.337166, Val Loss: 0.376150
2025-08-15 23:39:08,679 - INFO - Epoch 243/1000 - Train Loss: 0.337109, Val Loss: 0.365406
2025-08-15 23:41:18,192 - INFO - Epoch 244/1000 - Train Loss: 0.338489, Val Loss: 0.356781
2025-08-15 23:43:27,459 - INFO - Epoch 245/1000 - Train Loss: 0.338562, Val Loss: 0.366313
2025-08-15 23:45:36,698 - INFO - Epoch 246/1000 - Train Loss: 0.336608, Val Loss: 0.358881
2025-08-15 23:47:45,908 - INFO - Epoch 247/1000 - Train Loss: 0.335311, Val Loss: 0.365639
2025-08-15 23:49:55,006 - INFO - Epoch 248/1000 - Train Loss: 0.337086, Val Loss: 0.383786
2025-08-15 23:52:04,428 - INFO - Epoch 249/1000 - Train Loss: 0.334866, Val Loss: 0.366344
2025-08-15 23:54:14,032 - INFO - Epoch 250/1000 - Train Loss: 0.334875, Val Loss: 0.362615
2025-08-15 23:56:23,553 - INFO - Epoch 251/1000 - Train Loss: 0.335426, Val Loss: 0.366588
2025-08-15 23:58:32,845 - INFO - Epoch 252/1000 - Train Loss: 0.341471, Val Loss: 0.404886
2025-08-16 00:00:42,236 - INFO - Epoch 253/1000 - Train Loss: 0.340736, Val Loss: 0.351805
2025-08-16 00:00:42,296 - INFO - New best model saved with Val Loss: 0.351805
2025-08-16 00:02:51,757 - INFO - Epoch 254/1000 - Train Loss: 0.338044, Val Loss: 0.359059
2025-08-16 00:05:00,996 - INFO - Epoch 255/1000 - Train Loss: 0.335392, Val Loss: 0.362512
2025-08-16 00:07:10,148 - INFO - Epoch 256/1000 - Train Loss: 0.334960, Val Loss: 0.379171
2025-08-16 00:09:19,736 - INFO - Epoch 257/1000 - Train Loss: 0.333766, Val Loss: 0.369659
2025-08-16 00:11:28,900 - INFO - Epoch 258/1000 - Train Loss: 0.333844, Val Loss: 0.361777
2025-08-16 00:13:37,986 - INFO - Epoch 259/1000 - Train Loss: 0.334852, Val Loss: 0.372968
2025-08-16 00:15:47,131 - INFO - Epoch 260/1000 - Train Loss: 0.332161, Val Loss: 0.359335
2025-08-16 00:17:56,807 - INFO - Epoch 261/1000 - Train Loss: 0.335344, Val Loss: 0.357809
2025-08-16 00:20:06,340 - INFO - Epoch 262/1000 - Train Loss: 0.332209, Val Loss: 0.371452
2025-08-16 00:22:15,619 - INFO - Epoch 263/1000 - Train Loss: 0.330370, Val Loss: 0.375959
2025-08-16 00:24:24,810 - INFO - Epoch 264/1000 - Train Loss: 0.336319, Val Loss: 0.363092
2025-08-16 00:26:34,038 - INFO - Epoch 265/1000 - Train Loss: 0.333897, Val Loss: 0.363756
2025-08-16 00:28:43,183 - INFO - Epoch 266/1000 - Train Loss: 0.335207, Val Loss: 0.362685
2025-08-16 00:30:52,442 - INFO - Epoch 267/1000 - Train Loss: 0.332442, Val Loss: 0.375774
2025-08-16 00:33:01,584 - INFO - Epoch 268/1000 - Train Loss: 0.332243, Val Loss: 0.368053
2025-08-16 00:35:10,446 - INFO - Epoch 269/1000 - Train Loss: 0.330840, Val Loss: 0.356620
2025-08-16 00:37:20,033 - INFO - Epoch 270/1000 - Train Loss: 0.328665, Val Loss: 0.379375
2025-08-16 00:39:35,641 - INFO - Epoch 271/1000 - Train Loss: 0.329857, Val Loss: 0.352942
2025-08-16 00:41:51,682 - INFO - Epoch 272/1000 - Train Loss: 0.330522, Val Loss: 0.370871
2025-08-16 00:44:07,540 - INFO - Epoch 273/1000 - Train Loss: 0.328747, Val Loss: 0.355903
2025-08-16 00:46:22,952 - INFO - Epoch 274/1000 - Train Loss: 0.330113, Val Loss: 0.353439
2025-08-16 00:48:38,937 - INFO - Epoch 275/1000 - Train Loss: 0.331774, Val Loss: 0.364111
2025-08-16 00:50:54,610 - INFO - Epoch 276/1000 - Train Loss: 0.329908, Val Loss: 0.353829
2025-08-16 00:53:09,617 - INFO - Epoch 277/1000 - Train Loss: 0.327949, Val Loss: 0.344314
2025-08-16 00:53:09,672 - INFO - New best model saved with Val Loss: 0.344314
2025-08-16 00:55:25,406 - INFO - Epoch 278/1000 - Train Loss: 0.326114, Val Loss: 0.346611
2025-08-16 00:57:41,901 - INFO - Epoch 279/1000 - Train Loss: 0.328145, Val Loss: 0.360737
2025-08-16 00:59:58,529 - INFO - Epoch 280/1000 - Train Loss: 0.326977, Val Loss: 0.360933
2025-08-16 01:02:15,149 - INFO - Epoch 281/1000 - Train Loss: 0.329226, Val Loss: 0.355837
2025-08-16 01:04:32,336 - INFO - Epoch 282/1000 - Train Loss: 0.327918, Val Loss: 0.359416
2025-08-16 01:06:48,657 - INFO - Epoch 283/1000 - Train Loss: 0.329768, Val Loss: 0.356637
2025-08-16 01:09:05,741 - INFO - Epoch 284/1000 - Train Loss: 0.326656, Val Loss: 0.357912
2025-08-16 01:11:21,123 - INFO - Epoch 285/1000 - Train Loss: 0.330791, Val Loss: 0.361563
2025-08-16 01:13:38,025 - INFO - Epoch 286/1000 - Train Loss: 0.327198, Val Loss: 0.356686
2025-08-16 01:15:54,699 - INFO - Epoch 287/1000 - Train Loss: 0.324834, Val Loss: 0.357602
2025-08-16 01:18:12,084 - INFO - Epoch 288/1000 - Train Loss: 0.328797, Val Loss: 0.358979
2025-08-16 01:20:27,892 - INFO - Epoch 289/1000 - Train Loss: 0.328394, Val Loss: 0.356049
2025-08-16 01:22:44,224 - INFO - Epoch 290/1000 - Train Loss: 0.330577, Val Loss: 0.365396
2025-08-16 01:25:00,481 - INFO - Epoch 291/1000 - Train Loss: 0.326170, Val Loss: 0.362672
2025-08-16 01:27:17,554 - INFO - Epoch 292/1000 - Train Loss: 0.326188, Val Loss: 0.360476
2025-08-16 01:29:35,715 - INFO - Epoch 293/1000 - Train Loss: 0.325830, Val Loss: 0.378403
2025-08-16 01:31:50,468 - INFO - Epoch 294/1000 - Train Loss: 0.325815, Val Loss: 0.341845
2025-08-16 01:31:50,540 - INFO - New best model saved with Val Loss: 0.341845
2025-08-16 01:34:05,419 - INFO - Epoch 295/1000 - Train Loss: 0.324658, Val Loss: 0.349444
2025-08-16 01:36:19,944 - INFO - Epoch 296/1000 - Train Loss: 0.325175, Val Loss: 0.357456
2025-08-16 01:38:36,853 - INFO - Epoch 297/1000 - Train Loss: 0.324493, Val Loss: 0.377338
2025-08-16 01:40:52,321 - INFO - Epoch 298/1000 - Train Loss: 0.323571, Val Loss: 0.350014
2025-08-16 01:43:03,846 - INFO - Epoch 299/1000 - Train Loss: 0.321608, Val Loss: 0.353899
2025-08-16 01:45:15,020 - INFO - Epoch 300/1000 - Train Loss: 0.322751, Val Loss: 0.360738
2025-08-16 01:47:27,457 - INFO - Epoch 301/1000 - Train Loss: 0.328272, Val Loss: 0.370782
2025-08-16 01:49:39,761 - INFO - Epoch 302/1000 - Train Loss: 0.325203, Val Loss: 0.349013
2025-08-16 01:51:50,472 - INFO - Epoch 303/1000 - Train Loss: 0.321129, Val Loss: 0.347142
2025-08-16 01:54:00,810 - INFO - Epoch 304/1000 - Train Loss: 0.321627, Val Loss: 0.346781
2025-08-16 01:56:10,361 - INFO - Epoch 305/1000 - Train Loss: 0.319952, Val Loss: 0.355613
2025-08-16 01:58:20,208 - INFO - Epoch 306/1000 - Train Loss: 0.319789, Val Loss: 0.347679
2025-08-16 02:00:29,565 - INFO - Epoch 307/1000 - Train Loss: 0.317911, Val Loss: 0.358726
2025-08-16 02:02:38,641 - INFO - Epoch 308/1000 - Train Loss: 0.319228, Val Loss: 0.355126
2025-08-16 02:04:48,425 - INFO - Epoch 309/1000 - Train Loss: 0.319952, Val Loss: 0.355967
2025-08-16 02:06:57,494 - INFO - Epoch 310/1000 - Train Loss: 0.321671, Val Loss: 0.356260
2025-08-16 02:09:06,898 - INFO - Epoch 311/1000 - Train Loss: 0.323105, Val Loss: 0.347989
2025-08-16 02:11:16,276 - INFO - Epoch 312/1000 - Train Loss: 0.319764, Val Loss: 0.366502
2025-08-16 02:13:26,135 - INFO - Epoch 313/1000 - Train Loss: 0.321377, Val Loss: 0.367419
2025-08-16 02:15:35,987 - INFO - Epoch 314/1000 - Train Loss: 0.320444, Val Loss: 0.363568
2025-08-16 02:17:45,382 - INFO - Epoch 315/1000 - Train Loss: 0.320134, Val Loss: 0.345356
2025-08-16 02:19:54,765 - INFO - Epoch 316/1000 - Train Loss: 0.320183, Val Loss: 0.353597
2025-08-16 02:22:04,381 - INFO - Epoch 317/1000 - Train Loss: 0.319884, Val Loss: 0.353394
2025-08-16 02:24:13,533 - INFO - Epoch 318/1000 - Train Loss: 0.317942, Val Loss: 0.347637
2025-08-16 02:26:22,649 - INFO - Epoch 319/1000 - Train Loss: 0.317025, Val Loss: 0.349280
2025-08-16 02:28:31,707 - INFO - Epoch 320/1000 - Train Loss: 0.320102, Val Loss: 0.373247
2025-08-16 02:30:40,984 - INFO - Epoch 321/1000 - Train Loss: 0.317652, Val Loss: 0.355151
2025-08-16 02:32:49,946 - INFO - Epoch 322/1000 - Train Loss: 0.320296, Val Loss: 0.348768
2025-08-16 02:34:59,461 - INFO - Epoch 323/1000 - Train Loss: 0.319561, Val Loss: 0.347161
2025-08-16 02:37:08,623 - INFO - Epoch 324/1000 - Train Loss: 0.315703, Val Loss: 0.345284
2025-08-16 02:39:18,113 - INFO - Epoch 325/1000 - Train Loss: 0.315819, Val Loss: 0.344369
2025-08-16 02:41:27,029 - INFO - Epoch 326/1000 - Train Loss: 0.316754, Val Loss: 0.340516
2025-08-16 02:41:27,101 - INFO - New best model saved with Val Loss: 0.340516
2025-08-16 02:43:36,356 - INFO - Epoch 327/1000 - Train Loss: 0.315343, Val Loss: 0.345844
2025-08-16 02:45:45,514 - INFO - Epoch 328/1000 - Train Loss: 0.316593, Val Loss: 0.348324
2025-08-16 02:47:54,729 - INFO - Epoch 329/1000 - Train Loss: 0.313378, Val Loss: 0.367883
2025-08-16 02:50:03,689 - INFO - Epoch 330/1000 - Train Loss: 0.317904, Val Loss: 0.360386
2025-08-16 02:52:15,036 - INFO - Epoch 331/1000 - Train Loss: 0.315085, Val Loss: 0.359102
2025-08-16 02:54:24,042 - INFO - Epoch 332/1000 - Train Loss: 0.316794, Val Loss: 0.349547
2025-08-16 02:56:33,386 - INFO - Epoch 333/1000 - Train Loss: 0.315215, Val Loss: 0.347028
2025-08-16 02:58:42,726 - INFO - Epoch 334/1000 - Train Loss: 0.313492, Val Loss: 0.356419
2025-08-16 03:00:52,647 - INFO - Epoch 335/1000 - Train Loss: 0.316075, Val Loss: 0.352449
2025-08-16 03:03:01,963 - INFO - Epoch 336/1000 - Train Loss: 0.314411, Val Loss: 0.348596
2025-08-16 03:05:11,202 - INFO - Epoch 337/1000 - Train Loss: 0.313944, Val Loss: 0.345104
2025-08-16 03:07:21,028 - INFO - Epoch 338/1000 - Train Loss: 0.313084, Val Loss: 0.364162
2025-08-16 03:09:30,172 - INFO - Epoch 339/1000 - Train Loss: 0.313744, Val Loss: 0.352147
2025-08-16 03:11:39,211 - INFO - Epoch 340/1000 - Train Loss: 0.313839, Val Loss: 0.344513
2025-08-16 03:13:48,414 - INFO - Epoch 341/1000 - Train Loss: 0.311132, Val Loss: 0.347404
2025-08-16 03:15:57,419 - INFO - Epoch 342/1000 - Train Loss: 0.313861, Val Loss: 0.355159
2025-08-16 03:18:06,725 - INFO - Epoch 343/1000 - Train Loss: 0.313450, Val Loss: 0.351434
2025-08-16 03:20:15,745 - INFO - Epoch 344/1000 - Train Loss: 0.314033, Val Loss: 0.366565
2025-08-16 03:22:24,837 - INFO - Epoch 345/1000 - Train Loss: 0.311923, Val Loss: 0.345262
2025-08-16 03:24:33,957 - INFO - Epoch 346/1000 - Train Loss: 0.312335, Val Loss: 0.353917
2025-08-16 03:26:42,949 - INFO - Epoch 347/1000 - Train Loss: 0.316203, Val Loss: 0.341193
2025-08-16 03:28:51,866 - INFO - Epoch 348/1000 - Train Loss: 0.314239, Val Loss: 0.356688
2025-08-16 03:31:00,943 - INFO - Epoch 349/1000 - Train Loss: 0.311856, Val Loss: 0.343987
2025-08-16 03:33:10,025 - INFO - Epoch 350/1000 - Train Loss: 0.313892, Val Loss: 0.347840
2025-08-16 03:35:19,341 - INFO - Epoch 351/1000 - Train Loss: 0.310568, Val Loss: 0.338005
2025-08-16 03:35:19,417 - INFO - New best model saved with Val Loss: 0.338005
2025-08-16 03:37:28,616 - INFO - Epoch 352/1000 - Train Loss: 0.310853, Val Loss: 0.345451
2025-08-16 03:39:38,010 - INFO - Epoch 353/1000 - Train Loss: 0.312905, Val Loss: 0.352976
2025-08-16 03:41:47,431 - INFO - Epoch 354/1000 - Train Loss: 0.311627, Val Loss: 0.347242
2025-08-16 03:43:56,668 - INFO - Epoch 355/1000 - Train Loss: 0.310794, Val Loss: 0.336041
2025-08-16 03:43:56,727 - INFO - New best model saved with Val Loss: 0.336041
2025-08-16 03:46:06,376 - INFO - Epoch 356/1000 - Train Loss: 0.308596, Val Loss: 0.343782
2025-08-16 03:48:15,864 - INFO - Epoch 357/1000 - Train Loss: 0.310305, Val Loss: 0.352040
2025-08-16 03:50:25,423 - INFO - Epoch 358/1000 - Train Loss: 0.310111, Val Loss: 0.339958
2025-08-16 03:52:34,504 - INFO - Epoch 359/1000 - Train Loss: 0.309336, Val Loss: 0.345002
2025-08-16 03:54:43,568 - INFO - Epoch 360/1000 - Train Loss: 0.313044, Val Loss: 0.346001
2025-08-16 03:56:52,840 - INFO - Epoch 361/1000 - Train Loss: 0.308949, Val Loss: 0.343357
2025-08-16 03:59:01,760 - INFO - Epoch 362/1000 - Train Loss: 0.308933, Val Loss: 0.362929
2025-08-16 04:01:10,664 - INFO - Epoch 363/1000 - Train Loss: 0.313626, Val Loss: 0.350332
2025-08-16 04:03:19,638 - INFO - Epoch 364/1000 - Train Loss: 0.309868, Val Loss: 0.337651
2025-08-16 04:05:28,561 - INFO - Epoch 365/1000 - Train Loss: 0.309821, Val Loss: 0.345838
2025-08-16 04:07:37,767 - INFO - Epoch 366/1000 - Train Loss: 0.310119, Val Loss: 0.341046
2025-08-16 04:09:46,840 - INFO - Epoch 367/1000 - Train Loss: 0.311342, Val Loss: 0.354405
2025-08-16 04:11:56,143 - INFO - Epoch 368/1000 - Train Loss: 0.310084, Val Loss: 0.343662
2025-08-16 04:14:05,066 - INFO - Epoch 369/1000 - Train Loss: 0.305697, Val Loss: 0.352983
2025-08-16 04:16:14,003 - INFO - Epoch 370/1000 - Train Loss: 0.305272, Val Loss: 0.348078
2025-08-16 04:18:23,247 - INFO - Epoch 371/1000 - Train Loss: 0.307944, Val Loss: 0.351923
2025-08-16 04:20:32,348 - INFO - Epoch 372/1000 - Train Loss: 0.307809, Val Loss: 0.358557
2025-08-16 04:22:41,873 - INFO - Epoch 373/1000 - Train Loss: 0.306653, Val Loss: 0.344669
2025-08-16 04:24:51,473 - INFO - Epoch 374/1000 - Train Loss: 0.304823, Val Loss: 0.348317
2025-08-16 04:27:00,531 - INFO - Epoch 375/1000 - Train Loss: 0.308687, Val Loss: 0.337730
2025-08-16 04:29:09,586 - INFO - Epoch 376/1000 - Train Loss: 0.306330, Val Loss: 0.357918
2025-08-16 04:31:18,647 - INFO - Epoch 377/1000 - Train Loss: 0.310821, Val Loss: 0.342933
2025-08-16 04:33:27,799 - INFO - Epoch 378/1000 - Train Loss: 0.308751, Val Loss: 0.340247
2025-08-16 04:35:37,017 - INFO - Epoch 379/1000 - Train Loss: 0.307152, Val Loss: 0.346597
2025-08-16 04:37:46,448 - INFO - Epoch 380/1000 - Train Loss: 0.305701, Val Loss: 0.338739
2025-08-16 04:39:56,047 - INFO - Epoch 381/1000 - Train Loss: 0.305408, Val Loss: 0.340910
2025-08-16 04:42:05,207 - INFO - Epoch 382/1000 - Train Loss: 0.308706, Val Loss: 0.342896
2025-08-16 04:44:14,176 - INFO - Epoch 383/1000 - Train Loss: 0.305514, Val Loss: 0.343757
2025-08-16 04:46:23,486 - INFO - Epoch 384/1000 - Train Loss: 0.304897, Val Loss: 0.340002
2025-08-16 04:48:32,446 - INFO - Epoch 385/1000 - Train Loss: 0.303252, Val Loss: 0.373630
2025-08-16 04:50:41,535 - INFO - Epoch 386/1000 - Train Loss: 0.304551, Val Loss: 0.343973
2025-08-16 04:52:50,644 - INFO - Epoch 387/1000 - Train Loss: 0.303789, Val Loss: 0.340668
2025-08-16 04:54:59,464 - INFO - Epoch 388/1000 - Train Loss: 0.304702, Val Loss: 0.347040
2025-08-16 04:57:09,034 - INFO - Epoch 389/1000 - Train Loss: 0.304172, Val Loss: 0.358572
2025-08-16 04:59:17,986 - INFO - Epoch 390/1000 - Train Loss: 0.305529, Val Loss: 0.331587
2025-08-16 04:59:18,043 - INFO - New best model saved with Val Loss: 0.331587
2025-08-16 05:01:27,136 - INFO - Epoch 391/1000 - Train Loss: 0.305122, Val Loss: 0.347990
2025-08-16 05:03:35,775 - INFO - Epoch 392/1000 - Train Loss: 0.303595, Val Loss: 0.341910
2025-08-16 05:05:44,606 - INFO - Epoch 393/1000 - Train Loss: 0.303194, Val Loss: 0.340259
2025-08-16 05:07:53,639 - INFO - Epoch 394/1000 - Train Loss: 0.302562, Val Loss: 0.345941
2025-08-16 05:10:02,450 - INFO - Epoch 395/1000 - Train Loss: 0.302521, Val Loss: 0.331423
2025-08-16 05:10:02,486 - INFO - New best model saved with Val Loss: 0.331423
2025-08-16 05:12:11,492 - INFO - Epoch 396/1000 - Train Loss: 0.303796, Val Loss: 0.340387
2025-08-16 05:14:20,141 - INFO - Epoch 397/1000 - Train Loss: 0.301993, Val Loss: 0.343226
2025-08-16 05:16:28,910 - INFO - Epoch 398/1000 - Train Loss: 0.302282, Val Loss: 0.355375
2025-08-16 05:18:37,611 - INFO - Epoch 399/1000 - Train Loss: 0.302741, Val Loss: 0.350918
2025-08-16 05:20:46,500 - INFO - Epoch 400/1000 - Train Loss: 0.302103, Val Loss: 0.345989
2025-08-16 05:22:55,693 - INFO - Epoch 401/1000 - Train Loss: 0.300060, Val Loss: 0.346497
2025-08-16 05:25:04,515 - INFO - Epoch 402/1000 - Train Loss: 0.302674, Val Loss: 0.367310
2025-08-16 05:27:13,160 - INFO - Epoch 403/1000 - Train Loss: 0.304613, Val Loss: 0.343879
2025-08-16 05:29:21,972 - INFO - Epoch 404/1000 - Train Loss: 0.302910, Val Loss: 0.351734
2025-08-16 05:31:30,830 - INFO - Epoch 405/1000 - Train Loss: 0.299382, Val Loss: 0.337585
2025-08-16 05:33:39,656 - INFO - Epoch 406/1000 - Train Loss: 0.299686, Val Loss: 0.353496
2025-08-16 05:35:49,070 - INFO - Epoch 407/1000 - Train Loss: 0.300769, Val Loss: 0.336474
2025-08-16 05:37:57,979 - INFO - Epoch 408/1000 - Train Loss: 0.298497, Val Loss: 0.347613
2025-08-16 05:40:06,758 - INFO - Epoch 409/1000 - Train Loss: 0.299865, Val Loss: 0.335884
2025-08-16 05:42:15,564 - INFO - Epoch 410/1000 - Train Loss: 0.300608, Val Loss: 0.337202
2025-08-16 05:44:24,638 - INFO - Epoch 411/1000 - Train Loss: 0.299499, Val Loss: 0.336031
2025-08-16 05:46:33,255 - INFO - Epoch 412/1000 - Train Loss: 0.299227, Val Loss: 0.335855
2025-08-16 05:48:42,019 - INFO - Epoch 413/1000 - Train Loss: 0.300210, Val Loss: 0.337693
2025-08-16 05:50:50,752 - INFO - Epoch 414/1000 - Train Loss: 0.298904, Val Loss: 0.329988
2025-08-16 05:50:50,807 - INFO - New best model saved with Val Loss: 0.329988
2025-08-16 05:52:59,730 - INFO - Epoch 415/1000 - Train Loss: 0.301465, Val Loss: 0.339696
2025-08-16 05:55:08,387 - INFO - Epoch 416/1000 - Train Loss: 0.303228, Val Loss: 0.336796
2025-08-16 05:57:17,388 - INFO - Epoch 417/1000 - Train Loss: 0.297682, Val Loss: 0.340502
2025-08-16 05:59:26,099 - INFO - Epoch 418/1000 - Train Loss: 0.297564, Val Loss: 0.351448
2025-08-16 06:01:35,130 - INFO - Epoch 419/1000 - Train Loss: 0.299147, Val Loss: 0.342910
2025-08-16 06:03:44,046 - INFO - Epoch 420/1000 - Train Loss: 0.296030, Val Loss: 0.339789
2025-08-16 06:05:53,207 - INFO - Epoch 421/1000 - Train Loss: 0.295967, Val Loss: 0.351912
2025-08-16 06:08:01,945 - INFO - Epoch 422/1000 - Train Loss: 0.297424, Val Loss: 0.340764
2025-08-16 06:10:10,887 - INFO - Epoch 423/1000 - Train Loss: 0.296635, Val Loss: 0.331778
2025-08-16 06:12:19,903 - INFO - Epoch 424/1000 - Train Loss: 0.296881, Val Loss: 0.350006
2025-08-16 06:14:28,651 - INFO - Epoch 425/1000 - Train Loss: 0.300543, Val Loss: 0.341918
2025-08-16 06:16:37,454 - INFO - Epoch 426/1000 - Train Loss: 0.298514, Val Loss: 0.335671
2025-08-16 06:18:46,302 - INFO - Epoch 427/1000 - Train Loss: 0.295587, Val Loss: 0.333430
2025-08-16 06:20:55,207 - INFO - Epoch 428/1000 - Train Loss: 0.296190, Val Loss: 0.342638
2025-08-16 06:23:04,087 - INFO - Epoch 429/1000 - Train Loss: 0.298458, Val Loss: 0.350417
2025-08-16 06:25:13,278 - INFO - Epoch 430/1000 - Train Loss: 0.300619, Val Loss: 0.336113
2025-08-16 06:27:22,625 - INFO - Epoch 431/1000 - Train Loss: 0.297163, Val Loss: 0.344851
2025-08-16 06:29:31,643 - INFO - Epoch 432/1000 - Train Loss: 0.294989, Val Loss: 0.339322
2025-08-16 06:31:40,597 - INFO - Epoch 433/1000 - Train Loss: 0.294961, Val Loss: 0.331400
2025-08-16 06:33:49,508 - INFO - Epoch 434/1000 - Train Loss: 0.297110, Val Loss: 0.348721
2025-08-16 06:35:58,417 - INFO - Epoch 435/1000 - Train Loss: 0.293421, Val Loss: 0.354754
2025-08-16 06:38:07,485 - INFO - Epoch 436/1000 - Train Loss: 0.298478, Val Loss: 0.327848
2025-08-16 06:38:07,532 - INFO - New best model saved with Val Loss: 0.327848
2025-08-16 06:40:16,170 - INFO - Epoch 437/1000 - Train Loss: 0.299162, Val Loss: 0.341415
2025-08-16 06:42:24,871 - INFO - Epoch 438/1000 - Train Loss: 0.294654, Val Loss: 0.345872
2025-08-16 06:44:33,604 - INFO - Epoch 439/1000 - Train Loss: 0.291612, Val Loss: 0.342806
2025-08-16 06:46:42,695 - INFO - Epoch 440/1000 - Train Loss: 0.295234, Val Loss: 0.342007
2025-08-16 06:48:51,636 - INFO - Epoch 441/1000 - Train Loss: 0.294955, Val Loss: 0.336605
2025-08-16 06:51:00,846 - INFO - Epoch 442/1000 - Train Loss: 0.292918, Val Loss: 0.335886
2025-08-16 06:53:09,811 - INFO - Epoch 443/1000 - Train Loss: 0.294506, Val Loss: 0.338214
2025-08-16 06:55:18,648 - INFO - Epoch 444/1000 - Train Loss: 0.295448, Val Loss: 0.334170
2025-08-16 06:57:27,824 - INFO - Epoch 445/1000 - Train Loss: 0.295249, Val Loss: 0.335569
2025-08-16 06:59:36,780 - INFO - Epoch 446/1000 - Train Loss: 0.294358, Val Loss: 0.347624
2025-08-16 07:01:45,686 - INFO - Epoch 447/1000 - Train Loss: 0.294079, Val Loss: 0.350431
2025-08-16 07:03:54,501 - INFO - Epoch 448/1000 - Train Loss: 0.293594, Val Loss: 0.327956
2025-08-16 07:06:03,430 - INFO - Epoch 449/1000 - Train Loss: 0.292156, Val Loss: 0.339980
2025-08-16 07:08:12,251 - INFO - Epoch 450/1000 - Train Loss: 0.294722, Val Loss: 0.323163
2025-08-16 07:08:12,307 - INFO - New best model saved with Val Loss: 0.323163
2025-08-16 07:10:21,780 - INFO - Epoch 451/1000 - Train Loss: 0.292445, Val Loss: 0.341695
2025-08-16 07:12:31,221 - INFO - Epoch 452/1000 - Train Loss: 0.294776, Val Loss: 0.340999
2025-08-16 07:14:40,392 - INFO - Epoch 453/1000 - Train Loss: 0.290788, Val Loss: 0.335728
2025-08-16 07:16:49,617 - INFO - Epoch 454/1000 - Train Loss: 0.291563, Val Loss: 0.351211
2025-08-16 07:18:58,650 - INFO - Epoch 455/1000 - Train Loss: 0.292002, Val Loss: 0.341126
2025-08-16 07:21:07,912 - INFO - Epoch 456/1000 - Train Loss: 0.291275, Val Loss: 0.337633
2025-08-16 07:23:16,855 - INFO - Epoch 457/1000 - Train Loss: 0.291442, Val Loss: 0.348526
2025-08-16 07:25:25,712 - INFO - Epoch 458/1000 - Train Loss: 0.291805, Val Loss: 0.330619
2025-08-16 07:27:34,809 - INFO - Epoch 459/1000 - Train Loss: 0.290538, Val Loss: 0.351120
2025-08-16 07:29:43,827 - INFO - Epoch 460/1000 - Train Loss: 0.288599, Val Loss: 0.345911
2025-08-16 07:31:53,157 - INFO - Epoch 461/1000 - Train Loss: 0.289878, Val Loss: 0.340336
2025-08-16 07:34:02,417 - INFO - Epoch 462/1000 - Train Loss: 0.289523, Val Loss: 0.341174
2025-08-16 07:36:11,311 - INFO - Epoch 463/1000 - Train Loss: 0.289274, Val Loss: 0.366300
2025-08-16 07:38:20,326 - INFO - Epoch 464/1000 - Train Loss: 0.290873, Val Loss: 0.335987
2025-08-16 07:40:29,462 - INFO - Epoch 465/1000 - Train Loss: 0.290138, Val Loss: 0.343419
2025-08-16 07:42:38,795 - INFO - Epoch 466/1000 - Train Loss: 0.289361, Val Loss: 0.352246
2025-08-16 07:44:47,603 - INFO - Epoch 467/1000 - Train Loss: 0.291940, Val Loss: 0.339923
2025-08-16 07:46:56,726 - INFO - Epoch 468/1000 - Train Loss: 0.289612, Val Loss: 0.339738
2025-08-16 07:49:06,070 - INFO - Epoch 469/1000 - Train Loss: 0.291268, Val Loss: 0.333322
2025-08-16 07:51:14,963 - INFO - Epoch 470/1000 - Train Loss: 0.294049, Val Loss: 0.346082
2025-08-16 07:53:24,258 - INFO - Epoch 471/1000 - Train Loss: 0.293211, Val Loss: 0.336667
2025-08-16 07:55:33,418 - INFO - Epoch 472/1000 - Train Loss: 0.288755, Val Loss: 0.336241
2025-08-16 07:57:42,572 - INFO - Epoch 473/1000 - Train Loss: 0.290307, Val Loss: 0.326454
2025-08-16 07:59:51,486 - INFO - Epoch 474/1000 - Train Loss: 0.290190, Val Loss: 0.344736
2025-08-16 08:02:00,444 - INFO - Epoch 475/1000 - Train Loss: 0.293444, Val Loss: 0.354124
2025-08-16 08:04:09,522 - INFO - Epoch 476/1000 - Train Loss: 0.290142, Val Loss: 0.334269
2025-08-16 08:06:18,485 - INFO - Epoch 477/1000 - Train Loss: 0.286874, Val Loss: 0.340237
2025-08-16 08:08:27,292 - INFO - Epoch 478/1000 - Train Loss: 0.288428, Val Loss: 0.336381
2025-08-16 08:10:36,302 - INFO - Epoch 479/1000 - Train Loss: 0.285954, Val Loss: 0.326810
2025-08-16 08:12:45,374 - INFO - Epoch 480/1000 - Train Loss: 0.283932, Val Loss: 0.355082
2025-08-16 08:14:54,606 - INFO - Epoch 481/1000 - Train Loss: 0.288804, Val Loss: 0.328867
2025-08-16 08:17:03,734 - INFO - Epoch 482/1000 - Train Loss: 0.287071, Val Loss: 0.332876
2025-08-16 08:19:12,712 - INFO - Epoch 483/1000 - Train Loss: 0.286618, Val Loss: 0.335901
2025-08-16 08:21:21,599 - INFO - Epoch 484/1000 - Train Loss: 0.289912, Val Loss: 0.345128
2025-08-16 08:23:30,886 - INFO - Epoch 485/1000 - Train Loss: 0.288129, Val Loss: 0.323520
2025-08-16 08:25:39,957 - INFO - Epoch 486/1000 - Train Loss: 0.286021, Val Loss: 0.336642
2025-08-16 08:27:48,909 - INFO - Epoch 487/1000 - Train Loss: 0.283019, Val Loss: 0.328358
2025-08-16 08:29:58,069 - INFO - Epoch 488/1000 - Train Loss: 0.285422, Val Loss: 0.337166
2025-08-16 08:32:07,047 - INFO - Epoch 489/1000 - Train Loss: 0.288622, Val Loss: 0.338413
2025-08-16 08:34:16,628 - INFO - Epoch 490/1000 - Train Loss: 0.288032, Val Loss: 0.339719
2025-08-16 08:36:25,998 - INFO - Epoch 491/1000 - Train Loss: 0.286279, Val Loss: 0.331609
2025-08-16 08:38:34,734 - INFO - Epoch 492/1000 - Train Loss: 0.285442, Val Loss: 0.346877
2025-08-16 08:40:44,107 - INFO - Epoch 493/1000 - Train Loss: 0.286573, Val Loss: 0.338387
2025-08-16 08:42:53,142 - INFO - Epoch 494/1000 - Train Loss: 0.285546, Val Loss: 0.326435
2025-08-16 08:45:02,356 - INFO - Epoch 495/1000 - Train Loss: 0.283596, Val Loss: 0.347911
2025-08-16 08:47:11,282 - INFO - Epoch 496/1000 - Train Loss: 0.288151, Val Loss: 0.342516
2025-08-16 08:49:19,997 - INFO - Epoch 497/1000 - Train Loss: 0.285570, Val Loss: 0.349293
2025-08-16 08:51:29,127 - INFO - Epoch 498/1000 - Train Loss: 0.283269, Val Loss: 0.336823
2025-08-16 08:53:38,278 - INFO - Epoch 499/1000 - Train Loss: 0.285439, Val Loss: 0.337025
2025-08-16 08:55:47,392 - INFO - Epoch 500/1000 - Train Loss: 0.285716, Val Loss: 0.325821
2025-08-16 08:57:56,542 - INFO - Epoch 501/1000 - Train Loss: 0.284346, Val Loss: 0.343727
2025-08-16 09:00:05,450 - INFO - Epoch 502/1000 - Train Loss: 0.284373, Val Loss: 0.349153
2025-08-16 09:02:14,345 - INFO - Epoch 503/1000 - Train Loss: 0.286388, Val Loss: 0.330728
2025-08-16 09:04:23,320 - INFO - Epoch 504/1000 - Train Loss: 0.281690, Val Loss: 0.322299
2025-08-16 09:04:23,372 - INFO - New best model saved with Val Loss: 0.322299
2025-08-16 09:06:32,584 - INFO - Epoch 505/1000 - Train Loss: 0.286948, Val Loss: 0.331321
2025-08-16 09:08:41,467 - INFO - Epoch 506/1000 - Train Loss: 0.282711, Val Loss: 0.338613
2025-08-16 09:10:50,557 - INFO - Epoch 507/1000 - Train Loss: 0.283765, Val Loss: 0.321173
2025-08-16 09:10:50,591 - INFO - New best model saved with Val Loss: 0.321173
2025-08-16 09:12:59,690 - INFO - Epoch 508/1000 - Train Loss: 0.284146, Val Loss: 0.334369
2025-08-16 09:15:08,917 - INFO - Epoch 509/1000 - Train Loss: 0.282205, Val Loss: 0.341521
2025-08-16 09:17:17,735 - INFO - Epoch 510/1000 - Train Loss: 0.283757, Val Loss: 0.331604
2025-08-16 09:19:26,997 - INFO - Epoch 511/1000 - Train Loss: 0.283115, Val Loss: 0.337127
2025-08-16 09:21:36,041 - INFO - Epoch 512/1000 - Train Loss: 0.280895, Val Loss: 0.332219
2025-08-16 09:23:44,830 - INFO - Epoch 513/1000 - Train Loss: 0.286216, Val Loss: 0.329624
2025-08-16 09:25:53,973 - INFO - Epoch 514/1000 - Train Loss: 0.281996, Val Loss: 0.333505
2025-08-16 09:28:02,911 - INFO - Epoch 515/1000 - Train Loss: 0.280712, Val Loss: 0.344041
2025-08-16 09:30:12,008 - INFO - Epoch 516/1000 - Train Loss: 0.281563, Val Loss: 0.320094
2025-08-16 09:30:12,044 - INFO - New best model saved with Val Loss: 0.320094
2025-08-16 09:32:21,136 - INFO - Epoch 517/1000 - Train Loss: 0.284606, Val Loss: 0.339756
2025-08-16 09:34:30,419 - INFO - Epoch 518/1000 - Train Loss: 0.284786, Val Loss: 0.331902
2025-08-16 09:36:39,183 - INFO - Epoch 519/1000 - Train Loss: 0.282650, Val Loss: 0.345871
2025-08-16 09:38:48,459 - INFO - Epoch 520/1000 - Train Loss: 0.283302, Val Loss: 0.342004
2025-08-16 09:40:57,683 - INFO - Epoch 521/1000 - Train Loss: 0.286897, Val Loss: 0.343593
2025-08-16 09:43:06,806 - INFO - Epoch 522/1000 - Train Loss: 0.282109, Val Loss: 0.335057
2025-08-16 09:45:15,991 - INFO - Epoch 523/1000 - Train Loss: 0.283209, Val Loss: 0.331453
2025-08-16 09:47:24,990 - INFO - Epoch 524/1000 - Train Loss: 0.281549, Val Loss: 0.324095
2025-08-16 09:49:33,942 - INFO - Epoch 525/1000 - Train Loss: 0.278975, Val Loss: 0.327582
2025-08-16 09:51:42,874 - INFO - Epoch 526/1000 - Train Loss: 0.282764, Val Loss: 0.324067
2025-08-16 09:53:51,711 - INFO - Epoch 527/1000 - Train Loss: 0.280745, Val Loss: 0.318543
2025-08-16 09:53:51,765 - INFO - New best model saved with Val Loss: 0.318543
2025-08-16 09:56:00,667 - INFO - Epoch 528/1000 - Train Loss: 0.280111, Val Loss: 0.330274
2025-08-16 09:58:09,793 - INFO - Epoch 529/1000 - Train Loss: 0.280484, Val Loss: 0.331661
2025-08-16 10:00:18,711 - INFO - Epoch 530/1000 - Train Loss: 0.285091, Val Loss: 0.339979
2025-08-16 10:02:27,860 - INFO - Epoch 531/1000 - Train Loss: 0.279535, Val Loss: 0.337536
2025-08-16 10:04:36,835 - INFO - Epoch 532/1000 - Train Loss: 0.280481, Val Loss: 0.339302
2025-08-16 10:06:45,693 - INFO - Epoch 533/1000 - Train Loss: 0.279549, Val Loss: 0.332043
2025-08-16 10:08:54,923 - INFO - Epoch 534/1000 - Train Loss: 0.279794, Val Loss: 0.345385
2025-08-16 10:11:03,919 - INFO - Epoch 535/1000 - Train Loss: 0.277125, Val Loss: 0.336368
2025-08-16 10:13:12,851 - INFO - Epoch 536/1000 - Train Loss: 0.279216, Val Loss: 0.333713
2025-08-16 10:15:21,898 - INFO - Epoch 537/1000 - Train Loss: 0.276894, Val Loss: 0.323605
2025-08-16 10:17:31,253 - INFO - Epoch 538/1000 - Train Loss: 0.279273, Val Loss: 0.327907
2025-08-16 10:19:40,236 - INFO - Epoch 539/1000 - Train Loss: 0.277687, Val Loss: 0.328626
2025-08-16 10:21:49,265 - INFO - Epoch 540/1000 - Train Loss: 0.279111, Val Loss: 0.325830
2025-08-16 10:23:58,496 - INFO - Epoch 541/1000 - Train Loss: 0.277546, Val Loss: 0.348278
2025-08-16 10:26:07,317 - INFO - Epoch 542/1000 - Train Loss: 0.278778, Val Loss: 0.323922
2025-08-16 10:28:16,517 - INFO - Epoch 543/1000 - Train Loss: 0.277000, Val Loss: 0.320530
2025-08-16 10:30:25,681 - INFO - Epoch 544/1000 - Train Loss: 0.276957, Val Loss: 0.322109
2025-08-16 10:32:34,857 - INFO - Epoch 545/1000 - Train Loss: 0.275180, Val Loss: 0.325044
2025-08-16 10:34:43,717 - INFO - Epoch 546/1000 - Train Loss: 0.276729, Val Loss: 0.323643
2025-08-16 10:36:52,794 - INFO - Epoch 547/1000 - Train Loss: 0.275085, Val Loss: 0.328479
2025-08-16 10:39:01,966 - INFO - Epoch 548/1000 - Train Loss: 0.276011, Val Loss: 0.333559
2025-08-16 10:41:10,916 - INFO - Epoch 549/1000 - Train Loss: 0.278677, Val Loss: 0.332236
2025-08-16 10:43:19,925 - INFO - Epoch 550/1000 - Train Loss: 0.276467, Val Loss: 0.347052
2025-08-16 10:45:28,984 - INFO - Epoch 551/1000 - Train Loss: 0.277034, Val Loss: 0.325517
2025-08-16 10:47:37,945 - INFO - Epoch 552/1000 - Train Loss: 0.278851, Val Loss: 0.329340
2025-08-16 10:49:46,812 - INFO - Epoch 553/1000 - Train Loss: 0.278059, Val Loss: 0.341593
2025-08-16 10:51:55,919 - INFO - Epoch 554/1000 - Train Loss: 0.275318, Val Loss: 0.321714
2025-08-16 10:54:04,724 - INFO - Epoch 555/1000 - Train Loss: 0.275053, Val Loss: 0.327389
2025-08-16 10:56:14,006 - INFO - Epoch 556/1000 - Train Loss: 0.274402, Val Loss: 0.338945
2025-08-16 10:58:23,189 - INFO - Epoch 557/1000 - Train Loss: 0.276781, Val Loss: 0.328892
2025-08-16 11:00:31,877 - INFO - Epoch 558/1000 - Train Loss: 0.279007, Val Loss: 0.333600
2025-08-16 11:02:43,345 - INFO - Epoch 559/1000 - Train Loss: 0.274552, Val Loss: 0.328538
2025-08-16 11:04:52,353 - INFO - Epoch 560/1000 - Train Loss: 0.277640, Val Loss: 0.335858
2025-08-16 11:07:01,251 - INFO - Epoch 561/1000 - Train Loss: 0.275804, Val Loss: 0.327050
2025-08-16 11:09:10,214 - INFO - Epoch 562/1000 - Train Loss: 0.274297, Val Loss: 0.314558
2025-08-16 11:09:10,253 - INFO - New best model saved with Val Loss: 0.314558
2025-08-16 11:11:19,259 - INFO - Epoch 563/1000 - Train Loss: 0.275147, Val Loss: 0.321068
2025-08-16 11:13:28,481 - INFO - Epoch 564/1000 - Train Loss: 0.276657, Val Loss: 0.329941
2025-08-16 11:15:37,412 - INFO - Epoch 565/1000 - Train Loss: 0.275446, Val Loss: 0.332355
2025-08-16 11:17:46,767 - INFO - Epoch 566/1000 - Train Loss: 0.273563, Val Loss: 0.325985
2025-08-16 11:19:55,572 - INFO - Epoch 567/1000 - Train Loss: 0.275823, Val Loss: 0.342744
2025-08-16 11:22:04,433 - INFO - Epoch 568/1000 - Train Loss: 0.273997, Val Loss: 0.345471
2025-08-16 11:24:13,278 - INFO - Epoch 569/1000 - Train Loss: 0.271595, Val Loss: 0.314405
2025-08-16 11:24:13,313 - INFO - New best model saved with Val Loss: 0.314405
2025-08-16 11:26:22,432 - INFO - Epoch 570/1000 - Train Loss: 0.272193, Val Loss: 0.318285
2025-08-16 11:28:32,002 - INFO - Epoch 571/1000 - Train Loss: 0.271669, Val Loss: 0.331091
2025-08-16 11:30:41,200 - INFO - Epoch 572/1000 - Train Loss: 0.274227, Val Loss: 0.326221
2025-08-16 11:32:50,045 - INFO - Epoch 573/1000 - Train Loss: 0.272534, Val Loss: 0.319374
2025-08-16 11:34:59,234 - INFO - Epoch 574/1000 - Train Loss: 0.270930, Val Loss: 0.321760
2025-08-16 11:37:08,266 - INFO - Epoch 575/1000 - Train Loss: 0.272484, Val Loss: 0.334574
2025-08-16 11:39:17,434 - INFO - Epoch 576/1000 - Train Loss: 0.269949, Val Loss: 0.338578
2025-08-16 11:41:26,604 - INFO - Epoch 577/1000 - Train Loss: 0.274750, Val Loss: 0.343905
2025-08-16 11:43:35,705 - INFO - Epoch 578/1000 - Train Loss: 0.275465, Val Loss: 0.321554
2025-08-16 11:45:44,616 - INFO - Epoch 579/1000 - Train Loss: 0.272713, Val Loss: 0.319955
2025-08-16 11:47:53,558 - INFO - Epoch 580/1000 - Train Loss: 0.272550, Val Loss: 0.339941
2025-08-16 11:50:02,915 - INFO - Epoch 581/1000 - Train Loss: 0.273543, Val Loss: 0.321238
2025-08-16 11:52:12,133 - INFO - Epoch 582/1000 - Train Loss: 0.269638, Val Loss: 0.318514
2025-08-16 11:54:21,248 - INFO - Epoch 583/1000 - Train Loss: 0.272080, Val Loss: 0.336579
2025-08-16 11:56:30,320 - INFO - Epoch 584/1000 - Train Loss: 0.272266, Val Loss: 0.344720
2025-08-16 11:58:39,408 - INFO - Epoch 585/1000 - Train Loss: 0.272256, Val Loss: 0.325337
2025-08-16 12:00:48,503 - INFO - Epoch 586/1000 - Train Loss: 0.270269, Val Loss: 0.318137
2025-08-16 12:02:58,020 - INFO - Epoch 587/1000 - Train Loss: 0.270885, Val Loss: 0.327271
2025-08-16 12:05:07,032 - INFO - Epoch 588/1000 - Train Loss: 0.269286, Val Loss: 0.337688
2025-08-16 12:07:16,171 - INFO - Epoch 589/1000 - Train Loss: 0.272027, Val Loss: 0.332794
2025-08-16 12:09:25,284 - INFO - Epoch 590/1000 - Train Loss: 0.269613, Val Loss: 0.339130
2025-08-16 12:11:34,630 - INFO - Epoch 591/1000 - Train Loss: 0.273737, Val Loss: 0.350477
2025-08-16 12:13:44,015 - INFO - Epoch 592/1000 - Train Loss: 0.273132, Val Loss: 0.327583
2025-08-16 12:15:53,315 - INFO - Epoch 593/1000 - Train Loss: 0.269835, Val Loss: 0.345097
2025-08-16 12:18:02,277 - INFO - Epoch 594/1000 - Train Loss: 0.270720, Val Loss: 0.345156
2025-08-16 12:20:11,467 - INFO - Epoch 595/1000 - Train Loss: 0.268255, Val Loss: 0.315498
2025-08-16 12:22:20,539 - INFO - Epoch 596/1000 - Train Loss: 0.270626, Val Loss: 0.312774
2025-08-16 12:22:20,589 - INFO - New best model saved with Val Loss: 0.312774
2025-08-16 12:24:29,421 - INFO - Epoch 597/1000 - Train Loss: 0.273467, Val Loss: 0.331705
2025-08-16 12:26:38,418 - INFO - Epoch 598/1000 - Train Loss: 0.270440, Val Loss: 0.338575
2025-08-16 12:28:47,643 - INFO - Epoch 599/1000 - Train Loss: 0.268765, Val Loss: 0.318077
2025-08-16 12:30:56,768 - INFO - Epoch 600/1000 - Train Loss: 0.268404, Val Loss: 0.363572
2025-08-16 12:33:05,953 - INFO - Epoch 601/1000 - Train Loss: 0.269384, Val Loss: 0.318137
2025-08-16 12:35:15,104 - INFO - Epoch 602/1000 - Train Loss: 0.268071, Val Loss: 0.321681
2025-08-16 12:37:24,488 - INFO - Epoch 603/1000 - Train Loss: 0.270786, Val Loss: 0.327871
2025-08-16 12:39:33,460 - INFO - Epoch 604/1000 - Train Loss: 0.267402, Val Loss: 0.324619
2025-08-16 12:41:42,979 - INFO - Epoch 605/1000 - Train Loss: 0.268966, Val Loss: 0.332398
2025-08-16 12:43:51,789 - INFO - Epoch 606/1000 - Train Loss: 0.266878, Val Loss: 0.356232
2025-08-16 12:46:00,604 - INFO - Epoch 607/1000 - Train Loss: 0.270446, Val Loss: 0.324304
2025-08-16 12:48:09,942 - INFO - Epoch 608/1000 - Train Loss: 0.267351, Val Loss: 0.338213
2025-08-16 12:50:18,861 - INFO - Epoch 609/1000 - Train Loss: 0.265426, Val Loss: 0.338042
2025-08-16 12:52:27,836 - INFO - Epoch 610/1000 - Train Loss: 0.269190, Val Loss: 0.337706
2025-08-16 12:54:37,148 - INFO - Epoch 611/1000 - Train Loss: 0.269751, Val Loss: 0.321668
2025-08-16 12:56:46,115 - INFO - Epoch 612/1000 - Train Loss: 0.267188, Val Loss: 0.344408
2025-08-16 12:58:55,418 - INFO - Epoch 613/1000 - Train Loss: 0.269371, Val Loss: 0.318383
2025-08-16 13:01:04,632 - INFO - Epoch 614/1000 - Train Loss: 0.267285, Val Loss: 0.318289
2025-08-16 13:03:14,040 - INFO - Epoch 615/1000 - Train Loss: 0.265983, Val Loss: 0.328020
2025-08-16 13:05:23,669 - INFO - Epoch 616/1000 - Train Loss: 0.265069, Val Loss: 0.324535
2025-08-16 13:07:32,873 - INFO - Epoch 617/1000 - Train Loss: 0.266434, Val Loss: 0.320574
2025-08-16 13:09:41,794 - INFO - Epoch 618/1000 - Train Loss: 0.268812, Val Loss: 0.320836
2025-08-16 13:11:51,148 - INFO - Epoch 619/1000 - Train Loss: 0.264512, Val Loss: 0.308165
2025-08-16 13:11:51,183 - INFO - New best model saved with Val Loss: 0.308165
2025-08-16 13:14:00,562 - INFO - Epoch 620/1000 - Train Loss: 0.265763, Val Loss: 0.336668
2025-08-16 13:16:10,184 - INFO - Epoch 621/1000 - Train Loss: 0.266498, Val Loss: 0.320219
2025-08-16 13:18:19,309 - INFO - Epoch 622/1000 - Train Loss: 0.264424, Val Loss: 0.351288
2025-08-16 13:20:28,957 - INFO - Epoch 623/1000 - Train Loss: 0.263727, Val Loss: 0.332505
2025-08-16 13:22:37,898 - INFO - Epoch 624/1000 - Train Loss: 0.261279, Val Loss: 0.318921
2025-08-16 13:24:47,413 - INFO - Epoch 625/1000 - Train Loss: 0.264504, Val Loss: 0.331253
2025-08-16 13:26:56,878 - INFO - Epoch 626/1000 - Train Loss: 0.265918, Val Loss: 0.318964
2025-08-16 13:29:06,464 - INFO - Epoch 627/1000 - Train Loss: 0.264576, Val Loss: 0.326522
2025-08-16 13:31:15,745 - INFO - Epoch 628/1000 - Train Loss: 0.265810, Val Loss: 0.334343
2025-08-16 13:33:25,024 - INFO - Epoch 629/1000 - Train Loss: 0.263637, Val Loss: 0.314460
2025-08-16 13:35:34,240 - INFO - Epoch 630/1000 - Train Loss: 0.265807, Val Loss: 0.332790
2025-08-16 13:37:43,962 - INFO - Epoch 631/1000 - Train Loss: 0.268235, Val Loss: 0.332162
2025-08-16 13:39:53,229 - INFO - Epoch 632/1000 - Train Loss: 0.263874, Val Loss: 0.327657
2025-08-16 13:42:02,693 - INFO - Epoch 633/1000 - Train Loss: 0.265323, Val Loss: 0.316748
2025-08-16 13:44:11,755 - INFO - Epoch 634/1000 - Train Loss: 0.265930, Val Loss: 0.327674
2025-08-16 13:46:21,119 - INFO - Epoch 635/1000 - Train Loss: 0.263952, Val Loss: 0.315939
2025-08-16 13:48:30,181 - INFO - Epoch 636/1000 - Train Loss: 0.263296, Val Loss: 0.324936
2025-08-16 13:50:39,568 - INFO - Epoch 637/1000 - Train Loss: 0.261394, Val Loss: 0.341988
2025-08-16 13:52:48,665 - INFO - Epoch 638/1000 - Train Loss: 0.265693, Val Loss: 0.328424
2025-08-16 13:54:57,714 - INFO - Epoch 639/1000 - Train Loss: 0.262994, Val Loss: 0.327367
2025-08-16 13:57:06,977 - INFO - Epoch 640/1000 - Train Loss: 0.263458, Val Loss: 0.322363
2025-08-16 13:59:16,450 - INFO - Epoch 641/1000 - Train Loss: 0.265318, Val Loss: 0.343230
2025-08-16 14:01:25,347 - INFO - Epoch 642/1000 - Train Loss: 0.263350, Val Loss: 0.318775
2025-08-16 14:03:34,360 - INFO - Epoch 643/1000 - Train Loss: 0.260810, Val Loss: 0.314938
2025-08-16 14:05:43,584 - INFO - Epoch 644/1000 - Train Loss: 0.265149, Val Loss: 0.322827
2025-08-16 14:07:52,798 - INFO - Epoch 645/1000 - Train Loss: 0.262203, Val Loss: 0.328343
2025-08-16 14:10:02,021 - INFO - Epoch 646/1000 - Train Loss: 0.261775, Val Loss: 0.334876
2025-08-16 14:12:10,973 - INFO - Epoch 647/1000 - Train Loss: 0.263025, Val Loss: 0.326296
2025-08-16 14:14:19,602 - INFO - Epoch 648/1000 - Train Loss: 0.261915, Val Loss: 0.326091
2025-08-16 14:16:28,512 - INFO - Epoch 649/1000 - Train Loss: 0.262568, Val Loss: 0.325418
2025-08-16 14:18:37,741 - INFO - Epoch 650/1000 - Train Loss: 0.261641, Val Loss: 0.329796
2025-08-16 14:20:47,027 - INFO - Epoch 651/1000 - Train Loss: 0.261689, Val Loss: 0.325223
2025-08-16 14:22:56,267 - INFO - Epoch 652/1000 - Train Loss: 0.263097, Val Loss: 0.318406
2025-08-16 14:25:05,556 - INFO - Epoch 653/1000 - Train Loss: 0.262148, Val Loss: 0.313251
2025-08-16 14:27:14,567 - INFO - Epoch 654/1000 - Train Loss: 0.261072, Val Loss: 0.313987
2025-08-16 14:29:23,355 - INFO - Epoch 655/1000 - Train Loss: 0.258845, Val Loss: 0.330678
2025-08-16 14:31:32,443 - INFO - Epoch 656/1000 - Train Loss: 0.261066, Val Loss: 0.309763
2025-08-16 14:33:41,776 - INFO - Epoch 657/1000 - Train Loss: 0.262937, Val Loss: 0.313158
2025-08-16 14:35:50,889 - INFO - Epoch 658/1000 - Train Loss: 0.259375, Val Loss: 0.322401
2025-08-16 14:37:59,719 - INFO - Epoch 659/1000 - Train Loss: 0.258344, Val Loss: 0.311298
2025-08-16 14:40:08,758 - INFO - Epoch 660/1000 - Train Loss: 0.261157, Val Loss: 0.325823
2025-08-16 14:42:17,977 - INFO - Epoch 661/1000 - Train Loss: 0.259821, Val Loss: 0.340254
2025-08-16 14:44:27,401 - INFO - Epoch 662/1000 - Train Loss: 0.260117, Val Loss: 0.311235
2025-08-16 14:46:40,239 - INFO - Epoch 663/1000 - Train Loss: 0.261385, Val Loss: 0.314695
2025-08-16 14:48:49,314 - INFO - Epoch 664/1000 - Train Loss: 0.259199, Val Loss: 0.326266
2025-08-16 14:50:58,323 - INFO - Epoch 665/1000 - Train Loss: 0.262104, Val Loss: 0.324581
2025-08-16 14:53:07,395 - INFO - Epoch 666/1000 - Train Loss: 0.259873, Val Loss: 0.315450
2025-08-16 14:55:16,822 - INFO - Epoch 667/1000 - Train Loss: 0.258738, Val Loss: 0.331357
2025-08-16 14:57:26,031 - INFO - Epoch 668/1000 - Train Loss: 0.260033, Val Loss: 0.324242
2025-08-16 14:59:35,210 - INFO - Epoch 669/1000 - Train Loss: 0.258449, Val Loss: 0.325304
2025-08-16 15:01:44,893 - INFO - Epoch 670/1000 - Train Loss: 0.258564, Val Loss: 0.312448
2025-08-16 15:03:54,166 - INFO - Epoch 671/1000 - Train Loss: 0.258605, Val Loss: 0.308689
2025-08-16 15:06:03,458 - INFO - Epoch 672/1000 - Train Loss: 0.260389, Val Loss: 0.310602
2025-08-16 15:08:12,658 - INFO - Epoch 673/1000 - Train Loss: 0.258498, Val Loss: 0.350961
2025-08-16 15:10:21,887 - INFO - Epoch 674/1000 - Train Loss: 0.260664, Val Loss: 0.323113
2025-08-16 15:12:32,199 - INFO - Epoch 675/1000 - Train Loss: 0.258474, Val Loss: 0.317471
2025-08-16 15:14:43,045 - INFO - Epoch 676/1000 - Train Loss: 0.256459, Val Loss: 0.313227
2025-08-16 15:16:54,530 - INFO - Epoch 677/1000 - Train Loss: 0.255912, Val Loss: 0.324537
2025-08-16 15:19:05,698 - INFO - Epoch 678/1000 - Train Loss: 0.258939, Val Loss: 0.343257
2025-08-16 15:21:16,546 - INFO - Epoch 679/1000 - Train Loss: 0.257461, Val Loss: 0.350072
2025-08-16 15:23:27,613 - INFO - Epoch 680/1000 - Train Loss: 0.256881, Val Loss: 0.328759
2025-08-16 15:25:37,799 - INFO - Epoch 681/1000 - Train Loss: 0.257077, Val Loss: 0.311692
2025-08-16 15:27:47,905 - INFO - Epoch 682/1000 - Train Loss: 0.255602, Val Loss: 0.340084
2025-08-16 15:29:57,976 - INFO - Epoch 683/1000 - Train Loss: 0.256565, Val Loss: 0.308265
2025-08-16 15:32:08,161 - INFO - Epoch 684/1000 - Train Loss: 0.258052, Val Loss: 0.325795
2025-08-16 15:34:18,273 - INFO - Epoch 685/1000 - Train Loss: 0.256780, Val Loss: 0.306709
2025-08-16 15:34:18,324 - INFO - New best model saved with Val Loss: 0.306709
2025-08-16 15:44:28,712 - INFO - args.exp_name : Test
2025-08-16 15:44:28,735 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 15:44:28,735 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 15:44:28,792 - INFO - [35m n_hidden: 256 [0m
2025-08-16 15:44:28,792 - INFO - [35m n_output: 128 [0m
2025-08-16 15:44:29,212 - INFO - Total trainable parameters: 11103178
2025-08-16 15:44:29,487 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 15:44:29,488 - INFO - Staring training for 1000 epochs
2025-08-16 15:47:07,082 - INFO - args.exp_name : Test
2025-08-16 15:47:07,086 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 15:47:07,086 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 15:47:07,145 - INFO - [35m n_hidden: 256 [0m
2025-08-16 15:47:07,145 - INFO - [35m n_output: 128 [0m
2025-08-16 15:47:07,573 - INFO - Total trainable parameters: 12282826
2025-08-16 15:47:07,775 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 15:47:07,775 - INFO - Staring training for 1000 epochs
2025-08-16 15:51:34,864 - INFO - args.exp_name : Test
2025-08-16 15:51:34,888 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 15:51:34,888 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 15:51:34,949 - INFO - [35m n_hidden: 256 [0m
2025-08-16 15:51:34,949 - INFO - [35m n_output: 128 [0m
2025-08-16 15:51:35,337 - INFO - Total trainable parameters: 12282826
2025-08-16 15:51:35,553 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 15:51:35,557 - INFO - Staring training for 1000 epochs
2025-08-16 15:51:41,681 - INFO - [35m x.shape: torch.Size([6, 20000, 256, 40]) [0m
2025-08-16 15:52:59,116 - INFO - args.exp_name : Test
2025-08-16 15:52:59,121 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 15:52:59,121 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 15:52:59,184 - INFO - [35m n_hidden: 256 [0m
2025-08-16 15:52:59,184 - INFO - [35m n_output: 128 [0m
2025-08-16 15:52:59,646 - INFO - Total trainable parameters: 12282826
2025-08-16 15:52:59,857 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 15:52:59,861 - INFO - Staring training for 1000 epochs
2025-08-16 15:53:05,811 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 15:53:05,815 - INFO - [35m x.shape: torch.Size([6, 20000, 256, 40]) [0m
2025-08-16 15:57:21,269 - INFO - args.exp_name : Test
2025-08-16 15:57:21,280 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 15:57:21,280 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 15:57:21,357 - INFO - [35m n_hidden: 256 [0m
2025-08-16 15:57:21,357 - INFO - [35m n_output: 128 [0m
2025-08-16 15:57:21,784 - INFO - Total trainable parameters: 12282826
2025-08-16 15:57:21,975 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 15:57:21,978 - INFO - Staring training for 1000 epochs
2025-08-16 15:57:27,976 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:02:29,502 - INFO - args.exp_name : Test
2025-08-16 16:02:29,551 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:02:29,551 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:02:29,622 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:02:29,623 - INFO - [35m n_output: 128 [0m
2025-08-16 16:02:30,043 - INFO - Total trainable parameters: 12282826
2025-08-16 16:02:30,239 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:02:30,240 - INFO - Staring training for 1000 epochs
2025-08-16 16:02:36,241 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:02:36,244 - INFO - [35m x1.shape: torch.Size([6, 10000, 256, 40]) [0m
2025-08-16 16:03:40,062 - INFO - args.exp_name : Test
2025-08-16 16:03:40,066 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:03:40,066 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:03:40,126 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:03:40,126 - INFO - [35m n_output: 128 [0m
2025-08-16 16:03:40,543 - INFO - Total trainable parameters: 12282826
2025-08-16 16:03:40,740 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:03:40,741 - INFO - Staring training for 1000 epochs
2025-08-16 16:03:47,080 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:03:47,083 - INFO - [35m x1.shape: torch.Size([6, 10000, 256]) [0m
2025-08-16 16:07:11,832 - INFO - args.exp_name : Test
2025-08-16 16:07:11,853 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:07:11,854 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:07:11,912 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:07:11,912 - INFO - [35m n_output: 128 [0m
2025-08-16 16:07:12,325 - INFO - Total trainable parameters: 12282826
2025-08-16 16:07:12,533 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:07:12,533 - INFO - Staring training for 1000 epochs
2025-08-16 16:07:18,423 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:07:18,426 - INFO - [35m x1.shape: torch.Size([6, 10000, 256]) [0m
2025-08-16 16:07:18,428 - INFO - [35m x.shape: torch.Size([6, 512, 10000, 40]) [0m
2025-08-16 16:09:54,547 - INFO - args.exp_name : Test
2025-08-16 16:09:54,574 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:09:54,574 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:09:54,633 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:09:54,636 - INFO - [35m n_output: 128 [0m
2025-08-16 16:09:55,051 - INFO - Total trainable parameters: 12282826
2025-08-16 16:09:55,254 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:09:55,255 - INFO - Staring training for 1000 epochs
2025-08-16 16:10:01,313 - INFO - [35m x.shape: torch.Size([6, 512, 10000, 40]) [0m
2025-08-16 16:13:40,580 - INFO - args.exp_name : Test
2025-08-16 16:13:40,583 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:13:40,583 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:13:40,641 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:13:40,642 - INFO - [35m n_output: 128 [0m
2025-08-16 16:13:41,021 - INFO - Total trainable parameters: 12282826
2025-08-16 16:13:41,212 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:13:41,213 - INFO - Staring training for 1000 epochs
2025-08-16 16:13:47,251 - INFO - [35m x.shape: torch.Size([6, 512, 10000, 40]) [0m
2025-08-16 16:16:23,216 - INFO - args.exp_name : Test
2025-08-16 16:16:23,220 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:16:23,220 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:16:23,278 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:16:23,278 - INFO - [35m n_output: 128 [0m
2025-08-16 16:16:23,679 - INFO - Total trainable parameters: 12282826
2025-08-16 16:16:23,869 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:16:23,870 - INFO - Staring training for 1000 epochs
2025-08-16 16:16:29,803 - INFO - [35m x.shape: torch.Size([6, 512, 10000, 40]) [0m
2025-08-16 16:16:29,809 - INFO - [35m x.shape: torch.Size([6, 768, 10000]) [0m
2025-08-16 16:16:29,809 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:16:29,809 - INFO - [35m x2.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:16:29,809 - INFO - [35m x3.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:17:52,442 - INFO - args.exp_name : Test
2025-08-16 16:17:52,446 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:17:52,453 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:17:52,524 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:17:52,524 - INFO - [35m n_output: 128 [0m
2025-08-16 16:17:52,948 - INFO - Total trainable parameters: 12282826
2025-08-16 16:17:53,144 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:17:53,148 - INFO - Staring training for 1000 epochs
2025-08-16 16:17:59,112 - INFO - [35m x.shape: torch.Size([6, 768, 10000]) [0m
2025-08-16 16:17:59,114 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:17:59,114 - INFO - [35m x2.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:17:59,114 - INFO - [35m x3.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:17:59,115 - INFO - [35m x.shape: torch.Size([6, 1024, 3]) [0m
2025-08-16 16:18:43,194 - INFO - args.exp_name : Test
2025-08-16 16:18:43,197 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:18:43,197 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:18:43,257 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:18:43,257 - INFO - [35m n_output: 128 [0m
2025-08-16 16:18:43,675 - INFO - Total trainable parameters: 12282826
2025-08-16 16:18:43,873 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:18:43,876 - INFO - Staring training for 1000 epochs
2025-08-16 16:18:49,637 - INFO - [35m x.shape: torch.Size([6, 768, 10000]) [0m
2025-08-16 16:18:49,639 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:18:49,639 - INFO - [35m x2.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:18:49,639 - INFO - [35m x3.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:18:49,640 - INFO - [35m x.shape: torch.Size([6, 1024, 10000]) [0m
2025-08-16 16:20:49,248 - INFO - args.exp_name : Test
2025-08-16 16:20:49,251 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:20:49,252 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:20:49,308 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:20:49,309 - INFO - [35m n_output: 128 [0m
2025-08-16 16:20:49,725 - INFO - Total trainable parameters: 11299786
2025-08-16 16:20:49,924 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:20:49,956 - INFO - Staring training for 1000 epochs
2025-08-16 16:20:55,900 - INFO - [35m x.shape: torch.Size([6, 768, 10000]) [0m
2025-08-16 16:20:55,902 - INFO - [35m x1.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:20:55,902 - INFO - [35m x2.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:20:55,902 - INFO - [35m x3.shape: torch.Size([6, 256, 10000]) [0m
2025-08-16 16:20:55,903 - INFO - [35m x.shape: torch.Size([6, 1024, 10000]) [0m
2025-08-16 16:24:53,342 - INFO - args.exp_name : Test
2025-08-16 16:24:53,345 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:24:53,346 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:24:53,413 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:24:53,413 - INFO - [35m n_output: 128 [0m
2025-08-16 16:24:53,826 - INFO - Total trainable parameters: 11299786
2025-08-16 16:24:54,025 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:24:54,026 - INFO - Staring training for 1000 epochs
2025-08-16 16:26:05,694 - INFO - args.exp_name : Test
2025-08-16 16:26:05,698 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 0,
  'weight_decay': 1e-05}
2025-08-16 16:26:05,698 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-08-16 16:26:05,753 - INFO - [35m n_hidden: 256 [0m
2025-08-16 16:26:05,753 - INFO - [35m n_output: 128 [0m
2025-08-16 16:26:06,184 - INFO - Total trainable parameters: 11299786
2025-08-16 16:26:06,378 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-08-16 16:26:06,378 - INFO - Staring training for 1000 epochs
2025-08-16 16:28:07,586 - INFO - Epoch 1/1000 - Train Loss: 1.099105, Val Loss: 1.068490
2025-08-16 16:28:07,729 - INFO - New best model saved with Val Loss: 1.068490
2025-08-16 16:30:09,366 - INFO - Epoch 2/1000 - Train Loss: 1.067067, Val Loss: 1.040051
2025-08-16 16:30:09,467 - INFO - New best model saved with Val Loss: 1.040051
2025-08-16 16:32:10,841 - INFO - Epoch 3/1000 - Train Loss: 1.003706, Val Loss: 1.038643
2025-08-16 16:32:10,944 - INFO - New best model saved with Val Loss: 1.038643
2025-08-16 16:34:13,335 - INFO - Epoch 4/1000 - Train Loss: 0.936859, Val Loss: 0.936382
2025-08-16 16:34:13,440 - INFO - New best model saved with Val Loss: 0.936382
2025-08-16 16:36:15,167 - INFO - Epoch 5/1000 - Train Loss: 0.871409, Val Loss: 0.852191
2025-08-16 16:36:15,285 - INFO - New best model saved with Val Loss: 0.852191
2025-08-16 16:38:16,866 - INFO - Epoch 6/1000 - Train Loss: 0.831825, Val Loss: 0.831897
2025-08-16 16:38:16,958 - INFO - New best model saved with Val Loss: 0.831897
2025-08-16 16:40:18,765 - INFO - Epoch 7/1000 - Train Loss: 0.797304, Val Loss: 0.793121
2025-08-16 16:40:18,877 - INFO - New best model saved with Val Loss: 0.793121
2025-08-16 16:42:20,627 - INFO - Epoch 8/1000 - Train Loss: 0.762688, Val Loss: 0.797143
2025-08-16 16:44:22,215 - INFO - Epoch 9/1000 - Train Loss: 0.723087, Val Loss: 0.734650
2025-08-16 16:44:22,305 - INFO - New best model saved with Val Loss: 0.734650
2025-08-16 16:46:24,069 - INFO - Epoch 10/1000 - Train Loss: 0.688814, Val Loss: 0.811112
2025-08-16 16:48:26,017 - INFO - Epoch 11/1000 - Train Loss: 0.649955, Val Loss: 0.684467
2025-08-16 16:48:26,136 - INFO - New best model saved with Val Loss: 0.684467
2025-08-16 16:50:28,007 - INFO - Epoch 12/1000 - Train Loss: 0.608764, Val Loss: 0.568841
2025-08-16 16:50:28,104 - INFO - New best model saved with Val Loss: 0.568841
2025-08-16 16:52:29,917 - INFO - Epoch 13/1000 - Train Loss: 0.576051, Val Loss: 0.606751
2025-08-16 16:54:31,594 - INFO - Epoch 14/1000 - Train Loss: 0.548831, Val Loss: 0.562481
2025-08-16 16:54:31,698 - INFO - New best model saved with Val Loss: 0.562481
2025-08-16 16:56:33,496 - INFO - Epoch 15/1000 - Train Loss: 0.525306, Val Loss: 0.534156
2025-08-16 16:56:33,612 - INFO - New best model saved with Val Loss: 0.534156
2025-08-16 16:58:35,205 - INFO - Epoch 16/1000 - Train Loss: 0.510144, Val Loss: 0.489238
2025-08-16 16:58:35,317 - INFO - New best model saved with Val Loss: 0.489238
2025-08-16 17:00:36,953 - INFO - Epoch 17/1000 - Train Loss: 0.493916, Val Loss: 0.495178
2025-08-16 17:02:38,526 - INFO - Epoch 18/1000 - Train Loss: 0.479288, Val Loss: 0.485189
2025-08-16 17:02:38,639 - INFO - New best model saved with Val Loss: 0.485189
2025-08-16 17:04:40,236 - INFO - Epoch 19/1000 - Train Loss: 0.470913, Val Loss: 0.463787
2025-08-16 17:04:40,342 - INFO - New best model saved with Val Loss: 0.463787
2025-08-16 17:06:41,957 - INFO - Epoch 20/1000 - Train Loss: 0.463309, Val Loss: 0.490718
2025-08-16 17:08:43,888 - INFO - Epoch 21/1000 - Train Loss: 0.454155, Val Loss: 0.478695
2025-08-16 17:10:45,628 - INFO - Epoch 22/1000 - Train Loss: 0.445671, Val Loss: 0.453631
2025-08-16 17:10:45,735 - INFO - New best model saved with Val Loss: 0.453631
2025-08-16 17:12:47,430 - INFO - Epoch 23/1000 - Train Loss: 0.440383, Val Loss: 0.477956
2025-08-16 17:14:49,025 - INFO - Epoch 24/1000 - Train Loss: 0.434094, Val Loss: 0.443602
2025-08-16 17:14:49,128 - INFO - New best model saved with Val Loss: 0.443602
2025-08-16 17:16:50,676 - INFO - Epoch 25/1000 - Train Loss: 0.428594, Val Loss: 0.433386
2025-08-16 17:16:50,781 - INFO - New best model saved with Val Loss: 0.433386
2025-08-16 17:18:52,522 - INFO - Epoch 26/1000 - Train Loss: 0.422262, Val Loss: 0.443139
2025-08-16 17:20:54,058 - INFO - Epoch 27/1000 - Train Loss: 0.422164, Val Loss: 0.425425
2025-08-16 17:20:54,161 - INFO - New best model saved with Val Loss: 0.425425
2025-08-16 17:22:55,875 - INFO - Epoch 28/1000 - Train Loss: 0.414110, Val Loss: 0.420810
2025-08-16 17:22:55,976 - INFO - New best model saved with Val Loss: 0.420810
2025-08-16 17:24:57,492 - INFO - Epoch 29/1000 - Train Loss: 0.408160, Val Loss: 0.424819
2025-08-16 17:26:59,101 - INFO - Epoch 30/1000 - Train Loss: 0.405890, Val Loss: 0.550648
2025-08-16 17:29:00,955 - INFO - Epoch 31/1000 - Train Loss: 0.402666, Val Loss: 0.411259
2025-08-16 17:29:01,056 - INFO - New best model saved with Val Loss: 0.411259
2025-08-16 17:31:02,782 - INFO - Epoch 32/1000 - Train Loss: 0.400341, Val Loss: 0.402042
2025-08-16 17:31:02,881 - INFO - New best model saved with Val Loss: 0.402042
2025-08-16 17:33:04,712 - INFO - Epoch 33/1000 - Train Loss: 0.399384, Val Loss: 0.437562
2025-08-16 17:35:06,196 - INFO - Epoch 34/1000 - Train Loss: 0.393880, Val Loss: 0.412362
2025-08-16 17:37:08,011 - INFO - Epoch 35/1000 - Train Loss: 0.387585, Val Loss: 0.412606
2025-08-16 17:39:09,470 - INFO - Epoch 36/1000 - Train Loss: 0.383060, Val Loss: 0.416911
2025-08-16 17:41:10,999 - INFO - Epoch 37/1000 - Train Loss: 0.379586, Val Loss: 0.436615
2025-08-16 17:43:12,736 - INFO - Epoch 38/1000 - Train Loss: 0.380238, Val Loss: 0.401583
2025-08-16 17:43:12,833 - INFO - New best model saved with Val Loss: 0.401583
2025-08-16 17:45:14,442 - INFO - Epoch 39/1000 - Train Loss: 0.374043, Val Loss: 0.396476
2025-08-16 17:45:14,542 - INFO - New best model saved with Val Loss: 0.396476
2025-08-16 17:47:16,361 - INFO - Epoch 40/1000 - Train Loss: 0.373618, Val Loss: 0.383279
2025-08-16 17:47:16,464 - INFO - New best model saved with Val Loss: 0.383279
2025-08-16 17:49:18,345 - INFO - Epoch 41/1000 - Train Loss: 0.371969, Val Loss: 0.407148
2025-08-16 17:51:19,929 - INFO - Epoch 42/1000 - Train Loss: 0.368410, Val Loss: 0.396114
2025-08-16 17:53:21,483 - INFO - Epoch 43/1000 - Train Loss: 0.364948, Val Loss: 0.412676
2025-08-16 17:55:23,071 - INFO - Epoch 44/1000 - Train Loss: 0.363237, Val Loss: 0.397005
2025-08-16 17:57:24,469 - INFO - Epoch 45/1000 - Train Loss: 0.359886, Val Loss: 0.388163
2025-08-16 17:59:25,703 - INFO - Epoch 46/1000 - Train Loss: 0.358536, Val Loss: 0.373461
2025-08-16 17:59:25,816 - INFO - New best model saved with Val Loss: 0.373461
2025-08-16 18:01:27,452 - INFO - Epoch 47/1000 - Train Loss: 0.353048, Val Loss: 0.368991
2025-08-16 18:01:27,575 - INFO - New best model saved with Val Loss: 0.368991
2025-08-16 18:03:29,214 - INFO - Epoch 48/1000 - Train Loss: 0.351725, Val Loss: 0.370732
2025-08-16 18:05:30,655 - INFO - Epoch 49/1000 - Train Loss: 0.353143, Val Loss: 0.443821
2025-08-16 18:07:32,090 - INFO - Epoch 50/1000 - Train Loss: 0.348617, Val Loss: 0.361475
2025-08-16 18:07:32,190 - INFO - New best model saved with Val Loss: 0.361475
2025-08-16 18:09:33,847 - INFO - Epoch 51/1000 - Train Loss: 0.346849, Val Loss: 0.408751
2025-08-16 18:11:35,566 - INFO - Epoch 52/1000 - Train Loss: 0.346409, Val Loss: 0.433652
2025-08-16 18:13:37,146 - INFO - Epoch 53/1000 - Train Loss: 0.342015, Val Loss: 0.365979
2025-08-16 18:15:38,749 - INFO - Epoch 54/1000 - Train Loss: 0.338740, Val Loss: 0.353342
2025-08-16 18:15:38,872 - INFO - New best model saved with Val Loss: 0.353342
2025-08-16 18:17:40,656 - INFO - Epoch 55/1000 - Train Loss: 0.336119, Val Loss: 0.367059
2025-08-16 18:19:41,934 - INFO - Epoch 56/1000 - Train Loss: 0.339871, Val Loss: 0.345880
2025-08-16 18:19:42,058 - INFO - New best model saved with Val Loss: 0.345880
2025-08-16 18:21:43,844 - INFO - Epoch 57/1000 - Train Loss: 0.335402, Val Loss: 0.354498
2025-08-16 18:23:45,544 - INFO - Epoch 58/1000 - Train Loss: 0.333977, Val Loss: 0.355492
2025-08-16 18:25:47,017 - INFO - Epoch 59/1000 - Train Loss: 0.330835, Val Loss: 0.402898
2025-08-16 18:27:48,640 - INFO - Epoch 60/1000 - Train Loss: 0.328909, Val Loss: 0.341038
2025-08-16 18:27:48,739 - INFO - New best model saved with Val Loss: 0.341038
2025-08-16 18:29:50,186 - INFO - Epoch 61/1000 - Train Loss: 0.329569, Val Loss: 0.385815
2025-08-16 18:31:51,489 - INFO - Epoch 62/1000 - Train Loss: 0.325161, Val Loss: 0.368330
2025-08-16 18:33:52,842 - INFO - Epoch 63/1000 - Train Loss: 0.324035, Val Loss: 0.342839
2025-08-16 18:35:54,045 - INFO - Epoch 64/1000 - Train Loss: 0.323472, Val Loss: 0.381962
2025-08-16 18:37:55,533 - INFO - Epoch 65/1000 - Train Loss: 0.323139, Val Loss: 0.339134
2025-08-16 18:37:55,637 - INFO - New best model saved with Val Loss: 0.339134
2025-08-16 18:39:57,037 - INFO - Epoch 66/1000 - Train Loss: 0.320037, Val Loss: 0.330534
2025-08-16 18:39:57,147 - INFO - New best model saved with Val Loss: 0.330534
2025-08-16 18:41:58,617 - INFO - Epoch 67/1000 - Train Loss: 0.318192, Val Loss: 0.334193
2025-08-16 18:43:59,840 - INFO - Epoch 68/1000 - Train Loss: 0.315460, Val Loss: 0.348799
2025-08-16 18:46:01,039 - INFO - Epoch 69/1000 - Train Loss: 0.312779, Val Loss: 0.334357
2025-08-16 18:48:02,450 - INFO - Epoch 70/1000 - Train Loss: 0.314154, Val Loss: 0.326891
2025-08-16 18:48:02,554 - INFO - New best model saved with Val Loss: 0.326891
2025-08-16 18:50:04,009 - INFO - Epoch 71/1000 - Train Loss: 0.315969, Val Loss: 0.372496
2025-08-16 18:52:05,046 - INFO - Epoch 72/1000 - Train Loss: 0.311141, Val Loss: 0.353403
2025-08-16 18:54:06,534 - INFO - Epoch 73/1000 - Train Loss: 0.311988, Val Loss: 0.325103
2025-08-16 18:54:06,640 - INFO - New best model saved with Val Loss: 0.325103
2025-08-16 18:56:07,834 - INFO - Epoch 74/1000 - Train Loss: 0.308112, Val Loss: 0.355266
2025-08-16 18:58:09,264 - INFO - Epoch 75/1000 - Train Loss: 0.308234, Val Loss: 0.370104
2025-08-16 19:00:10,421 - INFO - Epoch 76/1000 - Train Loss: 0.305152, Val Loss: 0.358886
2025-08-16 19:02:11,915 - INFO - Epoch 77/1000 - Train Loss: 0.307974, Val Loss: 0.341811
2025-08-16 19:04:13,235 - INFO - Epoch 78/1000 - Train Loss: 0.304016, Val Loss: 0.387245
2025-08-16 19:06:14,526 - INFO - Epoch 79/1000 - Train Loss: 0.303248, Val Loss: 0.333546
2025-08-16 19:08:15,803 - INFO - Epoch 80/1000 - Train Loss: 0.301832, Val Loss: 0.340745
2025-08-16 19:10:17,235 - INFO - Epoch 81/1000 - Train Loss: 0.298827, Val Loss: 0.347861
2025-08-16 19:12:18,509 - INFO - Epoch 82/1000 - Train Loss: 0.297764, Val Loss: 0.400527
2025-08-16 19:14:20,035 - INFO - Epoch 83/1000 - Train Loss: 0.297493, Val Loss: 0.337927
2025-08-16 19:16:21,285 - INFO - Epoch 84/1000 - Train Loss: 0.296037, Val Loss: 0.328868
2025-08-16 19:18:22,634 - INFO - Epoch 85/1000 - Train Loss: 0.296887, Val Loss: 0.314395
2025-08-16 19:18:22,842 - INFO - New best model saved with Val Loss: 0.314395
2025-08-16 19:20:24,292 - INFO - Epoch 86/1000 - Train Loss: 0.292599, Val Loss: 0.404030
2025-08-16 19:22:25,955 - INFO - Epoch 87/1000 - Train Loss: 0.292455, Val Loss: 0.369751
2025-08-16 19:24:27,252 - INFO - Epoch 88/1000 - Train Loss: 0.292822, Val Loss: 0.318774
2025-08-16 19:26:28,771 - INFO - Epoch 89/1000 - Train Loss: 0.289937, Val Loss: 0.331697
2025-08-16 19:28:30,357 - INFO - Epoch 90/1000 - Train Loss: 0.291003, Val Loss: 0.321957
2025-08-16 19:30:32,092 - INFO - Epoch 91/1000 - Train Loss: 0.290341, Val Loss: 0.318009
2025-08-16 19:32:33,702 - INFO - Epoch 92/1000 - Train Loss: 0.286413, Val Loss: 0.315591
2025-08-16 19:34:35,367 - INFO - Epoch 93/1000 - Train Loss: 0.286842, Val Loss: 0.356044
2025-08-16 19:36:36,862 - INFO - Epoch 94/1000 - Train Loss: 0.284076, Val Loss: 0.319420
2025-08-16 19:38:38,353 - INFO - Epoch 95/1000 - Train Loss: 0.285644, Val Loss: 0.316927
2025-08-16 19:40:40,348 - INFO - Epoch 96/1000 - Train Loss: 0.283312, Val Loss: 0.305084
2025-08-16 19:40:40,452 - INFO - New best model saved with Val Loss: 0.305084
2025-08-16 19:42:42,059 - INFO - Epoch 97/1000 - Train Loss: 0.282542, Val Loss: 0.332689
2025-08-16 19:44:43,645 - INFO - Epoch 98/1000 - Train Loss: 0.278766, Val Loss: 0.338863
2025-08-16 19:46:45,101 - INFO - Epoch 99/1000 - Train Loss: 0.281784, Val Loss: 0.334653
2025-08-16 19:48:46,369 - INFO - Epoch 100/1000 - Train Loss: 0.280732, Val Loss: 0.353239
2025-08-16 19:50:47,816 - INFO - Epoch 101/1000 - Train Loss: 0.278709, Val Loss: 0.333737
2025-08-16 19:52:49,284 - INFO - Epoch 102/1000 - Train Loss: 0.275233, Val Loss: 0.332489
2025-08-16 19:54:50,823 - INFO - Epoch 103/1000 - Train Loss: 0.277051, Val Loss: 0.303289
2025-08-16 19:54:50,927 - INFO - New best model saved with Val Loss: 0.303289
2025-08-16 19:56:52,449 - INFO - Epoch 104/1000 - Train Loss: 0.276184, Val Loss: 0.347528
2025-08-16 19:58:53,832 - INFO - Epoch 105/1000 - Train Loss: 0.276138, Val Loss: 0.314659
2025-08-16 20:00:55,269 - INFO - Epoch 106/1000 - Train Loss: 0.272060, Val Loss: 0.331623
2025-08-16 20:02:56,816 - INFO - Epoch 107/1000 - Train Loss: 0.271643, Val Loss: 0.304678
2025-08-16 20:04:58,475 - INFO - Epoch 108/1000 - Train Loss: 0.271338, Val Loss: 0.310078
2025-08-16 20:07:00,682 - INFO - Epoch 109/1000 - Train Loss: 0.271639, Val Loss: 0.327967
2025-08-16 20:09:02,599 - INFO - Epoch 110/1000 - Train Loss: 0.266877, Val Loss: 0.324262
2025-08-16 20:11:04,174 - INFO - Epoch 111/1000 - Train Loss: 0.267023, Val Loss: 0.314622
2025-08-16 20:13:05,835 - INFO - Epoch 112/1000 - Train Loss: 0.266190, Val Loss: 0.297979
2025-08-16 20:13:05,937 - INFO - New best model saved with Val Loss: 0.297979
2025-08-16 20:15:07,383 - INFO - Epoch 113/1000 - Train Loss: 0.267640, Val Loss: 0.295536
2025-08-16 20:15:07,489 - INFO - New best model saved with Val Loss: 0.295536
2025-08-16 20:17:09,328 - INFO - Epoch 114/1000 - Train Loss: 0.267124, Val Loss: 0.308611
2025-08-16 20:19:11,129 - INFO - Epoch 115/1000 - Train Loss: 0.266032, Val Loss: 0.302500
2025-08-16 20:21:12,807 - INFO - Epoch 116/1000 - Train Loss: 0.265013, Val Loss: 0.295877
2025-08-16 20:23:14,552 - INFO - Epoch 117/1000 - Train Loss: 0.266295, Val Loss: 0.382485
2025-08-16 20:25:15,982 - INFO - Epoch 118/1000 - Train Loss: 0.263409, Val Loss: 0.293624
2025-08-16 20:25:16,090 - INFO - New best model saved with Val Loss: 0.293624
2025-08-16 20:27:17,629 - INFO - Epoch 119/1000 - Train Loss: 0.262052, Val Loss: 0.309068
2025-08-16 20:29:19,147 - INFO - Epoch 120/1000 - Train Loss: 0.260354, Val Loss: 0.302892
2025-08-16 20:31:20,744 - INFO - Epoch 121/1000 - Train Loss: 0.257238, Val Loss: 0.298667
2025-08-16 20:33:22,268 - INFO - Epoch 122/1000 - Train Loss: 0.258552, Val Loss: 0.311651
2025-08-16 20:35:23,844 - INFO - Epoch 123/1000 - Train Loss: 0.259324, Val Loss: 0.316622
2025-08-16 20:37:25,491 - INFO - Epoch 124/1000 - Train Loss: 0.257277, Val Loss: 0.312829
2025-08-16 20:39:26,909 - INFO - Epoch 125/1000 - Train Loss: 0.255700, Val Loss: 0.310993
2025-08-16 20:41:28,583 - INFO - Epoch 126/1000 - Train Loss: 0.257019, Val Loss: 0.297050
2025-08-16 20:43:30,178 - INFO - Epoch 127/1000 - Train Loss: 0.255537, Val Loss: 0.293612
2025-08-16 20:43:30,289 - INFO - New best model saved with Val Loss: 0.293612
2025-08-16 20:45:31,941 - INFO - Epoch 128/1000 - Train Loss: 0.253401, Val Loss: 0.331593
2025-08-16 20:47:33,499 - INFO - Epoch 129/1000 - Train Loss: 0.254042, Val Loss: 0.299466
2025-08-16 20:49:35,124 - INFO - Epoch 130/1000 - Train Loss: 0.251358, Val Loss: 0.294099
2025-08-16 20:51:36,587 - INFO - Epoch 131/1000 - Train Loss: 0.250461, Val Loss: 0.309671
2025-08-16 20:53:38,209 - INFO - Epoch 132/1000 - Train Loss: 0.250975, Val Loss: 0.295882
2025-08-16 20:55:39,356 - INFO - Epoch 133/1000 - Train Loss: 0.248013, Val Loss: 0.298405
2025-08-16 20:57:40,740 - INFO - Epoch 134/1000 - Train Loss: 0.250292, Val Loss: 0.326292
2025-08-16 20:59:42,713 - INFO - Epoch 135/1000 - Train Loss: 0.248029, Val Loss: 0.301535
2025-08-16 21:01:44,268 - INFO - Epoch 136/1000 - Train Loss: 0.248135, Val Loss: 0.292490
2025-08-16 21:01:44,396 - INFO - New best model saved with Val Loss: 0.292490
2025-08-16 21:03:46,172 - INFO - Epoch 137/1000 - Train Loss: 0.248381, Val Loss: 0.293412
2025-08-16 21:05:47,993 - INFO - Epoch 138/1000 - Train Loss: 0.248564, Val Loss: 0.302989
2025-08-16 21:07:49,537 - INFO - Epoch 139/1000 - Train Loss: 0.248564, Val Loss: 0.288866
2025-08-16 21:07:49,660 - INFO - New best model saved with Val Loss: 0.288866
2025-08-16 21:09:51,269 - INFO - Epoch 140/1000 - Train Loss: 0.245063, Val Loss: 0.318172
2025-08-16 21:11:53,116 - INFO - Epoch 141/1000 - Train Loss: 0.245962, Val Loss: 0.323560
2025-08-16 21:13:54,862 - INFO - Epoch 142/1000 - Train Loss: 0.244453, Val Loss: 0.334492
2025-08-16 21:15:56,665 - INFO - Epoch 143/1000 - Train Loss: 0.244492, Val Loss: 0.298986
2025-08-16 21:17:58,713 - INFO - Epoch 144/1000 - Train Loss: 0.241870, Val Loss: 0.299355
2025-08-16 21:20:00,438 - INFO - Epoch 145/1000 - Train Loss: 0.241139, Val Loss: 0.308139
2025-08-16 21:22:02,586 - INFO - Epoch 146/1000 - Train Loss: 0.243790, Val Loss: 0.292420
2025-08-16 21:24:04,357 - INFO - Epoch 147/1000 - Train Loss: 0.244006, Val Loss: 0.295169
2025-08-16 21:26:06,267 - INFO - Epoch 148/1000 - Train Loss: 0.238049, Val Loss: 0.295759
2025-08-16 21:28:08,193 - INFO - Epoch 149/1000 - Train Loss: 0.239455, Val Loss: 0.306071
2025-08-16 21:30:09,953 - INFO - Epoch 150/1000 - Train Loss: 0.239650, Val Loss: 0.314094
2025-08-16 21:32:11,806 - INFO - Epoch 151/1000 - Train Loss: 0.240216, Val Loss: 0.294242
2025-08-16 21:34:13,458 - INFO - Epoch 152/1000 - Train Loss: 0.237532, Val Loss: 0.299537
2025-08-16 21:36:15,321 - INFO - Epoch 153/1000 - Train Loss: 0.237411, Val Loss: 0.304671
2025-08-16 21:38:17,192 - INFO - Epoch 154/1000 - Train Loss: 0.238555, Val Loss: 0.311758
2025-08-16 21:40:18,960 - INFO - Epoch 155/1000 - Train Loss: 0.236873, Val Loss: 0.327570
2025-08-16 21:42:20,679 - INFO - Epoch 156/1000 - Train Loss: 0.235661, Val Loss: 0.288148
2025-08-16 21:42:20,781 - INFO - New best model saved with Val Loss: 0.288148
2025-08-16 21:44:22,615 - INFO - Epoch 157/1000 - Train Loss: 0.233595, Val Loss: 0.291291
2025-08-16 21:46:24,232 - INFO - Epoch 158/1000 - Train Loss: 0.233280, Val Loss: 0.323185
2025-08-16 21:48:26,001 - INFO - Epoch 159/1000 - Train Loss: 0.233861, Val Loss: 0.303468
2025-08-16 21:50:27,732 - INFO - Epoch 160/1000 - Train Loss: 0.231908, Val Loss: 0.289167
2025-08-16 21:52:29,592 - INFO - Epoch 161/1000 - Train Loss: 0.233284, Val Loss: 0.298306
2025-08-16 21:54:31,474 - INFO - Epoch 162/1000 - Train Loss: 0.232566, Val Loss: 0.287331
2025-08-16 21:54:31,568 - INFO - New best model saved with Val Loss: 0.287331
2025-08-16 21:56:33,138 - INFO - Epoch 163/1000 - Train Loss: 0.231659, Val Loss: 0.293067
2025-08-16 21:58:34,877 - INFO - Epoch 164/1000 - Train Loss: 0.231684, Val Loss: 0.304477
2025-08-16 22:00:36,383 - INFO - Epoch 165/1000 - Train Loss: 0.231027, Val Loss: 0.302327
2025-08-16 22:02:37,668 - INFO - Epoch 166/1000 - Train Loss: 0.233250, Val Loss: 0.288193
2025-08-16 22:04:39,303 - INFO - Epoch 167/1000 - Train Loss: 0.229428, Val Loss: 0.302019
2025-08-16 22:06:40,771 - INFO - Epoch 168/1000 - Train Loss: 0.229055, Val Loss: 0.291178
2025-08-16 22:08:42,470 - INFO - Epoch 169/1000 - Train Loss: 0.229099, Val Loss: 0.301657
2025-08-16 22:10:44,315 - INFO - Epoch 170/1000 - Train Loss: 0.228439, Val Loss: 0.290113
2025-08-16 22:12:46,048 - INFO - Epoch 171/1000 - Train Loss: 0.228550, Val Loss: 0.296324
2025-08-16 22:14:48,129 - INFO - Epoch 172/1000 - Train Loss: 0.227871, Val Loss: 0.280920
2025-08-16 22:14:48,234 - INFO - New best model saved with Val Loss: 0.280920
2025-08-16 22:16:49,956 - INFO - Epoch 173/1000 - Train Loss: 0.226794, Val Loss: 0.295171
2025-08-16 22:18:51,978 - INFO - Epoch 174/1000 - Train Loss: 0.224894, Val Loss: 0.288798
2025-08-16 22:20:54,068 - INFO - Epoch 175/1000 - Train Loss: 0.225868, Val Loss: 0.309382
2025-08-16 22:22:55,716 - INFO - Epoch 176/1000 - Train Loss: 0.222709, Val Loss: 0.284934
2025-08-16 22:24:57,292 - INFO - Epoch 177/1000 - Train Loss: 0.225105, Val Loss: 0.319150
2025-08-16 22:26:58,886 - INFO - Epoch 178/1000 - Train Loss: 0.224087, Val Loss: 0.337738
2025-08-16 22:29:00,624 - INFO - Epoch 179/1000 - Train Loss: 0.223523, Val Loss: 0.281516
2025-08-16 22:31:02,354 - INFO - Epoch 180/1000 - Train Loss: 0.223403, Val Loss: 0.306676
2025-08-16 22:33:04,226 - INFO - Epoch 181/1000 - Train Loss: 0.220841, Val Loss: 0.290620
2025-08-16 22:35:06,233 - INFO - Epoch 182/1000 - Train Loss: 0.221429, Val Loss: 0.283776
2025-08-16 22:37:08,129 - INFO - Epoch 183/1000 - Train Loss: 0.221543, Val Loss: 0.301999
2025-08-16 22:39:10,713 - INFO - Epoch 184/1000 - Train Loss: 0.219551, Val Loss: 0.290380
2025-08-16 22:41:14,300 - INFO - Epoch 185/1000 - Train Loss: 0.221216, Val Loss: 0.295199
2025-08-16 22:43:17,730 - INFO - Epoch 186/1000 - Train Loss: 0.219120, Val Loss: 0.289429
2025-08-16 22:45:21,387 - INFO - Epoch 187/1000 - Train Loss: 0.222610, Val Loss: 0.292008
2025-08-16 22:47:23,723 - INFO - Epoch 188/1000 - Train Loss: 0.218985, Val Loss: 0.286111
2025-08-16 22:49:26,886 - INFO - Epoch 189/1000 - Train Loss: 0.217697, Val Loss: 0.292060
2025-08-16 22:51:29,682 - INFO - Epoch 190/1000 - Train Loss: 0.218036, Val Loss: 0.290794
2025-08-16 22:53:32,987 - INFO - Epoch 191/1000 - Train Loss: 0.216663, Val Loss: 0.322934
2025-08-16 22:55:36,113 - INFO - Epoch 192/1000 - Train Loss: 0.218066, Val Loss: 0.312502
2025-08-16 22:57:39,668 - INFO - Epoch 193/1000 - Train Loss: 0.218454, Val Loss: 0.298906
2025-08-16 22:59:42,469 - INFO - Epoch 194/1000 - Train Loss: 0.215588, Val Loss: 0.310489
2025-08-16 23:01:46,002 - INFO - Epoch 195/1000 - Train Loss: 0.215794, Val Loss: 0.306259
2025-08-16 23:03:48,447 - INFO - Epoch 196/1000 - Train Loss: 0.216734, Val Loss: 0.298595
2025-08-16 23:05:51,332 - INFO - Epoch 197/1000 - Train Loss: 0.214988, Val Loss: 0.290440
2025-08-16 23:07:54,252 - INFO - Epoch 198/1000 - Train Loss: 0.214724, Val Loss: 0.300928
2025-08-16 23:09:57,524 - INFO - Epoch 199/1000 - Train Loss: 0.214057, Val Loss: 0.286641
2025-08-16 23:11:59,998 - INFO - Epoch 200/1000 - Train Loss: 0.213483, Val Loss: 0.292161
2025-08-16 23:14:02,829 - INFO - Epoch 201/1000 - Train Loss: 0.213184, Val Loss: 0.287287
2025-08-16 23:16:05,451 - INFO - Epoch 202/1000 - Train Loss: 0.210851, Val Loss: 0.293625
2025-08-16 23:18:08,919 - INFO - Epoch 203/1000 - Train Loss: 0.211697, Val Loss: 0.302273
2025-08-16 23:20:12,045 - INFO - Epoch 204/1000 - Train Loss: 0.210765, Val Loss: 0.311032
2025-08-16 23:22:14,891 - INFO - Epoch 205/1000 - Train Loss: 0.208254, Val Loss: 0.309412
2025-08-16 23:24:17,325 - INFO - Epoch 206/1000 - Train Loss: 0.208472, Val Loss: 0.289165
2025-08-16 23:26:19,826 - INFO - Epoch 207/1000 - Train Loss: 0.210312, Val Loss: 0.311185
2025-08-16 23:28:22,679 - INFO - Epoch 208/1000 - Train Loss: 0.210178, Val Loss: 0.295278
2025-08-16 23:30:25,266 - INFO - Epoch 209/1000 - Train Loss: 0.208650, Val Loss: 0.302965
2025-08-16 23:32:29,036 - INFO - Epoch 210/1000 - Train Loss: 0.206374, Val Loss: 0.297359
2025-08-16 23:34:32,209 - INFO - Epoch 211/1000 - Train Loss: 0.209586, Val Loss: 0.305701
2025-08-16 23:36:34,674 - INFO - Epoch 212/1000 - Train Loss: 0.208592, Val Loss: 0.281061
2025-08-16 23:38:37,717 - INFO - Epoch 213/1000 - Train Loss: 0.207857, Val Loss: 0.287086
2025-08-16 23:40:40,319 - INFO - Epoch 214/1000 - Train Loss: 0.206498, Val Loss: 0.298997
2025-08-16 23:42:43,152 - INFO - Epoch 215/1000 - Train Loss: 0.207737, Val Loss: 0.289191
2025-08-16 23:44:46,228 - INFO - Epoch 216/1000 - Train Loss: 0.205429, Val Loss: 0.306852
2025-08-16 23:46:48,556 - INFO - Epoch 217/1000 - Train Loss: 0.205817, Val Loss: 0.296787
2025-08-16 23:48:51,056 - INFO - Epoch 218/1000 - Train Loss: 0.204407, Val Loss: 0.297458
2025-08-16 23:50:53,541 - INFO - Epoch 219/1000 - Train Loss: 0.204047, Val Loss: 0.290084
2025-08-16 23:52:56,154 - INFO - Epoch 220/1000 - Train Loss: 0.205679, Val Loss: 0.289135
2025-08-16 23:54:58,692 - INFO - Epoch 221/1000 - Train Loss: 0.204500, Val Loss: 0.293121
2025-08-16 23:57:01,820 - INFO - Epoch 222/1000 - Train Loss: 0.205169, Val Loss: 0.291172
2025-08-16 23:59:04,613 - INFO - Epoch 223/1000 - Train Loss: 0.202906, Val Loss: 0.291838
2025-08-17 00:01:07,406 - INFO - Epoch 224/1000 - Train Loss: 0.203201, Val Loss: 0.280172
2025-08-17 00:01:07,511 - INFO - New best model saved with Val Loss: 0.280172
2025-08-17 00:03:10,488 - INFO - Epoch 225/1000 - Train Loss: 0.202511, Val Loss: 0.289796
2025-08-17 00:05:13,008 - INFO - Epoch 226/1000 - Train Loss: 0.202622, Val Loss: 0.314309
2025-08-17 00:07:15,310 - INFO - Epoch 227/1000 - Train Loss: 0.201255, Val Loss: 0.300974
2025-08-17 00:09:18,037 - INFO - Epoch 228/1000 - Train Loss: 0.205469, Val Loss: 0.289954
2025-08-17 00:11:21,145 - INFO - Epoch 229/1000 - Train Loss: 0.204302, Val Loss: 0.315798
2025-08-17 00:13:24,192 - INFO - Epoch 230/1000 - Train Loss: 0.201738, Val Loss: 0.285688
2025-08-17 00:15:27,902 - INFO - Epoch 231/1000 - Train Loss: 0.200094, Val Loss: 0.282348
2025-08-17 00:17:31,262 - INFO - Epoch 232/1000 - Train Loss: 0.199039, Val Loss: 0.340669
2025-08-17 00:19:33,851 - INFO - Epoch 233/1000 - Train Loss: 0.200413, Val Loss: 0.306072
2025-08-17 00:21:36,639 - INFO - Epoch 234/1000 - Train Loss: 0.197864, Val Loss: 0.294763
2025-08-17 00:23:38,963 - INFO - Epoch 235/1000 - Train Loss: 0.199756, Val Loss: 0.324183
2025-08-17 00:25:41,497 - INFO - Epoch 236/1000 - Train Loss: 0.197925, Val Loss: 0.308151
2025-08-17 00:27:43,632 - INFO - Epoch 237/1000 - Train Loss: 0.196194, Val Loss: 0.289523
2025-08-17 00:29:46,171 - INFO - Epoch 238/1000 - Train Loss: 0.198608, Val Loss: 0.301617
2025-08-17 00:31:49,380 - INFO - Epoch 239/1000 - Train Loss: 0.196540, Val Loss: 0.303891
2025-08-17 00:33:52,000 - INFO - Epoch 240/1000 - Train Loss: 0.199210, Val Loss: 0.303046
2025-08-17 00:35:54,896 - INFO - Epoch 241/1000 - Train Loss: 0.194637, Val Loss: 0.302476
2025-08-17 00:37:57,684 - INFO - Epoch 242/1000 - Train Loss: 0.196572, Val Loss: 0.321256
2025-08-17 00:39:59,972 - INFO - Epoch 243/1000 - Train Loss: 0.195409, Val Loss: 0.302073
2025-08-17 00:42:02,385 - INFO - Epoch 244/1000 - Train Loss: 0.194206, Val Loss: 0.290955
2025-08-17 00:44:05,113 - INFO - Epoch 245/1000 - Train Loss: 0.194573, Val Loss: 0.301178
2025-08-17 00:46:07,375 - INFO - Epoch 246/1000 - Train Loss: 0.194906, Val Loss: 0.312864
2025-08-17 00:48:09,692 - INFO - Epoch 247/1000 - Train Loss: 0.193018, Val Loss: 0.291272
2025-08-17 00:50:11,939 - INFO - Epoch 248/1000 - Train Loss: 0.193559, Val Loss: 0.293630
2025-08-17 00:52:14,336 - INFO - Epoch 249/1000 - Train Loss: 0.192278, Val Loss: 0.298975
2025-08-17 00:54:17,165 - INFO - Epoch 250/1000 - Train Loss: 0.192905, Val Loss: 0.300605
2025-08-17 00:56:19,747 - INFO - Epoch 251/1000 - Train Loss: 0.191787, Val Loss: 0.290198
2025-08-17 00:58:22,505 - INFO - Epoch 252/1000 - Train Loss: 0.192862, Val Loss: 0.301646
2025-08-17 01:00:25,619 - INFO - Epoch 253/1000 - Train Loss: 0.194271, Val Loss: 0.305074
2025-08-17 01:02:28,247 - INFO - Epoch 254/1000 - Train Loss: 0.191927, Val Loss: 0.283538
2025-08-17 01:04:31,035 - INFO - Epoch 255/1000 - Train Loss: 0.193002, Val Loss: 0.308794
2025-08-17 01:06:33,343 - INFO - Epoch 256/1000 - Train Loss: 0.193224, Val Loss: 0.291614
2025-08-17 01:08:36,365 - INFO - Epoch 257/1000 - Train Loss: 0.193715, Val Loss: 0.286832
2025-08-17 01:10:39,368 - INFO - Epoch 258/1000 - Train Loss: 0.193200, Val Loss: 0.302744
2025-08-17 01:12:42,044 - INFO - Epoch 259/1000 - Train Loss: 0.190339, Val Loss: 0.330189
2025-08-17 01:14:45,205 - INFO - Epoch 260/1000 - Train Loss: 0.190963, Val Loss: 0.327186
2025-08-17 01:16:47,882 - INFO - Epoch 261/1000 - Train Loss: 0.191284, Val Loss: 0.287558
2025-08-17 01:18:50,742 - INFO - Epoch 262/1000 - Train Loss: 0.191563, Val Loss: 0.296176
2025-08-17 01:20:53,259 - INFO - Epoch 263/1000 - Train Loss: 0.191287, Val Loss: 0.290835
2025-08-17 01:22:55,875 - INFO - Epoch 264/1000 - Train Loss: 0.189177, Val Loss: 0.305857
2025-08-17 01:24:58,482 - INFO - Epoch 265/1000 - Train Loss: 0.187785, Val Loss: 0.307210
2025-08-17 01:27:01,380 - INFO - Epoch 266/1000 - Train Loss: 0.187263, Val Loss: 0.298915
2025-08-17 01:29:04,176 - INFO - Epoch 267/1000 - Train Loss: 0.187713, Val Loss: 0.288735
2025-08-17 01:31:07,492 - INFO - Epoch 268/1000 - Train Loss: 0.185578, Val Loss: 0.283713
2025-08-17 01:33:10,018 - INFO - Epoch 269/1000 - Train Loss: 0.187645, Val Loss: 0.300346
2025-08-17 01:35:13,006 - INFO - Epoch 270/1000 - Train Loss: 0.185718, Val Loss: 0.335626
2025-08-17 01:37:16,005 - INFO - Epoch 271/1000 - Train Loss: 0.186617, Val Loss: 0.284457
2025-08-17 01:39:18,374 - INFO - Epoch 272/1000 - Train Loss: 0.189487, Val Loss: 0.289419
2025-08-17 01:41:21,077 - INFO - Epoch 273/1000 - Train Loss: 0.184917, Val Loss: 0.302444
2025-08-17 01:43:23,963 - INFO - Epoch 274/1000 - Train Loss: 0.186151, Val Loss: 0.304160
2025-08-17 01:45:26,433 - INFO - Epoch 275/1000 - Train Loss: 0.187344, Val Loss: 0.297023
2025-08-17 01:47:30,406 - INFO - Epoch 276/1000 - Train Loss: 0.185200, Val Loss: 0.278974
2025-08-17 01:47:30,507 - INFO - New best model saved with Val Loss: 0.278974
2025-08-17 01:49:32,789 - INFO - Epoch 277/1000 - Train Loss: 0.185631, Val Loss: 0.296752
2025-08-17 01:51:35,410 - INFO - Epoch 278/1000 - Train Loss: 0.184538, Val Loss: 0.281894
2025-08-17 01:53:38,894 - INFO - Epoch 279/1000 - Train Loss: 0.184499, Val Loss: 0.303902
2025-08-17 01:55:42,000 - INFO - Epoch 280/1000 - Train Loss: 0.183478, Val Loss: 0.296585
2025-08-17 01:57:45,206 - INFO - Epoch 281/1000 - Train Loss: 0.184356, Val Loss: 0.287907
2025-08-17 01:59:47,778 - INFO - Epoch 282/1000 - Train Loss: 0.182656, Val Loss: 0.290167
2025-08-17 02:01:50,404 - INFO - Epoch 283/1000 - Train Loss: 0.183123, Val Loss: 0.315971
2025-08-17 02:03:53,789 - INFO - Epoch 284/1000 - Train Loss: 0.181494, Val Loss: 0.294169
2025-08-17 02:05:58,382 - INFO - Epoch 285/1000 - Train Loss: 0.183180, Val Loss: 0.292048
2025-08-17 02:08:01,709 - INFO - Epoch 286/1000 - Train Loss: 0.182253, Val Loss: 0.298447
2025-08-17 02:10:04,160 - INFO - Epoch 287/1000 - Train Loss: 0.183377, Val Loss: 0.299673
2025-08-17 02:12:06,818 - INFO - Epoch 288/1000 - Train Loss: 0.181971, Val Loss: 0.280340
2025-08-17 02:14:09,910 - INFO - Epoch 289/1000 - Train Loss: 0.180441, Val Loss: 0.294813
2025-08-17 02:16:12,597 - INFO - Epoch 290/1000 - Train Loss: 0.180710, Val Loss: 0.303926
2025-08-17 02:18:15,348 - INFO - Epoch 291/1000 - Train Loss: 0.179790, Val Loss: 0.313048
2025-08-17 02:20:18,259 - INFO - Epoch 292/1000 - Train Loss: 0.181464, Val Loss: 0.309392
2025-08-17 02:22:20,905 - INFO - Epoch 293/1000 - Train Loss: 0.179927, Val Loss: 0.289550
2025-08-17 02:24:23,946 - INFO - Epoch 294/1000 - Train Loss: 0.182359, Val Loss: 0.299308
2025-08-17 02:26:27,186 - INFO - Epoch 295/1000 - Train Loss: 0.180307, Val Loss: 0.287845
2025-08-17 02:28:29,771 - INFO - Epoch 296/1000 - Train Loss: 0.179940, Val Loss: 0.296360
2025-08-17 02:30:32,783 - INFO - Epoch 297/1000 - Train Loss: 0.179141, Val Loss: 0.290837
2025-08-17 02:32:35,612 - INFO - Epoch 298/1000 - Train Loss: 0.177728, Val Loss: 0.303077
2025-08-17 02:34:38,559 - INFO - Epoch 299/1000 - Train Loss: 0.179440, Val Loss: 0.314087
2025-08-17 02:36:40,970 - INFO - Epoch 300/1000 - Train Loss: 0.176628, Val Loss: 0.302751
2025-08-17 02:38:43,910 - INFO - Epoch 301/1000 - Train Loss: 0.179412, Val Loss: 0.298404
2025-08-17 02:40:46,524 - INFO - Epoch 302/1000 - Train Loss: 0.177185, Val Loss: 0.294792
2025-08-17 02:42:49,332 - INFO - Epoch 303/1000 - Train Loss: 0.178146, Val Loss: 0.304375
2025-08-17 02:44:52,319 - INFO - Epoch 304/1000 - Train Loss: 0.177894, Val Loss: 0.291554
2025-08-17 02:46:55,100 - INFO - Epoch 305/1000 - Train Loss: 0.175925, Val Loss: 0.297550
2025-08-17 02:48:58,321 - INFO - Epoch 306/1000 - Train Loss: 0.176149, Val Loss: 0.308607
2025-08-17 02:51:00,675 - INFO - Epoch 307/1000 - Train Loss: 0.177276, Val Loss: 0.296648
2025-08-17 02:53:03,585 - INFO - Epoch 308/1000 - Train Loss: 0.178022, Val Loss: 0.330445
2025-08-17 02:55:05,942 - INFO - Epoch 309/1000 - Train Loss: 0.177784, Val Loss: 0.299637
2025-08-17 02:57:08,931 - INFO - Epoch 310/1000 - Train Loss: 0.177874, Val Loss: 0.281116
2025-08-17 02:59:11,754 - INFO - Epoch 311/1000 - Train Loss: 0.176758, Val Loss: 0.315178
2025-08-17 03:01:14,495 - INFO - Epoch 312/1000 - Train Loss: 0.174791, Val Loss: 0.293124
2025-08-17 03:03:17,167 - INFO - Epoch 313/1000 - Train Loss: 0.173260, Val Loss: 0.298883
2025-08-17 03:05:19,794 - INFO - Epoch 314/1000 - Train Loss: 0.174100, Val Loss: 0.306440
2025-08-17 03:07:21,778 - INFO - Epoch 315/1000 - Train Loss: 0.173771, Val Loss: 0.306728
2025-08-17 03:09:24,535 - INFO - Epoch 316/1000 - Train Loss: 0.175088, Val Loss: 0.294041
2025-08-17 03:11:27,483 - INFO - Epoch 317/1000 - Train Loss: 0.171712, Val Loss: 0.288278
2025-08-17 03:13:30,184 - INFO - Epoch 318/1000 - Train Loss: 0.172328, Val Loss: 0.324514
2025-08-17 03:15:32,838 - INFO - Epoch 319/1000 - Train Loss: 0.172977, Val Loss: 0.295806
2025-08-17 03:17:35,821 - INFO - Epoch 320/1000 - Train Loss: 0.173352, Val Loss: 0.285953
2025-08-17 03:19:38,519 - INFO - Epoch 321/1000 - Train Loss: 0.171571, Val Loss: 0.310893
2025-08-17 03:21:41,431 - INFO - Epoch 322/1000 - Train Loss: 0.174338, Val Loss: 0.291335
2025-08-17 03:23:44,162 - INFO - Epoch 323/1000 - Train Loss: 0.172608, Val Loss: 0.296002
2025-08-17 03:25:47,121 - INFO - Epoch 324/1000 - Train Loss: 0.172667, Val Loss: 0.282549
2025-08-17 03:27:49,247 - INFO - Epoch 325/1000 - Train Loss: 0.171047, Val Loss: 0.301726
2025-08-17 03:29:52,044 - INFO - Epoch 326/1000 - Train Loss: 0.170742, Val Loss: 0.289552
2025-08-17 03:31:53,982 - INFO - Epoch 327/1000 - Train Loss: 0.172357, Val Loss: 0.304235
2025-08-17 03:33:58,253 - INFO - Epoch 328/1000 - Train Loss: 0.171492, Val Loss: 0.305893
2025-08-17 03:36:01,082 - INFO - Epoch 329/1000 - Train Loss: 0.169771, Val Loss: 0.295334
2025-08-17 03:38:03,640 - INFO - Epoch 330/1000 - Train Loss: 0.170730, Val Loss: 0.301607
2025-08-17 03:40:06,572 - INFO - Epoch 331/1000 - Train Loss: 0.169438, Val Loss: 0.287252
2025-08-17 03:42:09,762 - INFO - Epoch 332/1000 - Train Loss: 0.169972, Val Loss: 0.287077
2025-08-17 03:44:12,251 - INFO - Epoch 333/1000 - Train Loss: 0.169067, Val Loss: 0.310431
2025-08-17 03:46:14,703 - INFO - Epoch 334/1000 - Train Loss: 0.168773, Val Loss: 0.289024
2025-08-17 03:48:17,587 - INFO - Epoch 335/1000 - Train Loss: 0.166227, Val Loss: 0.311376
2025-08-17 03:50:20,288 - INFO - Epoch 336/1000 - Train Loss: 0.171402, Val Loss: 0.305239
2025-08-17 03:52:23,196 - INFO - Epoch 337/1000 - Train Loss: 0.170293, Val Loss: 0.323603
2025-08-17 03:54:25,767 - INFO - Epoch 338/1000 - Train Loss: 0.168231, Val Loss: 0.296421
2025-08-17 03:56:30,560 - INFO - Epoch 339/1000 - Train Loss: 0.170066, Val Loss: 0.315352
2025-08-17 03:58:33,881 - INFO - Epoch 340/1000 - Train Loss: 0.169030, Val Loss: 0.288955
2025-08-17 04:00:36,834 - INFO - Epoch 341/1000 - Train Loss: 0.167316, Val Loss: 0.311153
2025-08-17 04:02:39,174 - INFO - Epoch 342/1000 - Train Loss: 0.166600, Val Loss: 0.286892
2025-08-17 04:04:41,734 - INFO - Epoch 343/1000 - Train Loss: 0.167477, Val Loss: 0.319838
2025-08-17 04:06:44,176 - INFO - Epoch 344/1000 - Train Loss: 0.170637, Val Loss: 0.285542
2025-08-17 04:08:47,214 - INFO - Epoch 345/1000 - Train Loss: 0.167217, Val Loss: 0.291118
2025-08-17 04:10:49,677 - INFO - Epoch 346/1000 - Train Loss: 0.165338, Val Loss: 0.297546
2025-08-17 04:12:54,045 - INFO - Epoch 347/1000 - Train Loss: 0.167913, Val Loss: 0.289483
2025-08-17 04:14:57,334 - INFO - Epoch 348/1000 - Train Loss: 0.166152, Val Loss: 0.310144
2025-08-17 04:17:00,496 - INFO - Epoch 349/1000 - Train Loss: 0.164419, Val Loss: 0.326421
2025-08-17 04:19:03,330 - INFO - Epoch 350/1000 - Train Loss: 0.165455, Val Loss: 0.304979
2025-08-17 04:21:06,228 - INFO - Epoch 351/1000 - Train Loss: 0.167673, Val Loss: 0.296945
2025-08-17 04:23:08,850 - INFO - Epoch 352/1000 - Train Loss: 0.164250, Val Loss: 0.296903
2025-08-17 04:25:12,238 - INFO - Epoch 353/1000 - Train Loss: 0.163065, Val Loss: 0.313095
2025-08-17 04:27:15,091 - INFO - Epoch 354/1000 - Train Loss: 0.164756, Val Loss: 0.288697
2025-08-17 04:29:17,063 - INFO - Epoch 355/1000 - Train Loss: 0.164094, Val Loss: 0.296070
2025-08-17 04:31:19,835 - INFO - Epoch 356/1000 - Train Loss: 0.165000, Val Loss: 0.310260
2025-08-17 04:33:22,044 - INFO - Epoch 357/1000 - Train Loss: 0.164778, Val Loss: 0.289204
2025-08-17 04:35:24,356 - INFO - Epoch 358/1000 - Train Loss: 0.162062, Val Loss: 0.284730
2025-08-17 04:37:27,103 - INFO - Epoch 359/1000 - Train Loss: 0.163757, Val Loss: 0.304090
2025-08-17 04:39:29,780 - INFO - Epoch 360/1000 - Train Loss: 0.165956, Val Loss: 0.319820
2025-08-17 04:41:32,740 - INFO - Epoch 361/1000 - Train Loss: 0.163983, Val Loss: 0.304891
2025-08-17 04:43:35,754 - INFO - Epoch 362/1000 - Train Loss: 0.162950, Val Loss: 0.303789
2025-08-17 04:45:38,905 - INFO - Epoch 363/1000 - Train Loss: 0.162564, Val Loss: 0.307550
2025-08-17 04:47:41,996 - INFO - Epoch 364/1000 - Train Loss: 0.161401, Val Loss: 0.291827
2025-08-17 04:49:44,737 - INFO - Epoch 365/1000 - Train Loss: 0.160430, Val Loss: 0.293944
2025-08-17 04:51:47,205 - INFO - Epoch 366/1000 - Train Loss: 0.163086, Val Loss: 0.296037
2025-08-17 04:53:49,443 - INFO - Epoch 367/1000 - Train Loss: 0.165040, Val Loss: 0.296613
2025-08-17 04:55:51,974 - INFO - Epoch 368/1000 - Train Loss: 0.161298, Val Loss: 0.311496
2025-08-17 04:57:55,012 - INFO - Epoch 369/1000 - Train Loss: 0.161240, Val Loss: 0.340734
2025-08-17 04:59:57,943 - INFO - Epoch 370/1000 - Train Loss: 0.161647, Val Loss: 0.295986
2025-08-17 05:02:00,204 - INFO - Epoch 371/1000 - Train Loss: 0.161703, Val Loss: 0.310555
2025-08-17 05:04:02,372 - INFO - Epoch 372/1000 - Train Loss: 0.160675, Val Loss: 0.287921
2025-08-17 05:06:04,582 - INFO - Epoch 373/1000 - Train Loss: 0.160851, Val Loss: 0.304445
2025-08-17 05:08:07,150 - INFO - Epoch 374/1000 - Train Loss: 0.159927, Val Loss: 0.308489
2025-08-17 05:10:09,302 - INFO - Epoch 375/1000 - Train Loss: 0.163686, Val Loss: 0.288037
2025-08-17 05:12:11,560 - INFO - Epoch 376/1000 - Train Loss: 0.159475, Val Loss: 0.296133
2025-08-17 05:14:14,095 - INFO - Epoch 377/1000 - Train Loss: 0.160413, Val Loss: 0.294360
2025-08-17 05:16:16,844 - INFO - Epoch 378/1000 - Train Loss: 0.161057, Val Loss: 0.284434
2025-08-17 05:18:18,681 - INFO - Epoch 379/1000 - Train Loss: 0.161101, Val Loss: 0.313523
2025-08-17 05:20:20,972 - INFO - Epoch 380/1000 - Train Loss: 0.161529, Val Loss: 0.335864
2025-08-17 05:22:24,247 - INFO - Epoch 381/1000 - Train Loss: 0.161047, Val Loss: 0.303769
2025-08-17 05:24:26,784 - INFO - Epoch 382/1000 - Train Loss: 0.159139, Val Loss: 0.290144
2025-08-17 05:26:29,346 - INFO - Epoch 383/1000 - Train Loss: 0.159618, Val Loss: 0.311630
2025-08-17 05:28:31,482 - INFO - Epoch 384/1000 - Train Loss: 0.159468, Val Loss: 0.285771
2025-08-17 05:30:34,304 - INFO - Epoch 385/1000 - Train Loss: 0.157863, Val Loss: 0.290722
2025-08-17 05:32:37,542 - INFO - Epoch 386/1000 - Train Loss: 0.159065, Val Loss: 0.290591
2025-08-17 05:34:41,043 - INFO - Epoch 387/1000 - Train Loss: 0.158400, Val Loss: 0.285668
2025-08-17 05:36:43,779 - INFO - Epoch 388/1000 - Train Loss: 0.158214, Val Loss: 0.305540
2025-08-17 05:38:45,810 - INFO - Epoch 389/1000 - Train Loss: 0.158575, Val Loss: 0.306703
2025-08-17 05:40:48,459 - INFO - Epoch 390/1000 - Train Loss: 0.159004, Val Loss: 0.299400
2025-08-17 05:42:50,696 - INFO - Epoch 391/1000 - Train Loss: 0.157201, Val Loss: 0.293727
2025-08-17 05:44:52,877 - INFO - Epoch 392/1000 - Train Loss: 0.157180, Val Loss: 0.292107
2025-08-17 05:46:57,413 - INFO - Epoch 393/1000 - Train Loss: 0.156235, Val Loss: 0.306115
2025-08-17 05:48:59,949 - INFO - Epoch 394/1000 - Train Loss: 0.155814, Val Loss: 0.294229
2025-08-17 05:51:02,335 - INFO - Epoch 395/1000 - Train Loss: 0.156207, Val Loss: 0.289050
2025-08-17 05:53:05,196 - INFO - Epoch 396/1000 - Train Loss: 0.155914, Val Loss: 0.325636
2025-08-17 05:55:07,495 - INFO - Epoch 397/1000 - Train Loss: 0.157470, Val Loss: 0.295136
2025-08-17 05:57:10,018 - INFO - Epoch 398/1000 - Train Loss: 0.157020, Val Loss: 0.295827
2025-08-17 05:59:12,183 - INFO - Epoch 399/1000 - Train Loss: 0.156474, Val Loss: 0.298403
2025-08-17 06:01:15,104 - INFO - Epoch 400/1000 - Train Loss: 0.154510, Val Loss: 0.311744
2025-08-17 06:03:17,773 - INFO - Epoch 401/1000 - Train Loss: 0.154082, Val Loss: 0.298618
2025-08-17 06:05:19,855 - INFO - Epoch 402/1000 - Train Loss: 0.156978, Val Loss: 0.293735
2025-08-17 06:07:21,868 - INFO - Epoch 403/1000 - Train Loss: 0.157640, Val Loss: 0.300683
2025-08-17 06:09:24,523 - INFO - Epoch 404/1000 - Train Loss: 0.155483, Val Loss: 0.308624
2025-08-17 06:11:27,541 - INFO - Epoch 405/1000 - Train Loss: 0.154174, Val Loss: 0.296559
2025-08-17 06:13:29,651 - INFO - Epoch 406/1000 - Train Loss: 0.153513, Val Loss: 0.306772
2025-08-17 06:15:32,069 - INFO - Epoch 407/1000 - Train Loss: 0.155381, Val Loss: 0.302354
2025-08-17 06:17:34,941 - INFO - Epoch 408/1000 - Train Loss: 0.154249, Val Loss: 0.285150
2025-08-17 06:19:37,571 - INFO - Epoch 409/1000 - Train Loss: 0.154179, Val Loss: 0.296958
2025-08-17 06:21:39,674 - INFO - Epoch 410/1000 - Train Loss: 0.153740, Val Loss: 0.290689
2025-08-17 06:23:42,538 - INFO - Epoch 411/1000 - Train Loss: 0.151153, Val Loss: 0.293004
2025-08-17 06:25:45,318 - INFO - Epoch 412/1000 - Train Loss: 0.153785, Val Loss: 0.289055
2025-08-17 06:27:47,487 - INFO - Epoch 413/1000 - Train Loss: 0.155514, Val Loss: 0.300843
2025-08-17 06:29:50,471 - INFO - Epoch 414/1000 - Train Loss: 0.152699, Val Loss: 0.282606
2025-08-17 06:31:52,664 - INFO - Epoch 415/1000 - Train Loss: 0.150744, Val Loss: 0.295884
2025-08-17 06:33:54,983 - INFO - Epoch 416/1000 - Train Loss: 0.154256, Val Loss: 0.322334
2025-08-17 06:35:57,523 - INFO - Epoch 417/1000 - Train Loss: 0.153559, Val Loss: 0.292421
2025-08-17 06:37:59,963 - INFO - Epoch 418/1000 - Train Loss: 0.152579, Val Loss: 0.312229
2025-08-17 06:40:02,217 - INFO - Epoch 419/1000 - Train Loss: 0.153069, Val Loss: 0.307199
2025-08-17 06:42:04,768 - INFO - Epoch 420/1000 - Train Loss: 0.150645, Val Loss: 0.294501
2025-08-17 06:44:07,062 - INFO - Epoch 421/1000 - Train Loss: 0.151015, Val Loss: 0.280577
2025-08-17 06:46:09,818 - INFO - Epoch 422/1000 - Train Loss: 0.151586, Val Loss: 0.291593
2025-08-17 06:48:12,633 - INFO - Epoch 423/1000 - Train Loss: 0.151046, Val Loss: 0.298439
2025-08-17 06:50:15,099 - INFO - Epoch 424/1000 - Train Loss: 0.150166, Val Loss: 0.302046
2025-08-17 06:52:18,114 - INFO - Epoch 425/1000 - Train Loss: 0.151717, Val Loss: 0.292507
2025-08-17 06:54:20,770 - INFO - Epoch 426/1000 - Train Loss: 0.151703, Val Loss: 0.304325
2025-08-17 06:56:23,031 - INFO - Epoch 427/1000 - Train Loss: 0.151240, Val Loss: 0.290635
2025-08-17 06:58:25,586 - INFO - Epoch 428/1000 - Train Loss: 0.151814, Val Loss: 0.302656
2025-08-17 07:00:27,960 - INFO - Epoch 429/1000 - Train Loss: 0.149633, Val Loss: 0.286716
2025-08-17 07:02:30,855 - INFO - Epoch 430/1000 - Train Loss: 0.150794, Val Loss: 0.294370
2025-08-17 07:04:33,746 - INFO - Epoch 431/1000 - Train Loss: 0.149865, Val Loss: 0.299325
2025-08-17 07:06:35,873 - INFO - Epoch 432/1000 - Train Loss: 0.148162, Val Loss: 0.298323
2025-08-17 07:08:38,818 - INFO - Epoch 433/1000 - Train Loss: 0.148917, Val Loss: 0.288097
2025-08-17 07:10:41,687 - INFO - Epoch 434/1000 - Train Loss: 0.148447, Val Loss: 0.305428
2025-08-17 07:12:44,604 - INFO - Epoch 435/1000 - Train Loss: 0.148885, Val Loss: 0.289493
2025-08-17 07:14:47,058 - INFO - Epoch 436/1000 - Train Loss: 0.149417, Val Loss: 0.288997
2025-08-17 07:16:50,411 - INFO - Epoch 437/1000 - Train Loss: 0.150821, Val Loss: 0.309879
2025-08-17 07:18:52,976 - INFO - Epoch 438/1000 - Train Loss: 0.149127, Val Loss: 0.306517
2025-08-17 07:20:55,723 - INFO - Epoch 439/1000 - Train Loss: 0.149116, Val Loss: 0.291610
2025-08-17 07:22:58,606 - INFO - Epoch 440/1000 - Train Loss: 0.152049, Val Loss: 0.295883
2025-08-17 07:25:00,928 - INFO - Epoch 441/1000 - Train Loss: 0.148836, Val Loss: 0.312924
2025-08-17 07:27:03,530 - INFO - Epoch 442/1000 - Train Loss: 0.148402, Val Loss: 0.294304
2025-08-17 07:29:05,952 - INFO - Epoch 443/1000 - Train Loss: 0.150045, Val Loss: 0.297809
2025-08-17 07:31:08,191 - INFO - Epoch 444/1000 - Train Loss: 0.148047, Val Loss: 0.301871
2025-08-17 07:33:10,967 - INFO - Epoch 445/1000 - Train Loss: 0.148450, Val Loss: 0.303468
2025-08-17 07:35:13,337 - INFO - Epoch 446/1000 - Train Loss: 0.149266, Val Loss: 0.297028
2025-08-17 07:37:16,184 - INFO - Epoch 447/1000 - Train Loss: 0.148884, Val Loss: 0.304143
2025-08-17 07:39:19,784 - INFO - Epoch 448/1000 - Train Loss: 0.149016, Val Loss: 0.302612
2025-08-17 07:41:22,102 - INFO - Epoch 449/1000 - Train Loss: 0.146771, Val Loss: 0.299022
2025-08-17 07:43:24,902 - INFO - Epoch 450/1000 - Train Loss: 0.145487, Val Loss: 0.295916
2025-08-17 07:45:28,310 - INFO - Epoch 451/1000 - Train Loss: 0.147096, Val Loss: 0.282234
2025-08-17 07:47:31,516 - INFO - Epoch 452/1000 - Train Loss: 0.146194, Val Loss: 0.295711
2025-08-17 07:49:34,463 - INFO - Epoch 453/1000 - Train Loss: 0.146750, Val Loss: 0.301147
2025-08-17 07:51:36,716 - INFO - Epoch 454/1000 - Train Loss: 0.148166, Val Loss: 0.296353
2025-08-17 07:53:39,190 - INFO - Epoch 455/1000 - Train Loss: 0.148636, Val Loss: 0.312299
2025-08-17 07:55:42,565 - INFO - Epoch 456/1000 - Train Loss: 0.149159, Val Loss: 0.286007
2025-08-17 07:57:46,280 - INFO - Epoch 457/1000 - Train Loss: 0.147661, Val Loss: 0.295318
2025-08-17 07:59:48,716 - INFO - Epoch 458/1000 - Train Loss: 0.146591, Val Loss: 0.288648
2025-08-17 08:01:51,659 - INFO - Epoch 459/1000 - Train Loss: 0.144043, Val Loss: 0.294322
2025-08-17 08:03:54,350 - INFO - Epoch 460/1000 - Train Loss: 0.147158, Val Loss: 0.290251
2025-08-17 08:05:57,760 - INFO - Epoch 461/1000 - Train Loss: 0.146542, Val Loss: 0.298755
2025-08-17 08:08:00,533 - INFO - Epoch 462/1000 - Train Loss: 0.146696, Val Loss: 0.295184
2025-08-17 08:10:04,308 - INFO - Epoch 463/1000 - Train Loss: 0.145087, Val Loss: 0.293950
2025-08-17 08:12:07,920 - INFO - Epoch 464/1000 - Train Loss: 0.146617, Val Loss: 0.310740
2025-08-17 08:14:10,681 - INFO - Epoch 465/1000 - Train Loss: 0.145027, Val Loss: 0.294719
2025-08-17 08:16:13,214 - INFO - Epoch 466/1000 - Train Loss: 0.144881, Val Loss: 0.285632
2025-08-17 08:18:16,273 - INFO - Epoch 467/1000 - Train Loss: 0.144485, Val Loss: 0.302157
2025-08-17 08:20:18,866 - INFO - Epoch 468/1000 - Train Loss: 0.146080, Val Loss: 0.343297
2025-08-17 08:22:21,613 - INFO - Epoch 469/1000 - Train Loss: 0.145404, Val Loss: 0.306789
2025-08-17 08:24:23,903 - INFO - Epoch 470/1000 - Train Loss: 0.145737, Val Loss: 0.289476
2025-08-17 08:26:27,424 - INFO - Epoch 471/1000 - Train Loss: 0.143388, Val Loss: 0.289995
2025-08-17 08:28:30,150 - INFO - Epoch 472/1000 - Train Loss: 0.144047, Val Loss: 0.311921
2025-08-17 08:30:32,756 - INFO - Epoch 473/1000 - Train Loss: 0.145920, Val Loss: 0.284405
2025-08-17 08:32:35,643 - INFO - Epoch 474/1000 - Train Loss: 0.143139, Val Loss: 0.293116
2025-08-17 08:34:38,106 - INFO - Epoch 475/1000 - Train Loss: 0.144143, Val Loss: 0.299779
2025-08-17 08:36:40,375 - INFO - Epoch 476/1000 - Train Loss: 0.142593, Val Loss: 0.297125
2025-08-17 08:38:44,296 - INFO - Epoch 477/1000 - Train Loss: 0.145174, Val Loss: 0.315013
2025-08-17 08:40:46,851 - INFO - Epoch 478/1000 - Train Loss: 0.142574, Val Loss: 0.290289
2025-08-17 08:42:50,191 - INFO - Epoch 479/1000 - Train Loss: 0.142467, Val Loss: 0.293162
2025-08-17 08:44:53,295 - INFO - Epoch 480/1000 - Train Loss: 0.140681, Val Loss: 0.321385
2025-08-17 08:46:56,210 - INFO - Epoch 481/1000 - Train Loss: 0.141799, Val Loss: 0.299777
2025-08-17 08:48:58,822 - INFO - Epoch 482/1000 - Train Loss: 0.143052, Val Loss: 0.306130
2025-08-17 08:51:01,679 - INFO - Epoch 483/1000 - Train Loss: 0.143770, Val Loss: 0.286338
2025-08-17 08:53:05,106 - INFO - Epoch 484/1000 - Train Loss: 0.142861, Val Loss: 0.293222
2025-08-17 08:55:08,027 - INFO - Epoch 485/1000 - Train Loss: 0.141902, Val Loss: 0.292530
2025-08-17 08:57:10,593 - INFO - Epoch 486/1000 - Train Loss: 0.143154, Val Loss: 0.294547
2025-08-17 08:59:12,977 - INFO - Epoch 487/1000 - Train Loss: 0.141611, Val Loss: 0.306833
2025-08-17 09:01:15,328 - INFO - Epoch 488/1000 - Train Loss: 0.141397, Val Loss: 0.305019
2025-08-17 09:03:18,362 - INFO - Epoch 489/1000 - Train Loss: 0.143015, Val Loss: 0.296414
2025-08-17 09:05:22,008 - INFO - Epoch 490/1000 - Train Loss: 0.140667, Val Loss: 0.303514
2025-08-17 09:07:25,280 - INFO - Epoch 491/1000 - Train Loss: 0.141976, Val Loss: 0.290734
2025-08-17 09:09:27,722 - INFO - Epoch 492/1000 - Train Loss: 0.142609, Val Loss: 0.292195
2025-08-17 09:11:30,363 - INFO - Epoch 493/1000 - Train Loss: 0.144037, Val Loss: 0.344101
2025-08-17 09:13:33,858 - INFO - Epoch 494/1000 - Train Loss: 0.142604, Val Loss: 0.305861
2025-08-17 09:15:36,185 - INFO - Epoch 495/1000 - Train Loss: 0.139829, Val Loss: 0.316036
2025-08-17 09:17:38,446 - INFO - Epoch 496/1000 - Train Loss: 0.140802, Val Loss: 0.284666
2025-08-17 09:19:41,349 - INFO - Epoch 497/1000 - Train Loss: 0.142289, Val Loss: 0.304538
2025-08-17 09:21:43,720 - INFO - Epoch 498/1000 - Train Loss: 0.139439, Val Loss: 0.292656
2025-08-17 09:23:46,675 - INFO - Epoch 499/1000 - Train Loss: 0.138908, Val Loss: 0.290561
2025-08-17 09:25:49,427 - INFO - Epoch 500/1000 - Train Loss: 0.141195, Val Loss: 0.310861
2025-08-17 09:27:53,245 - INFO - Epoch 501/1000 - Train Loss: 0.141140, Val Loss: 0.286967
2025-08-17 09:29:57,835 - INFO - Epoch 502/1000 - Train Loss: 0.140673, Val Loss: 0.294221
2025-08-17 09:32:00,896 - INFO - Epoch 503/1000 - Train Loss: 0.141584, Val Loss: 0.291518
2025-08-17 09:34:03,773 - INFO - Epoch 504/1000 - Train Loss: 0.140533, Val Loss: 0.292900
2025-08-17 09:36:06,665 - INFO - Epoch 505/1000 - Train Loss: 0.140656, Val Loss: 0.296497
2025-08-17 09:38:09,279 - INFO - Epoch 506/1000 - Train Loss: 0.139979, Val Loss: 0.291476
2025-08-17 09:40:12,092 - INFO - Epoch 507/1000 - Train Loss: 0.138813, Val Loss: 0.283338
2025-08-17 09:42:15,529 - INFO - Epoch 508/1000 - Train Loss: 0.139970, Val Loss: 0.285916
2025-08-17 09:44:18,105 - INFO - Epoch 509/1000 - Train Loss: 0.140397, Val Loss: 0.310196
2025-08-17 09:46:21,166 - INFO - Epoch 510/1000 - Train Loss: 0.140053, Val Loss: 0.293567
2025-08-17 09:48:24,797 - INFO - Epoch 511/1000 - Train Loss: 0.140035, Val Loss: 0.302302
2025-08-17 09:50:27,525 - INFO - Epoch 512/1000 - Train Loss: 0.139870, Val Loss: 0.289458
2025-08-17 09:52:30,545 - INFO - Epoch 513/1000 - Train Loss: 0.138720, Val Loss: 0.301316
2025-08-17 09:54:33,447 - INFO - Epoch 514/1000 - Train Loss: 0.139698, Val Loss: 0.310486
2025-08-17 09:56:36,160 - INFO - Epoch 515/1000 - Train Loss: 0.138255, Val Loss: 0.290391
2025-08-17 09:58:39,207 - INFO - Epoch 516/1000 - Train Loss: 0.138725, Val Loss: 0.301595
2025-08-17 10:00:42,999 - INFO - Epoch 517/1000 - Train Loss: 0.139388, Val Loss: 0.283439
2025-08-17 10:02:47,345 - INFO - Epoch 518/1000 - Train Loss: 0.138838, Val Loss: 0.295824
2025-08-17 10:04:50,455 - INFO - Epoch 519/1000 - Train Loss: 0.139689, Val Loss: 0.293549
2025-08-17 10:06:52,912 - INFO - Epoch 520/1000 - Train Loss: 0.140346, Val Loss: 0.299599
2025-08-17 10:08:56,235 - INFO - Epoch 521/1000 - Train Loss: 0.137842, Val Loss: 0.288243
2025-08-17 10:11:00,547 - INFO - Epoch 522/1000 - Train Loss: 0.137282, Val Loss: 0.306229
2025-08-17 10:13:04,342 - INFO - Epoch 523/1000 - Train Loss: 0.137511, Val Loss: 0.282971
2025-08-17 10:15:09,333 - INFO - Epoch 524/1000 - Train Loss: 0.137879, Val Loss: 0.302911
2025-08-17 10:17:13,720 - INFO - Epoch 525/1000 - Train Loss: 0.137180, Val Loss: 0.307571
2025-08-17 10:19:17,356 - INFO - Epoch 526/1000 - Train Loss: 0.138398, Val Loss: 0.287532
2025-08-17 10:21:21,690 - INFO - Epoch 527/1000 - Train Loss: 0.137657, Val Loss: 0.299830
2025-08-17 10:23:24,019 - INFO - Epoch 528/1000 - Train Loss: 0.136689, Val Loss: 0.286331
2025-08-17 10:25:28,947 - INFO - Epoch 529/1000 - Train Loss: 0.137541, Val Loss: 0.300123
2025-08-17 10:27:33,453 - INFO - Epoch 530/1000 - Train Loss: 0.141144, Val Loss: 0.308568
2025-08-17 10:29:36,644 - INFO - Epoch 531/1000 - Train Loss: 0.137745, Val Loss: 0.299420
2025-08-17 10:31:39,864 - INFO - Epoch 532/1000 - Train Loss: 0.137637, Val Loss: 0.302923
2025-08-17 10:33:42,490 - INFO - Epoch 533/1000 - Train Loss: 0.135632, Val Loss: 0.321607
2025-08-17 10:35:45,054 - INFO - Epoch 534/1000 - Train Loss: 0.138355, Val Loss: 0.302107
2025-08-17 10:37:47,906 - INFO - Epoch 535/1000 - Train Loss: 0.136114, Val Loss: 0.330625
2025-08-17 10:39:50,792 - INFO - Epoch 536/1000 - Train Loss: 0.137526, Val Loss: 0.291981
2025-08-17 10:41:52,891 - INFO - Epoch 537/1000 - Train Loss: 0.135651, Val Loss: 0.288683
2025-08-17 10:43:55,868 - INFO - Epoch 538/1000 - Train Loss: 0.135342, Val Loss: 0.295119
2025-08-17 10:45:59,213 - INFO - Epoch 539/1000 - Train Loss: 0.134011, Val Loss: 0.291791
2025-08-17 10:48:01,979 - INFO - Epoch 540/1000 - Train Loss: 0.135513, Val Loss: 0.293719
2025-08-17 10:50:05,016 - INFO - Epoch 541/1000 - Train Loss: 0.134415, Val Loss: 0.305600
2025-08-17 10:52:07,630 - INFO - Epoch 542/1000 - Train Loss: 0.136575, Val Loss: 0.304687
2025-08-17 10:54:10,951 - INFO - Epoch 543/1000 - Train Loss: 0.134397, Val Loss: 0.296529
2025-08-17 10:56:13,619 - INFO - Epoch 544/1000 - Train Loss: 0.134921, Val Loss: 0.287024
2025-08-17 10:58:16,041 - INFO - Epoch 545/1000 - Train Loss: 0.132751, Val Loss: 0.294216
2025-08-17 11:00:18,729 - INFO - Epoch 546/1000 - Train Loss: 0.134566, Val Loss: 0.290324
2025-08-17 11:02:27,709 - INFO - Epoch 547/1000 - Train Loss: 0.134697, Val Loss: 0.304472
2025-08-17 11:04:30,505 - INFO - Epoch 548/1000 - Train Loss: 0.133721, Val Loss: 0.288993
2025-08-17 11:06:33,374 - INFO - Epoch 549/1000 - Train Loss: 0.136914, Val Loss: 0.287906
2025-08-17 11:08:35,993 - INFO - Epoch 550/1000 - Train Loss: 0.134616, Val Loss: 0.308088
2025-08-17 11:10:38,652 - INFO - Epoch 551/1000 - Train Loss: 0.134386, Val Loss: 0.285513
2025-08-17 11:12:41,265 - INFO - Epoch 552/1000 - Train Loss: 0.135457, Val Loss: 0.294263
2025-08-17 11:14:44,292 - INFO - Epoch 553/1000 - Train Loss: 0.134726, Val Loss: 0.316161
2025-08-17 11:16:47,165 - INFO - Epoch 554/1000 - Train Loss: 0.133695, Val Loss: 0.303658
2025-08-17 11:18:50,365 - INFO - Epoch 555/1000 - Train Loss: 0.132749, Val Loss: 0.285893
2025-08-17 11:20:53,214 - INFO - Epoch 556/1000 - Train Loss: 0.133579, Val Loss: 0.290497
2025-08-17 11:22:56,201 - INFO - Epoch 557/1000 - Train Loss: 0.134891, Val Loss: 0.299296
2025-08-17 11:24:58,812 - INFO - Epoch 558/1000 - Train Loss: 0.135499, Val Loss: 0.301503
2025-08-17 11:27:01,838 - INFO - Epoch 559/1000 - Train Loss: 0.135155, Val Loss: 0.295111
2025-08-17 11:29:04,718 - INFO - Epoch 560/1000 - Train Loss: 0.133323, Val Loss: 0.291006
2025-08-17 11:31:07,628 - INFO - Epoch 561/1000 - Train Loss: 0.132082, Val Loss: 0.293628
2025-08-17 11:33:10,372 - INFO - Epoch 562/1000 - Train Loss: 0.132673, Val Loss: 0.297383
2025-08-17 11:35:13,421 - INFO - Epoch 563/1000 - Train Loss: 0.133584, Val Loss: 0.302033
2025-08-17 11:37:16,618 - INFO - Epoch 564/1000 - Train Loss: 0.133268, Val Loss: 0.300247
2025-08-17 11:39:19,649 - INFO - Epoch 565/1000 - Train Loss: 0.134398, Val Loss: 0.298522
2025-08-17 11:41:22,554 - INFO - Epoch 566/1000 - Train Loss: 0.131300, Val Loss: 0.288302
2025-08-17 11:43:25,496 - INFO - Epoch 567/1000 - Train Loss: 0.131253, Val Loss: 0.291303
2025-08-17 11:45:28,501 - INFO - Epoch 568/1000 - Train Loss: 0.132854, Val Loss: 0.291653
2025-08-17 11:47:31,080 - INFO - Epoch 569/1000 - Train Loss: 0.130619, Val Loss: 0.292786
2025-08-17 11:49:33,653 - INFO - Epoch 570/1000 - Train Loss: 0.132964, Val Loss: 0.289855
2025-08-17 11:51:36,707 - INFO - Epoch 571/1000 - Train Loss: 0.133467, Val Loss: 0.285550
2025-08-17 11:53:39,732 - INFO - Epoch 572/1000 - Train Loss: 0.133590, Val Loss: 0.301908
2025-08-17 11:55:42,545 - INFO - Epoch 573/1000 - Train Loss: 0.133674, Val Loss: 0.285695
2025-08-17 11:57:44,694 - INFO - Epoch 574/1000 - Train Loss: 0.130898, Val Loss: 0.287858
2025-08-17 11:59:46,378 - INFO - Epoch 575/1000 - Train Loss: 0.129944, Val Loss: 0.293017
2025-08-17 12:01:47,892 - INFO - Epoch 576/1000 - Train Loss: 0.131360, Val Loss: 0.296678
2025-08-17 12:03:49,351 - INFO - Epoch 577/1000 - Train Loss: 0.130131, Val Loss: 0.305501
2025-08-17 12:05:50,976 - INFO - Epoch 578/1000 - Train Loss: 0.132414, Val Loss: 0.284760
2025-08-17 12:07:52,469 - INFO - Epoch 579/1000 - Train Loss: 0.132737, Val Loss: 0.295248
2025-08-17 12:09:54,294 - INFO - Epoch 580/1000 - Train Loss: 0.130513, Val Loss: 0.302397
2025-08-17 12:11:56,105 - INFO - Epoch 581/1000 - Train Loss: 0.132019, Val Loss: 0.284350
2025-08-17 12:13:57,582 - INFO - Epoch 582/1000 - Train Loss: 0.132329, Val Loss: 0.283509
2025-08-17 12:15:59,016 - INFO - Epoch 583/1000 - Train Loss: 0.131213, Val Loss: 0.284501
2025-08-17 12:18:00,437 - INFO - Epoch 584/1000 - Train Loss: 0.131095, Val Loss: 0.301083
2025-08-17 12:20:01,921 - INFO - Epoch 585/1000 - Train Loss: 0.131131, Val Loss: 0.305384
2025-08-17 12:22:03,589 - INFO - Epoch 586/1000 - Train Loss: 0.129653, Val Loss: 0.297544
2025-08-17 12:24:05,018 - INFO - Epoch 587/1000 - Train Loss: 0.130573, Val Loss: 0.296244
2025-08-17 12:26:06,460 - INFO - Epoch 588/1000 - Train Loss: 0.130002, Val Loss: 0.288405
2025-08-17 12:28:08,161 - INFO - Epoch 589/1000 - Train Loss: 0.131268, Val Loss: 0.282758
2025-08-17 12:30:09,588 - INFO - Epoch 590/1000 - Train Loss: 0.130574, Val Loss: 0.295869
2025-08-17 12:32:11,206 - INFO - Epoch 591/1000 - Train Loss: 0.131155, Val Loss: 0.337356
2025-08-17 12:34:12,580 - INFO - Epoch 592/1000 - Train Loss: 0.132100, Val Loss: 0.301091
2025-08-17 12:36:13,916 - INFO - Epoch 593/1000 - Train Loss: 0.130601, Val Loss: 0.302319
2025-08-17 12:38:15,334 - INFO - Epoch 594/1000 - Train Loss: 0.130060, Val Loss: 0.318130
2025-08-17 12:40:16,607 - INFO - Epoch 595/1000 - Train Loss: 0.130935, Val Loss: 0.295380
2025-08-17 12:42:18,134 - INFO - Epoch 596/1000 - Train Loss: 0.129325, Val Loss: 0.279434
2025-08-17 12:44:19,447 - INFO - Epoch 597/1000 - Train Loss: 0.132485, Val Loss: 0.301068
2025-08-17 12:46:20,886 - INFO - Epoch 598/1000 - Train Loss: 0.129511, Val Loss: 0.291967
2025-08-17 12:48:22,565 - INFO - Epoch 599/1000 - Train Loss: 0.128695, Val Loss: 0.294591
2025-08-17 12:50:24,102 - INFO - Epoch 600/1000 - Train Loss: 0.128790, Val Loss: 0.281103
2025-08-17 12:52:25,871 - INFO - Epoch 601/1000 - Train Loss: 0.129626, Val Loss: 0.295114
2025-08-17 12:54:27,405 - INFO - Epoch 602/1000 - Train Loss: 0.129604, Val Loss: 0.287813
2025-08-17 12:56:29,121 - INFO - Epoch 603/1000 - Train Loss: 0.129367, Val Loss: 0.310059
2025-08-17 12:58:30,484 - INFO - Epoch 604/1000 - Train Loss: 0.128413, Val Loss: 0.291587
2025-08-17 13:00:32,370 - INFO - Epoch 605/1000 - Train Loss: 0.129251, Val Loss: 0.299216
2025-08-17 13:02:33,807 - INFO - Epoch 606/1000 - Train Loss: 0.129334, Val Loss: 0.285875
2025-08-17 13:04:35,197 - INFO - Epoch 607/1000 - Train Loss: 0.131807, Val Loss: 0.297022
2025-08-17 13:06:36,503 - INFO - Epoch 608/1000 - Train Loss: 0.129032, Val Loss: 0.294137
2025-08-17 13:08:37,986 - INFO - Epoch 609/1000 - Train Loss: 0.128929, Val Loss: 0.296801
2025-08-17 13:10:39,405 - INFO - Epoch 610/1000 - Train Loss: 0.128706, Val Loss: 0.295002
2025-08-17 13:12:40,878 - INFO - Epoch 611/1000 - Train Loss: 0.129407, Val Loss: 0.309264
2025-08-17 13:14:42,375 - INFO - Epoch 612/1000 - Train Loss: 0.128672, Val Loss: 0.293712
2025-08-17 13:16:44,037 - INFO - Epoch 613/1000 - Train Loss: 0.128901, Val Loss: 0.295798
2025-08-17 13:18:45,590 - INFO - Epoch 614/1000 - Train Loss: 0.128422, Val Loss: 0.289420
2025-08-17 13:20:47,038 - INFO - Epoch 615/1000 - Train Loss: 0.126840, Val Loss: 0.291905
2025-08-17 13:22:48,773 - INFO - Epoch 616/1000 - Train Loss: 0.126678, Val Loss: 0.299333
2025-08-17 13:24:50,536 - INFO - Epoch 617/1000 - Train Loss: 0.127358, Val Loss: 0.290991
2025-08-17 13:26:52,224 - INFO - Epoch 618/1000 - Train Loss: 0.127510, Val Loss: 0.289011
2025-08-17 13:28:53,692 - INFO - Epoch 619/1000 - Train Loss: 0.128626, Val Loss: 0.288096
2025-08-17 13:30:55,482 - INFO - Epoch 620/1000 - Train Loss: 0.128277, Val Loss: 0.307469
2025-08-17 13:32:57,269 - INFO - Epoch 621/1000 - Train Loss: 0.127502, Val Loss: 0.294023
2025-08-17 13:34:58,850 - INFO - Epoch 622/1000 - Train Loss: 0.125984, Val Loss: 0.311853
2025-08-17 13:37:00,491 - INFO - Epoch 623/1000 - Train Loss: 0.126586, Val Loss: 0.298540
2025-08-17 13:39:02,051 - INFO - Epoch 624/1000 - Train Loss: 0.125573, Val Loss: 0.297674
2025-08-17 13:41:03,494 - INFO - Epoch 625/1000 - Train Loss: 0.127229, Val Loss: 0.281624
2025-08-17 13:43:05,208 - INFO - Epoch 626/1000 - Train Loss: 0.128086, Val Loss: 0.295982
2025-08-17 13:45:07,034 - INFO - Epoch 627/1000 - Train Loss: 0.128384, Val Loss: 0.289193
2025-08-17 13:47:08,683 - INFO - Epoch 628/1000 - Train Loss: 0.127648, Val Loss: 0.306338
2025-08-17 13:49:10,144 - INFO - Epoch 629/1000 - Train Loss: 0.126510, Val Loss: 0.289680
2025-08-17 13:51:11,596 - INFO - Epoch 630/1000 - Train Loss: 0.125265, Val Loss: 0.289061
2025-08-17 13:53:13,181 - INFO - Epoch 631/1000 - Train Loss: 0.125651, Val Loss: 0.288167
2025-08-17 13:55:15,088 - INFO - Epoch 632/1000 - Train Loss: 0.126475, Val Loss: 0.290520
2025-08-17 13:57:16,700 - INFO - Epoch 633/1000 - Train Loss: 0.127134, Val Loss: 0.290582
2025-08-17 13:59:18,097 - INFO - Epoch 634/1000 - Train Loss: 0.126372, Val Loss: 0.302272
2025-08-17 14:01:19,378 - INFO - Epoch 635/1000 - Train Loss: 0.124801, Val Loss: 0.290646
2025-08-17 14:03:20,593 - INFO - Epoch 636/1000 - Train Loss: 0.125438, Val Loss: 0.284989
2025-08-17 14:05:22,038 - INFO - Epoch 637/1000 - Train Loss: 0.125165, Val Loss: 0.299824
2025-08-17 14:07:23,652 - INFO - Epoch 638/1000 - Train Loss: 0.126595, Val Loss: 0.291381
2025-08-17 14:09:25,138 - INFO - Epoch 639/1000 - Train Loss: 0.125809, Val Loss: 0.286553
2025-08-17 14:11:26,673 - INFO - Epoch 640/1000 - Train Loss: 0.124462, Val Loss: 0.295837
2025-08-17 14:13:28,255 - INFO - Epoch 641/1000 - Train Loss: 0.125514, Val Loss: 0.297199
2025-08-17 14:15:29,780 - INFO - Epoch 642/1000 - Train Loss: 0.126487, Val Loss: 0.285708
2025-08-17 14:17:31,304 - INFO - Epoch 643/1000 - Train Loss: 0.126650, Val Loss: 0.317123
2025-08-17 14:19:32,870 - INFO - Epoch 644/1000 - Train Loss: 0.128230, Val Loss: 0.287973
2025-08-17 14:21:34,520 - INFO - Epoch 645/1000 - Train Loss: 0.126244, Val Loss: 0.298618
2025-08-17 14:23:36,278 - INFO - Epoch 646/1000 - Train Loss: 0.124565, Val Loss: 0.291284
2025-08-17 14:25:37,998 - INFO - Epoch 647/1000 - Train Loss: 0.123873, Val Loss: 0.286864
2025-08-17 14:27:41,999 - INFO - Epoch 648/1000 - Train Loss: 0.123925, Val Loss: 0.302116
2025-08-17 14:29:49,686 - INFO - Epoch 649/1000 - Train Loss: 0.123827, Val Loss: 0.292518
2025-08-17 14:31:59,886 - INFO - Epoch 650/1000 - Train Loss: 0.123696, Val Loss: 0.287921
2025-08-17 14:34:09,811 - INFO - Epoch 651/1000 - Train Loss: 0.123730, Val Loss: 0.287589
2025-08-17 14:36:13,402 - INFO - Epoch 652/1000 - Train Loss: 0.126973, Val Loss: 0.301950
2025-08-17 14:38:15,929 - INFO - Epoch 653/1000 - Train Loss: 0.125082, Val Loss: 0.286668
2025-08-17 14:40:18,452 - INFO - Epoch 654/1000 - Train Loss: 0.123926, Val Loss: 0.304836
2025-08-17 14:42:21,117 - INFO - Epoch 655/1000 - Train Loss: 0.123955, Val Loss: 0.281371
2025-08-17 14:44:23,144 - INFO - Epoch 656/1000 - Train Loss: 0.124212, Val Loss: 0.295503
2025-08-17 14:46:25,158 - INFO - Epoch 657/1000 - Train Loss: 0.125906, Val Loss: 0.295920
2025-08-17 14:48:27,430 - INFO - Epoch 658/1000 - Train Loss: 0.124322, Val Loss: 0.311657
2025-08-17 14:50:30,129 - INFO - Epoch 659/1000 - Train Loss: 0.121798, Val Loss: 0.282506
2025-08-17 14:52:32,282 - INFO - Epoch 660/1000 - Train Loss: 0.125030, Val Loss: 0.290717
2025-08-17 14:54:34,879 - INFO - Epoch 661/1000 - Train Loss: 0.124026, Val Loss: 0.301192
2025-08-17 14:56:41,059 - INFO - Epoch 662/1000 - Train Loss: 0.122613, Val Loss: 0.307540
2025-08-17 14:58:42,694 - INFO - Epoch 663/1000 - Train Loss: 0.124172, Val Loss: 0.283596
2025-08-17 15:00:44,307 - INFO - Epoch 664/1000 - Train Loss: 0.125880, Val Loss: 0.292704
2025-08-17 15:02:45,796 - INFO - Epoch 665/1000 - Train Loss: 0.123130, Val Loss: 0.292065
2025-08-17 15:04:47,446 - INFO - Epoch 666/1000 - Train Loss: 0.122804, Val Loss: 0.285736
2025-08-17 15:06:49,155 - INFO - Epoch 667/1000 - Train Loss: 0.121704, Val Loss: 0.286601
2025-08-17 15:08:50,706 - INFO - Epoch 668/1000 - Train Loss: 0.123422, Val Loss: 0.290589
2025-08-17 15:10:52,606 - INFO - Epoch 669/1000 - Train Loss: 0.122220, Val Loss: 0.299682
2025-08-17 15:12:54,145 - INFO - Epoch 670/1000 - Train Loss: 0.122768, Val Loss: 0.290404
2025-08-17 15:14:55,983 - INFO - Epoch 671/1000 - Train Loss: 0.124101, Val Loss: 0.293946
2025-08-17 15:16:57,680 - INFO - Epoch 672/1000 - Train Loss: 0.125777, Val Loss: 0.290200
2025-08-17 15:18:59,418 - INFO - Epoch 673/1000 - Train Loss: 0.122781, Val Loss: 0.312510
2025-08-17 15:21:00,745 - INFO - Epoch 674/1000 - Train Loss: 0.123077, Val Loss: 0.299738
2025-08-17 15:23:02,451 - INFO - Epoch 675/1000 - Train Loss: 0.122093, Val Loss: 0.307163
2025-08-17 15:25:04,042 - INFO - Epoch 676/1000 - Train Loss: 0.122785, Val Loss: 0.300022
2025-08-17 15:27:05,545 - INFO - Epoch 677/1000 - Train Loss: 0.122442, Val Loss: 0.296629
2025-08-17 15:29:07,024 - INFO - Epoch 678/1000 - Train Loss: 0.122127, Val Loss: 0.292708
2025-08-17 15:31:08,592 - INFO - Epoch 679/1000 - Train Loss: 0.122475, Val Loss: 0.288124
2025-08-17 15:33:10,429 - INFO - Epoch 680/1000 - Train Loss: 0.121301, Val Loss: 0.290916
2025-08-17 15:35:12,188 - INFO - Epoch 681/1000 - Train Loss: 0.124019, Val Loss: 0.291498
2025-08-17 15:37:13,965 - INFO - Epoch 682/1000 - Train Loss: 0.121587, Val Loss: 0.302984
2025-08-17 15:39:15,567 - INFO - Epoch 683/1000 - Train Loss: 0.121979, Val Loss: 0.303792
2025-08-17 15:41:17,217 - INFO - Epoch 684/1000 - Train Loss: 0.121571, Val Loss: 0.291153
2025-08-17 15:43:18,655 - INFO - Epoch 685/1000 - Train Loss: 0.120603, Val Loss: 0.306381
2025-08-17 15:45:20,367 - INFO - Epoch 686/1000 - Train Loss: 0.120077, Val Loss: 0.305623
2025-08-17 15:47:21,961 - INFO - Epoch 687/1000 - Train Loss: 0.121321, Val Loss: 0.292799
2025-08-17 15:49:23,454 - INFO - Epoch 688/1000 - Train Loss: 0.121649, Val Loss: 0.303718
2025-08-17 15:51:25,004 - INFO - Epoch 689/1000 - Train Loss: 0.121487, Val Loss: 0.287127
2025-08-17 15:53:26,809 - INFO - Epoch 690/1000 - Train Loss: 0.121405, Val Loss: 0.294535
2025-08-17 15:55:28,241 - INFO - Epoch 691/1000 - Train Loss: 0.121770, Val Loss: 0.298634
2025-08-17 15:57:29,797 - INFO - Epoch 692/1000 - Train Loss: 0.121595, Val Loss: 0.318622
2025-08-17 15:59:31,491 - INFO - Epoch 693/1000 - Train Loss: 0.120840, Val Loss: 0.284888
2025-08-17 16:01:33,494 - INFO - Epoch 694/1000 - Train Loss: 0.120983, Val Loss: 0.295139
2025-08-17 16:03:35,064 - INFO - Epoch 695/1000 - Train Loss: 0.122574, Val Loss: 0.292794
2025-08-17 16:05:37,028 - INFO - Epoch 696/1000 - Train Loss: 0.123108, Val Loss: 0.296853
2025-08-17 16:07:39,071 - INFO - Epoch 697/1000 - Train Loss: 0.120672, Val Loss: 0.299304
2025-08-17 16:09:41,091 - INFO - Epoch 698/1000 - Train Loss: 0.120040, Val Loss: 0.284984
2025-08-17 16:11:42,810 - INFO - Epoch 699/1000 - Train Loss: 0.121253, Val Loss: 0.296915
2025-08-17 16:13:44,716 - INFO - Epoch 700/1000 - Train Loss: 0.121131, Val Loss: 0.295798
2025-08-17 16:15:46,736 - INFO - Epoch 701/1000 - Train Loss: 0.120162, Val Loss: 0.295551
2025-08-17 16:17:48,315 - INFO - Epoch 702/1000 - Train Loss: 0.121298, Val Loss: 0.291705
2025-08-17 16:19:49,378 - INFO - Epoch 703/1000 - Train Loss: 0.120537, Val Loss: 0.303224
2025-08-17 16:21:50,841 - INFO - Epoch 704/1000 - Train Loss: 0.120146, Val Loss: 0.307281
2025-08-17 16:23:52,278 - INFO - Epoch 705/1000 - Train Loss: 0.120767, Val Loss: 0.303321
2025-08-17 16:25:53,828 - INFO - Epoch 706/1000 - Train Loss: 0.119474, Val Loss: 0.285563
2025-08-17 16:27:55,259 - INFO - Epoch 707/1000 - Train Loss: 0.119214, Val Loss: 0.298410
2025-08-17 16:29:56,608 - INFO - Epoch 708/1000 - Train Loss: 0.119971, Val Loss: 0.287888
2025-08-17 16:31:58,043 - INFO - Epoch 709/1000 - Train Loss: 0.120431, Val Loss: 0.291071
2025-08-17 16:33:59,248 - INFO - Epoch 710/1000 - Train Loss: 0.120634, Val Loss: 0.286621
2025-08-17 16:36:00,615 - INFO - Epoch 711/1000 - Train Loss: 0.120587, Val Loss: 0.288022
2025-08-17 16:38:01,944 - INFO - Epoch 712/1000 - Train Loss: 0.119195, Val Loss: 0.288950
2025-08-17 16:40:03,233 - INFO - Epoch 713/1000 - Train Loss: 0.118631, Val Loss: 0.302078
2025-08-17 16:42:04,541 - INFO - Epoch 714/1000 - Train Loss: 0.120649, Val Loss: 0.293824
2025-08-17 16:44:05,922 - INFO - Epoch 715/1000 - Train Loss: 0.119713, Val Loss: 0.289481
2025-08-17 16:46:07,146 - INFO - Epoch 716/1000 - Train Loss: 0.117617, Val Loss: 0.298141
2025-08-17 16:48:08,383 - INFO - Epoch 717/1000 - Train Loss: 0.120475, Val Loss: 0.287311
2025-08-17 16:50:09,534 - INFO - Epoch 718/1000 - Train Loss: 0.120025, Val Loss: 0.290254
2025-08-17 16:52:10,789 - INFO - Epoch 719/1000 - Train Loss: 0.118830, Val Loss: 0.287826
2025-08-17 16:54:12,072 - INFO - Epoch 720/1000 - Train Loss: 0.119440, Val Loss: 0.297427
2025-08-17 16:56:13,460 - INFO - Epoch 721/1000 - Train Loss: 0.119311, Val Loss: 0.286764
2025-08-17 16:58:14,741 - INFO - Epoch 722/1000 - Train Loss: 0.121040, Val Loss: 0.293877
2025-08-17 17:00:15,925 - INFO - Epoch 723/1000 - Train Loss: 0.121421, Val Loss: 0.293953
2025-08-17 17:02:17,018 - INFO - Epoch 724/1000 - Train Loss: 0.119881, Val Loss: 0.294872
2025-08-17 17:04:18,251 - INFO - Epoch 725/1000 - Train Loss: 0.121577, Val Loss: 0.288114
2025-08-17 17:06:19,581 - INFO - Epoch 726/1000 - Train Loss: 0.118846, Val Loss: 0.290580
2025-08-17 17:08:20,654 - INFO - Epoch 727/1000 - Train Loss: 0.119700, Val Loss: 0.294874
2025-08-17 17:10:22,033 - INFO - Epoch 728/1000 - Train Loss: 0.118382, Val Loss: 0.285105
2025-08-17 17:12:23,208 - INFO - Epoch 729/1000 - Train Loss: 0.117356, Val Loss: 0.289887
2025-08-17 17:14:24,397 - INFO - Epoch 730/1000 - Train Loss: 0.117983, Val Loss: 0.300807
2025-08-17 17:16:25,730 - INFO - Epoch 731/1000 - Train Loss: 0.118253, Val Loss: 0.308102
2025-08-17 17:18:26,908 - INFO - Epoch 732/1000 - Train Loss: 0.117966, Val Loss: 0.303674
2025-08-17 17:20:28,204 - INFO - Epoch 733/1000 - Train Loss: 0.117157, Val Loss: 0.310321
2025-08-17 17:22:29,272 - INFO - Epoch 734/1000 - Train Loss: 0.120018, Val Loss: 0.297903
2025-08-17 17:24:30,536 - INFO - Epoch 735/1000 - Train Loss: 0.120130, Val Loss: 0.295039
2025-08-17 17:26:31,716 - INFO - Epoch 736/1000 - Train Loss: 0.117288, Val Loss: 0.308708
2025-08-17 17:28:32,897 - INFO - Epoch 737/1000 - Train Loss: 0.116941, Val Loss: 0.303232
2025-08-17 17:30:34,099 - INFO - Epoch 738/1000 - Train Loss: 0.118391, Val Loss: 0.306280
2025-08-17 17:32:35,656 - INFO - Epoch 739/1000 - Train Loss: 0.120060, Val Loss: 0.289010
2025-08-17 17:34:36,819 - INFO - Epoch 740/1000 - Train Loss: 0.118086, Val Loss: 0.295859
2025-08-17 17:36:38,123 - INFO - Epoch 741/1000 - Train Loss: 0.117195, Val Loss: 0.293358
2025-08-17 17:38:39,426 - INFO - Epoch 742/1000 - Train Loss: 0.117779, Val Loss: 0.291575
2025-08-17 17:40:40,577 - INFO - Epoch 743/1000 - Train Loss: 0.116551, Val Loss: 0.296960
2025-08-17 17:42:41,632 - INFO - Epoch 744/1000 - Train Loss: 0.118142, Val Loss: 0.305114
2025-08-17 17:44:42,862 - INFO - Epoch 745/1000 - Train Loss: 0.118420, Val Loss: 0.282632
2025-08-17 17:46:44,063 - INFO - Epoch 746/1000 - Train Loss: 0.116870, Val Loss: 0.310821
2025-08-17 17:48:45,176 - INFO - Epoch 747/1000 - Train Loss: 0.116543, Val Loss: 0.296092
2025-08-17 17:50:46,318 - INFO - Epoch 748/1000 - Train Loss: 0.117829, Val Loss: 0.295311
2025-08-17 17:52:47,573 - INFO - Epoch 749/1000 - Train Loss: 0.118392, Val Loss: 0.304746
2025-08-17 17:54:50,265 - INFO - Epoch 750/1000 - Train Loss: 0.116013, Val Loss: 0.293260
2025-08-17 17:56:51,638 - INFO - Epoch 751/1000 - Train Loss: 0.116975, Val Loss: 0.295339
2025-08-17 17:58:52,756 - INFO - Epoch 752/1000 - Train Loss: 0.116155, Val Loss: 0.298871
2025-08-17 18:00:53,913 - INFO - Epoch 753/1000 - Train Loss: 0.115628, Val Loss: 0.282810
2025-08-17 18:02:55,402 - INFO - Epoch 754/1000 - Train Loss: 0.115825, Val Loss: 0.294480
2025-08-17 18:04:56,507 - INFO - Epoch 755/1000 - Train Loss: 0.114467, Val Loss: 0.282347
2025-08-17 18:06:57,865 - INFO - Epoch 756/1000 - Train Loss: 0.115632, Val Loss: 0.300879
2025-08-17 18:08:59,179 - INFO - Epoch 757/1000 - Train Loss: 0.116334, Val Loss: 0.295629
2025-08-17 18:11:00,436 - INFO - Epoch 758/1000 - Train Loss: 0.115504, Val Loss: 0.287802
2025-08-17 18:13:01,636 - INFO - Epoch 759/1000 - Train Loss: 0.115196, Val Loss: 0.291648
2025-08-17 18:15:02,931 - INFO - Epoch 760/1000 - Train Loss: 0.116838, Val Loss: 0.292232
2025-08-17 18:17:04,336 - INFO - Epoch 761/1000 - Train Loss: 0.116054, Val Loss: 0.300059
2025-08-17 18:19:05,627 - INFO - Epoch 762/1000 - Train Loss: 0.117961, Val Loss: 0.287018
2025-08-17 18:21:06,821 - INFO - Epoch 763/1000 - Train Loss: 0.117326, Val Loss: 0.299822
2025-08-17 18:23:08,205 - INFO - Epoch 764/1000 - Train Loss: 0.116562, Val Loss: 0.304457
2025-08-17 18:25:09,549 - INFO - Epoch 765/1000 - Train Loss: 0.115838, Val Loss: 0.287907
2025-08-17 18:27:10,910 - INFO - Epoch 766/1000 - Train Loss: 0.115767, Val Loss: 0.297672
2025-08-17 18:29:11,942 - INFO - Epoch 767/1000 - Train Loss: 0.114872, Val Loss: 0.289106
2025-08-17 18:31:13,263 - INFO - Epoch 768/1000 - Train Loss: 0.116018, Val Loss: 0.294690
2025-08-17 18:33:14,498 - INFO - Epoch 769/1000 - Train Loss: 0.114744, Val Loss: 0.286249
2025-08-17 18:35:15,573 - INFO - Epoch 770/1000 - Train Loss: 0.115804, Val Loss: 0.312535
2025-08-17 18:37:16,852 - INFO - Epoch 771/1000 - Train Loss: 0.116663, Val Loss: 0.290329
2025-08-17 18:39:18,184 - INFO - Epoch 772/1000 - Train Loss: 0.115869, Val Loss: 0.290480
2025-08-17 18:41:19,364 - INFO - Epoch 773/1000 - Train Loss: 0.116864, Val Loss: 0.301009
2025-08-17 18:43:20,747 - INFO - Epoch 774/1000 - Train Loss: 0.115802, Val Loss: 0.299731
2025-08-17 18:45:22,068 - INFO - Epoch 775/1000 - Train Loss: 0.116147, Val Loss: 0.297827
2025-08-17 18:47:23,334 - INFO - Epoch 776/1000 - Train Loss: 0.116184, Val Loss: 0.295179
2025-08-17 18:49:24,525 - INFO - Epoch 777/1000 - Train Loss: 0.114778, Val Loss: 0.282832
2025-08-17 18:51:25,771 - INFO - Epoch 778/1000 - Train Loss: 0.113185, Val Loss: 0.300684
2025-08-17 18:53:26,965 - INFO - Epoch 779/1000 - Train Loss: 0.114866, Val Loss: 0.285072
2025-08-17 18:55:28,109 - INFO - Epoch 780/1000 - Train Loss: 0.115749, Val Loss: 0.290078
2025-08-17 18:57:29,405 - INFO - Epoch 781/1000 - Train Loss: 0.114945, Val Loss: 0.293435
2025-08-17 18:59:30,675 - INFO - Epoch 782/1000 - Train Loss: 0.114906, Val Loss: 0.288488
2025-08-17 19:01:31,845 - INFO - Epoch 783/1000 - Train Loss: 0.114325, Val Loss: 0.300034
2025-08-17 19:03:33,031 - INFO - Epoch 784/1000 - Train Loss: 0.114790, Val Loss: 0.284039
2025-08-17 19:05:34,155 - INFO - Epoch 785/1000 - Train Loss: 0.114854, Val Loss: 0.305128
2025-08-17 19:07:35,400 - INFO - Epoch 786/1000 - Train Loss: 0.114088, Val Loss: 0.302767
2025-08-17 19:09:36,613 - INFO - Epoch 787/1000 - Train Loss: 0.114173, Val Loss: 0.286456
2025-08-17 19:11:37,893 - INFO - Epoch 788/1000 - Train Loss: 0.114225, Val Loss: 0.310548
2025-08-17 19:13:39,237 - INFO - Epoch 789/1000 - Train Loss: 0.113544, Val Loss: 0.279953
2025-08-17 19:15:40,491 - INFO - Epoch 790/1000 - Train Loss: 0.114019, Val Loss: 0.295957
2025-08-17 19:17:41,768 - INFO - Epoch 791/1000 - Train Loss: 0.114205, Val Loss: 0.277816
2025-08-17 19:17:41,879 - INFO - New best model saved with Val Loss: 0.277816
2025-08-17 19:19:43,259 - INFO - Epoch 792/1000 - Train Loss: 0.114776, Val Loss: 0.296722
2025-08-17 19:21:44,354 - INFO - Epoch 793/1000 - Train Loss: 0.115179, Val Loss: 0.296724
2025-08-17 19:23:45,534 - INFO - Epoch 794/1000 - Train Loss: 0.113150, Val Loss: 0.296897
2025-08-17 19:25:46,966 - INFO - Epoch 795/1000 - Train Loss: 0.114491, Val Loss: 0.292186
2025-08-17 19:27:48,148 - INFO - Epoch 796/1000 - Train Loss: 0.113363, Val Loss: 0.287164
2025-08-17 19:29:49,494 - INFO - Epoch 797/1000 - Train Loss: 0.115129, Val Loss: 0.289075
2025-08-17 19:31:50,931 - INFO - Epoch 798/1000 - Train Loss: 0.114367, Val Loss: 0.288934
2025-08-17 19:33:52,125 - INFO - Epoch 799/1000 - Train Loss: 0.113499, Val Loss: 0.310421
2025-08-17 19:35:53,455 - INFO - Epoch 800/1000 - Train Loss: 0.114379, Val Loss: 0.288609
2025-08-17 19:37:54,825 - INFO - Epoch 801/1000 - Train Loss: 0.113258, Val Loss: 0.285133
2025-08-17 19:39:55,928 - INFO - Epoch 802/1000 - Train Loss: 0.114154, Val Loss: 0.314405
2025-08-17 19:41:57,324 - INFO - Epoch 803/1000 - Train Loss: 0.112344, Val Loss: 0.286721
2025-08-17 19:43:58,459 - INFO - Epoch 804/1000 - Train Loss: 0.113271, Val Loss: 0.291588
2025-08-17 19:45:59,791 - INFO - Epoch 805/1000 - Train Loss: 0.113206, Val Loss: 0.297087
2025-08-17 19:48:00,983 - INFO - Epoch 806/1000 - Train Loss: 0.112660, Val Loss: 0.298200
2025-08-17 19:50:02,110 - INFO - Epoch 807/1000 - Train Loss: 0.114380, Val Loss: 0.291378
2025-08-17 19:52:03,226 - INFO - Epoch 808/1000 - Train Loss: 0.113058, Val Loss: 0.289048
2025-08-17 19:54:04,429 - INFO - Epoch 809/1000 - Train Loss: 0.112377, Val Loss: 0.297156
2025-08-17 19:56:05,665 - INFO - Epoch 810/1000 - Train Loss: 0.112975, Val Loss: 0.281395
2025-08-17 19:58:06,993 - INFO - Epoch 811/1000 - Train Loss: 0.111925, Val Loss: 0.299509
2025-08-17 20:00:08,294 - INFO - Epoch 812/1000 - Train Loss: 0.114004, Val Loss: 0.296608
2025-08-17 20:02:09,660 - INFO - Epoch 813/1000 - Train Loss: 0.112408, Val Loss: 0.289420
2025-08-17 20:04:10,937 - INFO - Epoch 814/1000 - Train Loss: 0.113225, Val Loss: 0.299218
2025-08-17 20:06:12,122 - INFO - Epoch 815/1000 - Train Loss: 0.112369, Val Loss: 0.302980
2025-08-17 20:08:13,418 - INFO - Epoch 816/1000 - Train Loss: 0.113625, Val Loss: 0.290058
2025-08-17 20:10:14,660 - INFO - Epoch 817/1000 - Train Loss: 0.111865, Val Loss: 0.305247
2025-08-17 20:12:15,930 - INFO - Epoch 818/1000 - Train Loss: 0.111474, Val Loss: 0.284564
2025-08-17 20:14:17,185 - INFO - Epoch 819/1000 - Train Loss: 0.111055, Val Loss: 0.293079
2025-08-17 20:16:18,351 - INFO - Epoch 820/1000 - Train Loss: 0.112103, Val Loss: 0.289286
2025-08-17 20:18:19,550 - INFO - Epoch 821/1000 - Train Loss: 0.111071, Val Loss: 0.310693
2025-08-17 20:20:20,858 - INFO - Epoch 822/1000 - Train Loss: 0.114441, Val Loss: 0.293482
2025-08-17 20:22:22,132 - INFO - Epoch 823/1000 - Train Loss: 0.113677, Val Loss: 0.289852
2025-08-17 20:24:23,330 - INFO - Epoch 824/1000 - Train Loss: 0.112389, Val Loss: 0.292116
2025-08-17 20:26:24,582 - INFO - Epoch 825/1000 - Train Loss: 0.111278, Val Loss: 0.299099
2025-08-17 20:28:25,957 - INFO - Epoch 826/1000 - Train Loss: 0.113945, Val Loss: 0.283595
2025-08-17 20:30:27,104 - INFO - Epoch 827/1000 - Train Loss: 0.113224, Val Loss: 0.298011
2025-08-17 20:32:28,378 - INFO - Epoch 828/1000 - Train Loss: 0.111205, Val Loss: 0.290258
2025-08-17 20:34:29,808 - INFO - Epoch 829/1000 - Train Loss: 0.111219, Val Loss: 0.287470
2025-08-17 20:36:31,420 - INFO - Epoch 830/1000 - Train Loss: 0.111539, Val Loss: 0.290905
2025-08-17 20:38:32,813 - INFO - Epoch 831/1000 - Train Loss: 0.111503, Val Loss: 0.297300
2025-08-17 20:40:34,056 - INFO - Epoch 832/1000 - Train Loss: 0.113170, Val Loss: 0.283739
2025-08-17 20:42:35,384 - INFO - Epoch 833/1000 - Train Loss: 0.113687, Val Loss: 0.293397
2025-08-17 20:44:36,439 - INFO - Epoch 834/1000 - Train Loss: 0.113188, Val Loss: 0.288716
2025-08-17 20:46:37,943 - INFO - Epoch 835/1000 - Train Loss: 0.113429, Val Loss: 0.288725
2025-08-17 20:48:39,076 - INFO - Epoch 836/1000 - Train Loss: 0.111952, Val Loss: 0.291447
2025-08-17 20:50:40,357 - INFO - Epoch 837/1000 - Train Loss: 0.109989, Val Loss: 0.292052
2025-08-17 20:52:41,675 - INFO - Epoch 838/1000 - Train Loss: 0.111410, Val Loss: 0.296312
2025-08-17 20:54:43,059 - INFO - Epoch 839/1000 - Train Loss: 0.110501, Val Loss: 0.295478
2025-08-17 20:56:44,282 - INFO - Epoch 840/1000 - Train Loss: 0.110154, Val Loss: 0.309284
2025-08-17 20:58:45,750 - INFO - Epoch 841/1000 - Train Loss: 0.111337, Val Loss: 0.299042
2025-08-17 21:00:46,885 - INFO - Epoch 842/1000 - Train Loss: 0.111709, Val Loss: 0.306406
2025-08-17 21:02:48,029 - INFO - Epoch 843/1000 - Train Loss: 0.110711, Val Loss: 0.290823
2025-08-17 21:04:49,391 - INFO - Epoch 844/1000 - Train Loss: 0.109635, Val Loss: 0.282742
2025-08-17 21:06:50,848 - INFO - Epoch 845/1000 - Train Loss: 0.111180, Val Loss: 0.285967
2025-08-17 21:08:53,389 - INFO - Epoch 846/1000 - Train Loss: 0.111108, Val Loss: 0.298175
2025-08-17 21:10:57,002 - INFO - Epoch 847/1000 - Train Loss: 0.109649, Val Loss: 0.289270
2025-08-17 21:12:58,723 - INFO - Epoch 848/1000 - Train Loss: 0.110536, Val Loss: 0.291954
2025-08-17 21:15:00,264 - INFO - Epoch 849/1000 - Train Loss: 0.111741, Val Loss: 0.293539
2025-08-17 21:17:01,497 - INFO - Epoch 850/1000 - Train Loss: 0.109994, Val Loss: 0.294087
2025-08-17 21:19:02,837 - INFO - Epoch 851/1000 - Train Loss: 0.112477, Val Loss: 0.286318
2025-08-17 21:21:04,088 - INFO - Epoch 852/1000 - Train Loss: 0.111276, Val Loss: 0.288390
2025-08-17 21:23:05,576 - INFO - Epoch 853/1000 - Train Loss: 0.110122, Val Loss: 0.284160
2025-08-17 21:25:06,943 - INFO - Epoch 854/1000 - Train Loss: 0.109902, Val Loss: 0.313353
2025-08-17 21:27:08,311 - INFO - Epoch 855/1000 - Train Loss: 0.108679, Val Loss: 0.296924
2025-08-17 21:29:09,777 - INFO - Epoch 856/1000 - Train Loss: 0.108679, Val Loss: 0.278635
2025-08-17 21:31:10,979 - INFO - Epoch 857/1000 - Train Loss: 0.111059, Val Loss: 0.291689
2025-08-17 21:33:12,168 - INFO - Epoch 858/1000 - Train Loss: 0.110600, Val Loss: 0.294285
2025-08-17 21:35:13,254 - INFO - Epoch 859/1000 - Train Loss: 0.110827, Val Loss: 0.295385
2025-08-17 21:37:14,510 - INFO - Epoch 860/1000 - Train Loss: 0.110256, Val Loss: 0.292060
2025-08-17 21:39:15,668 - INFO - Epoch 861/1000 - Train Loss: 0.110225, Val Loss: 0.290840
2025-08-17 21:41:16,839 - INFO - Epoch 862/1000 - Train Loss: 0.112147, Val Loss: 0.297113
2025-08-17 21:43:17,984 - INFO - Epoch 863/1000 - Train Loss: 0.109677, Val Loss: 0.294002
2025-08-17 21:45:18,765 - INFO - Epoch 864/1000 - Train Loss: 0.109205, Val Loss: 0.284873
2025-08-17 21:47:19,959 - INFO - Epoch 865/1000 - Train Loss: 0.109641, Val Loss: 0.326573
2025-08-17 21:49:21,380 - INFO - Epoch 866/1000 - Train Loss: 0.108565, Val Loss: 0.284941
2025-08-17 21:51:22,951 - INFO - Epoch 867/1000 - Train Loss: 0.109023, Val Loss: 0.295271
2025-08-17 21:53:24,325 - INFO - Epoch 868/1000 - Train Loss: 0.108943, Val Loss: 0.294698
2025-08-17 21:55:25,615 - INFO - Epoch 869/1000 - Train Loss: 0.109218, Val Loss: 0.293879
2025-08-17 21:57:26,892 - INFO - Epoch 870/1000 - Train Loss: 0.108949, Val Loss: 0.284778
2025-08-17 21:59:28,141 - INFO - Epoch 871/1000 - Train Loss: 0.109261, Val Loss: 0.300952
2025-08-17 22:01:29,790 - INFO - Epoch 872/1000 - Train Loss: 0.108455, Val Loss: 0.297757
2025-08-17 22:03:31,005 - INFO - Epoch 873/1000 - Train Loss: 0.110115, Val Loss: 0.299919
2025-08-17 22:05:32,361 - INFO - Epoch 874/1000 - Train Loss: 0.109396, Val Loss: 0.285345
2025-08-17 22:07:33,842 - INFO - Epoch 875/1000 - Train Loss: 0.108121, Val Loss: 0.292620
2025-08-17 22:09:35,123 - INFO - Epoch 876/1000 - Train Loss: 0.107408, Val Loss: 0.287254
2025-08-17 22:11:36,377 - INFO - Epoch 877/1000 - Train Loss: 0.108811, Val Loss: 0.285932
2025-08-17 22:13:37,477 - INFO - Epoch 878/1000 - Train Loss: 0.108258, Val Loss: 0.297072
2025-08-17 22:15:38,535 - INFO - Epoch 879/1000 - Train Loss: 0.108850, Val Loss: 0.283724
2025-08-17 22:17:39,732 - INFO - Epoch 880/1000 - Train Loss: 0.109414, Val Loss: 0.283736
2025-08-17 22:19:41,294 - INFO - Epoch 881/1000 - Train Loss: 0.110130, Val Loss: 0.288564
2025-08-17 22:21:43,245 - INFO - Epoch 882/1000 - Train Loss: 0.109158, Val Loss: 0.291733
2025-08-17 22:23:44,316 - INFO - Epoch 883/1000 - Train Loss: 0.108694, Val Loss: 0.283078
2025-08-17 22:25:46,309 - INFO - Epoch 884/1000 - Train Loss: 0.107908, Val Loss: 0.295821
2025-08-17 22:27:47,508 - INFO - Epoch 885/1000 - Train Loss: 0.108625, Val Loss: 0.288272
2025-08-17 22:29:48,856 - INFO - Epoch 886/1000 - Train Loss: 0.108782, Val Loss: 0.295602
2025-08-17 22:31:50,144 - INFO - Epoch 887/1000 - Train Loss: 0.108451, Val Loss: 0.289614
2025-08-17 22:33:51,221 - INFO - Epoch 888/1000 - Train Loss: 0.106834, Val Loss: 0.295299
2025-08-17 22:35:52,393 - INFO - Epoch 889/1000 - Train Loss: 0.109005, Val Loss: 0.282280
2025-08-17 22:37:53,472 - INFO - Epoch 890/1000 - Train Loss: 0.107918, Val Loss: 0.304194
2025-08-17 22:39:54,774 - INFO - Epoch 891/1000 - Train Loss: 0.108006, Val Loss: 0.303340
2025-08-17 22:41:56,106 - INFO - Epoch 892/1000 - Train Loss: 0.108618, Val Loss: 0.285451
2025-08-17 22:43:57,195 - INFO - Epoch 893/1000 - Train Loss: 0.107911, Val Loss: 0.295236
2025-08-17 22:45:58,591 - INFO - Epoch 894/1000 - Train Loss: 0.109428, Val Loss: 0.295661
2025-08-17 22:47:59,852 - INFO - Epoch 895/1000 - Train Loss: 0.107774, Val Loss: 0.296018
2025-08-17 22:50:01,163 - INFO - Epoch 896/1000 - Train Loss: 0.109341, Val Loss: 0.308611
2025-08-17 22:52:02,438 - INFO - Epoch 897/1000 - Train Loss: 0.107500, Val Loss: 0.285407
2025-08-17 22:54:03,821 - INFO - Epoch 898/1000 - Train Loss: 0.106390, Val Loss: 0.306294
2025-08-17 22:56:05,326 - INFO - Epoch 899/1000 - Train Loss: 0.107345, Val Loss: 0.290575
2025-08-17 22:58:06,577 - INFO - Epoch 900/1000 - Train Loss: 0.106953, Val Loss: 0.292057
2025-08-17 23:00:08,037 - INFO - Epoch 901/1000 - Train Loss: 0.105919, Val Loss: 0.288537
2025-08-17 23:02:09,294 - INFO - Epoch 902/1000 - Train Loss: 0.106615, Val Loss: 0.287731
2025-08-17 23:04:10,372 - INFO - Epoch 903/1000 - Train Loss: 0.107409, Val Loss: 0.294603
2025-08-17 23:06:11,702 - INFO - Epoch 904/1000 - Train Loss: 0.108316, Val Loss: 0.286835
2025-08-17 23:08:12,998 - INFO - Epoch 905/1000 - Train Loss: 0.108344, Val Loss: 0.289709
2025-08-17 23:10:14,389 - INFO - Epoch 906/1000 - Train Loss: 0.108118, Val Loss: 0.291964
2025-08-17 23:12:15,688 - INFO - Epoch 907/1000 - Train Loss: 0.108271, Val Loss: 0.281890
2025-08-17 23:14:16,894 - INFO - Epoch 908/1000 - Train Loss: 0.109668, Val Loss: 0.289126
2025-08-17 23:16:18,162 - INFO - Epoch 909/1000 - Train Loss: 0.107478, Val Loss: 0.289640
2025-08-17 23:18:19,391 - INFO - Epoch 910/1000 - Train Loss: 0.107120, Val Loss: 0.315691
2025-08-17 23:20:20,861 - INFO - Epoch 911/1000 - Train Loss: 0.107497, Val Loss: 0.305806
2025-08-17 23:22:22,071 - INFO - Epoch 912/1000 - Train Loss: 0.106810, Val Loss: 0.284431
2025-08-17 23:24:23,300 - INFO - Epoch 913/1000 - Train Loss: 0.105262, Val Loss: 0.312294
2025-08-17 23:26:24,401 - INFO - Epoch 914/1000 - Train Loss: 0.105807, Val Loss: 0.297477
2025-08-17 23:28:25,546 - INFO - Epoch 915/1000 - Train Loss: 0.105773, Val Loss: 0.301667
2025-08-17 23:30:26,632 - INFO - Epoch 916/1000 - Train Loss: 0.107672, Val Loss: 0.296588
2025-08-17 23:32:27,711 - INFO - Epoch 917/1000 - Train Loss: 0.107028, Val Loss: 0.292730
2025-08-17 23:34:28,940 - INFO - Epoch 918/1000 - Train Loss: 0.107912, Val Loss: 0.319512
2025-08-17 23:36:30,232 - INFO - Epoch 919/1000 - Train Loss: 0.106368, Val Loss: 0.289825
2025-08-17 23:38:31,325 - INFO - Epoch 920/1000 - Train Loss: 0.107495, Val Loss: 0.301118
2025-08-17 23:40:32,690 - INFO - Epoch 921/1000 - Train Loss: 0.106334, Val Loss: 0.299845
2025-08-17 23:42:33,732 - INFO - Epoch 922/1000 - Train Loss: 0.106674, Val Loss: 0.298707
2025-08-17 23:44:34,816 - INFO - Epoch 923/1000 - Train Loss: 0.106512, Val Loss: 0.286902
2025-08-17 23:46:35,837 - INFO - Epoch 924/1000 - Train Loss: 0.106712, Val Loss: 0.303538
2025-08-17 23:48:37,047 - INFO - Epoch 925/1000 - Train Loss: 0.106472, Val Loss: 0.286812
2025-08-17 23:50:38,300 - INFO - Epoch 926/1000 - Train Loss: 0.107188, Val Loss: 0.280348
2025-08-17 23:52:39,317 - INFO - Epoch 927/1000 - Train Loss: 0.105954, Val Loss: 0.289661
2025-08-17 23:54:40,621 - INFO - Epoch 928/1000 - Train Loss: 0.107653, Val Loss: 0.283109
2025-08-17 23:56:42,239 - INFO - Epoch 929/1000 - Train Loss: 0.105714, Val Loss: 0.288589
2025-08-17 23:58:43,684 - INFO - Epoch 930/1000 - Train Loss: 0.105636, Val Loss: 0.327537
2025-08-18 00:00:44,891 - INFO - Epoch 931/1000 - Train Loss: 0.105280, Val Loss: 0.293204
2025-08-18 00:02:46,146 - INFO - Epoch 932/1000 - Train Loss: 0.106888, Val Loss: 0.286608
2025-08-18 00:04:47,377 - INFO - Epoch 933/1000 - Train Loss: 0.106652, Val Loss: 0.294355
2025-08-18 00:06:48,723 - INFO - Epoch 934/1000 - Train Loss: 0.105615, Val Loss: 0.307549
2025-08-18 00:08:49,917 - INFO - Epoch 935/1000 - Train Loss: 0.105172, Val Loss: 0.289245
2025-08-18 00:10:51,147 - INFO - Epoch 936/1000 - Train Loss: 0.104143, Val Loss: 0.298054
2025-08-18 00:12:52,308 - INFO - Epoch 937/1000 - Train Loss: 0.105656, Val Loss: 0.290094
2025-08-18 00:14:53,541 - INFO - Epoch 938/1000 - Train Loss: 0.106104, Val Loss: 0.285346
2025-08-18 00:16:54,533 - INFO - Epoch 939/1000 - Train Loss: 0.106182, Val Loss: 0.288015
2025-08-18 00:18:55,753 - INFO - Epoch 940/1000 - Train Loss: 0.105500, Val Loss: 0.299143
2025-08-18 00:20:57,041 - INFO - Epoch 941/1000 - Train Loss: 0.105618, Val Loss: 0.283323
2025-08-18 00:22:58,594 - INFO - Epoch 942/1000 - Train Loss: 0.104987, Val Loss: 0.286134
2025-08-18 00:24:59,782 - INFO - Epoch 943/1000 - Train Loss: 0.105203, Val Loss: 0.298817
2025-08-18 00:27:01,056 - INFO - Epoch 944/1000 - Train Loss: 0.105150, Val Loss: 0.286419
2025-08-18 00:29:02,155 - INFO - Epoch 945/1000 - Train Loss: 0.107018, Val Loss: 0.293016
2025-08-18 00:31:03,454 - INFO - Epoch 946/1000 - Train Loss: 0.105211, Val Loss: 0.289719
2025-08-18 00:33:04,618 - INFO - Epoch 947/1000 - Train Loss: 0.105176, Val Loss: 0.287958
2025-08-18 00:35:05,910 - INFO - Epoch 948/1000 - Train Loss: 0.105343, Val Loss: 0.286101
2025-08-18 00:37:07,140 - INFO - Epoch 949/1000 - Train Loss: 0.104328, Val Loss: 0.287214
2025-08-18 00:39:08,375 - INFO - Epoch 950/1000 - Train Loss: 0.103063, Val Loss: 0.297185
2025-08-18 00:41:09,663 - INFO - Epoch 951/1000 - Train Loss: 0.103822, Val Loss: 0.288127
2025-08-18 00:43:11,031 - INFO - Epoch 952/1000 - Train Loss: 0.105136, Val Loss: 0.301613
2025-08-18 00:45:12,256 - INFO - Epoch 953/1000 - Train Loss: 0.104962, Val Loss: 0.291013
2025-08-18 00:47:13,505 - INFO - Epoch 954/1000 - Train Loss: 0.104824, Val Loss: 0.301195
2025-08-18 00:49:14,753 - INFO - Epoch 955/1000 - Train Loss: 0.105942, Val Loss: 0.291537
2025-08-18 00:51:16,025 - INFO - Epoch 956/1000 - Train Loss: 0.104756, Val Loss: 0.283154
2025-08-18 00:53:17,128 - INFO - Epoch 957/1000 - Train Loss: 0.103756, Val Loss: 0.287607
2025-08-18 00:55:18,450 - INFO - Epoch 958/1000 - Train Loss: 0.104172, Val Loss: 0.296236
2025-08-18 00:57:19,589 - INFO - Epoch 959/1000 - Train Loss: 0.104438, Val Loss: 0.286748
2025-08-18 00:59:20,782 - INFO - Epoch 960/1000 - Train Loss: 0.105628, Val Loss: 0.284034
2025-08-18 01:01:22,089 - INFO - Epoch 961/1000 - Train Loss: 0.104879, Val Loss: 0.295086
2025-08-18 01:03:23,324 - INFO - Epoch 962/1000 - Train Loss: 0.104257, Val Loss: 0.286196
2025-08-18 01:05:24,456 - INFO - Epoch 963/1000 - Train Loss: 0.102892, Val Loss: 0.315525
2025-08-18 01:07:25,667 - INFO - Epoch 964/1000 - Train Loss: 0.103052, Val Loss: 0.280324
2025-08-18 01:09:27,119 - INFO - Epoch 965/1000 - Train Loss: 0.103449, Val Loss: 0.307863
2025-08-18 01:11:28,326 - INFO - Epoch 966/1000 - Train Loss: 0.103411, Val Loss: 0.313026
2025-08-18 01:13:29,689 - INFO - Epoch 967/1000 - Train Loss: 0.104000, Val Loss: 0.290575
2025-08-18 01:15:30,862 - INFO - Epoch 968/1000 - Train Loss: 0.105435, Val Loss: 0.291585
2025-08-18 01:17:31,938 - INFO - Epoch 969/1000 - Train Loss: 0.103554, Val Loss: 0.302366
2025-08-18 01:19:33,188 - INFO - Epoch 970/1000 - Train Loss: 0.104391, Val Loss: 0.306674
2025-08-18 01:21:34,471 - INFO - Epoch 971/1000 - Train Loss: 0.103499, Val Loss: 0.303826
2025-08-18 01:23:36,102 - INFO - Epoch 972/1000 - Train Loss: 0.102626, Val Loss: 0.287035
2025-08-18 01:25:37,112 - INFO - Epoch 973/1000 - Train Loss: 0.103060, Val Loss: 0.289842
2025-08-18 01:27:38,598 - INFO - Epoch 974/1000 - Train Loss: 0.104660, Val Loss: 0.292735
2025-08-18 01:29:39,929 - INFO - Epoch 975/1000 - Train Loss: 0.103356, Val Loss: 0.286728
2025-08-18 01:31:41,237 - INFO - Epoch 976/1000 - Train Loss: 0.102727, Val Loss: 0.291595
2025-08-18 01:33:42,322 - INFO - Epoch 977/1000 - Train Loss: 0.102492, Val Loss: 0.288025
2025-08-18 01:35:43,716 - INFO - Epoch 978/1000 - Train Loss: 0.104448, Val Loss: 0.298912
2025-08-18 01:37:44,944 - INFO - Epoch 979/1000 - Train Loss: 0.103317, Val Loss: 0.284426
2025-08-18 01:39:46,144 - INFO - Epoch 980/1000 - Train Loss: 0.103319, Val Loss: 0.284826
2025-08-18 01:41:47,928 - INFO - Epoch 981/1000 - Train Loss: 0.101621, Val Loss: 0.306592
2025-08-18 01:43:49,060 - INFO - Epoch 982/1000 - Train Loss: 0.101770, Val Loss: 0.283666
2025-08-18 01:45:50,199 - INFO - Epoch 983/1000 - Train Loss: 0.102267, Val Loss: 0.285702
2025-08-18 01:47:51,322 - INFO - Epoch 984/1000 - Train Loss: 0.102253, Val Loss: 0.286937
2025-08-18 01:49:52,672 - INFO - Epoch 985/1000 - Train Loss: 0.103212, Val Loss: 0.294077
2025-08-18 01:51:53,798 - INFO - Epoch 986/1000 - Train Loss: 0.103347, Val Loss: 0.297855
2025-08-18 01:53:54,970 - INFO - Epoch 987/1000 - Train Loss: 0.103532, Val Loss: 0.292932
2025-08-18 01:55:55,766 - INFO - Epoch 988/1000 - Train Loss: 0.102285, Val Loss: 0.296708
2025-08-18 01:57:56,877 - INFO - Epoch 989/1000 - Train Loss: 0.102837, Val Loss: 0.295663
2025-08-18 01:59:58,006 - INFO - Epoch 990/1000 - Train Loss: 0.102543, Val Loss: 0.296645
2025-08-18 02:01:59,065 - INFO - Epoch 991/1000 - Train Loss: 0.102760, Val Loss: 0.305689
2025-08-18 02:04:00,042 - INFO - Epoch 992/1000 - Train Loss: 0.100916, Val Loss: 0.294437
2025-08-18 02:06:00,905 - INFO - Epoch 993/1000 - Train Loss: 0.103070, Val Loss: 0.298151
2025-08-18 02:08:02,029 - INFO - Epoch 994/1000 - Train Loss: 0.102424, Val Loss: 0.294453
2025-08-18 02:10:03,027 - INFO - Epoch 995/1000 - Train Loss: 0.103246, Val Loss: 0.295173
2025-08-18 02:12:04,166 - INFO - Epoch 996/1000 - Train Loss: 0.102248, Val Loss: 0.287725
2025-08-18 02:14:05,403 - INFO - Epoch 997/1000 - Train Loss: 0.102765, Val Loss: 0.296961
2025-08-18 02:16:06,546 - INFO - Epoch 998/1000 - Train Loss: 0.101960, Val Loss: 0.288270
2025-08-18 02:18:07,541 - INFO - Epoch 999/1000 - Train Loss: 0.102991, Val Loss: 0.293339
2025-08-18 02:20:08,830 - INFO - Epoch 1000/1000 - Train Loss: 0.101810, Val Loss: 0.291866
2025-08-18 02:20:09,017 - INFO - Final model saved to experiments/Test/final_model.pth
2025-08-18 02:20:09,032 - INFO - Testing the final model
2025-08-18 02:20:26,740 - INFO - Total MSE across all processes: 33.0653076171875
2025-08-18 02:20:26,741 - INFO - mean value for all_targets: {tmp}
2025-08-18 02:20:26,745 - INFO - Test MSE: 0.290047, Test MAE: 0.263866, Max AE: 28.575594, Test R2: 0.7270
2025-08-18 02:20:26,745 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-18 02:20:26,746 - INFO - Total inference time:  0.18s for 114 samples
2025-08-18 02:20:26,758 - INFO - Testing the best model
2025-08-18 02:20:44,526 - INFO - Total MSE across all processes: 31.211278915405273
2025-08-18 02:20:44,529 - INFO - mean value for all_targets: {tmp}
2025-08-18 02:20:44,532 - INFO - Test MSE: 0.273783, Test MAE: 0.259495, Max AE: 28.733593, Test R2: 0.7423
2025-08-18 02:20:44,532 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-08-18 02:20:44,532 - INFO - Total inference time:  0.18s for 114 samples
2025-09-01 11:04:01,802 - INFO - args.exp_name : Test
2025-09-01 11:04:01,844 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 11:04:01,844 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 11:04:01,926 - INFO - [35m n_hidden: 256 [0m
2025-09-01 11:04:01,926 - INFO - [35m n_output: 128 [0m
2025-09-01 11:04:02,326 - INFO - Total trainable parameters: 12465610
2025-09-01 11:04:02,635 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 11:04:02,636 - INFO - Staring training for 1000 epochs
2025-09-01 11:13:53,347 - INFO - args.exp_name : Test
2025-09-01 11:13:53,350 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 11:13:53,350 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 11:13:53,362 - INFO - [35m n_hidden: 256 [0m
2025-09-01 11:13:53,362 - INFO - [35m n_output: 128 [0m
2025-09-01 11:13:53,725 - INFO - Total trainable parameters: 2286017
2025-09-01 11:13:53,963 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 11:13:53,963 - INFO - Staring training for 1000 epochs
2025-09-01 11:16:47,875 - INFO - args.exp_name : Test
2025-09-01 11:16:47,879 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 11:16:47,879 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 11:16:47,891 - INFO - [35m n_hidden: 256 [0m
2025-09-01 11:16:47,891 - INFO - [35m n_output: 128 [0m
2025-09-01 11:16:48,251 - INFO - Total trainable parameters: 2286017
2025-09-01 11:16:48,498 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 11:16:48,502 - INFO - Staring training for 1000 epochs
2025-09-01 11:20:23,042 - INFO - args.exp_name : Test
2025-09-01 11:20:23,044 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 11:20:23,044 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 11:20:23,056 - INFO - [35m n_hidden: 256 [0m
2025-09-01 11:20:23,056 - INFO - [35m n_output: 128 [0m
2025-09-01 11:20:23,422 - INFO - Total trainable parameters: 2286017
2025-09-01 11:20:23,656 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 11:20:23,659 - INFO - Staring training for 1000 epochs
2025-09-01 11:22:43,975 - INFO - args.exp_name : Test
2025-09-01 11:22:43,988 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 11:22:43,988 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 11:22:44,000 - INFO - [35m n_hidden: 256 [0m
2025-09-01 11:22:44,000 - INFO - [35m n_output: 128 [0m
2025-09-01 11:22:44,354 - INFO - Total trainable parameters: 2286017
2025-09-01 11:22:44,591 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 11:22:44,592 - INFO - Staring training for 1000 epochs
2025-09-01 11:23:16,642 - INFO - args.exp_name : Test
2025-09-01 11:23:16,642 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 1000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 11:23:16,642 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 11:23:16,655 - INFO - [35m n_hidden: 256 [0m
2025-09-01 11:23:16,655 - INFO - [35m n_output: 128 [0m
2025-09-01 11:23:17,024 - INFO - Total trainable parameters: 2286017
2025-09-01 11:23:17,257 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 11:23:17,258 - INFO - Staring training for 1000 epochs
2025-09-01 11:23:45,155 - INFO - Epoch 1/1000 - Train Loss: 1.056168, Val Loss: 1.015847
2025-09-01 11:23:45,208 - INFO - New best model saved with Val Loss: 1.015847
2025-09-01 11:24:10,932 - INFO - Epoch 2/1000 - Train Loss: 0.875395, Val Loss: 0.750042
2025-09-01 11:24:10,953 - INFO - New best model saved with Val Loss: 0.750042
2025-09-01 11:24:36,625 - INFO - Epoch 3/1000 - Train Loss: 0.706542, Val Loss: 0.667274
2025-09-01 11:24:36,645 - INFO - New best model saved with Val Loss: 0.667274
2025-09-01 11:25:02,172 - INFO - Epoch 4/1000 - Train Loss: 0.660669, Val Loss: 0.648352
2025-09-01 11:25:02,211 - INFO - New best model saved with Val Loss: 0.648352
2025-09-01 11:25:27,669 - INFO - Epoch 5/1000 - Train Loss: 0.635273, Val Loss: 0.632823
2025-09-01 11:25:27,688 - INFO - New best model saved with Val Loss: 0.632823
2025-09-01 11:25:53,320 - INFO - Epoch 6/1000 - Train Loss: 0.619574, Val Loss: 0.626690
2025-09-01 11:25:53,340 - INFO - New best model saved with Val Loss: 0.626690
2025-09-01 11:26:18,903 - INFO - Epoch 7/1000 - Train Loss: 0.605915, Val Loss: 0.600411
2025-09-01 11:26:18,923 - INFO - New best model saved with Val Loss: 0.600411
2025-09-01 11:26:44,661 - INFO - Epoch 8/1000 - Train Loss: 0.593503, Val Loss: 0.581513
2025-09-01 11:26:44,681 - INFO - New best model saved with Val Loss: 0.581513
2025-09-01 11:27:10,276 - INFO - Epoch 9/1000 - Train Loss: 0.576795, Val Loss: 0.569709
2025-09-01 11:27:10,296 - INFO - New best model saved with Val Loss: 0.569709
2025-09-01 11:27:35,774 - INFO - Epoch 10/1000 - Train Loss: 0.570783, Val Loss: 0.573991
2025-09-01 11:28:01,650 - INFO - Epoch 11/1000 - Train Loss: 0.561627, Val Loss: 0.566849
2025-09-01 11:28:01,674 - INFO - New best model saved with Val Loss: 0.566849
2025-09-01 11:28:27,252 - INFO - Epoch 12/1000 - Train Loss: 0.556711, Val Loss: 0.552829
2025-09-01 11:28:27,289 - INFO - New best model saved with Val Loss: 0.552829
2025-09-01 11:28:52,767 - INFO - Epoch 13/1000 - Train Loss: 0.550674, Val Loss: 0.550492
2025-09-01 11:28:52,806 - INFO - New best model saved with Val Loss: 0.550492
2025-09-01 11:29:18,546 - INFO - Epoch 14/1000 - Train Loss: 0.547937, Val Loss: 0.540840
2025-09-01 11:29:18,574 - INFO - New best model saved with Val Loss: 0.540840
2025-09-01 11:29:44,295 - INFO - Epoch 15/1000 - Train Loss: 0.538862, Val Loss: 0.532854
2025-09-01 11:29:44,325 - INFO - New best model saved with Val Loss: 0.532854
2025-09-01 11:30:09,831 - INFO - Epoch 16/1000 - Train Loss: 0.541332, Val Loss: 0.534566
2025-09-01 11:30:35,643 - INFO - Epoch 17/1000 - Train Loss: 0.533474, Val Loss: 0.539365
2025-09-01 11:31:01,140 - INFO - Epoch 18/1000 - Train Loss: 0.529112, Val Loss: 0.518170
2025-09-01 11:31:01,179 - INFO - New best model saved with Val Loss: 0.518170
2025-09-01 11:31:26,933 - INFO - Epoch 19/1000 - Train Loss: 0.522290, Val Loss: 0.515370
2025-09-01 11:31:26,953 - INFO - New best model saved with Val Loss: 0.515370
2025-09-01 11:31:52,267 - INFO - Epoch 20/1000 - Train Loss: 0.525329, Val Loss: 0.527137
2025-09-01 11:32:18,022 - INFO - Epoch 21/1000 - Train Loss: 0.516851, Val Loss: 0.509659
2025-09-01 11:32:18,042 - INFO - New best model saved with Val Loss: 0.509659
2025-09-01 11:32:43,648 - INFO - Epoch 22/1000 - Train Loss: 0.517313, Val Loss: 0.517760
2025-09-01 11:33:09,167 - INFO - Epoch 23/1000 - Train Loss: 0.514738, Val Loss: 0.518653
2025-09-01 11:33:34,657 - INFO - Epoch 24/1000 - Train Loss: 0.510372, Val Loss: 0.498224
2025-09-01 11:33:34,676 - INFO - New best model saved with Val Loss: 0.498224
2025-09-01 11:34:00,205 - INFO - Epoch 25/1000 - Train Loss: 0.506349, Val Loss: 0.498740
2025-09-01 11:34:25,726 - INFO - Epoch 26/1000 - Train Loss: 0.503998, Val Loss: 0.539363
2025-09-01 11:34:51,434 - INFO - Epoch 27/1000 - Train Loss: 0.513136, Val Loss: 0.496631
2025-09-01 11:34:51,454 - INFO - New best model saved with Val Loss: 0.496631
2025-09-01 11:35:16,909 - INFO - Epoch 28/1000 - Train Loss: 0.500721, Val Loss: 0.499860
2025-09-01 11:35:42,542 - INFO - Epoch 29/1000 - Train Loss: 0.497318, Val Loss: 0.486283
2025-09-01 11:35:42,562 - INFO - New best model saved with Val Loss: 0.486283
2025-09-01 11:36:08,085 - INFO - Epoch 30/1000 - Train Loss: 0.493571, Val Loss: 0.495389
2025-09-01 11:36:33,697 - INFO - Epoch 31/1000 - Train Loss: 0.495245, Val Loss: 0.491789
2025-09-01 11:36:59,264 - INFO - Epoch 32/1000 - Train Loss: 0.494707, Val Loss: 0.484213
2025-09-01 11:36:59,285 - INFO - New best model saved with Val Loss: 0.484213
2025-09-01 11:37:24,829 - INFO - Epoch 33/1000 - Train Loss: 0.492426, Val Loss: 0.482499
2025-09-01 11:37:24,848 - INFO - New best model saved with Val Loss: 0.482499
2025-09-01 11:37:50,617 - INFO - Epoch 34/1000 - Train Loss: 0.491058, Val Loss: 0.491712
2025-09-01 11:38:16,032 - INFO - Epoch 35/1000 - Train Loss: 0.491267, Val Loss: 0.484627
2025-09-01 11:38:41,771 - INFO - Epoch 36/1000 - Train Loss: 0.490704, Val Loss: 0.486219
2025-09-01 11:39:07,431 - INFO - Epoch 37/1000 - Train Loss: 0.491392, Val Loss: 0.477299
2025-09-01 11:39:07,471 - INFO - New best model saved with Val Loss: 0.477299
2025-09-01 11:39:32,924 - INFO - Epoch 38/1000 - Train Loss: 0.483956, Val Loss: 0.480989
2025-09-01 11:39:58,458 - INFO - Epoch 39/1000 - Train Loss: 0.479513, Val Loss: 0.472048
2025-09-01 11:39:58,494 - INFO - New best model saved with Val Loss: 0.472048
2025-09-01 11:40:23,903 - INFO - Epoch 40/1000 - Train Loss: 0.481551, Val Loss: 0.471332
2025-09-01 11:40:23,922 - INFO - New best model saved with Val Loss: 0.471332
2025-09-01 11:40:50,072 - INFO - Epoch 41/1000 - Train Loss: 0.476592, Val Loss: 0.472313
2025-09-01 11:41:15,449 - INFO - Epoch 42/1000 - Train Loss: 0.480180, Val Loss: 0.470733
2025-09-01 11:41:15,469 - INFO - New best model saved with Val Loss: 0.470733
2025-09-01 11:41:41,158 - INFO - Epoch 43/1000 - Train Loss: 0.482159, Val Loss: 0.468418
2025-09-01 11:41:41,178 - INFO - New best model saved with Val Loss: 0.468418
2025-09-01 11:42:06,834 - INFO - Epoch 44/1000 - Train Loss: 0.473163, Val Loss: 0.465565
2025-09-01 11:42:06,853 - INFO - New best model saved with Val Loss: 0.465565
2025-09-01 11:42:32,560 - INFO - Epoch 45/1000 - Train Loss: 0.474198, Val Loss: 0.485222
2025-09-01 11:42:58,268 - INFO - Epoch 46/1000 - Train Loss: 0.473702, Val Loss: 0.470247
2025-09-01 11:43:24,045 - INFO - Epoch 47/1000 - Train Loss: 0.478167, Val Loss: 0.475754
2025-09-01 11:43:49,604 - INFO - Epoch 48/1000 - Train Loss: 0.470765, Val Loss: 0.466037
2025-09-01 11:44:15,199 - INFO - Epoch 49/1000 - Train Loss: 0.474589, Val Loss: 0.460153
2025-09-01 11:44:15,232 - INFO - New best model saved with Val Loss: 0.460153
2025-09-01 11:44:40,732 - INFO - Epoch 50/1000 - Train Loss: 0.467839, Val Loss: 0.463028
2025-09-01 11:45:06,379 - INFO - Epoch 51/1000 - Train Loss: 0.473847, Val Loss: 0.460576
2025-09-01 11:45:32,046 - INFO - Epoch 52/1000 - Train Loss: 0.468685, Val Loss: 0.474487
2025-09-01 11:45:57,750 - INFO - Epoch 53/1000 - Train Loss: 0.466457, Val Loss: 0.457123
2025-09-01 11:45:57,769 - INFO - New best model saved with Val Loss: 0.457123
2025-09-01 11:46:23,456 - INFO - Epoch 54/1000 - Train Loss: 0.462245, Val Loss: 0.468619
2025-09-01 11:46:48,601 - INFO - Epoch 55/1000 - Train Loss: 0.466153, Val Loss: 0.474336
2025-09-01 11:47:14,460 - INFO - Epoch 56/1000 - Train Loss: 0.470213, Val Loss: 0.450516
2025-09-01 11:47:14,497 - INFO - New best model saved with Val Loss: 0.450516
2025-09-01 11:47:40,552 - INFO - Epoch 57/1000 - Train Loss: 0.456739, Val Loss: 0.455432
2025-09-01 11:48:05,958 - INFO - Epoch 58/1000 - Train Loss: 0.458332, Val Loss: 0.451740
2025-09-01 11:48:31,390 - INFO - Epoch 59/1000 - Train Loss: 0.456068, Val Loss: 0.456134
2025-09-01 11:48:56,991 - INFO - Epoch 60/1000 - Train Loss: 0.455678, Val Loss: 0.447210
2025-09-01 11:48:57,011 - INFO - New best model saved with Val Loss: 0.447210
2025-09-01 11:49:22,873 - INFO - Epoch 61/1000 - Train Loss: 0.454283, Val Loss: 0.489659
2025-09-01 11:49:48,720 - INFO - Epoch 62/1000 - Train Loss: 0.458354, Val Loss: 0.443401
2025-09-01 11:49:48,741 - INFO - New best model saved with Val Loss: 0.443401
2025-09-01 11:50:14,397 - INFO - Epoch 63/1000 - Train Loss: 0.447304, Val Loss: 0.456108
2025-09-01 11:50:39,934 - INFO - Epoch 64/1000 - Train Loss: 0.450408, Val Loss: 0.461589
2025-09-01 11:51:05,701 - INFO - Epoch 65/1000 - Train Loss: 0.458063, Val Loss: 0.473511
2025-09-01 11:51:31,162 - INFO - Epoch 66/1000 - Train Loss: 0.448568, Val Loss: 0.440437
2025-09-01 11:51:31,207 - INFO - New best model saved with Val Loss: 0.440437
2025-09-01 11:51:56,840 - INFO - Epoch 67/1000 - Train Loss: 0.446285, Val Loss: 0.443114
2025-09-01 11:52:22,511 - INFO - Epoch 68/1000 - Train Loss: 0.444654, Val Loss: 0.441149
2025-09-01 11:52:48,322 - INFO - Epoch 69/1000 - Train Loss: 0.444451, Val Loss: 0.440143
2025-09-01 11:52:48,342 - INFO - New best model saved with Val Loss: 0.440143
2025-09-01 11:53:13,981 - INFO - Epoch 70/1000 - Train Loss: 0.445009, Val Loss: 0.433517
2025-09-01 11:53:14,001 - INFO - New best model saved with Val Loss: 0.433517
2025-09-01 11:53:39,701 - INFO - Epoch 71/1000 - Train Loss: 0.445875, Val Loss: 0.449245
2025-09-01 11:54:05,072 - INFO - Epoch 72/1000 - Train Loss: 0.440970, Val Loss: 0.447506
2025-09-01 11:54:30,502 - INFO - Epoch 73/1000 - Train Loss: 0.443421, Val Loss: 0.436862
2025-09-01 11:54:56,169 - INFO - Epoch 74/1000 - Train Loss: 0.440775, Val Loss: 0.435553
2025-09-01 11:55:21,876 - INFO - Epoch 75/1000 - Train Loss: 0.438215, Val Loss: 0.435006
2025-09-01 11:55:47,792 - INFO - Epoch 76/1000 - Train Loss: 0.439653, Val Loss: 0.437951
2025-09-01 11:56:13,262 - INFO - Epoch 77/1000 - Train Loss: 0.444836, Val Loss: 0.460200
2025-09-01 11:56:38,585 - INFO - Epoch 78/1000 - Train Loss: 0.437206, Val Loss: 0.425584
2025-09-01 11:56:38,608 - INFO - New best model saved with Val Loss: 0.425584
2025-09-01 11:57:04,328 - INFO - Epoch 79/1000 - Train Loss: 0.439414, Val Loss: 0.434517
2025-09-01 11:57:29,899 - INFO - Epoch 80/1000 - Train Loss: 0.436649, Val Loss: 0.440203
2025-09-01 11:57:55,326 - INFO - Epoch 81/1000 - Train Loss: 0.435237, Val Loss: 0.432543
2025-09-01 11:58:21,141 - INFO - Epoch 82/1000 - Train Loss: 0.437173, Val Loss: 0.435907
2025-09-01 11:58:46,791 - INFO - Epoch 83/1000 - Train Loss: 0.430181, Val Loss: 0.457602
2025-09-01 11:59:12,106 - INFO - Epoch 84/1000 - Train Loss: 0.434453, Val Loss: 0.432737
2025-09-01 11:59:37,751 - INFO - Epoch 85/1000 - Train Loss: 0.429417, Val Loss: 0.440193
2025-09-01 12:00:03,184 - INFO - Epoch 86/1000 - Train Loss: 0.429012, Val Loss: 0.437731
2025-09-01 12:00:28,862 - INFO - Epoch 87/1000 - Train Loss: 0.428205, Val Loss: 0.425643
2025-09-01 12:00:54,348 - INFO - Epoch 88/1000 - Train Loss: 0.437475, Val Loss: 0.436827
2025-09-01 12:01:19,956 - INFO - Epoch 89/1000 - Train Loss: 0.430382, Val Loss: 0.446553
2025-09-01 12:01:45,496 - INFO - Epoch 90/1000 - Train Loss: 0.432030, Val Loss: 0.426456
2025-09-01 12:02:11,231 - INFO - Epoch 91/1000 - Train Loss: 0.429080, Val Loss: 0.453495
2025-09-01 12:02:36,911 - INFO - Epoch 92/1000 - Train Loss: 0.428837, Val Loss: 0.436246
2025-09-01 12:03:02,565 - INFO - Epoch 93/1000 - Train Loss: 0.424819, Val Loss: 0.424269
2025-09-01 12:03:02,586 - INFO - New best model saved with Val Loss: 0.424269
2025-09-01 12:03:28,091 - INFO - Epoch 94/1000 - Train Loss: 0.423849, Val Loss: 0.424479
2025-09-01 12:03:53,572 - INFO - Epoch 95/1000 - Train Loss: 0.431064, Val Loss: 0.432971
2025-09-01 12:04:19,076 - INFO - Epoch 96/1000 - Train Loss: 0.424720, Val Loss: 0.439299
2025-09-01 12:04:44,431 - INFO - Epoch 97/1000 - Train Loss: 0.427440, Val Loss: 0.424164
2025-09-01 12:04:44,451 - INFO - New best model saved with Val Loss: 0.424164
2025-09-01 12:05:10,001 - INFO - Epoch 98/1000 - Train Loss: 0.422400, Val Loss: 0.429350
2025-09-01 12:05:35,414 - INFO - Epoch 99/1000 - Train Loss: 0.423529, Val Loss: 0.420274
2025-09-01 12:05:35,433 - INFO - New best model saved with Val Loss: 0.420274
2025-09-01 12:06:00,929 - INFO - Epoch 100/1000 - Train Loss: 0.419682, Val Loss: 0.414362
2025-09-01 12:06:00,958 - INFO - New best model saved with Val Loss: 0.414362
2025-09-01 12:06:26,567 - INFO - Epoch 101/1000 - Train Loss: 0.422918, Val Loss: 0.418027
2025-09-01 12:06:52,358 - INFO - Epoch 102/1000 - Train Loss: 0.420890, Val Loss: 0.424415
2025-09-01 12:07:17,733 - INFO - Epoch 103/1000 - Train Loss: 0.418429, Val Loss: 0.414021
2025-09-01 12:07:17,753 - INFO - New best model saved with Val Loss: 0.414021
2025-09-01 12:07:43,090 - INFO - Epoch 104/1000 - Train Loss: 0.416163, Val Loss: 0.424333
2025-09-01 12:08:08,519 - INFO - Epoch 105/1000 - Train Loss: 0.423996, Val Loss: 0.412435
2025-09-01 12:08:08,539 - INFO - New best model saved with Val Loss: 0.412435
2025-09-01 12:08:34,226 - INFO - Epoch 106/1000 - Train Loss: 0.417551, Val Loss: 0.418327
2025-09-01 12:08:59,748 - INFO - Epoch 107/1000 - Train Loss: 0.416646, Val Loss: 0.446683
2025-09-01 12:09:25,388 - INFO - Epoch 108/1000 - Train Loss: 0.417593, Val Loss: 0.424255
2025-09-01 12:09:51,101 - INFO - Epoch 109/1000 - Train Loss: 0.413788, Val Loss: 0.418835
2025-09-01 12:10:16,469 - INFO - Epoch 110/1000 - Train Loss: 0.419680, Val Loss: 0.420273
2025-09-01 12:10:42,157 - INFO - Epoch 111/1000 - Train Loss: 0.422688, Val Loss: 0.422007
2025-09-01 12:11:07,584 - INFO - Epoch 112/1000 - Train Loss: 0.422405, Val Loss: 0.453688
2025-09-01 12:11:32,980 - INFO - Epoch 113/1000 - Train Loss: 0.417607, Val Loss: 0.408543
2025-09-01 12:11:33,000 - INFO - New best model saved with Val Loss: 0.408543
2025-09-01 12:11:58,443 - INFO - Epoch 114/1000 - Train Loss: 0.414682, Val Loss: 0.411232
2025-09-01 12:12:24,139 - INFO - Epoch 115/1000 - Train Loss: 0.413130, Val Loss: 0.413983
2025-09-01 12:12:49,598 - INFO - Epoch 116/1000 - Train Loss: 0.413349, Val Loss: 0.411327
2025-09-01 12:13:15,256 - INFO - Epoch 117/1000 - Train Loss: 0.411347, Val Loss: 0.413056
2025-09-01 12:13:40,802 - INFO - Epoch 118/1000 - Train Loss: 0.409850, Val Loss: 0.434564
2025-09-01 12:14:06,423 - INFO - Epoch 119/1000 - Train Loss: 0.412646, Val Loss: 0.423646
2025-09-01 12:14:31,861 - INFO - Epoch 120/1000 - Train Loss: 0.410187, Val Loss: 0.418923
2025-09-01 12:14:57,384 - INFO - Epoch 121/1000 - Train Loss: 0.408835, Val Loss: 0.420447
2025-09-01 12:15:23,142 - INFO - Epoch 122/1000 - Train Loss: 0.406526, Val Loss: 0.402965
2025-09-01 12:15:23,187 - INFO - New best model saved with Val Loss: 0.402965
2025-09-01 12:15:48,592 - INFO - Epoch 123/1000 - Train Loss: 0.408003, Val Loss: 0.409209
2025-09-01 12:16:14,066 - INFO - Epoch 124/1000 - Train Loss: 0.409930, Val Loss: 0.414095
2025-09-01 12:16:39,389 - INFO - Epoch 125/1000 - Train Loss: 0.406378, Val Loss: 0.411590
2025-09-01 12:17:04,874 - INFO - Epoch 126/1000 - Train Loss: 0.407370, Val Loss: 0.432128
2025-09-01 12:17:30,413 - INFO - Epoch 127/1000 - Train Loss: 0.408972, Val Loss: 0.405878
2025-09-01 12:17:55,697 - INFO - Epoch 128/1000 - Train Loss: 0.410693, Val Loss: 0.423206
2025-09-01 12:18:21,355 - INFO - Epoch 129/1000 - Train Loss: 0.408380, Val Loss: 0.436003
2025-09-01 12:18:46,861 - INFO - Epoch 130/1000 - Train Loss: 0.407154, Val Loss: 0.412711
2025-09-01 12:19:12,198 - INFO - Epoch 131/1000 - Train Loss: 0.404372, Val Loss: 0.399249
2025-09-01 12:19:12,237 - INFO - New best model saved with Val Loss: 0.399249
2025-09-01 12:19:37,947 - INFO - Epoch 132/1000 - Train Loss: 0.409074, Val Loss: 0.402585
2025-09-01 12:20:03,572 - INFO - Epoch 133/1000 - Train Loss: 0.403840, Val Loss: 0.401551
2025-09-01 12:20:29,086 - INFO - Epoch 134/1000 - Train Loss: 0.406409, Val Loss: 0.406791
2025-09-01 12:20:54,443 - INFO - Epoch 135/1000 - Train Loss: 0.402522, Val Loss: 0.405867
2025-09-01 12:21:19,972 - INFO - Epoch 136/1000 - Train Loss: 0.403270, Val Loss: 0.407174
2025-09-01 12:21:45,759 - INFO - Epoch 137/1000 - Train Loss: 0.401827, Val Loss: 0.406272
2025-09-01 12:22:11,492 - INFO - Epoch 138/1000 - Train Loss: 0.399398, Val Loss: 0.405140
2025-09-01 12:22:37,376 - INFO - Epoch 139/1000 - Train Loss: 0.398495, Val Loss: 0.411164
2025-09-01 12:23:02,806 - INFO - Epoch 140/1000 - Train Loss: 0.403969, Val Loss: 0.411364
2025-09-01 12:23:28,644 - INFO - Epoch 141/1000 - Train Loss: 0.398145, Val Loss: 0.409925
2025-09-01 12:23:54,186 - INFO - Epoch 142/1000 - Train Loss: 0.400914, Val Loss: 0.400368
2025-09-01 12:24:19,838 - INFO - Epoch 143/1000 - Train Loss: 0.406669, Val Loss: 0.409376
2025-09-01 12:24:45,456 - INFO - Epoch 144/1000 - Train Loss: 0.400280, Val Loss: 0.407004
2025-09-01 12:25:10,941 - INFO - Epoch 145/1000 - Train Loss: 0.396410, Val Loss: 0.404727
2025-09-01 12:25:36,482 - INFO - Epoch 146/1000 - Train Loss: 0.397766, Val Loss: 0.397357
2025-09-01 12:25:36,503 - INFO - New best model saved with Val Loss: 0.397357
2025-09-01 12:26:02,017 - INFO - Epoch 147/1000 - Train Loss: 0.395118, Val Loss: 0.400105
2025-09-01 12:26:27,597 - INFO - Epoch 148/1000 - Train Loss: 0.397984, Val Loss: 0.406356
2025-09-01 12:26:53,036 - INFO - Epoch 149/1000 - Train Loss: 0.402766, Val Loss: 0.403482
2025-09-01 12:27:18,582 - INFO - Epoch 150/1000 - Train Loss: 0.396028, Val Loss: 0.391395
2025-09-01 12:27:18,621 - INFO - New best model saved with Val Loss: 0.391395
2025-09-01 12:27:44,095 - INFO - Epoch 151/1000 - Train Loss: 0.398132, Val Loss: 0.406346
2025-09-01 12:28:09,671 - INFO - Epoch 152/1000 - Train Loss: 0.395991, Val Loss: 0.399652
2025-09-01 12:28:35,143 - INFO - Epoch 153/1000 - Train Loss: 0.392154, Val Loss: 0.390905
2025-09-01 12:28:35,164 - INFO - New best model saved with Val Loss: 0.390905
2025-09-01 12:29:00,595 - INFO - Epoch 154/1000 - Train Loss: 0.397364, Val Loss: 0.400830
2025-09-01 12:29:26,499 - INFO - Epoch 155/1000 - Train Loss: 0.394104, Val Loss: 0.394947
2025-09-01 12:29:51,920 - INFO - Epoch 156/1000 - Train Loss: 0.393864, Val Loss: 0.410712
2025-09-01 12:30:17,529 - INFO - Epoch 157/1000 - Train Loss: 0.392016, Val Loss: 0.386549
2025-09-01 12:30:17,571 - INFO - New best model saved with Val Loss: 0.386549
2025-09-01 12:30:43,264 - INFO - Epoch 158/1000 - Train Loss: 0.392193, Val Loss: 0.392000
2025-09-01 12:31:08,602 - INFO - Epoch 159/1000 - Train Loss: 0.388012, Val Loss: 0.382502
2025-09-01 12:31:08,621 - INFO - New best model saved with Val Loss: 0.382502
2025-09-01 12:31:34,202 - INFO - Epoch 160/1000 - Train Loss: 0.387191, Val Loss: 0.400791
2025-09-01 12:32:00,033 - INFO - Epoch 161/1000 - Train Loss: 0.387177, Val Loss: 0.385075
2025-09-01 12:32:25,610 - INFO - Epoch 162/1000 - Train Loss: 0.390468, Val Loss: 0.423450
2025-09-01 12:32:51,079 - INFO - Epoch 163/1000 - Train Loss: 0.393177, Val Loss: 0.383766
2025-09-01 12:33:16,633 - INFO - Epoch 164/1000 - Train Loss: 0.388437, Val Loss: 0.397361
2025-09-01 12:33:42,093 - INFO - Epoch 165/1000 - Train Loss: 0.387338, Val Loss: 0.384641
2025-09-01 12:34:07,718 - INFO - Epoch 166/1000 - Train Loss: 0.391137, Val Loss: 0.388872
2025-09-01 12:34:33,463 - INFO - Epoch 167/1000 - Train Loss: 0.385992, Val Loss: 0.396096
2025-09-01 12:34:59,139 - INFO - Epoch 168/1000 - Train Loss: 0.384630, Val Loss: 0.384397
2025-09-01 12:35:25,091 - INFO - Epoch 169/1000 - Train Loss: 0.383966, Val Loss: 0.385618
2025-09-01 12:35:50,656 - INFO - Epoch 170/1000 - Train Loss: 0.385022, Val Loss: 0.382196
2025-09-01 12:35:50,677 - INFO - New best model saved with Val Loss: 0.382196
2025-09-01 12:36:16,183 - INFO - Epoch 171/1000 - Train Loss: 0.389361, Val Loss: 0.382947
2025-09-01 12:36:41,887 - INFO - Epoch 172/1000 - Train Loss: 0.384148, Val Loss: 0.391403
2025-09-01 12:37:07,445 - INFO - Epoch 173/1000 - Train Loss: 0.380789, Val Loss: 0.386379
2025-09-01 12:37:33,371 - INFO - Epoch 174/1000 - Train Loss: 0.379953, Val Loss: 0.390952
2025-09-01 12:37:59,139 - INFO - Epoch 175/1000 - Train Loss: 0.379150, Val Loss: 0.386657
2025-09-01 12:38:24,845 - INFO - Epoch 176/1000 - Train Loss: 0.382248, Val Loss: 0.410234
2025-09-01 12:38:50,633 - INFO - Epoch 177/1000 - Train Loss: 0.382135, Val Loss: 0.374307
2025-09-01 12:38:50,773 - INFO - New best model saved with Val Loss: 0.374307
2025-09-01 12:39:16,199 - INFO - Epoch 178/1000 - Train Loss: 0.380870, Val Loss: 0.388343
2025-09-01 12:39:41,503 - INFO - Epoch 179/1000 - Train Loss: 0.381765, Val Loss: 0.379291
2025-09-01 12:40:07,010 - INFO - Epoch 180/1000 - Train Loss: 0.377734, Val Loss: 0.383345
2025-09-01 12:40:32,720 - INFO - Epoch 181/1000 - Train Loss: 0.376974, Val Loss: 0.371051
2025-09-01 12:40:32,740 - INFO - New best model saved with Val Loss: 0.371051
2025-09-01 12:40:58,450 - INFO - Epoch 182/1000 - Train Loss: 0.375045, Val Loss: 0.378664
2025-09-01 12:41:24,141 - INFO - Epoch 183/1000 - Train Loss: 0.375685, Val Loss: 0.386706
2025-09-01 12:41:49,892 - INFO - Epoch 184/1000 - Train Loss: 0.373808, Val Loss: 0.378012
2025-09-01 12:42:15,212 - INFO - Epoch 185/1000 - Train Loss: 0.374054, Val Loss: 0.383527
2025-09-01 12:42:40,742 - INFO - Epoch 186/1000 - Train Loss: 0.377705, Val Loss: 0.376477
2025-09-01 12:43:06,458 - INFO - Epoch 187/1000 - Train Loss: 0.378666, Val Loss: 0.388666
2025-09-01 12:43:32,090 - INFO - Epoch 188/1000 - Train Loss: 0.381836, Val Loss: 0.371098
2025-09-01 12:43:57,744 - INFO - Epoch 189/1000 - Train Loss: 0.370579, Val Loss: 0.368454
2025-09-01 12:43:57,767 - INFO - New best model saved with Val Loss: 0.368454
2025-09-01 12:44:23,409 - INFO - Epoch 190/1000 - Train Loss: 0.369158, Val Loss: 0.386331
2025-09-01 12:44:49,086 - INFO - Epoch 191/1000 - Train Loss: 0.370171, Val Loss: 0.369456
2025-09-01 12:45:14,854 - INFO - Epoch 192/1000 - Train Loss: 0.371930, Val Loss: 0.379977
2025-09-01 12:45:40,629 - INFO - Epoch 193/1000 - Train Loss: 0.368307, Val Loss: 0.368313
2025-09-01 12:45:40,649 - INFO - New best model saved with Val Loss: 0.368313
2025-09-01 12:46:06,092 - INFO - Epoch 194/1000 - Train Loss: 0.373859, Val Loss: 0.376222
2025-09-01 12:46:31,657 - INFO - Epoch 195/1000 - Train Loss: 0.373306, Val Loss: 0.378804
2025-09-01 12:46:57,112 - INFO - Epoch 196/1000 - Train Loss: 0.367066, Val Loss: 0.369336
2025-09-01 12:47:22,689 - INFO - Epoch 197/1000 - Train Loss: 0.367864, Val Loss: 0.374447
2025-09-01 12:47:48,345 - INFO - Epoch 198/1000 - Train Loss: 0.379609, Val Loss: 0.367520
2025-09-01 12:47:48,365 - INFO - New best model saved with Val Loss: 0.367520
2025-09-01 12:48:13,820 - INFO - Epoch 199/1000 - Train Loss: 0.369121, Val Loss: 0.374246
2025-09-01 12:48:39,435 - INFO - Epoch 200/1000 - Train Loss: 0.369037, Val Loss: 0.363627
2025-09-01 12:48:39,455 - INFO - New best model saved with Val Loss: 0.363627
2025-09-01 12:49:05,134 - INFO - Epoch 201/1000 - Train Loss: 0.366927, Val Loss: 0.369404
2025-09-01 12:49:30,534 - INFO - Epoch 202/1000 - Train Loss: 0.369029, Val Loss: 0.359591
2025-09-01 12:49:30,555 - INFO - New best model saved with Val Loss: 0.359591
2025-09-01 12:49:56,416 - INFO - Epoch 203/1000 - Train Loss: 0.361317, Val Loss: 0.358561
2025-09-01 12:49:56,436 - INFO - New best model saved with Val Loss: 0.358561
2025-09-01 12:50:22,101 - INFO - Epoch 204/1000 - Train Loss: 0.360513, Val Loss: 0.370355
2025-09-01 12:50:47,663 - INFO - Epoch 205/1000 - Train Loss: 0.363595, Val Loss: 0.367585
2025-09-01 12:51:13,270 - INFO - Epoch 206/1000 - Train Loss: 0.369806, Val Loss: 0.373040
2025-09-01 12:51:39,073 - INFO - Epoch 207/1000 - Train Loss: 0.361992, Val Loss: 0.362432
2025-09-01 12:52:04,598 - INFO - Epoch 208/1000 - Train Loss: 0.360005, Val Loss: 0.361121
2025-09-01 12:52:30,102 - INFO - Epoch 209/1000 - Train Loss: 0.370077, Val Loss: 0.386689
2025-09-01 12:52:55,592 - INFO - Epoch 210/1000 - Train Loss: 0.361309, Val Loss: 0.363443
2025-09-01 12:53:21,395 - INFO - Epoch 211/1000 - Train Loss: 0.361633, Val Loss: 0.370742
2025-09-01 12:53:47,249 - INFO - Epoch 212/1000 - Train Loss: 0.364075, Val Loss: 0.382162
2025-09-01 12:54:12,765 - INFO - Epoch 213/1000 - Train Loss: 0.365220, Val Loss: 0.376172
2025-09-01 12:54:38,334 - INFO - Epoch 214/1000 - Train Loss: 0.356876, Val Loss: 0.352684
2025-09-01 12:54:38,354 - INFO - New best model saved with Val Loss: 0.352684
2025-09-01 12:55:04,085 - INFO - Epoch 215/1000 - Train Loss: 0.364478, Val Loss: 0.353885
2025-09-01 12:55:29,586 - INFO - Epoch 216/1000 - Train Loss: 0.360741, Val Loss: 0.369793
2025-09-01 12:55:55,291 - INFO - Epoch 217/1000 - Train Loss: 0.357179, Val Loss: 0.361778
2025-09-01 12:56:20,879 - INFO - Epoch 218/1000 - Train Loss: 0.357044, Val Loss: 0.377043
2025-09-01 12:56:46,465 - INFO - Epoch 219/1000 - Train Loss: 0.361286, Val Loss: 0.364465
2025-09-01 12:57:12,057 - INFO - Epoch 220/1000 - Train Loss: 0.361500, Val Loss: 0.380236
2025-09-01 12:57:37,862 - INFO - Epoch 221/1000 - Train Loss: 0.360217, Val Loss: 0.353862
2025-09-01 12:58:03,618 - INFO - Epoch 222/1000 - Train Loss: 0.358270, Val Loss: 0.360134
2025-09-01 12:58:29,639 - INFO - Epoch 223/1000 - Train Loss: 0.355067, Val Loss: 0.347367
2025-09-01 12:58:29,659 - INFO - New best model saved with Val Loss: 0.347367
2025-09-01 12:58:55,148 - INFO - Epoch 224/1000 - Train Loss: 0.362273, Val Loss: 0.373583
2025-09-01 12:59:20,690 - INFO - Epoch 225/1000 - Train Loss: 0.361171, Val Loss: 0.365910
2025-09-01 12:59:46,322 - INFO - Epoch 226/1000 - Train Loss: 0.358639, Val Loss: 0.361916
2025-09-01 13:00:11,826 - INFO - Epoch 227/1000 - Train Loss: 0.357418, Val Loss: 0.354925
2025-09-01 13:00:37,139 - INFO - Epoch 228/1000 - Train Loss: 0.352949, Val Loss: 0.352349
2025-09-01 13:01:02,519 - INFO - Epoch 229/1000 - Train Loss: 0.350265, Val Loss: 0.376030
2025-09-01 13:01:28,134 - INFO - Epoch 230/1000 - Train Loss: 0.354500, Val Loss: 0.354139
2025-09-01 13:01:53,835 - INFO - Epoch 231/1000 - Train Loss: 0.350930, Val Loss: 0.354836
2025-09-01 13:02:19,494 - INFO - Epoch 232/1000 - Train Loss: 0.353891, Val Loss: 0.349729
2025-09-01 13:02:45,008 - INFO - Epoch 233/1000 - Train Loss: 0.356675, Val Loss: 0.357450
2025-09-01 13:03:10,767 - INFO - Epoch 234/1000 - Train Loss: 0.354783, Val Loss: 0.345654
2025-09-01 13:03:10,787 - INFO - New best model saved with Val Loss: 0.345654
2025-09-01 13:03:36,339 - INFO - Epoch 235/1000 - Train Loss: 0.354863, Val Loss: 0.363750
2025-09-01 13:04:01,600 - INFO - Epoch 236/1000 - Train Loss: 0.352383, Val Loss: 0.362169
2025-09-01 13:04:27,170 - INFO - Epoch 237/1000 - Train Loss: 0.348606, Val Loss: 0.348884
2025-09-01 13:04:52,682 - INFO - Epoch 238/1000 - Train Loss: 0.350939, Val Loss: 0.347024
2025-09-01 13:05:18,327 - INFO - Epoch 239/1000 - Train Loss: 0.350391, Val Loss: 0.351512
2025-09-01 13:05:43,738 - INFO - Epoch 240/1000 - Train Loss: 0.357663, Val Loss: 0.355558
2025-09-01 13:06:09,525 - INFO - Epoch 241/1000 - Train Loss: 0.353207, Val Loss: 0.350666
2025-09-01 13:06:35,203 - INFO - Epoch 242/1000 - Train Loss: 0.348739, Val Loss: 0.353311
2025-09-01 13:07:00,951 - INFO - Epoch 243/1000 - Train Loss: 0.350404, Val Loss: 0.343697
2025-09-01 13:07:00,972 - INFO - New best model saved with Val Loss: 0.343697
2025-09-01 13:07:26,407 - INFO - Epoch 244/1000 - Train Loss: 0.348625, Val Loss: 0.355518
2025-09-01 13:07:51,941 - INFO - Epoch 245/1000 - Train Loss: 0.348374, Val Loss: 0.343258
2025-09-01 13:07:51,961 - INFO - New best model saved with Val Loss: 0.343258
2025-09-01 13:08:17,398 - INFO - Epoch 246/1000 - Train Loss: 0.347137, Val Loss: 0.340326
2025-09-01 13:08:17,418 - INFO - New best model saved with Val Loss: 0.340326
2025-09-01 13:08:42,930 - INFO - Epoch 247/1000 - Train Loss: 0.352816, Val Loss: 0.349838
2025-09-01 13:09:08,536 - INFO - Epoch 248/1000 - Train Loss: 0.347345, Val Loss: 0.350692
2025-09-01 13:09:34,063 - INFO - Epoch 249/1000 - Train Loss: 0.348256, Val Loss: 0.345496
2025-09-01 13:09:59,821 - INFO - Epoch 250/1000 - Train Loss: 0.345866, Val Loss: 0.361631
2025-09-01 13:10:25,621 - INFO - Epoch 251/1000 - Train Loss: 0.345154, Val Loss: 0.338399
2025-09-01 13:10:25,640 - INFO - New best model saved with Val Loss: 0.338399
2025-09-01 13:10:51,185 - INFO - Epoch 252/1000 - Train Loss: 0.346099, Val Loss: 0.360094
2025-09-01 13:11:16,699 - INFO - Epoch 253/1000 - Train Loss: 0.341522, Val Loss: 0.359086
2025-09-01 13:11:42,348 - INFO - Epoch 254/1000 - Train Loss: 0.344109, Val Loss: 0.348230
2025-09-01 13:12:08,012 - INFO - Epoch 255/1000 - Train Loss: 0.349415, Val Loss: 0.352705
2025-09-01 13:12:33,588 - INFO - Epoch 256/1000 - Train Loss: 0.343372, Val Loss: 0.351583
2025-09-01 13:12:59,309 - INFO - Epoch 257/1000 - Train Loss: 0.344165, Val Loss: 0.341944
2025-09-01 13:13:24,664 - INFO - Epoch 258/1000 - Train Loss: 0.343957, Val Loss: 0.368790
2025-09-01 13:13:50,141 - INFO - Epoch 259/1000 - Train Loss: 0.343690, Val Loss: 0.346646
2025-09-01 13:14:15,922 - INFO - Epoch 260/1000 - Train Loss: 0.340884, Val Loss: 0.342836
2025-09-01 13:14:41,683 - INFO - Epoch 261/1000 - Train Loss: 0.342082, Val Loss: 0.338433
2025-09-01 13:15:07,415 - INFO - Epoch 262/1000 - Train Loss: 0.339956, Val Loss: 0.337325
2025-09-01 13:15:07,436 - INFO - New best model saved with Val Loss: 0.337325
2025-09-01 13:15:32,936 - INFO - Epoch 263/1000 - Train Loss: 0.336430, Val Loss: 0.337852
2025-09-01 13:15:58,412 - INFO - Epoch 264/1000 - Train Loss: 0.342004, Val Loss: 0.345509
2025-09-01 13:16:24,102 - INFO - Epoch 265/1000 - Train Loss: 0.343372, Val Loss: 0.358024
2025-09-01 13:16:49,668 - INFO - Epoch 266/1000 - Train Loss: 0.338540, Val Loss: 0.346475
2025-09-01 13:17:15,250 - INFO - Epoch 267/1000 - Train Loss: 0.341506, Val Loss: 0.361280
2025-09-01 13:17:40,774 - INFO - Epoch 268/1000 - Train Loss: 0.342068, Val Loss: 0.348893
2025-09-01 13:18:06,024 - INFO - Epoch 269/1000 - Train Loss: 0.336927, Val Loss: 0.333520
2025-09-01 13:18:06,043 - INFO - New best model saved with Val Loss: 0.333520
2025-09-01 13:18:31,510 - INFO - Epoch 270/1000 - Train Loss: 0.334580, Val Loss: 0.340907
2025-09-01 13:18:56,961 - INFO - Epoch 271/1000 - Train Loss: 0.334434, Val Loss: 0.339484
2025-09-01 13:19:22,334 - INFO - Epoch 272/1000 - Train Loss: 0.336173, Val Loss: 0.362226
2025-09-01 13:19:47,921 - INFO - Epoch 273/1000 - Train Loss: 0.337293, Val Loss: 0.334772
2025-09-01 13:20:13,729 - INFO - Epoch 274/1000 - Train Loss: 0.338545, Val Loss: 0.363675
2025-09-01 13:20:39,263 - INFO - Epoch 275/1000 - Train Loss: 0.338534, Val Loss: 0.347327
2025-09-01 13:21:04,662 - INFO - Epoch 276/1000 - Train Loss: 0.332869, Val Loss: 0.328523
2025-09-01 13:21:04,682 - INFO - New best model saved with Val Loss: 0.328523
2025-09-01 13:21:29,995 - INFO - Epoch 277/1000 - Train Loss: 0.333015, Val Loss: 0.335401
2025-09-01 13:21:55,582 - INFO - Epoch 278/1000 - Train Loss: 0.331400, Val Loss: 0.349888
2025-09-01 13:22:21,061 - INFO - Epoch 279/1000 - Train Loss: 0.331867, Val Loss: 0.342585
2025-09-01 13:22:46,399 - INFO - Epoch 280/1000 - Train Loss: 0.332806, Val Loss: 0.331394
2025-09-01 13:23:11,950 - INFO - Epoch 281/1000 - Train Loss: 0.337093, Val Loss: 0.339632
2025-09-01 13:23:37,533 - INFO - Epoch 282/1000 - Train Loss: 0.333376, Val Loss: 0.334106
2025-09-01 13:24:02,940 - INFO - Epoch 283/1000 - Train Loss: 0.330077, Val Loss: 0.340717
2025-09-01 13:24:28,515 - INFO - Epoch 284/1000 - Train Loss: 0.328909, Val Loss: 0.352742
2025-09-01 13:24:54,099 - INFO - Epoch 285/1000 - Train Loss: 0.333008, Val Loss: 0.327582
2025-09-01 13:24:54,119 - INFO - New best model saved with Val Loss: 0.327582
2025-09-01 13:25:19,831 - INFO - Epoch 286/1000 - Train Loss: 0.331473, Val Loss: 0.348078
2025-09-01 13:25:45,286 - INFO - Epoch 287/1000 - Train Loss: 0.330918, Val Loss: 0.323776
2025-09-01 13:25:45,306 - INFO - New best model saved with Val Loss: 0.323776
2025-09-01 13:26:10,414 - INFO - Epoch 288/1000 - Train Loss: 0.327413, Val Loss: 0.333460
2025-09-01 13:26:35,946 - INFO - Epoch 289/1000 - Train Loss: 0.328680, Val Loss: 0.324710
2025-09-01 13:27:01,586 - INFO - Epoch 290/1000 - Train Loss: 0.324958, Val Loss: 0.332587
2025-09-01 13:27:26,974 - INFO - Epoch 291/1000 - Train Loss: 0.323567, Val Loss: 0.325841
2025-09-01 13:27:52,405 - INFO - Epoch 292/1000 - Train Loss: 0.325342, Val Loss: 0.321481
2025-09-01 13:27:52,424 - INFO - New best model saved with Val Loss: 0.321481
2025-09-01 13:28:18,003 - INFO - Epoch 293/1000 - Train Loss: 0.326297, Val Loss: 0.326199
2025-09-01 13:28:43,494 - INFO - Epoch 294/1000 - Train Loss: 0.332521, Val Loss: 0.329418
2025-09-01 13:29:09,346 - INFO - Epoch 295/1000 - Train Loss: 0.326126, Val Loss: 0.321516
2025-09-01 13:29:35,161 - INFO - Epoch 296/1000 - Train Loss: 0.324190, Val Loss: 0.327532
2025-09-01 13:30:00,614 - INFO - Epoch 297/1000 - Train Loss: 0.328871, Val Loss: 0.339569
2025-09-01 13:30:26,414 - INFO - Epoch 298/1000 - Train Loss: 0.326416, Val Loss: 0.325440
2025-09-01 13:30:51,889 - INFO - Epoch 299/1000 - Train Loss: 0.323209, Val Loss: 0.330133
2025-09-01 13:31:17,458 - INFO - Epoch 300/1000 - Train Loss: 0.323687, Val Loss: 0.344557
2025-09-01 13:31:43,163 - INFO - Epoch 301/1000 - Train Loss: 0.326270, Val Loss: 0.325829
2025-09-01 13:32:08,591 - INFO - Epoch 302/1000 - Train Loss: 0.324015, Val Loss: 0.323447
2025-09-01 13:32:34,375 - INFO - Epoch 303/1000 - Train Loss: 0.324136, Val Loss: 0.336059
2025-09-01 13:32:59,884 - INFO - Epoch 304/1000 - Train Loss: 0.323058, Val Loss: 0.317006
2025-09-01 13:32:59,906 - INFO - New best model saved with Val Loss: 0.317006
2025-09-01 13:33:25,455 - INFO - Epoch 305/1000 - Train Loss: 0.316977, Val Loss: 0.335474
2025-09-01 13:33:51,047 - INFO - Epoch 306/1000 - Train Loss: 0.317218, Val Loss: 0.329363
2025-09-01 13:34:16,743 - INFO - Epoch 307/1000 - Train Loss: 0.316388, Val Loss: 0.326449
2025-09-01 13:34:42,217 - INFO - Epoch 308/1000 - Train Loss: 0.316129, Val Loss: 0.326919
2025-09-01 13:35:07,880 - INFO - Epoch 309/1000 - Train Loss: 0.319763, Val Loss: 0.324678
2025-09-01 13:35:33,417 - INFO - Epoch 310/1000 - Train Loss: 0.318768, Val Loss: 0.324252
2025-09-01 13:35:59,013 - INFO - Epoch 311/1000 - Train Loss: 0.317019, Val Loss: 0.323041
2025-09-01 13:36:24,566 - INFO - Epoch 312/1000 - Train Loss: 0.315994, Val Loss: 0.335315
2025-09-01 13:36:50,161 - INFO - Epoch 313/1000 - Train Loss: 0.318755, Val Loss: 0.313493
2025-09-01 13:36:50,183 - INFO - New best model saved with Val Loss: 0.313493
2025-09-01 13:37:15,372 - INFO - Epoch 314/1000 - Train Loss: 0.315207, Val Loss: 0.311330
2025-09-01 13:37:15,394 - INFO - New best model saved with Val Loss: 0.311330
2025-09-01 13:37:40,978 - INFO - Epoch 315/1000 - Train Loss: 0.316650, Val Loss: 0.312028
2025-09-01 13:38:06,685 - INFO - Epoch 316/1000 - Train Loss: 0.320513, Val Loss: 0.314375
2025-09-01 13:38:32,454 - INFO - Epoch 317/1000 - Train Loss: 0.321383, Val Loss: 0.311011
2025-09-01 13:38:32,490 - INFO - New best model saved with Val Loss: 0.311011
2025-09-01 13:38:58,168 - INFO - Epoch 318/1000 - Train Loss: 0.314002, Val Loss: 0.329330
2025-09-01 13:39:23,791 - INFO - Epoch 319/1000 - Train Loss: 0.312501, Val Loss: 0.313909
2025-09-01 13:39:49,601 - INFO - Epoch 320/1000 - Train Loss: 0.314544, Val Loss: 0.314234
2025-09-01 13:40:15,588 - INFO - Epoch 321/1000 - Train Loss: 0.312983, Val Loss: 0.318425
2025-09-01 13:40:41,091 - INFO - Epoch 322/1000 - Train Loss: 0.317619, Val Loss: 0.322689
2025-09-01 13:41:06,547 - INFO - Epoch 323/1000 - Train Loss: 0.316514, Val Loss: 0.314858
2025-09-01 13:41:32,138 - INFO - Epoch 324/1000 - Train Loss: 0.313649, Val Loss: 0.319893
2025-09-01 13:41:58,023 - INFO - Epoch 325/1000 - Train Loss: 0.314385, Val Loss: 0.318630
2025-09-01 13:42:23,480 - INFO - Epoch 326/1000 - Train Loss: 0.307451, Val Loss: 0.305800
2025-09-01 13:42:23,504 - INFO - New best model saved with Val Loss: 0.305800
2025-09-01 13:42:49,051 - INFO - Epoch 327/1000 - Train Loss: 0.308137, Val Loss: 0.302532
2025-09-01 13:42:49,073 - INFO - New best model saved with Val Loss: 0.302532
2025-09-01 13:43:14,549 - INFO - Epoch 328/1000 - Train Loss: 0.312071, Val Loss: 0.303342
2025-09-01 13:43:40,237 - INFO - Epoch 329/1000 - Train Loss: 0.310036, Val Loss: 0.308959
2025-09-01 13:44:05,819 - INFO - Epoch 330/1000 - Train Loss: 0.306895, Val Loss: 0.312704
2025-09-01 13:44:31,496 - INFO - Epoch 331/1000 - Train Loss: 0.308838, Val Loss: 0.307919
2025-09-01 13:44:57,285 - INFO - Epoch 332/1000 - Train Loss: 0.308502, Val Loss: 0.306546
2025-09-01 13:45:22,649 - INFO - Epoch 333/1000 - Train Loss: 0.307514, Val Loss: 0.303203
2025-09-01 13:45:48,143 - INFO - Epoch 334/1000 - Train Loss: 0.309045, Val Loss: 0.307677
2025-09-01 13:46:13,535 - INFO - Epoch 335/1000 - Train Loss: 0.307942, Val Loss: 0.309401
2025-09-01 13:46:39,488 - INFO - Epoch 336/1000 - Train Loss: 0.307555, Val Loss: 0.298929
2025-09-01 13:46:39,509 - INFO - New best model saved with Val Loss: 0.298929
2025-09-01 13:47:05,156 - INFO - Epoch 337/1000 - Train Loss: 0.304885, Val Loss: 0.307705
2025-09-01 13:47:30,847 - INFO - Epoch 338/1000 - Train Loss: 0.306823, Val Loss: 0.306633
2025-09-01 13:47:56,050 - INFO - Epoch 339/1000 - Train Loss: 0.309012, Val Loss: 0.302956
2025-09-01 13:48:21,506 - INFO - Epoch 340/1000 - Train Loss: 0.311479, Val Loss: 0.305317
2025-09-01 13:48:47,147 - INFO - Epoch 341/1000 - Train Loss: 0.304658, Val Loss: 0.308573
2025-09-01 13:49:12,839 - INFO - Epoch 342/1000 - Train Loss: 0.302805, Val Loss: 0.304353
2025-09-01 13:49:38,437 - INFO - Epoch 343/1000 - Train Loss: 0.303689, Val Loss: 0.305591
2025-09-01 13:50:03,953 - INFO - Epoch 344/1000 - Train Loss: 0.307813, Val Loss: 0.324498
2025-09-01 13:50:29,589 - INFO - Epoch 345/1000 - Train Loss: 0.306012, Val Loss: 0.301781
2025-09-01 13:50:55,083 - INFO - Epoch 346/1000 - Train Loss: 0.302579, Val Loss: 0.306504
2025-09-01 13:51:20,426 - INFO - Epoch 347/1000 - Train Loss: 0.305204, Val Loss: 0.297571
2025-09-01 13:51:20,447 - INFO - New best model saved with Val Loss: 0.297571
2025-09-01 13:51:45,774 - INFO - Epoch 348/1000 - Train Loss: 0.302434, Val Loss: 0.304822
2025-09-01 13:52:11,180 - INFO - Epoch 349/1000 - Train Loss: 0.303598, Val Loss: 0.302907
2025-09-01 13:52:36,635 - INFO - Epoch 350/1000 - Train Loss: 0.299104, Val Loss: 0.308414
2025-09-01 13:53:02,543 - INFO - Epoch 351/1000 - Train Loss: 0.300542, Val Loss: 0.307043
2025-09-01 13:53:27,965 - INFO - Epoch 352/1000 - Train Loss: 0.301613, Val Loss: 0.307885
2025-09-01 13:53:53,611 - INFO - Epoch 353/1000 - Train Loss: 0.297836, Val Loss: 0.316301
2025-09-01 13:54:18,996 - INFO - Epoch 354/1000 - Train Loss: 0.300772, Val Loss: 0.298960
2025-09-01 13:54:44,530 - INFO - Epoch 355/1000 - Train Loss: 0.295882, Val Loss: 0.304983
2025-09-01 13:55:09,913 - INFO - Epoch 356/1000 - Train Loss: 0.298073, Val Loss: 0.310687
2025-09-01 13:55:35,627 - INFO - Epoch 357/1000 - Train Loss: 0.299656, Val Loss: 0.294207
2025-09-01 13:55:35,650 - INFO - New best model saved with Val Loss: 0.294207
2025-09-01 13:56:01,232 - INFO - Epoch 358/1000 - Train Loss: 0.299130, Val Loss: 0.307433
2025-09-01 13:56:26,924 - INFO - Epoch 359/1000 - Train Loss: 0.295477, Val Loss: 0.294851
2025-09-01 13:56:52,510 - INFO - Epoch 360/1000 - Train Loss: 0.297192, Val Loss: 0.298823
2025-09-01 13:57:18,291 - INFO - Epoch 361/1000 - Train Loss: 0.294951, Val Loss: 0.295367
2025-09-01 13:57:43,992 - INFO - Epoch 362/1000 - Train Loss: 0.298992, Val Loss: 0.327113
2025-09-01 13:58:09,629 - INFO - Epoch 363/1000 - Train Loss: 0.297562, Val Loss: 0.303156
2025-09-01 13:58:35,009 - INFO - Epoch 364/1000 - Train Loss: 0.297253, Val Loss: 0.293925
2025-09-01 13:58:35,031 - INFO - New best model saved with Val Loss: 0.293925
2025-09-01 13:59:00,450 - INFO - Epoch 365/1000 - Train Loss: 0.296326, Val Loss: 0.297908
2025-09-01 13:59:26,150 - INFO - Epoch 366/1000 - Train Loss: 0.293173, Val Loss: 0.296078
2025-09-01 13:59:51,794 - INFO - Epoch 367/1000 - Train Loss: 0.294018, Val Loss: 0.294993
2025-09-01 14:00:17,588 - INFO - Epoch 368/1000 - Train Loss: 0.292061, Val Loss: 0.290100
2025-09-01 14:00:17,616 - INFO - New best model saved with Val Loss: 0.290100
2025-09-01 14:00:43,071 - INFO - Epoch 369/1000 - Train Loss: 0.294144, Val Loss: 0.295901
2025-09-01 14:01:08,660 - INFO - Epoch 370/1000 - Train Loss: 0.291021, Val Loss: 0.291873
2025-09-01 14:01:34,245 - INFO - Epoch 371/1000 - Train Loss: 0.295862, Val Loss: 0.293639
2025-09-01 14:02:00,027 - INFO - Epoch 372/1000 - Train Loss: 0.291442, Val Loss: 0.282347
2025-09-01 14:02:00,048 - INFO - New best model saved with Val Loss: 0.282347
2025-09-01 14:02:25,657 - INFO - Epoch 373/1000 - Train Loss: 0.289129, Val Loss: 0.286466
2025-09-01 14:02:51,431 - INFO - Epoch 374/1000 - Train Loss: 0.298692, Val Loss: 0.310274
2025-09-01 14:03:17,145 - INFO - Epoch 375/1000 - Train Loss: 0.291338, Val Loss: 0.286314
2025-09-01 14:03:42,529 - INFO - Epoch 376/1000 - Train Loss: 0.290814, Val Loss: 0.291279
2025-09-01 14:04:08,143 - INFO - Epoch 377/1000 - Train Loss: 0.290375, Val Loss: 0.286429
2025-09-01 14:04:33,771 - INFO - Epoch 378/1000 - Train Loss: 0.286893, Val Loss: 0.283786
2025-09-01 14:04:59,589 - INFO - Epoch 379/1000 - Train Loss: 0.288542, Val Loss: 0.298047
2025-09-01 14:05:25,397 - INFO - Epoch 380/1000 - Train Loss: 0.291545, Val Loss: 0.281225
2025-09-01 14:05:25,434 - INFO - New best model saved with Val Loss: 0.281225
2025-09-01 14:05:51,370 - INFO - Epoch 381/1000 - Train Loss: 0.288700, Val Loss: 0.289505
2025-09-01 14:06:17,122 - INFO - Epoch 382/1000 - Train Loss: 0.288742, Val Loss: 0.283898
2025-09-01 14:06:42,918 - INFO - Epoch 383/1000 - Train Loss: 0.286699, Val Loss: 0.281086
2025-09-01 14:06:42,953 - INFO - New best model saved with Val Loss: 0.281086
2025-09-01 14:07:08,824 - INFO - Epoch 384/1000 - Train Loss: 0.288032, Val Loss: 0.287857
2025-09-01 14:07:34,532 - INFO - Epoch 385/1000 - Train Loss: 0.286678, Val Loss: 0.281263
2025-09-01 14:08:00,122 - INFO - Epoch 386/1000 - Train Loss: 0.286183, Val Loss: 0.293644
2025-09-01 14:08:25,973 - INFO - Epoch 387/1000 - Train Loss: 0.291518, Val Loss: 0.283321
2025-09-01 14:08:51,370 - INFO - Epoch 388/1000 - Train Loss: 0.287905, Val Loss: 0.281125
2025-09-01 14:09:16,920 - INFO - Epoch 389/1000 - Train Loss: 0.289772, Val Loss: 0.290662
2025-09-01 14:09:42,610 - INFO - Epoch 390/1000 - Train Loss: 0.285841, Val Loss: 0.298646
2025-09-01 14:10:08,371 - INFO - Epoch 391/1000 - Train Loss: 0.285137, Val Loss: 0.284615
2025-09-01 14:10:33,821 - INFO - Epoch 392/1000 - Train Loss: 0.290720, Val Loss: 0.283738
2025-09-01 14:10:59,292 - INFO - Epoch 393/1000 - Train Loss: 0.282637, Val Loss: 0.288524
2025-09-01 14:11:24,861 - INFO - Epoch 394/1000 - Train Loss: 0.284760, Val Loss: 0.278762
2025-09-01 14:11:24,882 - INFO - New best model saved with Val Loss: 0.278762
2025-09-01 14:11:50,332 - INFO - Epoch 395/1000 - Train Loss: 0.284939, Val Loss: 0.288196
2025-09-01 14:12:16,135 - INFO - Epoch 396/1000 - Train Loss: 0.290222, Val Loss: 0.279908
2025-09-01 14:12:41,817 - INFO - Epoch 397/1000 - Train Loss: 0.286304, Val Loss: 0.282979
2025-09-01 14:13:07,534 - INFO - Epoch 398/1000 - Train Loss: 0.282677, Val Loss: 0.289912
2025-09-01 14:13:33,165 - INFO - Epoch 399/1000 - Train Loss: 0.284210, Val Loss: 0.296298
2025-09-01 14:13:58,506 - INFO - Epoch 400/1000 - Train Loss: 0.283688, Val Loss: 0.288548
2025-09-01 14:14:24,350 - INFO - Epoch 401/1000 - Train Loss: 0.278655, Val Loss: 0.285724
2025-09-01 14:14:50,056 - INFO - Epoch 402/1000 - Train Loss: 0.280087, Val Loss: 0.274723
2025-09-01 14:14:50,078 - INFO - New best model saved with Val Loss: 0.274723
2025-09-01 14:15:15,325 - INFO - Epoch 403/1000 - Train Loss: 0.281330, Val Loss: 0.280060
2025-09-01 14:15:40,975 - INFO - Epoch 404/1000 - Train Loss: 0.283696, Val Loss: 0.276495
2025-09-01 14:16:06,671 - INFO - Epoch 405/1000 - Train Loss: 0.283579, Val Loss: 0.270466
2025-09-01 14:16:06,707 - INFO - New best model saved with Val Loss: 0.270466
2025-09-01 14:16:32,427 - INFO - Epoch 406/1000 - Train Loss: 0.277845, Val Loss: 0.274268
2025-09-01 14:16:57,994 - INFO - Epoch 407/1000 - Train Loss: 0.277185, Val Loss: 0.274778
2025-09-01 14:17:23,760 - INFO - Epoch 408/1000 - Train Loss: 0.280253, Val Loss: 0.274323
2025-09-01 14:17:49,283 - INFO - Epoch 409/1000 - Train Loss: 0.277972, Val Loss: 0.267149
2025-09-01 14:17:49,303 - INFO - New best model saved with Val Loss: 0.267149
2025-09-01 14:18:14,981 - INFO - Epoch 410/1000 - Train Loss: 0.280688, Val Loss: 0.283814
2025-09-01 14:18:40,914 - INFO - Epoch 411/1000 - Train Loss: 0.277543, Val Loss: 0.276059
2025-09-01 14:19:06,683 - INFO - Epoch 412/1000 - Train Loss: 0.278324, Val Loss: 0.277477
2025-09-01 14:19:32,385 - INFO - Epoch 413/1000 - Train Loss: 0.278907, Val Loss: 0.267258
2025-09-01 14:19:57,905 - INFO - Epoch 414/1000 - Train Loss: 0.276928, Val Loss: 0.277298
2025-09-01 14:20:23,545 - INFO - Epoch 415/1000 - Train Loss: 0.275466, Val Loss: 0.273535
2025-09-01 14:20:48,890 - INFO - Epoch 416/1000 - Train Loss: 0.276304, Val Loss: 0.271786
2025-09-01 14:21:14,326 - INFO - Epoch 417/1000 - Train Loss: 0.277408, Val Loss: 0.276505
2025-09-01 14:21:39,798 - INFO - Epoch 418/1000 - Train Loss: 0.273624, Val Loss: 0.265517
2025-09-01 14:21:39,819 - INFO - New best model saved with Val Loss: 0.265517
2025-09-01 14:22:05,248 - INFO - Epoch 419/1000 - Train Loss: 0.272482, Val Loss: 0.282304
2025-09-01 14:22:30,979 - INFO - Epoch 420/1000 - Train Loss: 0.274806, Val Loss: 0.270036
2025-09-01 14:22:57,875 - INFO - Epoch 421/1000 - Train Loss: 0.272785, Val Loss: 0.273018
2025-09-01 14:23:23,264 - INFO - Epoch 422/1000 - Train Loss: 0.273512, Val Loss: 0.268366
2025-09-01 14:23:48,360 - INFO - Epoch 423/1000 - Train Loss: 0.272245, Val Loss: 0.272317
2025-09-01 14:24:13,841 - INFO - Epoch 424/1000 - Train Loss: 0.273113, Val Loss: 0.265308
2025-09-01 14:24:13,861 - INFO - New best model saved with Val Loss: 0.265308
2025-09-01 14:24:38,980 - INFO - Epoch 425/1000 - Train Loss: 0.271529, Val Loss: 0.269215
2025-09-01 14:25:04,299 - INFO - Epoch 426/1000 - Train Loss: 0.270795, Val Loss: 0.259112
2025-09-01 14:25:04,321 - INFO - New best model saved with Val Loss: 0.259112
2025-09-01 14:25:30,052 - INFO - Epoch 427/1000 - Train Loss: 0.271339, Val Loss: 0.273103
2025-09-01 14:25:55,519 - INFO - Epoch 428/1000 - Train Loss: 0.271803, Val Loss: 0.264919
2025-09-01 14:26:20,751 - INFO - Epoch 429/1000 - Train Loss: 0.273624, Val Loss: 0.265407
2025-09-01 14:26:46,157 - INFO - Epoch 430/1000 - Train Loss: 0.270986, Val Loss: 0.263294
2025-09-01 14:27:11,726 - INFO - Epoch 431/1000 - Train Loss: 0.271907, Val Loss: 0.265198
2025-09-01 14:27:37,116 - INFO - Epoch 432/1000 - Train Loss: 0.268047, Val Loss: 0.262145
2025-09-01 14:28:02,835 - INFO - Epoch 433/1000 - Train Loss: 0.270715, Val Loss: 0.263013
2025-09-01 14:28:29,050 - INFO - Epoch 434/1000 - Train Loss: 0.271131, Val Loss: 0.265779
2025-09-01 14:28:54,295 - INFO - Epoch 435/1000 - Train Loss: 0.268374, Val Loss: 0.258322
2025-09-01 14:28:54,316 - INFO - New best model saved with Val Loss: 0.258322
2025-09-01 14:29:19,657 - INFO - Epoch 436/1000 - Train Loss: 0.268559, Val Loss: 0.265146
2025-09-01 14:29:44,983 - INFO - Epoch 437/1000 - Train Loss: 0.268116, Val Loss: 0.270524
2025-09-01 14:30:10,458 - INFO - Epoch 438/1000 - Train Loss: 0.268060, Val Loss: 0.260250
2025-09-01 14:30:35,967 - INFO - Epoch 439/1000 - Train Loss: 0.267621, Val Loss: 0.259760
2025-09-01 14:31:01,683 - INFO - Epoch 440/1000 - Train Loss: 0.266025, Val Loss: 0.268859
2025-09-01 14:31:27,317 - INFO - Epoch 441/1000 - Train Loss: 0.268556, Val Loss: 0.263000
2025-09-01 14:31:52,864 - INFO - Epoch 442/1000 - Train Loss: 0.267368, Val Loss: 0.264478
2025-09-01 14:32:18,647 - INFO - Epoch 443/1000 - Train Loss: 0.265640, Val Loss: 0.263453
2025-09-01 14:32:49,027 - INFO - Epoch 444/1000 - Train Loss: 0.266688, Val Loss: 0.264030
2025-09-01 14:33:14,723 - INFO - Epoch 445/1000 - Train Loss: 0.265188, Val Loss: 0.251099
2025-09-01 14:33:14,758 - INFO - New best model saved with Val Loss: 0.251099
2025-09-01 14:33:40,437 - INFO - Epoch 446/1000 - Train Loss: 0.264159, Val Loss: 0.263072
2025-09-01 14:34:05,649 - INFO - Epoch 447/1000 - Train Loss: 0.267691, Val Loss: 0.265661
2025-09-01 14:34:31,812 - INFO - Epoch 448/1000 - Train Loss: 0.267110, Val Loss: 0.254129
2025-09-01 14:34:57,130 - INFO - Epoch 449/1000 - Train Loss: 0.263540, Val Loss: 0.262493
2025-09-01 14:35:22,715 - INFO - Epoch 450/1000 - Train Loss: 0.264808, Val Loss: 0.256745
2025-09-01 14:35:48,220 - INFO - Epoch 451/1000 - Train Loss: 0.263643, Val Loss: 0.266019
2025-09-01 14:36:13,730 - INFO - Epoch 452/1000 - Train Loss: 0.262982, Val Loss: 0.251474
2025-09-01 14:36:39,042 - INFO - Epoch 453/1000 - Train Loss: 0.261053, Val Loss: 0.251261
2025-09-01 14:37:04,717 - INFO - Epoch 454/1000 - Train Loss: 0.261836, Val Loss: 0.258797
2025-09-01 14:37:29,967 - INFO - Epoch 455/1000 - Train Loss: 0.257671, Val Loss: 0.263057
2025-09-01 14:37:55,337 - INFO - Epoch 456/1000 - Train Loss: 0.263963, Val Loss: 0.251152
2025-09-01 14:38:20,535 - INFO - Epoch 457/1000 - Train Loss: 0.264448, Val Loss: 0.252632
2025-09-01 14:38:47,340 - INFO - Epoch 458/1000 - Train Loss: 0.262719, Val Loss: 0.256812
2025-09-01 14:39:12,788 - INFO - Epoch 459/1000 - Train Loss: 0.262490, Val Loss: 0.245226
2025-09-01 14:39:12,824 - INFO - New best model saved with Val Loss: 0.245226
2025-09-01 14:39:39,205 - INFO - Epoch 460/1000 - Train Loss: 0.258202, Val Loss: 0.255898
2025-09-01 14:40:04,687 - INFO - Epoch 461/1000 - Train Loss: 0.261645, Val Loss: 0.250023
2025-09-01 14:40:30,068 - INFO - Epoch 462/1000 - Train Loss: 0.262272, Val Loss: 0.252372
2025-09-01 14:40:55,654 - INFO - Epoch 463/1000 - Train Loss: 0.260015, Val Loss: 0.250900
2025-09-01 14:41:21,001 - INFO - Epoch 464/1000 - Train Loss: 0.259517, Val Loss: 0.245757
2025-09-01 14:41:47,024 - INFO - Epoch 465/1000 - Train Loss: 0.257020, Val Loss: 0.252777
2025-09-01 14:42:13,626 - INFO - Epoch 466/1000 - Train Loss: 0.258853, Val Loss: 0.253881
2025-09-01 14:42:39,306 - INFO - Epoch 467/1000 - Train Loss: 0.259752, Val Loss: 0.243684
2025-09-01 14:42:39,327 - INFO - New best model saved with Val Loss: 0.243684
2025-09-01 14:43:04,881 - INFO - Epoch 468/1000 - Train Loss: 0.258710, Val Loss: 0.251780
2025-09-01 14:43:30,659 - INFO - Epoch 469/1000 - Train Loss: 0.256686, Val Loss: 0.246284
2025-09-01 14:43:57,862 - INFO - Epoch 470/1000 - Train Loss: 0.255289, Val Loss: 0.244089
2025-09-01 14:44:24,398 - INFO - Epoch 471/1000 - Train Loss: 0.257748, Val Loss: 0.267583
2025-09-01 14:44:49,997 - INFO - Epoch 472/1000 - Train Loss: 0.257630, Val Loss: 0.240475
2025-09-01 14:44:50,029 - INFO - New best model saved with Val Loss: 0.240475
2025-09-01 14:45:15,851 - INFO - Epoch 473/1000 - Train Loss: 0.254096, Val Loss: 0.246586
2025-09-01 14:45:41,156 - INFO - Epoch 474/1000 - Train Loss: 0.257206, Val Loss: 0.243069
2025-09-01 14:46:06,700 - INFO - Epoch 475/1000 - Train Loss: 0.253424, Val Loss: 0.244332
2025-09-01 14:46:32,225 - INFO - Epoch 476/1000 - Train Loss: 0.254980, Val Loss: 0.239857
2025-09-01 14:46:32,257 - INFO - New best model saved with Val Loss: 0.239857
2025-09-01 14:46:57,985 - INFO - Epoch 477/1000 - Train Loss: 0.253863, Val Loss: 0.238548
2025-09-01 14:46:58,020 - INFO - New best model saved with Val Loss: 0.238548
2025-09-01 14:47:23,962 - INFO - Epoch 478/1000 - Train Loss: 0.252652, Val Loss: 0.243391
2025-09-01 14:47:49,725 - INFO - Epoch 479/1000 - Train Loss: 0.253823, Val Loss: 0.250382
2025-09-01 14:48:15,635 - INFO - Epoch 480/1000 - Train Loss: 0.251043, Val Loss: 0.240940
2025-09-01 14:48:41,557 - INFO - Epoch 481/1000 - Train Loss: 0.253039, Val Loss: 0.250789
2025-09-01 14:49:07,539 - INFO - Epoch 482/1000 - Train Loss: 0.253840, Val Loss: 0.247017
2025-09-01 14:49:33,043 - INFO - Epoch 483/1000 - Train Loss: 0.251863, Val Loss: 0.241831
2025-09-01 14:49:58,690 - INFO - Epoch 484/1000 - Train Loss: 0.251199, Val Loss: 0.242225
2025-09-01 14:50:24,438 - INFO - Epoch 485/1000 - Train Loss: 0.251971, Val Loss: 0.248824
2025-09-01 14:50:50,259 - INFO - Epoch 486/1000 - Train Loss: 0.250483, Val Loss: 0.241562
2025-09-01 14:51:15,945 - INFO - Epoch 487/1000 - Train Loss: 0.252017, Val Loss: 0.239036
2025-09-01 14:51:41,803 - INFO - Epoch 488/1000 - Train Loss: 0.250598, Val Loss: 0.239737
2025-09-01 14:52:07,621 - INFO - Epoch 489/1000 - Train Loss: 0.250048, Val Loss: 0.234948
2025-09-01 14:52:07,671 - INFO - New best model saved with Val Loss: 0.234948
2025-09-01 14:52:33,066 - INFO - Epoch 490/1000 - Train Loss: 0.248135, Val Loss: 0.246426
2025-09-01 14:52:59,083 - INFO - Epoch 491/1000 - Train Loss: 0.250525, Val Loss: 0.234109
2025-09-01 14:52:59,128 - INFO - New best model saved with Val Loss: 0.234109
2025-09-01 14:53:24,860 - INFO - Epoch 492/1000 - Train Loss: 0.248447, Val Loss: 0.237377
2025-09-01 14:53:50,454 - INFO - Epoch 493/1000 - Train Loss: 0.251653, Val Loss: 0.242261
2025-09-01 14:54:16,059 - INFO - Epoch 494/1000 - Train Loss: 0.248411, Val Loss: 0.242182
2025-09-01 14:54:42,405 - INFO - Epoch 495/1000 - Train Loss: 0.247569, Val Loss: 0.236688
2025-09-01 14:55:14,444 - INFO - Epoch 496/1000 - Train Loss: 0.247496, Val Loss: 0.241999
2025-09-01 14:56:05,961 - INFO - Epoch 497/1000 - Train Loss: 0.245292, Val Loss: 0.239510
2025-09-01 14:58:13,272 - INFO - Epoch 498/1000 - Train Loss: 0.249757, Val Loss: 0.237381
2025-09-01 15:02:21,039 - INFO - Epoch 499/1000 - Train Loss: 0.246125, Val Loss: 0.235700
2025-09-01 15:05:13,961 - INFO - Epoch 500/1000 - Train Loss: 0.247769, Val Loss: 0.239964
2025-09-01 15:06:51,686 - INFO - Epoch 501/1000 - Train Loss: 0.246780, Val Loss: 0.233677
2025-09-01 15:06:51,891 - INFO - New best model saved with Val Loss: 0.233677
2025-09-01 15:07:54,510 - INFO - Epoch 502/1000 - Train Loss: 0.245534, Val Loss: 0.230077
2025-09-01 15:07:54,597 - INFO - New best model saved with Val Loss: 0.230077
2025-09-01 15:08:28,064 - INFO - Epoch 503/1000 - Train Loss: 0.246840, Val Loss: 0.240365
2025-09-01 15:08:57,412 - INFO - Epoch 504/1000 - Train Loss: 0.245949, Val Loss: 0.238173
2025-09-01 15:09:26,161 - INFO - Epoch 505/1000 - Train Loss: 0.246371, Val Loss: 0.232695
2025-09-01 15:09:56,110 - INFO - Epoch 506/1000 - Train Loss: 0.245262, Val Loss: 0.230764
2025-09-01 15:10:24,416 - INFO - Epoch 507/1000 - Train Loss: 0.243781, Val Loss: 0.233343
2025-09-01 15:10:52,989 - INFO - Epoch 508/1000 - Train Loss: 0.245752, Val Loss: 0.240187
2025-09-01 15:11:19,758 - INFO - Epoch 509/1000 - Train Loss: 0.247920, Val Loss: 0.239148
2025-09-01 15:11:45,625 - INFO - Epoch 510/1000 - Train Loss: 0.243895, Val Loss: 0.226677
2025-09-01 15:11:45,721 - INFO - New best model saved with Val Loss: 0.226677
2025-09-01 15:12:11,820 - INFO - Epoch 511/1000 - Train Loss: 0.241724, Val Loss: 0.243646
2025-09-01 15:12:37,753 - INFO - Epoch 512/1000 - Train Loss: 0.250273, Val Loss: 0.249423
2025-09-01 15:13:03,325 - INFO - Epoch 513/1000 - Train Loss: 0.244782, Val Loss: 0.228510
2025-09-01 15:13:28,500 - INFO - Epoch 514/1000 - Train Loss: 0.241095, Val Loss: 0.233793
2025-09-01 15:13:54,484 - INFO - Epoch 515/1000 - Train Loss: 0.242679, Val Loss: 0.229507
2025-09-01 15:14:20,679 - INFO - Epoch 516/1000 - Train Loss: 0.245104, Val Loss: 0.231897
2025-09-01 15:14:46,644 - INFO - Epoch 517/1000 - Train Loss: 0.245346, Val Loss: 0.230290
2025-09-01 15:15:12,227 - INFO - Epoch 518/1000 - Train Loss: 0.243575, Val Loss: 0.241028
2025-09-01 15:15:37,727 - INFO - Epoch 519/1000 - Train Loss: 0.240616, Val Loss: 0.238859
2025-09-01 15:16:03,301 - INFO - Epoch 520/1000 - Train Loss: 0.243772, Val Loss: 0.229272
2025-09-01 15:16:28,877 - INFO - Epoch 521/1000 - Train Loss: 0.240508, Val Loss: 0.225000
2025-09-01 15:16:28,918 - INFO - New best model saved with Val Loss: 0.225000
2025-09-01 15:16:54,322 - INFO - Epoch 522/1000 - Train Loss: 0.239257, Val Loss: 0.230338
2025-09-01 15:17:19,929 - INFO - Epoch 523/1000 - Train Loss: 0.237714, Val Loss: 0.228933
2025-09-01 15:17:45,534 - INFO - Epoch 524/1000 - Train Loss: 0.239674, Val Loss: 0.230462
2025-09-01 15:18:11,204 - INFO - Epoch 525/1000 - Train Loss: 0.239406, Val Loss: 0.230335
2025-09-01 15:18:36,873 - INFO - Epoch 526/1000 - Train Loss: 0.239186, Val Loss: 0.226203
2025-09-01 15:19:02,349 - INFO - Epoch 527/1000 - Train Loss: 0.238268, Val Loss: 0.226665
2025-09-01 15:19:28,085 - INFO - Epoch 528/1000 - Train Loss: 0.240914, Val Loss: 0.222643
2025-09-01 15:19:28,106 - INFO - New best model saved with Val Loss: 0.222643
2025-09-01 15:19:53,949 - INFO - Epoch 529/1000 - Train Loss: 0.239137, Val Loss: 0.234206
2025-09-01 15:20:19,690 - INFO - Epoch 530/1000 - Train Loss: 0.237326, Val Loss: 0.231830
2025-09-01 15:20:45,557 - INFO - Epoch 531/1000 - Train Loss: 0.241313, Val Loss: 0.226197
2025-09-01 15:21:11,021 - INFO - Epoch 532/1000 - Train Loss: 0.237949, Val Loss: 0.224414
2025-09-01 15:21:36,745 - INFO - Epoch 533/1000 - Train Loss: 0.237482, Val Loss: 0.225418
2025-09-01 15:22:02,141 - INFO - Epoch 534/1000 - Train Loss: 0.234039, Val Loss: 0.224859
2025-09-01 15:22:27,432 - INFO - Epoch 535/1000 - Train Loss: 0.243726, Val Loss: 0.236818
2025-09-01 15:22:53,111 - INFO - Epoch 536/1000 - Train Loss: 0.238154, Val Loss: 0.232274
2025-09-01 15:23:18,615 - INFO - Epoch 537/1000 - Train Loss: 0.234995, Val Loss: 0.225134
2025-09-01 15:23:44,213 - INFO - Epoch 538/1000 - Train Loss: 0.234683, Val Loss: 0.223278
2025-09-01 15:24:09,601 - INFO - Epoch 539/1000 - Train Loss: 0.234111, Val Loss: 0.222388
2025-09-01 15:24:09,704 - INFO - New best model saved with Val Loss: 0.222388
2025-09-01 15:24:35,363 - INFO - Epoch 540/1000 - Train Loss: 0.236843, Val Loss: 0.224198
2025-09-01 15:25:01,143 - INFO - Epoch 541/1000 - Train Loss: 0.236557, Val Loss: 0.224646
2025-09-01 15:25:26,790 - INFO - Epoch 542/1000 - Train Loss: 0.236665, Val Loss: 0.222155
2025-09-01 15:25:26,812 - INFO - New best model saved with Val Loss: 0.222155
2025-09-01 15:25:52,502 - INFO - Epoch 543/1000 - Train Loss: 0.238096, Val Loss: 0.226964
2025-09-01 15:26:18,292 - INFO - Epoch 544/1000 - Train Loss: 0.236506, Val Loss: 0.224698
2025-09-01 15:26:44,077 - INFO - Epoch 545/1000 - Train Loss: 0.236429, Val Loss: 0.234645
2025-09-01 15:27:09,419 - INFO - Epoch 546/1000 - Train Loss: 0.234007, Val Loss: 0.220118
2025-09-01 15:27:09,439 - INFO - New best model saved with Val Loss: 0.220118
2025-09-01 15:27:34,815 - INFO - Epoch 547/1000 - Train Loss: 0.233262, Val Loss: 0.221202
2025-09-01 15:28:00,278 - INFO - Epoch 548/1000 - Train Loss: 0.232087, Val Loss: 0.219656
2025-09-01 15:28:00,298 - INFO - New best model saved with Val Loss: 0.219656
2025-09-01 15:28:25,970 - INFO - Epoch 549/1000 - Train Loss: 0.233827, Val Loss: 0.218659
2025-09-01 15:28:25,990 - INFO - New best model saved with Val Loss: 0.218659
2025-09-01 15:28:51,747 - INFO - Epoch 550/1000 - Train Loss: 0.230568, Val Loss: 0.216952
2025-09-01 15:28:51,767 - INFO - New best model saved with Val Loss: 0.216952
2025-09-01 15:29:17,424 - INFO - Epoch 551/1000 - Train Loss: 0.231209, Val Loss: 0.221679
2025-09-01 15:29:43,105 - INFO - Epoch 552/1000 - Train Loss: 0.232443, Val Loss: 0.218747
2025-09-01 15:30:08,638 - INFO - Epoch 553/1000 - Train Loss: 0.232626, Val Loss: 0.219259
2025-09-01 15:30:34,264 - INFO - Epoch 554/1000 - Train Loss: 0.232102, Val Loss: 0.225925
2025-09-01 15:30:59,653 - INFO - Epoch 555/1000 - Train Loss: 0.231635, Val Loss: 0.220757
2025-09-01 15:31:25,332 - INFO - Epoch 556/1000 - Train Loss: 0.229842, Val Loss: 0.217130
2025-09-01 15:31:51,063 - INFO - Epoch 557/1000 - Train Loss: 0.231050, Val Loss: 0.217773
2025-09-01 15:32:16,627 - INFO - Epoch 558/1000 - Train Loss: 0.231108, Val Loss: 0.230017
2025-09-01 15:32:42,413 - INFO - Epoch 559/1000 - Train Loss: 0.229117, Val Loss: 0.215197
2025-09-01 15:32:42,433 - INFO - New best model saved with Val Loss: 0.215197
2025-09-01 15:33:07,935 - INFO - Epoch 560/1000 - Train Loss: 0.230872, Val Loss: 0.222955
2025-09-01 15:33:33,722 - INFO - Epoch 561/1000 - Train Loss: 0.231372, Val Loss: 0.217888
2025-09-01 15:33:59,148 - INFO - Epoch 562/1000 - Train Loss: 0.230506, Val Loss: 0.218006
2025-09-01 15:34:24,519 - INFO - Epoch 563/1000 - Train Loss: 0.230288, Val Loss: 0.219500
2025-09-01 15:34:50,154 - INFO - Epoch 564/1000 - Train Loss: 0.230042, Val Loss: 0.234489
2025-09-01 15:35:15,846 - INFO - Epoch 565/1000 - Train Loss: 0.233070, Val Loss: 0.241336
2025-09-01 15:35:41,430 - INFO - Epoch 566/1000 - Train Loss: 0.230799, Val Loss: 0.215962
2025-09-01 15:36:07,000 - INFO - Epoch 567/1000 - Train Loss: 0.229041, Val Loss: 0.219187
2025-09-01 15:36:32,643 - INFO - Epoch 568/1000 - Train Loss: 0.227048, Val Loss: 0.214215
2025-09-01 15:36:32,663 - INFO - New best model saved with Val Loss: 0.214215
2025-09-01 15:36:58,426 - INFO - Epoch 569/1000 - Train Loss: 0.227726, Val Loss: 0.219890
2025-09-01 15:37:24,098 - INFO - Epoch 570/1000 - Train Loss: 0.228580, Val Loss: 0.216630
2025-09-01 15:37:49,698 - INFO - Epoch 571/1000 - Train Loss: 0.229577, Val Loss: 0.217948
2025-09-01 15:38:15,349 - INFO - Epoch 572/1000 - Train Loss: 0.226267, Val Loss: 0.215792
2025-09-01 15:38:40,833 - INFO - Epoch 573/1000 - Train Loss: 0.226989, Val Loss: 0.219251
2025-09-01 15:39:06,520 - INFO - Epoch 574/1000 - Train Loss: 0.225522, Val Loss: 0.212903
2025-09-01 15:39:06,540 - INFO - New best model saved with Val Loss: 0.212903
2025-09-01 15:39:32,158 - INFO - Epoch 575/1000 - Train Loss: 0.227048, Val Loss: 0.221605
2025-09-01 15:39:57,697 - INFO - Epoch 576/1000 - Train Loss: 0.226991, Val Loss: 0.218202
2025-09-01 15:40:23,328 - INFO - Epoch 577/1000 - Train Loss: 0.225831, Val Loss: 0.213097
2025-09-01 15:40:49,049 - INFO - Epoch 578/1000 - Train Loss: 0.226220, Val Loss: 0.222612
2025-09-01 15:41:14,692 - INFO - Epoch 579/1000 - Train Loss: 0.226816, Val Loss: 0.219979
2025-09-01 15:41:40,161 - INFO - Epoch 580/1000 - Train Loss: 0.226286, Val Loss: 0.212400
2025-09-01 15:41:40,181 - INFO - New best model saved with Val Loss: 0.212400
2025-09-01 15:42:05,994 - INFO - Epoch 581/1000 - Train Loss: 0.225202, Val Loss: 0.209754
2025-09-01 15:42:06,014 - INFO - New best model saved with Val Loss: 0.209754
2025-09-01 15:42:31,583 - INFO - Epoch 582/1000 - Train Loss: 0.223117, Val Loss: 0.206124
2025-09-01 15:42:31,602 - INFO - New best model saved with Val Loss: 0.206124
2025-09-01 15:42:57,055 - INFO - Epoch 583/1000 - Train Loss: 0.225102, Val Loss: 0.233324
2025-09-01 15:43:22,746 - INFO - Epoch 584/1000 - Train Loss: 0.227022, Val Loss: 0.220267
2025-09-01 15:43:48,370 - INFO - Epoch 585/1000 - Train Loss: 0.225937, Val Loss: 0.228716
2025-09-01 15:44:13,898 - INFO - Epoch 586/1000 - Train Loss: 0.228090, Val Loss: 0.218276
2025-09-01 15:44:39,344 - INFO - Epoch 587/1000 - Train Loss: 0.224280, Val Loss: 0.216193
2025-09-01 15:45:04,970 - INFO - Epoch 588/1000 - Train Loss: 0.225008, Val Loss: 0.214895
2025-09-01 15:45:30,543 - INFO - Epoch 589/1000 - Train Loss: 0.222684, Val Loss: 0.208261
2025-09-01 15:45:56,250 - INFO - Epoch 590/1000 - Train Loss: 0.226873, Val Loss: 0.227161
2025-09-01 15:46:21,724 - INFO - Epoch 591/1000 - Train Loss: 0.225745, Val Loss: 0.217840
2025-09-01 15:46:47,078 - INFO - Epoch 592/1000 - Train Loss: 0.220567, Val Loss: 0.210173
2025-09-01 15:47:12,663 - INFO - Epoch 593/1000 - Train Loss: 0.224561, Val Loss: 0.217647
2025-09-01 15:47:38,348 - INFO - Epoch 594/1000 - Train Loss: 0.224203, Val Loss: 0.211458
2025-09-01 15:48:03,976 - INFO - Epoch 595/1000 - Train Loss: 0.220624, Val Loss: 0.216597
2025-09-01 15:48:29,551 - INFO - Epoch 596/1000 - Train Loss: 0.220135, Val Loss: 0.225764
2025-09-01 15:48:54,870 - INFO - Epoch 597/1000 - Train Loss: 0.220791, Val Loss: 0.214717
2025-09-01 15:49:20,631 - INFO - Epoch 598/1000 - Train Loss: 0.225522, Val Loss: 0.211161
2025-09-01 15:49:46,136 - INFO - Epoch 599/1000 - Train Loss: 0.222413, Val Loss: 0.206508
2025-09-01 15:50:11,781 - INFO - Epoch 600/1000 - Train Loss: 0.221357, Val Loss: 0.206785
2025-09-01 15:50:37,504 - INFO - Epoch 601/1000 - Train Loss: 0.218847, Val Loss: 0.211560
2025-09-01 15:51:03,345 - INFO - Epoch 602/1000 - Train Loss: 0.220126, Val Loss: 0.211876
2025-09-01 15:51:28,860 - INFO - Epoch 603/1000 - Train Loss: 0.222380, Val Loss: 0.214012
2025-09-01 15:51:54,521 - INFO - Epoch 604/1000 - Train Loss: 0.219194, Val Loss: 0.209251
2025-09-01 15:52:20,042 - INFO - Epoch 605/1000 - Train Loss: 0.221587, Val Loss: 0.214120
2025-09-01 15:52:45,777 - INFO - Epoch 606/1000 - Train Loss: 0.221793, Val Loss: 0.213545
2025-09-01 15:53:11,152 - INFO - Epoch 607/1000 - Train Loss: 0.218414, Val Loss: 0.204647
2025-09-01 15:53:11,194 - INFO - New best model saved with Val Loss: 0.204647
2025-09-01 15:53:36,790 - INFO - Epoch 608/1000 - Train Loss: 0.217091, Val Loss: 0.204810
2025-09-01 15:54:02,357 - INFO - Epoch 609/1000 - Train Loss: 0.220359, Val Loss: 0.210610
2025-09-01 15:54:28,076 - INFO - Epoch 610/1000 - Train Loss: 0.218940, Val Loss: 0.213572
2025-09-01 15:54:53,977 - INFO - Epoch 611/1000 - Train Loss: 0.218105, Val Loss: 0.216886
2025-09-01 15:55:19,416 - INFO - Epoch 612/1000 - Train Loss: 0.219209, Val Loss: 0.213154
2025-09-01 15:55:44,965 - INFO - Epoch 613/1000 - Train Loss: 0.215440, Val Loss: 0.203738
2025-09-01 15:55:45,006 - INFO - New best model saved with Val Loss: 0.203738
2025-09-01 15:56:10,559 - INFO - Epoch 614/1000 - Train Loss: 0.216258, Val Loss: 0.204705
2025-09-01 15:56:36,226 - INFO - Epoch 615/1000 - Train Loss: 0.216170, Val Loss: 0.206375
2025-09-01 15:57:01,909 - INFO - Epoch 616/1000 - Train Loss: 0.216296, Val Loss: 0.201656
2025-09-01 15:57:01,929 - INFO - New best model saved with Val Loss: 0.201656
2025-09-01 15:57:27,490 - INFO - Epoch 617/1000 - Train Loss: 0.215791, Val Loss: 0.205428
2025-09-01 15:57:52,997 - INFO - Epoch 618/1000 - Train Loss: 0.216543, Val Loss: 0.207622
2025-09-01 15:58:18,543 - INFO - Epoch 619/1000 - Train Loss: 0.217466, Val Loss: 0.208127
2025-09-01 15:58:43,940 - INFO - Epoch 620/1000 - Train Loss: 0.215365, Val Loss: 0.202696
2025-09-01 15:59:09,748 - INFO - Epoch 621/1000 - Train Loss: 0.215963, Val Loss: 0.198653
2025-09-01 15:59:09,768 - INFO - New best model saved with Val Loss: 0.198653
2025-09-01 15:59:35,195 - INFO - Epoch 622/1000 - Train Loss: 0.217163, Val Loss: 0.211741
2025-09-01 16:00:00,703 - INFO - Epoch 623/1000 - Train Loss: 0.216094, Val Loss: 0.198406
2025-09-01 16:00:00,723 - INFO - New best model saved with Val Loss: 0.198406
2025-09-01 16:00:26,371 - INFO - Epoch 624/1000 - Train Loss: 0.213534, Val Loss: 0.209514
2025-09-01 16:00:51,991 - INFO - Epoch 625/1000 - Train Loss: 0.214645, Val Loss: 0.203905
2025-09-01 16:01:17,780 - INFO - Epoch 626/1000 - Train Loss: 0.215591, Val Loss: 0.213711
2025-09-01 16:01:43,055 - INFO - Epoch 627/1000 - Train Loss: 0.218246, Val Loss: 0.198580
2025-09-01 16:02:08,843 - INFO - Epoch 628/1000 - Train Loss: 0.213389, Val Loss: 0.202764
2025-09-01 16:02:34,352 - INFO - Epoch 629/1000 - Train Loss: 0.213924, Val Loss: 0.204181
2025-09-01 16:02:59,874 - INFO - Epoch 630/1000 - Train Loss: 0.213613, Val Loss: 0.200186
2025-09-01 16:03:25,344 - INFO - Epoch 631/1000 - Train Loss: 0.216275, Val Loss: 0.210749
2025-09-01 16:03:51,019 - INFO - Epoch 632/1000 - Train Loss: 0.213460, Val Loss: 0.206686
2025-09-01 16:04:16,658 - INFO - Epoch 633/1000 - Train Loss: 0.215561, Val Loss: 0.199452
2025-09-01 16:04:42,514 - INFO - Epoch 634/1000 - Train Loss: 0.212274, Val Loss: 0.199484
2025-09-01 16:05:08,180 - INFO - Epoch 635/1000 - Train Loss: 0.212645, Val Loss: 0.205928
2025-09-01 16:05:33,706 - INFO - Epoch 636/1000 - Train Loss: 0.216288, Val Loss: 0.201647
2025-09-01 16:05:59,246 - INFO - Epoch 637/1000 - Train Loss: 0.213468, Val Loss: 0.200829
2025-09-01 16:06:24,769 - INFO - Epoch 638/1000 - Train Loss: 0.212876, Val Loss: 0.199564
2025-09-01 16:06:50,402 - INFO - Epoch 639/1000 - Train Loss: 0.211496, Val Loss: 0.197992
2025-09-01 16:06:50,423 - INFO - New best model saved with Val Loss: 0.197992
2025-09-01 16:07:16,144 - INFO - Epoch 640/1000 - Train Loss: 0.211442, Val Loss: 0.200443
2025-09-01 16:07:41,732 - INFO - Epoch 641/1000 - Train Loss: 0.212211, Val Loss: 0.203542
2025-09-01 16:08:07,099 - INFO - Epoch 642/1000 - Train Loss: 0.212048, Val Loss: 0.206549
2025-09-01 16:08:32,767 - INFO - Epoch 643/1000 - Train Loss: 0.212186, Val Loss: 0.203583
2025-09-01 16:08:58,265 - INFO - Epoch 644/1000 - Train Loss: 0.215395, Val Loss: 0.208025
2025-09-01 16:09:24,012 - INFO - Epoch 645/1000 - Train Loss: 0.216578, Val Loss: 0.201175
2025-09-01 16:09:49,577 - INFO - Epoch 646/1000 - Train Loss: 0.211961, Val Loss: 0.203581
2025-09-01 16:10:15,045 - INFO - Epoch 647/1000 - Train Loss: 0.211829, Val Loss: 0.201201
2025-09-01 16:10:40,587 - INFO - Epoch 648/1000 - Train Loss: 0.209981, Val Loss: 0.197841
2025-09-01 16:10:40,607 - INFO - New best model saved with Val Loss: 0.197841
2025-09-01 16:11:06,075 - INFO - Epoch 649/1000 - Train Loss: 0.212303, Val Loss: 0.198759
2025-09-01 16:11:31,666 - INFO - Epoch 650/1000 - Train Loss: 0.210909, Val Loss: 0.197638
2025-09-01 16:11:31,686 - INFO - New best model saved with Val Loss: 0.197638
2025-09-01 16:11:57,266 - INFO - Epoch 651/1000 - Train Loss: 0.212196, Val Loss: 0.197615
2025-09-01 16:11:57,285 - INFO - New best model saved with Val Loss: 0.197615
2025-09-01 16:12:22,859 - INFO - Epoch 652/1000 - Train Loss: 0.211334, Val Loss: 0.194249
2025-09-01 16:12:22,879 - INFO - New best model saved with Val Loss: 0.194249
2025-09-01 16:12:48,477 - INFO - Epoch 653/1000 - Train Loss: 0.209526, Val Loss: 0.197732
2025-09-01 16:13:14,415 - INFO - Epoch 654/1000 - Train Loss: 0.212537, Val Loss: 0.209681
2025-09-01 16:13:40,271 - INFO - Epoch 655/1000 - Train Loss: 0.211684, Val Loss: 0.193745
2025-09-01 16:13:40,291 - INFO - New best model saved with Val Loss: 0.193745
2025-09-01 16:14:05,911 - INFO - Epoch 656/1000 - Train Loss: 0.210431, Val Loss: 0.193335
2025-09-01 16:14:05,939 - INFO - New best model saved with Val Loss: 0.193335
2025-09-01 16:14:31,256 - INFO - Epoch 657/1000 - Train Loss: 0.208918, Val Loss: 0.193775
2025-09-01 16:14:56,909 - INFO - Epoch 658/1000 - Train Loss: 0.208364, Val Loss: 0.207247
2025-09-01 16:15:22,522 - INFO - Epoch 659/1000 - Train Loss: 0.206361, Val Loss: 0.195994
2025-09-01 16:15:48,163 - INFO - Epoch 660/1000 - Train Loss: 0.208538, Val Loss: 0.196691
2025-09-01 16:16:14,195 - INFO - Epoch 661/1000 - Train Loss: 0.208979, Val Loss: 0.197182
2025-09-01 16:16:39,551 - INFO - Epoch 662/1000 - Train Loss: 0.207530, Val Loss: 0.193763
2025-09-01 16:17:05,225 - INFO - Epoch 663/1000 - Train Loss: 0.207628, Val Loss: 0.195757
2025-09-01 16:17:30,797 - INFO - Epoch 664/1000 - Train Loss: 0.208893, Val Loss: 0.201018
2025-09-01 16:17:56,294 - INFO - Epoch 665/1000 - Train Loss: 0.207511, Val Loss: 0.189693
2025-09-01 16:17:56,314 - INFO - New best model saved with Val Loss: 0.189693
2025-09-01 16:18:21,916 - INFO - Epoch 666/1000 - Train Loss: 0.205694, Val Loss: 0.197508
2025-09-01 16:18:47,500 - INFO - Epoch 667/1000 - Train Loss: 0.206005, Val Loss: 0.198571
2025-09-01 16:19:13,011 - INFO - Epoch 668/1000 - Train Loss: 0.208644, Val Loss: 0.195146
2025-09-01 16:19:38,597 - INFO - Epoch 669/1000 - Train Loss: 0.207224, Val Loss: 0.196644
2025-09-01 16:20:04,133 - INFO - Epoch 670/1000 - Train Loss: 0.209600, Val Loss: 0.196166
2025-09-01 16:20:29,975 - INFO - Epoch 671/1000 - Train Loss: 0.211184, Val Loss: 0.198377
2025-09-01 16:20:55,592 - INFO - Epoch 672/1000 - Train Loss: 0.210235, Val Loss: 0.192375
2025-09-01 16:21:21,038 - INFO - Epoch 673/1000 - Train Loss: 0.206151, Val Loss: 0.192792
2025-09-01 16:21:46,401 - INFO - Epoch 674/1000 - Train Loss: 0.207240, Val Loss: 0.197684
2025-09-01 16:22:12,031 - INFO - Epoch 675/1000 - Train Loss: 0.207943, Val Loss: 0.198971
2025-09-01 16:22:37,778 - INFO - Epoch 676/1000 - Train Loss: 0.207244, Val Loss: 0.194845
2025-09-01 16:23:03,312 - INFO - Epoch 677/1000 - Train Loss: 0.205586, Val Loss: 0.191630
2025-09-01 16:23:28,934 - INFO - Epoch 678/1000 - Train Loss: 0.207171, Val Loss: 0.193929
2025-09-01 16:23:54,758 - INFO - Epoch 679/1000 - Train Loss: 0.204201, Val Loss: 0.191260
2025-09-01 16:24:20,449 - INFO - Epoch 680/1000 - Train Loss: 0.206240, Val Loss: 0.199032
2025-09-01 16:24:46,329 - INFO - Epoch 681/1000 - Train Loss: 0.206619, Val Loss: 0.192078
2025-09-01 16:25:11,757 - INFO - Epoch 682/1000 - Train Loss: 0.206348, Val Loss: 0.196421
2025-09-01 16:25:37,436 - INFO - Epoch 683/1000 - Train Loss: 0.208222, Val Loss: 0.202250
2025-09-01 16:26:03,587 - INFO - Epoch 684/1000 - Train Loss: 0.205561, Val Loss: 0.199767
2025-09-01 16:26:29,339 - INFO - Epoch 685/1000 - Train Loss: 0.205663, Val Loss: 0.192917
2025-09-01 16:26:54,948 - INFO - Epoch 686/1000 - Train Loss: 0.204369, Val Loss: 0.191924
2025-09-01 16:27:20,668 - INFO - Epoch 687/1000 - Train Loss: 0.205281, Val Loss: 0.193870
2025-09-01 16:27:46,122 - INFO - Epoch 688/1000 - Train Loss: 0.208625, Val Loss: 0.199476
2025-09-01 16:28:11,744 - INFO - Epoch 689/1000 - Train Loss: 0.208369, Val Loss: 0.192256
2025-09-01 16:28:37,376 - INFO - Epoch 690/1000 - Train Loss: 0.204075, Val Loss: 0.186762
2025-09-01 16:28:37,408 - INFO - New best model saved with Val Loss: 0.186762
2025-09-01 16:29:03,149 - INFO - Epoch 691/1000 - Train Loss: 0.203287, Val Loss: 0.189096
2025-09-01 16:29:28,744 - INFO - Epoch 692/1000 - Train Loss: 0.205673, Val Loss: 0.195104
2025-09-01 16:29:54,364 - INFO - Epoch 693/1000 - Train Loss: 0.205339, Val Loss: 0.199503
2025-09-01 16:30:19,951 - INFO - Epoch 694/1000 - Train Loss: 0.209083, Val Loss: 0.196225
2025-09-01 16:30:45,574 - INFO - Epoch 695/1000 - Train Loss: 0.205129, Val Loss: 0.198698
2025-09-01 16:31:11,167 - INFO - Epoch 696/1000 - Train Loss: 0.204998, Val Loss: 0.193563
2025-09-01 16:31:36,864 - INFO - Epoch 697/1000 - Train Loss: 0.202900, Val Loss: 0.191193
2025-09-01 16:32:02,530 - INFO - Epoch 698/1000 - Train Loss: 0.202903, Val Loss: 0.194049
2025-09-01 16:32:28,304 - INFO - Epoch 699/1000 - Train Loss: 0.205649, Val Loss: 0.192252
2025-09-01 16:32:53,858 - INFO - Epoch 700/1000 - Train Loss: 0.203186, Val Loss: 0.190981
2025-09-01 16:33:19,720 - INFO - Epoch 701/1000 - Train Loss: 0.202826, Val Loss: 0.191179
2025-09-01 16:33:45,152 - INFO - Epoch 702/1000 - Train Loss: 0.203313, Val Loss: 0.197585
2025-09-01 16:34:10,812 - INFO - Epoch 703/1000 - Train Loss: 0.203337, Val Loss: 0.189424
2025-09-01 16:34:36,253 - INFO - Epoch 704/1000 - Train Loss: 0.202894, Val Loss: 0.194308
2025-09-01 16:35:01,758 - INFO - Epoch 705/1000 - Train Loss: 0.201463, Val Loss: 0.189341
2025-09-01 16:35:27,466 - INFO - Epoch 706/1000 - Train Loss: 0.206972, Val Loss: 0.196529
2025-09-01 16:35:52,857 - INFO - Epoch 707/1000 - Train Loss: 0.204815, Val Loss: 0.188772
2025-09-01 16:36:18,532 - INFO - Epoch 708/1000 - Train Loss: 0.203217, Val Loss: 0.186661
2025-09-01 16:36:18,552 - INFO - New best model saved with Val Loss: 0.186661
2025-09-01 16:36:44,080 - INFO - Epoch 709/1000 - Train Loss: 0.200901, Val Loss: 0.197050
2025-09-01 16:37:09,592 - INFO - Epoch 710/1000 - Train Loss: 0.202972, Val Loss: 0.197491
2025-09-01 16:37:35,384 - INFO - Epoch 711/1000 - Train Loss: 0.201468, Val Loss: 0.188019
2025-09-01 16:38:00,780 - INFO - Epoch 712/1000 - Train Loss: 0.201810, Val Loss: 0.188430
2025-09-01 16:38:26,631 - INFO - Epoch 713/1000 - Train Loss: 0.201335, Val Loss: 0.197367
2025-09-01 16:38:52,234 - INFO - Epoch 714/1000 - Train Loss: 0.202081, Val Loss: 0.196729
2025-09-01 16:39:17,668 - INFO - Epoch 715/1000 - Train Loss: 0.199642, Val Loss: 0.184650
2025-09-01 16:39:17,688 - INFO - New best model saved with Val Loss: 0.184650
2025-09-01 16:39:43,309 - INFO - Epoch 716/1000 - Train Loss: 0.201672, Val Loss: 0.189503
2025-09-01 16:40:09,016 - INFO - Epoch 717/1000 - Train Loss: 0.200390, Val Loss: 0.196001
2025-09-01 16:40:34,586 - INFO - Epoch 718/1000 - Train Loss: 0.200919, Val Loss: 0.188118
2025-09-01 16:41:00,244 - INFO - Epoch 719/1000 - Train Loss: 0.200508, Val Loss: 0.188762
2025-09-01 16:41:25,753 - INFO - Epoch 720/1000 - Train Loss: 0.200140, Val Loss: 0.190243
2025-09-01 16:41:51,251 - INFO - Epoch 721/1000 - Train Loss: 0.203598, Val Loss: 0.192371
2025-09-01 16:42:16,839 - INFO - Epoch 722/1000 - Train Loss: 0.203516, Val Loss: 0.188139
2025-09-01 16:42:42,467 - INFO - Epoch 723/1000 - Train Loss: 0.199863, Val Loss: 0.195335
2025-09-01 16:43:08,192 - INFO - Epoch 724/1000 - Train Loss: 0.199624, Val Loss: 0.184298
2025-09-01 16:43:08,212 - INFO - New best model saved with Val Loss: 0.184298
2025-09-01 16:43:33,934 - INFO - Epoch 725/1000 - Train Loss: 0.199475, Val Loss: 0.191222
2025-09-01 16:43:59,414 - INFO - Epoch 726/1000 - Train Loss: 0.200277, Val Loss: 0.186514
2025-09-01 16:44:24,983 - INFO - Epoch 727/1000 - Train Loss: 0.201636, Val Loss: 0.188642
2025-09-01 16:44:50,761 - INFO - Epoch 728/1000 - Train Loss: 0.199839, Val Loss: 0.189956
2025-09-01 16:45:16,512 - INFO - Epoch 729/1000 - Train Loss: 0.199880, Val Loss: 0.182052
2025-09-01 16:45:16,550 - INFO - New best model saved with Val Loss: 0.182052
2025-09-01 16:45:42,324 - INFO - Epoch 730/1000 - Train Loss: 0.195919, Val Loss: 0.180506
2025-09-01 16:45:42,368 - INFO - New best model saved with Val Loss: 0.180506
2025-09-01 16:46:08,024 - INFO - Epoch 731/1000 - Train Loss: 0.198804, Val Loss: 0.191337
2025-09-01 16:46:33,577 - INFO - Epoch 732/1000 - Train Loss: 0.198863, Val Loss: 0.192102
2025-09-01 16:46:59,009 - INFO - Epoch 733/1000 - Train Loss: 0.203713, Val Loss: 0.188496
2025-09-01 16:47:24,816 - INFO - Epoch 734/1000 - Train Loss: 0.200670, Val Loss: 0.185991
2025-09-01 16:47:50,136 - INFO - Epoch 735/1000 - Train Loss: 0.199591, Val Loss: 0.194498
2025-09-01 16:48:15,528 - INFO - Epoch 736/1000 - Train Loss: 0.198570, Val Loss: 0.188718
2025-09-01 16:48:41,010 - INFO - Epoch 737/1000 - Train Loss: 0.195346, Val Loss: 0.186273
2025-09-01 16:49:06,527 - INFO - Epoch 738/1000 - Train Loss: 0.198337, Val Loss: 0.187000
2025-09-01 16:49:31,727 - INFO - Epoch 739/1000 - Train Loss: 0.197805, Val Loss: 0.183042
2025-09-01 16:49:57,126 - INFO - Epoch 740/1000 - Train Loss: 0.198682, Val Loss: 0.191604
2025-09-01 16:50:22,737 - INFO - Epoch 741/1000 - Train Loss: 0.196993, Val Loss: 0.194271
2025-09-01 16:50:48,468 - INFO - Epoch 742/1000 - Train Loss: 0.200370, Val Loss: 0.181702
2025-09-01 16:51:14,106 - INFO - Epoch 743/1000 - Train Loss: 0.199462, Val Loss: 0.184059
2025-09-01 16:51:39,567 - INFO - Epoch 744/1000 - Train Loss: 0.199623, Val Loss: 0.184158
2025-09-01 16:52:04,980 - INFO - Epoch 745/1000 - Train Loss: 0.198130, Val Loss: 0.183470
2025-09-01 16:52:30,477 - INFO - Epoch 746/1000 - Train Loss: 0.196549, Val Loss: 0.189859
2025-09-01 16:52:56,052 - INFO - Epoch 747/1000 - Train Loss: 0.197383, Val Loss: 0.185490
2025-09-01 16:53:21,672 - INFO - Epoch 748/1000 - Train Loss: 0.198572, Val Loss: 0.183309
2025-09-01 16:53:47,248 - INFO - Epoch 749/1000 - Train Loss: 0.199623, Val Loss: 0.192958
2025-09-01 16:54:12,701 - INFO - Epoch 750/1000 - Train Loss: 0.200233, Val Loss: 0.188914
2025-09-01 16:54:38,246 - INFO - Epoch 751/1000 - Train Loss: 0.199154, Val Loss: 0.186626
2025-09-01 16:55:03,784 - INFO - Epoch 752/1000 - Train Loss: 0.196550, Val Loss: 0.180032
2025-09-01 16:55:03,816 - INFO - New best model saved with Val Loss: 0.180032
2025-09-01 16:55:29,185 - INFO - Epoch 753/1000 - Train Loss: 0.194306, Val Loss: 0.184669
2025-09-01 16:55:54,528 - INFO - Epoch 754/1000 - Train Loss: 0.193493, Val Loss: 0.187846
2025-09-01 16:56:20,554 - INFO - Epoch 755/1000 - Train Loss: 0.194541, Val Loss: 0.182653
2025-09-01 16:56:48,861 - INFO - Epoch 756/1000 - Train Loss: 0.195043, Val Loss: 0.187639
2025-09-01 16:57:14,442 - INFO - Epoch 757/1000 - Train Loss: 0.194957, Val Loss: 0.187264
2025-09-01 16:57:39,853 - INFO - Epoch 758/1000 - Train Loss: 0.195683, Val Loss: 0.179944
2025-09-01 16:57:39,873 - INFO - New best model saved with Val Loss: 0.179944
2025-09-01 16:58:05,508 - INFO - Epoch 759/1000 - Train Loss: 0.197419, Val Loss: 0.185360
2025-09-01 16:58:31,145 - INFO - Epoch 760/1000 - Train Loss: 0.200314, Val Loss: 0.182624
2025-09-01 16:58:56,632 - INFO - Epoch 761/1000 - Train Loss: 0.194830, Val Loss: 0.181279
2025-09-01 16:59:22,244 - INFO - Epoch 762/1000 - Train Loss: 0.194037, Val Loss: 0.185078
2025-09-01 16:59:47,822 - INFO - Epoch 763/1000 - Train Loss: 0.196849, Val Loss: 0.183913
2025-09-01 17:00:13,572 - INFO - Epoch 764/1000 - Train Loss: 0.198962, Val Loss: 0.184352
2025-09-01 17:00:39,052 - INFO - Epoch 765/1000 - Train Loss: 0.197647, Val Loss: 0.185740
2025-09-01 17:01:04,407 - INFO - Epoch 766/1000 - Train Loss: 0.196670, Val Loss: 0.188480
2025-09-01 17:01:29,766 - INFO - Epoch 767/1000 - Train Loss: 0.194743, Val Loss: 0.184066
2025-09-01 17:01:55,343 - INFO - Epoch 768/1000 - Train Loss: 0.195780, Val Loss: 0.188224
2025-09-01 17:02:21,205 - INFO - Epoch 769/1000 - Train Loss: 0.193529, Val Loss: 0.181636
2025-09-01 17:02:46,721 - INFO - Epoch 770/1000 - Train Loss: 0.193592, Val Loss: 0.180271
2025-09-01 17:03:12,248 - INFO - Epoch 771/1000 - Train Loss: 0.196603, Val Loss: 0.187142
2025-09-01 17:03:37,871 - INFO - Epoch 772/1000 - Train Loss: 0.195242, Val Loss: 0.178724
2025-09-01 17:03:37,891 - INFO - New best model saved with Val Loss: 0.178724
2025-09-01 17:04:03,200 - INFO - Epoch 773/1000 - Train Loss: 0.193464, Val Loss: 0.182977
2025-09-01 17:04:28,683 - INFO - Epoch 774/1000 - Train Loss: 0.197970, Val Loss: 0.177679
2025-09-01 17:04:28,719 - INFO - New best model saved with Val Loss: 0.177679
2025-09-01 17:04:54,262 - INFO - Epoch 775/1000 - Train Loss: 0.194584, Val Loss: 0.180337
2025-09-01 17:05:19,980 - INFO - Epoch 776/1000 - Train Loss: 0.196212, Val Loss: 0.184325
2025-09-01 17:05:45,308 - INFO - Epoch 777/1000 - Train Loss: 0.199210, Val Loss: 0.189906
2025-09-01 17:06:10,622 - INFO - Epoch 778/1000 - Train Loss: 0.197601, Val Loss: 0.181012
2025-09-01 17:06:36,117 - INFO - Epoch 779/1000 - Train Loss: 0.195137, Val Loss: 0.182778
2025-09-01 17:07:01,405 - INFO - Epoch 780/1000 - Train Loss: 0.195098, Val Loss: 0.179813
2025-09-01 17:07:26,841 - INFO - Epoch 781/1000 - Train Loss: 0.194054, Val Loss: 0.179853
2025-09-01 17:07:52,120 - INFO - Epoch 782/1000 - Train Loss: 0.193105, Val Loss: 0.179494
2025-09-01 17:08:17,283 - INFO - Epoch 783/1000 - Train Loss: 0.192941, Val Loss: 0.186349
2025-09-01 17:08:42,905 - INFO - Epoch 784/1000 - Train Loss: 0.194097, Val Loss: 0.179904
2025-09-01 17:09:08,428 - INFO - Epoch 785/1000 - Train Loss: 0.193428, Val Loss: 0.177566
2025-09-01 17:09:08,448 - INFO - New best model saved with Val Loss: 0.177566
2025-09-01 17:09:33,628 - INFO - Epoch 786/1000 - Train Loss: 0.192116, Val Loss: 0.181951
2025-09-01 17:09:58,857 - INFO - Epoch 787/1000 - Train Loss: 0.192518, Val Loss: 0.178981
2025-09-01 17:10:24,584 - INFO - Epoch 788/1000 - Train Loss: 0.192251, Val Loss: 0.178284
2025-09-01 17:10:49,754 - INFO - Epoch 789/1000 - Train Loss: 0.193496, Val Loss: 0.176931
2025-09-01 17:10:49,793 - INFO - New best model saved with Val Loss: 0.176931
2025-09-01 17:11:15,301 - INFO - Epoch 790/1000 - Train Loss: 0.193684, Val Loss: 0.179686
2025-09-01 17:11:41,125 - INFO - Epoch 791/1000 - Train Loss: 0.193091, Val Loss: 0.185530
2025-09-01 17:12:06,871 - INFO - Epoch 792/1000 - Train Loss: 0.192335, Val Loss: 0.178492
2025-09-01 17:12:32,522 - INFO - Epoch 793/1000 - Train Loss: 0.193774, Val Loss: 0.186848
2025-09-01 17:12:57,876 - INFO - Epoch 794/1000 - Train Loss: 0.194394, Val Loss: 0.175324
2025-09-01 17:12:57,914 - INFO - New best model saved with Val Loss: 0.175324
2025-09-01 17:13:23,222 - INFO - Epoch 795/1000 - Train Loss: 0.195272, Val Loss: 0.180523
2025-09-01 17:13:48,623 - INFO - Epoch 796/1000 - Train Loss: 0.190782, Val Loss: 0.175206
2025-09-01 17:13:48,643 - INFO - New best model saved with Val Loss: 0.175206
2025-09-01 17:14:13,944 - INFO - Epoch 797/1000 - Train Loss: 0.190210, Val Loss: 0.179788
2025-09-01 17:14:39,230 - INFO - Epoch 798/1000 - Train Loss: 0.190465, Val Loss: 0.175250
2025-09-01 17:15:04,744 - INFO - Epoch 799/1000 - Train Loss: 0.190866, Val Loss: 0.177591
2025-09-01 17:15:30,289 - INFO - Epoch 800/1000 - Train Loss: 0.190187, Val Loss: 0.180430
2025-09-01 17:15:55,966 - INFO - Epoch 801/1000 - Train Loss: 0.191761, Val Loss: 0.176465
2025-09-01 17:16:21,168 - INFO - Epoch 802/1000 - Train Loss: 0.191325, Val Loss: 0.178505
2025-09-01 17:16:46,663 - INFO - Epoch 803/1000 - Train Loss: 0.192131, Val Loss: 0.182355
2025-09-01 17:17:12,062 - INFO - Epoch 804/1000 - Train Loss: 0.190961, Val Loss: 0.177799
2025-09-01 17:17:38,126 - INFO - Epoch 805/1000 - Train Loss: 0.189509, Val Loss: 0.184695
2025-09-01 17:18:03,327 - INFO - Epoch 806/1000 - Train Loss: 0.190273, Val Loss: 0.175019
2025-09-01 17:18:03,347 - INFO - New best model saved with Val Loss: 0.175019
2025-09-01 17:18:28,900 - INFO - Epoch 807/1000 - Train Loss: 0.188990, Val Loss: 0.182943
2025-09-01 17:18:54,479 - INFO - Epoch 808/1000 - Train Loss: 0.190488, Val Loss: 0.178128
2025-09-01 17:19:20,093 - INFO - Epoch 809/1000 - Train Loss: 0.190232, Val Loss: 0.176024
2025-09-01 17:19:45,786 - INFO - Epoch 810/1000 - Train Loss: 0.190630, Val Loss: 0.183261
2025-09-01 17:20:11,364 - INFO - Epoch 811/1000 - Train Loss: 0.194361, Val Loss: 0.176497
2025-09-01 17:20:36,671 - INFO - Epoch 812/1000 - Train Loss: 0.189148, Val Loss: 0.176730
2025-09-01 17:21:02,129 - INFO - Epoch 813/1000 - Train Loss: 0.188823, Val Loss: 0.179011
2025-09-01 17:21:27,478 - INFO - Epoch 814/1000 - Train Loss: 0.189402, Val Loss: 0.176386
2025-09-01 17:21:53,179 - INFO - Epoch 815/1000 - Train Loss: 0.192117, Val Loss: 0.175461
2025-09-01 17:22:18,647 - INFO - Epoch 816/1000 - Train Loss: 0.188235, Val Loss: 0.176878
2025-09-01 17:22:43,835 - INFO - Epoch 817/1000 - Train Loss: 0.190581, Val Loss: 0.175057
2025-09-01 17:23:09,520 - INFO - Epoch 818/1000 - Train Loss: 0.189004, Val Loss: 0.175105
2025-09-01 17:23:34,966 - INFO - Epoch 819/1000 - Train Loss: 0.188294, Val Loss: 0.173076
2025-09-01 17:23:35,007 - INFO - New best model saved with Val Loss: 0.173076
2025-09-01 17:24:00,830 - INFO - Epoch 820/1000 - Train Loss: 0.188068, Val Loss: 0.176094
2025-09-01 17:24:26,471 - INFO - Epoch 821/1000 - Train Loss: 0.188707, Val Loss: 0.178502
2025-09-01 17:24:52,015 - INFO - Epoch 822/1000 - Train Loss: 0.189406, Val Loss: 0.174101
2025-09-01 17:26:23,830 - INFO - args.exp_name : Test
2025-09-01 17:26:23,833 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 5000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-01 17:26:23,833 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-01 17:26:23,845 - INFO - [35m n_hidden: 256 [0m
2025-09-01 17:26:23,845 - INFO - [35m n_output: 128 [0m
2025-09-01 17:26:24,206 - INFO - Total trainable parameters: 2286017
2025-09-01 17:26:24,440 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-01 17:26:24,441 - INFO - Staring training for 5000 epochs
2025-09-01 17:26:50,231 - INFO - Epoch 1/5000 - Train Loss: 1.056168, Val Loss: 1.015847
2025-09-01 17:26:50,292 - INFO - New best model saved with Val Loss: 1.015847
2025-09-01 17:27:15,768 - INFO - Epoch 2/5000 - Train Loss: 0.875395, Val Loss: 0.750042
2025-09-01 17:27:15,802 - INFO - New best model saved with Val Loss: 0.750042
2025-09-01 17:27:41,509 - INFO - Epoch 3/5000 - Train Loss: 0.706542, Val Loss: 0.667274
2025-09-01 17:27:41,528 - INFO - New best model saved with Val Loss: 0.667274
2025-09-01 17:28:06,899 - INFO - Epoch 4/5000 - Train Loss: 0.660669, Val Loss: 0.648352
2025-09-01 17:28:06,936 - INFO - New best model saved with Val Loss: 0.648352
2025-09-01 17:28:32,476 - INFO - Epoch 5/5000 - Train Loss: 0.635273, Val Loss: 0.632823
2025-09-01 17:28:32,496 - INFO - New best model saved with Val Loss: 0.632823
2025-09-01 17:28:58,014 - INFO - Epoch 6/5000 - Train Loss: 0.619574, Val Loss: 0.626690
2025-09-01 17:28:58,054 - INFO - New best model saved with Val Loss: 0.626690
2025-09-01 17:29:23,587 - INFO - Epoch 7/5000 - Train Loss: 0.605915, Val Loss: 0.600411
2025-09-01 17:29:23,606 - INFO - New best model saved with Val Loss: 0.600411
2025-09-01 17:29:49,134 - INFO - Epoch 8/5000 - Train Loss: 0.593503, Val Loss: 0.581513
2025-09-01 17:29:49,174 - INFO - New best model saved with Val Loss: 0.581513
2025-09-01 17:30:14,744 - INFO - Epoch 9/5000 - Train Loss: 0.576795, Val Loss: 0.569709
2025-09-01 17:30:14,765 - INFO - New best model saved with Val Loss: 0.569709
2025-09-01 17:30:40,805 - INFO - Epoch 10/5000 - Train Loss: 0.570783, Val Loss: 0.573991
2025-09-01 17:31:06,591 - INFO - Epoch 11/5000 - Train Loss: 0.561627, Val Loss: 0.566849
2025-09-01 17:31:06,628 - INFO - New best model saved with Val Loss: 0.566849
2025-09-01 17:31:31,999 - INFO - Epoch 12/5000 - Train Loss: 0.556711, Val Loss: 0.552829
2025-09-01 17:31:32,021 - INFO - New best model saved with Val Loss: 0.552829
2025-09-01 17:31:57,425 - INFO - Epoch 13/5000 - Train Loss: 0.550674, Val Loss: 0.550492
2025-09-01 17:31:57,445 - INFO - New best model saved with Val Loss: 0.550492
2025-09-01 17:32:22,999 - INFO - Epoch 14/5000 - Train Loss: 0.547937, Val Loss: 0.540840
2025-09-01 17:32:23,033 - INFO - New best model saved with Val Loss: 0.540840
2025-09-01 17:32:48,256 - INFO - Epoch 15/5000 - Train Loss: 0.538862, Val Loss: 0.532854
2025-09-01 17:32:48,276 - INFO - New best model saved with Val Loss: 0.532854
2025-09-01 17:33:13,745 - INFO - Epoch 16/5000 - Train Loss: 0.541332, Val Loss: 0.534566
2025-09-01 17:33:39,028 - INFO - Epoch 17/5000 - Train Loss: 0.533474, Val Loss: 0.539365
2025-09-01 17:34:04,452 - INFO - Epoch 18/5000 - Train Loss: 0.529112, Val Loss: 0.518170
2025-09-01 17:34:04,472 - INFO - New best model saved with Val Loss: 0.518170
2025-09-01 17:34:30,041 - INFO - Epoch 19/5000 - Train Loss: 0.522290, Val Loss: 0.515370
2025-09-01 17:34:30,061 - INFO - New best model saved with Val Loss: 0.515370
2025-09-01 17:34:55,250 - INFO - Epoch 20/5000 - Train Loss: 0.525329, Val Loss: 0.527137
2025-09-01 17:35:20,868 - INFO - Epoch 21/5000 - Train Loss: 0.516851, Val Loss: 0.509659
2025-09-01 17:35:20,911 - INFO - New best model saved with Val Loss: 0.509659
2025-09-01 17:35:46,357 - INFO - Epoch 22/5000 - Train Loss: 0.517313, Val Loss: 0.517760
2025-09-01 17:36:11,705 - INFO - Epoch 23/5000 - Train Loss: 0.514738, Val Loss: 0.518653
2025-09-01 17:36:37,288 - INFO - Epoch 24/5000 - Train Loss: 0.510372, Val Loss: 0.498224
2025-09-01 17:36:37,310 - INFO - New best model saved with Val Loss: 0.498224
2025-09-01 17:37:02,784 - INFO - Epoch 25/5000 - Train Loss: 0.506349, Val Loss: 0.498740
2025-09-01 17:37:27,937 - INFO - Epoch 26/5000 - Train Loss: 0.503998, Val Loss: 0.539363
2025-09-01 17:37:53,032 - INFO - Epoch 27/5000 - Train Loss: 0.513136, Val Loss: 0.496631
2025-09-01 17:37:53,068 - INFO - New best model saved with Val Loss: 0.496631
2025-09-01 17:38:18,696 - INFO - Epoch 28/5000 - Train Loss: 0.500721, Val Loss: 0.499860
2025-09-01 17:38:44,324 - INFO - Epoch 29/5000 - Train Loss: 0.497318, Val Loss: 0.486283
2025-09-01 17:38:44,344 - INFO - New best model saved with Val Loss: 0.486283
2025-09-01 17:39:09,863 - INFO - Epoch 30/5000 - Train Loss: 0.493571, Val Loss: 0.495389
2025-09-01 17:39:35,532 - INFO - Epoch 31/5000 - Train Loss: 0.495245, Val Loss: 0.491789
2025-09-01 17:40:00,919 - INFO - Epoch 32/5000 - Train Loss: 0.494707, Val Loss: 0.484213
2025-09-01 17:40:00,956 - INFO - New best model saved with Val Loss: 0.484213
2025-09-01 17:40:26,330 - INFO - Epoch 33/5000 - Train Loss: 0.492426, Val Loss: 0.482499
2025-09-01 17:40:26,358 - INFO - New best model saved with Val Loss: 0.482499
2025-09-01 17:40:51,895 - INFO - Epoch 34/5000 - Train Loss: 0.491058, Val Loss: 0.491712
2025-09-01 17:41:17,515 - INFO - Epoch 35/5000 - Train Loss: 0.491267, Val Loss: 0.484627
2025-09-01 17:41:42,882 - INFO - Epoch 36/5000 - Train Loss: 0.490704, Val Loss: 0.486219
2025-09-01 17:42:08,513 - INFO - Epoch 37/5000 - Train Loss: 0.491392, Val Loss: 0.477299
2025-09-01 17:42:08,533 - INFO - New best model saved with Val Loss: 0.477299
2025-09-01 17:42:34,164 - INFO - Epoch 38/5000 - Train Loss: 0.483956, Val Loss: 0.480989
2025-09-01 17:42:59,730 - INFO - Epoch 39/5000 - Train Loss: 0.479513, Val Loss: 0.472048
2025-09-01 17:42:59,750 - INFO - New best model saved with Val Loss: 0.472048
2025-09-01 17:43:25,414 - INFO - Epoch 40/5000 - Train Loss: 0.481551, Val Loss: 0.471332
2025-09-01 17:43:25,455 - INFO - New best model saved with Val Loss: 0.471332
2025-09-01 17:43:51,088 - INFO - Epoch 41/5000 - Train Loss: 0.476592, Val Loss: 0.472313
2025-09-01 17:44:16,616 - INFO - Epoch 42/5000 - Train Loss: 0.480180, Val Loss: 0.470733
2025-09-01 17:44:16,656 - INFO - New best model saved with Val Loss: 0.470733
2025-09-01 17:44:42,355 - INFO - Epoch 43/5000 - Train Loss: 0.482159, Val Loss: 0.468418
2025-09-01 17:44:42,375 - INFO - New best model saved with Val Loss: 0.468418
2025-09-01 17:45:07,725 - INFO - Epoch 44/5000 - Train Loss: 0.473163, Val Loss: 0.465565
2025-09-01 17:45:07,756 - INFO - New best model saved with Val Loss: 0.465565
2025-09-01 17:45:33,105 - INFO - Epoch 45/5000 - Train Loss: 0.474198, Val Loss: 0.485222
2025-09-01 17:45:58,362 - INFO - Epoch 46/5000 - Train Loss: 0.473702, Val Loss: 0.470247
2025-09-01 17:46:24,083 - INFO - Epoch 47/5000 - Train Loss: 0.478167, Val Loss: 0.475754
2025-09-01 17:46:49,730 - INFO - Epoch 48/5000 - Train Loss: 0.470765, Val Loss: 0.466037
2025-09-01 17:47:15,293 - INFO - Epoch 49/5000 - Train Loss: 0.474589, Val Loss: 0.460153
2025-09-01 17:47:15,330 - INFO - New best model saved with Val Loss: 0.460153
2025-09-01 17:47:40,718 - INFO - Epoch 50/5000 - Train Loss: 0.467839, Val Loss: 0.463028
2025-09-01 17:48:06,558 - INFO - Epoch 51/5000 - Train Loss: 0.473847, Val Loss: 0.460576
2025-09-01 17:48:32,039 - INFO - Epoch 52/5000 - Train Loss: 0.468685, Val Loss: 0.474487
2025-09-01 17:48:57,637 - INFO - Epoch 53/5000 - Train Loss: 0.466457, Val Loss: 0.457123
2025-09-01 17:48:57,657 - INFO - New best model saved with Val Loss: 0.457123
2025-09-01 17:49:22,951 - INFO - Epoch 54/5000 - Train Loss: 0.462245, Val Loss: 0.468619
2025-09-01 17:49:48,526 - INFO - Epoch 55/5000 - Train Loss: 0.466153, Val Loss: 0.474336
2025-09-01 17:50:13,930 - INFO - Epoch 56/5000 - Train Loss: 0.470213, Val Loss: 0.450516
2025-09-01 17:50:13,950 - INFO - New best model saved with Val Loss: 0.450516
2025-09-01 17:50:39,510 - INFO - Epoch 57/5000 - Train Loss: 0.456739, Val Loss: 0.455432
2025-09-01 17:51:04,862 - INFO - Epoch 58/5000 - Train Loss: 0.458332, Val Loss: 0.451740
2025-09-01 17:51:30,119 - INFO - Epoch 59/5000 - Train Loss: 0.456068, Val Loss: 0.456134
2025-09-01 17:51:55,664 - INFO - Epoch 60/5000 - Train Loss: 0.455678, Val Loss: 0.447210
2025-09-01 17:51:55,684 - INFO - New best model saved with Val Loss: 0.447210
2025-09-01 17:52:21,473 - INFO - Epoch 61/5000 - Train Loss: 0.454283, Val Loss: 0.489659
2025-09-01 17:52:47,022 - INFO - Epoch 62/5000 - Train Loss: 0.458354, Val Loss: 0.443401
2025-09-01 17:52:47,042 - INFO - New best model saved with Val Loss: 0.443401
2025-09-01 17:53:12,441 - INFO - Epoch 63/5000 - Train Loss: 0.447304, Val Loss: 0.456108
2025-09-01 17:53:37,911 - INFO - Epoch 64/5000 - Train Loss: 0.450408, Val Loss: 0.461589
2025-09-01 17:54:03,423 - INFO - Epoch 65/5000 - Train Loss: 0.458063, Val Loss: 0.473511
2025-09-01 17:54:28,827 - INFO - Epoch 66/5000 - Train Loss: 0.448568, Val Loss: 0.440437
2025-09-01 17:54:28,848 - INFO - New best model saved with Val Loss: 0.440437
2025-09-01 17:54:54,283 - INFO - Epoch 67/5000 - Train Loss: 0.446285, Val Loss: 0.443114
2025-09-01 17:55:19,885 - INFO - Epoch 68/5000 - Train Loss: 0.444654, Val Loss: 0.441149
2025-09-01 17:55:45,473 - INFO - Epoch 69/5000 - Train Loss: 0.444451, Val Loss: 0.440143
2025-09-01 17:55:45,493 - INFO - New best model saved with Val Loss: 0.440143
2025-09-01 17:56:10,997 - INFO - Epoch 70/5000 - Train Loss: 0.445009, Val Loss: 0.433517
2025-09-01 17:56:11,017 - INFO - New best model saved with Val Loss: 0.433517
2025-09-01 17:56:36,730 - INFO - Epoch 71/5000 - Train Loss: 0.445875, Val Loss: 0.449245
2025-09-01 17:57:02,338 - INFO - Epoch 72/5000 - Train Loss: 0.440970, Val Loss: 0.447506
2025-09-01 17:57:27,842 - INFO - Epoch 73/5000 - Train Loss: 0.443421, Val Loss: 0.436862
2025-09-01 17:57:53,353 - INFO - Epoch 74/5000 - Train Loss: 0.440775, Val Loss: 0.435553
2025-09-01 17:58:18,583 - INFO - Epoch 75/5000 - Train Loss: 0.438215, Val Loss: 0.435006
2025-09-01 17:58:44,088 - INFO - Epoch 76/5000 - Train Loss: 0.439653, Val Loss: 0.437951
2025-09-01 17:59:09,529 - INFO - Epoch 77/5000 - Train Loss: 0.444836, Val Loss: 0.460200
2025-09-01 17:59:35,110 - INFO - Epoch 78/5000 - Train Loss: 0.437206, Val Loss: 0.425584
2025-09-01 17:59:35,167 - INFO - New best model saved with Val Loss: 0.425584
2025-09-01 18:00:00,665 - INFO - Epoch 79/5000 - Train Loss: 0.439414, Val Loss: 0.434517
2025-09-01 18:00:26,329 - INFO - Epoch 80/5000 - Train Loss: 0.436649, Val Loss: 0.440203
2025-09-01 18:00:52,251 - INFO - Epoch 81/5000 - Train Loss: 0.435237, Val Loss: 0.432543
2025-09-01 18:01:17,862 - INFO - Epoch 82/5000 - Train Loss: 0.437173, Val Loss: 0.435907
2025-09-01 18:01:43,418 - INFO - Epoch 83/5000 - Train Loss: 0.430181, Val Loss: 0.457602
2025-09-01 18:02:09,037 - INFO - Epoch 84/5000 - Train Loss: 0.434453, Val Loss: 0.432737
2025-09-01 18:02:34,818 - INFO - Epoch 85/5000 - Train Loss: 0.429417, Val Loss: 0.440193
2025-09-01 18:03:00,186 - INFO - Epoch 86/5000 - Train Loss: 0.429012, Val Loss: 0.437731
2025-09-01 18:03:25,638 - INFO - Epoch 87/5000 - Train Loss: 0.428205, Val Loss: 0.425643
2025-09-01 18:03:51,004 - INFO - Epoch 88/5000 - Train Loss: 0.437475, Val Loss: 0.436827
2025-09-01 18:04:16,685 - INFO - Epoch 89/5000 - Train Loss: 0.430382, Val Loss: 0.446553
2025-09-01 18:04:42,170 - INFO - Epoch 90/5000 - Train Loss: 0.432030, Val Loss: 0.426456
2025-09-01 18:05:07,997 - INFO - Epoch 91/5000 - Train Loss: 0.429080, Val Loss: 0.453495
2025-09-01 18:05:33,448 - INFO - Epoch 92/5000 - Train Loss: 0.428837, Val Loss: 0.436246
2025-09-01 18:05:59,080 - INFO - Epoch 93/5000 - Train Loss: 0.424819, Val Loss: 0.424269
2025-09-01 18:05:59,116 - INFO - New best model saved with Val Loss: 0.424269
2025-09-01 18:06:24,799 - INFO - Epoch 94/5000 - Train Loss: 0.423849, Val Loss: 0.424479
2025-09-01 18:06:50,307 - INFO - Epoch 95/5000 - Train Loss: 0.431064, Val Loss: 0.432971
2025-09-01 18:07:16,126 - INFO - Epoch 96/5000 - Train Loss: 0.424720, Val Loss: 0.439299
2025-09-01 18:07:41,743 - INFO - Epoch 97/5000 - Train Loss: 0.427440, Val Loss: 0.424164
2025-09-01 18:07:41,762 - INFO - New best model saved with Val Loss: 0.424164
2025-09-01 18:08:07,451 - INFO - Epoch 98/5000 - Train Loss: 0.422400, Val Loss: 0.429350
2025-09-01 18:08:32,982 - INFO - Epoch 99/5000 - Train Loss: 0.423529, Val Loss: 0.420274
2025-09-01 18:08:33,003 - INFO - New best model saved with Val Loss: 0.420274
2025-09-01 18:08:58,603 - INFO - Epoch 100/5000 - Train Loss: 0.419682, Val Loss: 0.414362
2025-09-01 18:08:58,623 - INFO - New best model saved with Val Loss: 0.414362
2025-09-01 18:09:24,465 - INFO - Epoch 101/5000 - Train Loss: 0.422918, Val Loss: 0.418027
2025-09-01 18:09:49,974 - INFO - Epoch 102/5000 - Train Loss: 0.420890, Val Loss: 0.424415
2025-09-01 18:10:15,389 - INFO - Epoch 103/5000 - Train Loss: 0.418429, Val Loss: 0.414021
2025-09-01 18:10:15,424 - INFO - New best model saved with Val Loss: 0.414021
2025-09-01 18:10:40,938 - INFO - Epoch 104/5000 - Train Loss: 0.416163, Val Loss: 0.424333
2025-09-01 18:11:06,427 - INFO - Epoch 105/5000 - Train Loss: 0.423996, Val Loss: 0.412435
2025-09-01 18:11:06,447 - INFO - New best model saved with Val Loss: 0.412435
2025-09-01 18:11:32,039 - INFO - Epoch 106/5000 - Train Loss: 0.417551, Val Loss: 0.418327
2025-09-01 18:11:57,848 - INFO - Epoch 107/5000 - Train Loss: 0.416646, Val Loss: 0.446683
2025-09-01 18:12:23,200 - INFO - Epoch 108/5000 - Train Loss: 0.417593, Val Loss: 0.424255
2025-09-01 18:12:48,616 - INFO - Epoch 109/5000 - Train Loss: 0.413788, Val Loss: 0.418835
2025-09-01 18:13:14,325 - INFO - Epoch 110/5000 - Train Loss: 0.419680, Val Loss: 0.420273
2025-09-01 18:13:39,898 - INFO - Epoch 111/5000 - Train Loss: 0.422688, Val Loss: 0.422007
2025-09-01 18:14:05,516 - INFO - Epoch 112/5000 - Train Loss: 0.422405, Val Loss: 0.453688
2025-09-01 18:14:31,329 - INFO - Epoch 113/5000 - Train Loss: 0.417607, Val Loss: 0.408543
2025-09-01 18:14:31,349 - INFO - New best model saved with Val Loss: 0.408543
2025-09-01 18:14:56,906 - INFO - Epoch 114/5000 - Train Loss: 0.414682, Val Loss: 0.411232
2025-09-01 18:15:22,722 - INFO - Epoch 115/5000 - Train Loss: 0.413130, Val Loss: 0.413983
2025-09-01 18:15:48,467 - INFO - Epoch 116/5000 - Train Loss: 0.413349, Val Loss: 0.411327
2025-09-01 18:16:13,969 - INFO - Epoch 117/5000 - Train Loss: 0.411347, Val Loss: 0.413056
2025-09-01 18:16:39,800 - INFO - Epoch 118/5000 - Train Loss: 0.409850, Val Loss: 0.434564
2025-09-01 18:17:05,722 - INFO - Epoch 119/5000 - Train Loss: 0.412646, Val Loss: 0.423646
2025-09-01 18:17:31,276 - INFO - Epoch 120/5000 - Train Loss: 0.410187, Val Loss: 0.418923
2025-09-01 18:17:56,984 - INFO - Epoch 121/5000 - Train Loss: 0.408835, Val Loss: 0.420447
2025-09-01 18:18:22,569 - INFO - Epoch 122/5000 - Train Loss: 0.406526, Val Loss: 0.402965
2025-09-01 18:18:22,590 - INFO - New best model saved with Val Loss: 0.402965
2025-09-01 18:18:47,952 - INFO - Epoch 123/5000 - Train Loss: 0.408003, Val Loss: 0.409209
2025-09-01 18:19:13,406 - INFO - Epoch 124/5000 - Train Loss: 0.409930, Val Loss: 0.414095
2025-09-01 18:19:39,219 - INFO - Epoch 125/5000 - Train Loss: 0.406378, Val Loss: 0.411590
2025-09-01 18:20:04,863 - INFO - Epoch 126/5000 - Train Loss: 0.407370, Val Loss: 0.432128
2025-09-01 18:20:30,624 - INFO - Epoch 127/5000 - Train Loss: 0.408972, Val Loss: 0.405878
2025-09-01 18:20:56,375 - INFO - Epoch 128/5000 - Train Loss: 0.410693, Val Loss: 0.423206
2025-09-01 18:21:22,363 - INFO - Epoch 129/5000 - Train Loss: 0.408380, Val Loss: 0.436003
2025-09-01 18:21:47,919 - INFO - Epoch 130/5000 - Train Loss: 0.407154, Val Loss: 0.412711
2025-09-01 18:22:13,533 - INFO - Epoch 131/5000 - Train Loss: 0.404372, Val Loss: 0.399249
2025-09-01 18:22:13,553 - INFO - New best model saved with Val Loss: 0.399249
2025-09-01 18:22:39,012 - INFO - Epoch 132/5000 - Train Loss: 0.409074, Val Loss: 0.402585
2025-09-01 18:23:04,658 - INFO - Epoch 133/5000 - Train Loss: 0.403840, Val Loss: 0.401551
2025-09-01 18:23:30,332 - INFO - Epoch 134/5000 - Train Loss: 0.406409, Val Loss: 0.406791
2025-09-01 18:23:55,714 - INFO - Epoch 135/5000 - Train Loss: 0.402522, Val Loss: 0.405867
2025-09-01 18:24:21,546 - INFO - Epoch 136/5000 - Train Loss: 0.403270, Val Loss: 0.407174
2025-09-01 18:24:47,385 - INFO - Epoch 137/5000 - Train Loss: 0.401827, Val Loss: 0.406272
2025-09-01 18:25:13,036 - INFO - Epoch 138/5000 - Train Loss: 0.399398, Val Loss: 0.405140
2025-09-01 18:25:38,609 - INFO - Epoch 139/5000 - Train Loss: 0.398495, Val Loss: 0.411164
2025-09-01 18:26:04,522 - INFO - Epoch 140/5000 - Train Loss: 0.403969, Val Loss: 0.411364
2025-09-01 18:26:30,440 - INFO - Epoch 141/5000 - Train Loss: 0.398145, Val Loss: 0.409925
2025-09-01 18:26:55,983 - INFO - Epoch 142/5000 - Train Loss: 0.400914, Val Loss: 0.400368
2025-09-01 18:27:21,607 - INFO - Epoch 143/5000 - Train Loss: 0.406669, Val Loss: 0.409376
2025-09-01 18:27:46,920 - INFO - Epoch 144/5000 - Train Loss: 0.400280, Val Loss: 0.407004
2025-09-01 18:28:12,613 - INFO - Epoch 145/5000 - Train Loss: 0.396410, Val Loss: 0.404727
2025-09-01 18:28:38,523 - INFO - Epoch 146/5000 - Train Loss: 0.397766, Val Loss: 0.397357
2025-09-01 18:28:38,544 - INFO - New best model saved with Val Loss: 0.397357
2025-09-01 18:29:04,284 - INFO - Epoch 147/5000 - Train Loss: 0.395118, Val Loss: 0.400105
2025-09-01 18:29:30,185 - INFO - Epoch 148/5000 - Train Loss: 0.397984, Val Loss: 0.406356
2025-09-01 18:29:56,073 - INFO - Epoch 149/5000 - Train Loss: 0.402766, Val Loss: 0.403482
2025-09-01 18:30:21,628 - INFO - Epoch 150/5000 - Train Loss: 0.396028, Val Loss: 0.391395
2025-09-01 18:30:21,649 - INFO - New best model saved with Val Loss: 0.391395
2025-09-01 18:30:47,359 - INFO - Epoch 151/5000 - Train Loss: 0.398132, Val Loss: 0.406346
2025-09-01 18:31:13,038 - INFO - Epoch 152/5000 - Train Loss: 0.395991, Val Loss: 0.399652
2025-09-01 18:31:38,916 - INFO - Epoch 153/5000 - Train Loss: 0.392154, Val Loss: 0.390905
2025-09-01 18:31:38,936 - INFO - New best model saved with Val Loss: 0.390905
2025-09-01 18:32:04,566 - INFO - Epoch 154/5000 - Train Loss: 0.397364, Val Loss: 0.400830
2025-09-01 18:32:30,480 - INFO - Epoch 155/5000 - Train Loss: 0.394104, Val Loss: 0.394947
2025-09-01 18:32:55,925 - INFO - Epoch 156/5000 - Train Loss: 0.393864, Val Loss: 0.410712
2025-09-01 18:33:21,704 - INFO - Epoch 157/5000 - Train Loss: 0.392016, Val Loss: 0.386549
2025-09-01 18:33:21,724 - INFO - New best model saved with Val Loss: 0.386549
2025-09-01 18:33:47,467 - INFO - Epoch 158/5000 - Train Loss: 0.392193, Val Loss: 0.392000
2025-09-01 18:34:12,869 - INFO - Epoch 159/5000 - Train Loss: 0.388012, Val Loss: 0.382502
2025-09-01 18:34:12,890 - INFO - New best model saved with Val Loss: 0.382502
2025-09-01 18:34:38,682 - INFO - Epoch 160/5000 - Train Loss: 0.387191, Val Loss: 0.400791
2025-09-01 18:35:04,552 - INFO - Epoch 161/5000 - Train Loss: 0.387177, Val Loss: 0.385075
2025-09-01 18:35:30,240 - INFO - Epoch 162/5000 - Train Loss: 0.390468, Val Loss: 0.423450
2025-09-01 18:35:55,798 - INFO - Epoch 163/5000 - Train Loss: 0.393177, Val Loss: 0.383766
2025-09-01 18:36:21,474 - INFO - Epoch 164/5000 - Train Loss: 0.388437, Val Loss: 0.397361
2025-09-01 18:36:47,186 - INFO - Epoch 165/5000 - Train Loss: 0.387338, Val Loss: 0.384641
2025-09-01 18:37:12,862 - INFO - Epoch 166/5000 - Train Loss: 0.391137, Val Loss: 0.388872
2025-09-01 18:37:38,555 - INFO - Epoch 167/5000 - Train Loss: 0.385992, Val Loss: 0.396096
2025-09-01 18:38:04,265 - INFO - Epoch 168/5000 - Train Loss: 0.384630, Val Loss: 0.384397
2025-09-01 18:38:29,620 - INFO - Epoch 169/5000 - Train Loss: 0.383966, Val Loss: 0.385618
2025-09-01 18:38:55,431 - INFO - Epoch 170/5000 - Train Loss: 0.385022, Val Loss: 0.382196
2025-09-01 18:38:55,452 - INFO - New best model saved with Val Loss: 0.382196
2025-09-01 18:39:21,056 - INFO - Epoch 171/5000 - Train Loss: 0.389361, Val Loss: 0.382947
2025-09-01 18:39:46,714 - INFO - Epoch 172/5000 - Train Loss: 0.384148, Val Loss: 0.391403
2025-09-01 18:40:12,159 - INFO - Epoch 173/5000 - Train Loss: 0.380789, Val Loss: 0.386379
2025-09-01 18:40:37,782 - INFO - Epoch 174/5000 - Train Loss: 0.379953, Val Loss: 0.390952
2025-09-01 18:41:03,401 - INFO - Epoch 175/5000 - Train Loss: 0.379150, Val Loss: 0.386657
2025-09-01 18:41:28,889 - INFO - Epoch 176/5000 - Train Loss: 0.382248, Val Loss: 0.410234
2025-09-01 18:41:54,328 - INFO - Epoch 177/5000 - Train Loss: 0.382135, Val Loss: 0.374307
2025-09-01 18:41:54,349 - INFO - New best model saved with Val Loss: 0.374307
2025-09-01 18:42:20,128 - INFO - Epoch 178/5000 - Train Loss: 0.380870, Val Loss: 0.388343
2025-09-01 18:42:45,490 - INFO - Epoch 179/5000 - Train Loss: 0.381765, Val Loss: 0.379291
2025-09-01 18:43:11,120 - INFO - Epoch 180/5000 - Train Loss: 0.377734, Val Loss: 0.383345
2025-09-01 18:43:37,053 - INFO - Epoch 181/5000 - Train Loss: 0.376974, Val Loss: 0.371051
2025-09-01 18:43:37,073 - INFO - New best model saved with Val Loss: 0.371051
2025-09-01 18:44:02,683 - INFO - Epoch 182/5000 - Train Loss: 0.375045, Val Loss: 0.378664
2025-09-01 18:44:28,210 - INFO - Epoch 183/5000 - Train Loss: 0.375685, Val Loss: 0.386706
2025-09-01 18:44:53,748 - INFO - Epoch 184/5000 - Train Loss: 0.373808, Val Loss: 0.378012
2025-09-01 18:45:19,440 - INFO - Epoch 185/5000 - Train Loss: 0.374054, Val Loss: 0.383527
2025-09-01 18:45:45,189 - INFO - Epoch 186/5000 - Train Loss: 0.377705, Val Loss: 0.376477
2025-09-01 18:46:10,859 - INFO - Epoch 187/5000 - Train Loss: 0.378666, Val Loss: 0.388666
2025-09-01 18:46:36,497 - INFO - Epoch 188/5000 - Train Loss: 0.381836, Val Loss: 0.371098
2025-09-01 18:47:01,961 - INFO - Epoch 189/5000 - Train Loss: 0.370579, Val Loss: 0.368454
2025-09-01 18:47:01,982 - INFO - New best model saved with Val Loss: 0.368454
2025-09-01 18:47:27,526 - INFO - Epoch 190/5000 - Train Loss: 0.369158, Val Loss: 0.386331
2025-09-01 18:47:53,306 - INFO - Epoch 191/5000 - Train Loss: 0.370171, Val Loss: 0.369456
2025-09-01 18:48:18,853 - INFO - Epoch 192/5000 - Train Loss: 0.371930, Val Loss: 0.379977
2025-09-01 18:48:44,336 - INFO - Epoch 193/5000 - Train Loss: 0.368307, Val Loss: 0.368313
2025-09-01 18:48:44,357 - INFO - New best model saved with Val Loss: 0.368313
2025-09-01 18:49:09,984 - INFO - Epoch 194/5000 - Train Loss: 0.373859, Val Loss: 0.376222
2025-09-01 18:49:35,538 - INFO - Epoch 195/5000 - Train Loss: 0.373306, Val Loss: 0.378804
2025-09-01 18:50:01,057 - INFO - Epoch 196/5000 - Train Loss: 0.367066, Val Loss: 0.369336
2025-09-01 18:50:26,373 - INFO - Epoch 197/5000 - Train Loss: 0.367864, Val Loss: 0.374447
2025-09-01 18:50:51,992 - INFO - Epoch 198/5000 - Train Loss: 0.379609, Val Loss: 0.367520
2025-09-01 18:50:52,031 - INFO - New best model saved with Val Loss: 0.367520
2025-09-01 18:51:17,650 - INFO - Epoch 199/5000 - Train Loss: 0.369121, Val Loss: 0.374246
2025-09-01 18:51:43,127 - INFO - Epoch 200/5000 - Train Loss: 0.369037, Val Loss: 0.363627
2025-09-01 18:51:43,147 - INFO - New best model saved with Val Loss: 0.363627
2025-09-01 18:52:09,058 - INFO - Epoch 201/5000 - Train Loss: 0.366927, Val Loss: 0.369404
2025-09-01 18:52:34,582 - INFO - Epoch 202/5000 - Train Loss: 0.369029, Val Loss: 0.359591
2025-09-01 18:52:34,602 - INFO - New best model saved with Val Loss: 0.359591
2025-09-01 18:53:00,329 - INFO - Epoch 203/5000 - Train Loss: 0.361317, Val Loss: 0.358561
2025-09-01 18:53:00,349 - INFO - New best model saved with Val Loss: 0.358561
2025-09-01 18:53:26,115 - INFO - Epoch 204/5000 - Train Loss: 0.360513, Val Loss: 0.370355
2025-09-01 18:53:51,637 - INFO - Epoch 205/5000 - Train Loss: 0.363595, Val Loss: 0.367585
2025-09-01 18:54:17,387 - INFO - Epoch 206/5000 - Train Loss: 0.369806, Val Loss: 0.373040
2025-09-01 18:54:43,177 - INFO - Epoch 207/5000 - Train Loss: 0.361992, Val Loss: 0.362432
2025-09-01 18:55:08,843 - INFO - Epoch 208/5000 - Train Loss: 0.360005, Val Loss: 0.361121
2025-09-01 18:55:34,731 - INFO - Epoch 209/5000 - Train Loss: 0.370077, Val Loss: 0.386689
2025-09-01 18:56:00,424 - INFO - Epoch 210/5000 - Train Loss: 0.361309, Val Loss: 0.363443
2025-09-01 18:56:26,175 - INFO - Epoch 211/5000 - Train Loss: 0.361633, Val Loss: 0.370742
2025-09-01 18:56:51,846 - INFO - Epoch 212/5000 - Train Loss: 0.364075, Val Loss: 0.382162
2025-09-01 18:57:17,643 - INFO - Epoch 213/5000 - Train Loss: 0.365220, Val Loss: 0.376172
2025-09-01 18:57:43,305 - INFO - Epoch 214/5000 - Train Loss: 0.356876, Val Loss: 0.352684
2025-09-01 18:57:43,325 - INFO - New best model saved with Val Loss: 0.352684
2025-09-01 18:58:08,908 - INFO - Epoch 215/5000 - Train Loss: 0.364478, Val Loss: 0.353885
2025-09-01 18:58:34,314 - INFO - Epoch 216/5000 - Train Loss: 0.360741, Val Loss: 0.369793
2025-09-01 18:58:59,795 - INFO - Epoch 217/5000 - Train Loss: 0.357179, Val Loss: 0.361778
2025-09-01 18:59:25,227 - INFO - Epoch 218/5000 - Train Loss: 0.357044, Val Loss: 0.377043
2025-09-01 18:59:50,803 - INFO - Epoch 219/5000 - Train Loss: 0.361286, Val Loss: 0.364465
2025-09-01 19:00:16,584 - INFO - Epoch 220/5000 - Train Loss: 0.361500, Val Loss: 0.380236
2025-09-01 19:00:42,393 - INFO - Epoch 221/5000 - Train Loss: 0.360217, Val Loss: 0.353862
2025-09-01 19:01:07,718 - INFO - Epoch 222/5000 - Train Loss: 0.358270, Val Loss: 0.360134
2025-09-01 19:01:33,315 - INFO - Epoch 223/5000 - Train Loss: 0.355067, Val Loss: 0.347367
2025-09-01 19:01:33,335 - INFO - New best model saved with Val Loss: 0.347367
2025-09-01 19:01:58,952 - INFO - Epoch 224/5000 - Train Loss: 0.362273, Val Loss: 0.373583
2025-09-01 19:02:24,584 - INFO - Epoch 225/5000 - Train Loss: 0.361171, Val Loss: 0.365910
2025-09-01 19:02:50,028 - INFO - Epoch 226/5000 - Train Loss: 0.358639, Val Loss: 0.361916
2025-09-01 19:03:15,875 - INFO - Epoch 227/5000 - Train Loss: 0.357418, Val Loss: 0.354925
2025-09-01 19:03:41,257 - INFO - Epoch 228/5000 - Train Loss: 0.352949, Val Loss: 0.352349
2025-09-01 19:04:06,863 - INFO - Epoch 229/5000 - Train Loss: 0.350265, Val Loss: 0.376030
2025-09-01 19:04:32,481 - INFO - Epoch 230/5000 - Train Loss: 0.354500, Val Loss: 0.354139
2025-09-01 19:04:58,219 - INFO - Epoch 231/5000 - Train Loss: 0.350930, Val Loss: 0.354836
2025-09-01 19:05:23,921 - INFO - Epoch 232/5000 - Train Loss: 0.353891, Val Loss: 0.349729
2025-09-01 19:05:49,552 - INFO - Epoch 233/5000 - Train Loss: 0.356675, Val Loss: 0.357450
2025-09-01 19:06:15,238 - INFO - Epoch 234/5000 - Train Loss: 0.354783, Val Loss: 0.345654
2025-09-01 19:06:15,260 - INFO - New best model saved with Val Loss: 0.345654
2025-09-01 19:06:40,906 - INFO - Epoch 235/5000 - Train Loss: 0.354863, Val Loss: 0.363750
2025-09-01 19:07:06,911 - INFO - Epoch 236/5000 - Train Loss: 0.352383, Val Loss: 0.362169
2025-09-01 19:07:32,453 - INFO - Epoch 237/5000 - Train Loss: 0.348606, Val Loss: 0.348884
2025-09-01 19:07:57,900 - INFO - Epoch 238/5000 - Train Loss: 0.350939, Val Loss: 0.347024
2025-09-01 19:08:23,418 - INFO - Epoch 239/5000 - Train Loss: 0.350391, Val Loss: 0.351512
2025-09-01 19:08:49,084 - INFO - Epoch 240/5000 - Train Loss: 0.357663, Val Loss: 0.355558
2025-09-01 19:09:14,635 - INFO - Epoch 241/5000 - Train Loss: 0.353207, Val Loss: 0.350666
2025-09-01 19:09:40,256 - INFO - Epoch 242/5000 - Train Loss: 0.348739, Val Loss: 0.353311
2025-09-01 19:10:06,037 - INFO - Epoch 243/5000 - Train Loss: 0.350404, Val Loss: 0.343697
2025-09-01 19:10:06,067 - INFO - New best model saved with Val Loss: 0.343697
2025-09-01 19:10:31,656 - INFO - Epoch 244/5000 - Train Loss: 0.348625, Val Loss: 0.355518
2025-09-01 19:10:57,221 - INFO - Epoch 245/5000 - Train Loss: 0.348374, Val Loss: 0.343258
2025-09-01 19:10:57,241 - INFO - New best model saved with Val Loss: 0.343258
2025-09-01 19:11:22,723 - INFO - Epoch 246/5000 - Train Loss: 0.347137, Val Loss: 0.340326
2025-09-01 19:11:22,743 - INFO - New best model saved with Val Loss: 0.340326
2025-09-01 19:11:48,100 - INFO - Epoch 247/5000 - Train Loss: 0.352816, Val Loss: 0.349838
2025-09-01 19:12:13,548 - INFO - Epoch 248/5000 - Train Loss: 0.347345, Val Loss: 0.350692
2025-09-01 19:12:39,401 - INFO - Epoch 249/5000 - Train Loss: 0.348256, Val Loss: 0.345496
2025-09-01 19:13:04,940 - INFO - Epoch 250/5000 - Train Loss: 0.345866, Val Loss: 0.361631
2025-09-01 19:13:30,853 - INFO - Epoch 251/5000 - Train Loss: 0.345154, Val Loss: 0.338399
2025-09-01 19:13:30,889 - INFO - New best model saved with Val Loss: 0.338399
2025-09-01 19:13:56,838 - INFO - Epoch 252/5000 - Train Loss: 0.346099, Val Loss: 0.360094
2025-09-01 19:14:22,401 - INFO - Epoch 253/5000 - Train Loss: 0.341522, Val Loss: 0.359086
2025-09-01 19:14:48,165 - INFO - Epoch 254/5000 - Train Loss: 0.344109, Val Loss: 0.348230
2025-09-01 19:15:13,771 - INFO - Epoch 255/5000 - Train Loss: 0.349415, Val Loss: 0.352705
2025-09-01 19:15:39,541 - INFO - Epoch 256/5000 - Train Loss: 0.343372, Val Loss: 0.351583
2025-09-01 19:16:05,274 - INFO - Epoch 257/5000 - Train Loss: 0.344165, Val Loss: 0.341944
2025-09-01 19:16:30,802 - INFO - Epoch 258/5000 - Train Loss: 0.343957, Val Loss: 0.368790
2025-09-01 19:16:56,654 - INFO - Epoch 259/5000 - Train Loss: 0.343690, Val Loss: 0.346646
2025-09-01 19:17:22,345 - INFO - Epoch 260/5000 - Train Loss: 0.340884, Val Loss: 0.342836
2025-09-01 19:17:48,055 - INFO - Epoch 261/5000 - Train Loss: 0.342082, Val Loss: 0.338433
2025-09-01 19:18:13,663 - INFO - Epoch 262/5000 - Train Loss: 0.339956, Val Loss: 0.337325
2025-09-01 19:18:13,684 - INFO - New best model saved with Val Loss: 0.337325
2025-09-01 19:18:39,297 - INFO - Epoch 263/5000 - Train Loss: 0.336430, Val Loss: 0.337852
2025-09-01 19:19:05,061 - INFO - Epoch 264/5000 - Train Loss: 0.342004, Val Loss: 0.345509
2025-09-01 19:19:30,533 - INFO - Epoch 265/5000 - Train Loss: 0.343372, Val Loss: 0.358024
2025-09-01 19:19:56,270 - INFO - Epoch 266/5000 - Train Loss: 0.338540, Val Loss: 0.346475
2025-09-01 19:20:21,832 - INFO - Epoch 267/5000 - Train Loss: 0.341506, Val Loss: 0.361280
2025-09-01 19:20:47,732 - INFO - Epoch 268/5000 - Train Loss: 0.342068, Val Loss: 0.348893
2025-09-01 19:21:13,522 - INFO - Epoch 269/5000 - Train Loss: 0.336927, Val Loss: 0.333520
2025-09-01 19:21:13,543 - INFO - New best model saved with Val Loss: 0.333520
2025-09-01 19:21:39,143 - INFO - Epoch 270/5000 - Train Loss: 0.334580, Val Loss: 0.340907
2025-09-01 19:22:04,988 - INFO - Epoch 271/5000 - Train Loss: 0.334434, Val Loss: 0.339484
2025-09-01 19:22:30,485 - INFO - Epoch 272/5000 - Train Loss: 0.336173, Val Loss: 0.362226
2025-09-01 19:22:56,104 - INFO - Epoch 273/5000 - Train Loss: 0.337293, Val Loss: 0.334772
2025-09-01 19:23:21,872 - INFO - Epoch 274/5000 - Train Loss: 0.338545, Val Loss: 0.363675
2025-09-01 19:23:47,617 - INFO - Epoch 275/5000 - Train Loss: 0.338534, Val Loss: 0.347327
2025-09-01 19:24:12,863 - INFO - Epoch 276/5000 - Train Loss: 0.332869, Val Loss: 0.328523
2025-09-01 19:24:12,884 - INFO - New best model saved with Val Loss: 0.328523
2025-09-01 19:24:38,387 - INFO - Epoch 277/5000 - Train Loss: 0.333015, Val Loss: 0.335401
2025-09-01 19:25:03,971 - INFO - Epoch 278/5000 - Train Loss: 0.331400, Val Loss: 0.349888
2025-09-01 19:25:29,832 - INFO - Epoch 279/5000 - Train Loss: 0.331867, Val Loss: 0.342585
2025-09-01 19:25:55,158 - INFO - Epoch 280/5000 - Train Loss: 0.332806, Val Loss: 0.331394
2025-09-01 19:26:20,995 - INFO - Epoch 281/5000 - Train Loss: 0.337093, Val Loss: 0.339632
2025-09-01 19:26:46,722 - INFO - Epoch 282/5000 - Train Loss: 0.333376, Val Loss: 0.334106
2025-09-01 19:27:12,501 - INFO - Epoch 283/5000 - Train Loss: 0.330077, Val Loss: 0.340717
2025-09-01 19:27:38,246 - INFO - Epoch 284/5000 - Train Loss: 0.328909, Val Loss: 0.352742
2025-09-01 19:28:04,013 - INFO - Epoch 285/5000 - Train Loss: 0.333008, Val Loss: 0.327582
2025-09-01 19:28:04,035 - INFO - New best model saved with Val Loss: 0.327582
2025-09-01 19:28:29,681 - INFO - Epoch 286/5000 - Train Loss: 0.331473, Val Loss: 0.348078
2025-09-01 19:28:55,496 - INFO - Epoch 287/5000 - Train Loss: 0.330918, Val Loss: 0.323776
2025-09-01 19:28:55,516 - INFO - New best model saved with Val Loss: 0.323776
2025-09-01 19:29:21,418 - INFO - Epoch 288/5000 - Train Loss: 0.327413, Val Loss: 0.333460
2025-09-01 19:29:47,192 - INFO - Epoch 289/5000 - Train Loss: 0.328680, Val Loss: 0.324710
2025-09-01 19:30:12,801 - INFO - Epoch 290/5000 - Train Loss: 0.324958, Val Loss: 0.332587
2025-09-01 19:30:38,715 - INFO - Epoch 291/5000 - Train Loss: 0.323567, Val Loss: 0.325841
2025-09-01 19:31:03,849 - INFO - Epoch 292/5000 - Train Loss: 0.325342, Val Loss: 0.321481
2025-09-01 19:31:03,870 - INFO - New best model saved with Val Loss: 0.321481
2025-09-01 19:31:29,318 - INFO - Epoch 293/5000 - Train Loss: 0.326297, Val Loss: 0.326199
2025-09-01 19:31:54,873 - INFO - Epoch 294/5000 - Train Loss: 0.332521, Val Loss: 0.329418
2025-09-01 19:32:20,567 - INFO - Epoch 295/5000 - Train Loss: 0.326126, Val Loss: 0.321516
2025-09-01 19:32:46,283 - INFO - Epoch 296/5000 - Train Loss: 0.324190, Val Loss: 0.327532
2025-09-01 19:33:11,983 - INFO - Epoch 297/5000 - Train Loss: 0.328871, Val Loss: 0.339569
2025-09-01 19:33:37,577 - INFO - Epoch 298/5000 - Train Loss: 0.326416, Val Loss: 0.325440
2025-09-01 19:34:03,047 - INFO - Epoch 299/5000 - Train Loss: 0.323209, Val Loss: 0.330133
2025-09-01 19:34:28,500 - INFO - Epoch 300/5000 - Train Loss: 0.323687, Val Loss: 0.344557
2025-09-01 19:34:54,381 - INFO - Epoch 301/5000 - Train Loss: 0.326270, Val Loss: 0.325829
2025-09-01 19:35:19,825 - INFO - Epoch 302/5000 - Train Loss: 0.324015, Val Loss: 0.323447
2025-09-01 19:35:45,338 - INFO - Epoch 303/5000 - Train Loss: 0.324136, Val Loss: 0.336059
2025-09-01 19:36:10,784 - INFO - Epoch 304/5000 - Train Loss: 0.323058, Val Loss: 0.317006
2025-09-01 19:36:10,805 - INFO - New best model saved with Val Loss: 0.317006
2025-09-01 19:36:36,608 - INFO - Epoch 305/5000 - Train Loss: 0.316977, Val Loss: 0.335474
2025-09-01 19:37:02,149 - INFO - Epoch 306/5000 - Train Loss: 0.317218, Val Loss: 0.329363
2025-09-01 19:37:27,912 - INFO - Epoch 307/5000 - Train Loss: 0.316388, Val Loss: 0.326449
2025-09-01 19:37:53,828 - INFO - Epoch 308/5000 - Train Loss: 0.316129, Val Loss: 0.326919
2025-09-01 19:38:19,661 - INFO - Epoch 309/5000 - Train Loss: 0.319763, Val Loss: 0.324678
2025-09-01 19:38:45,411 - INFO - Epoch 310/5000 - Train Loss: 0.318768, Val Loss: 0.324252
2025-09-01 19:39:11,320 - INFO - Epoch 311/5000 - Train Loss: 0.317019, Val Loss: 0.323041
2025-09-01 19:39:37,183 - INFO - Epoch 312/5000 - Train Loss: 0.315994, Val Loss: 0.335315
2025-09-01 19:40:02,649 - INFO - Epoch 313/5000 - Train Loss: 0.318755, Val Loss: 0.313493
2025-09-01 19:40:02,669 - INFO - New best model saved with Val Loss: 0.313493
2025-09-01 19:40:28,358 - INFO - Epoch 314/5000 - Train Loss: 0.315207, Val Loss: 0.311330
2025-09-01 19:40:28,378 - INFO - New best model saved with Val Loss: 0.311330
2025-09-01 19:40:54,221 - INFO - Epoch 315/5000 - Train Loss: 0.316650, Val Loss: 0.312028
2025-09-01 19:41:20,018 - INFO - Epoch 316/5000 - Train Loss: 0.320513, Val Loss: 0.314375
2025-09-01 19:41:45,540 - INFO - Epoch 317/5000 - Train Loss: 0.321383, Val Loss: 0.311011
2025-09-01 19:41:45,560 - INFO - New best model saved with Val Loss: 0.311011
2025-09-01 19:42:11,131 - INFO - Epoch 318/5000 - Train Loss: 0.314002, Val Loss: 0.329330
2025-09-01 19:42:36,899 - INFO - Epoch 319/5000 - Train Loss: 0.312501, Val Loss: 0.313909
2025-09-01 19:43:02,614 - INFO - Epoch 320/5000 - Train Loss: 0.314544, Val Loss: 0.314234
2025-09-01 19:43:28,454 - INFO - Epoch 321/5000 - Train Loss: 0.312983, Val Loss: 0.318425
2025-09-01 19:43:54,039 - INFO - Epoch 322/5000 - Train Loss: 0.317619, Val Loss: 0.322689
2025-09-01 19:44:19,662 - INFO - Epoch 323/5000 - Train Loss: 0.316514, Val Loss: 0.314858
2025-09-01 19:44:45,342 - INFO - Epoch 324/5000 - Train Loss: 0.313649, Val Loss: 0.319893
2025-09-01 19:45:10,709 - INFO - Epoch 325/5000 - Train Loss: 0.314385, Val Loss: 0.318630
2025-09-01 19:45:36,103 - INFO - Epoch 326/5000 - Train Loss: 0.307451, Val Loss: 0.305800
2025-09-01 19:45:36,123 - INFO - New best model saved with Val Loss: 0.305800
2025-09-01 19:46:01,593 - INFO - Epoch 327/5000 - Train Loss: 0.308137, Val Loss: 0.302532
2025-09-01 19:46:01,612 - INFO - New best model saved with Val Loss: 0.302532
2025-09-01 19:46:27,138 - INFO - Epoch 328/5000 - Train Loss: 0.312071, Val Loss: 0.303342
2025-09-01 19:46:52,455 - INFO - Epoch 329/5000 - Train Loss: 0.310036, Val Loss: 0.308959
2025-09-01 19:47:17,892 - INFO - Epoch 330/5000 - Train Loss: 0.306895, Val Loss: 0.312704
2025-09-01 19:47:43,540 - INFO - Epoch 331/5000 - Train Loss: 0.308838, Val Loss: 0.307919
2025-09-01 19:48:09,074 - INFO - Epoch 332/5000 - Train Loss: 0.308502, Val Loss: 0.306546
2025-09-01 19:48:34,638 - INFO - Epoch 333/5000 - Train Loss: 0.307514, Val Loss: 0.303203
2025-09-01 19:49:00,253 - INFO - Epoch 334/5000 - Train Loss: 0.309045, Val Loss: 0.307677
2025-09-01 19:49:25,625 - INFO - Epoch 335/5000 - Train Loss: 0.307942, Val Loss: 0.309401
2025-09-01 19:49:51,128 - INFO - Epoch 336/5000 - Train Loss: 0.307555, Val Loss: 0.298929
2025-09-01 19:49:51,147 - INFO - New best model saved with Val Loss: 0.298929
2025-09-01 19:50:16,901 - INFO - Epoch 337/5000 - Train Loss: 0.304885, Val Loss: 0.307705
2025-09-01 19:50:42,385 - INFO - Epoch 338/5000 - Train Loss: 0.306823, Val Loss: 0.306633
2025-09-01 19:51:08,060 - INFO - Epoch 339/5000 - Train Loss: 0.309012, Val Loss: 0.302956
2025-09-01 19:51:33,629 - INFO - Epoch 340/5000 - Train Loss: 0.311479, Val Loss: 0.305317
2025-09-01 19:51:59,134 - INFO - Epoch 341/5000 - Train Loss: 0.304658, Val Loss: 0.308573
2025-09-01 19:52:24,919 - INFO - Epoch 342/5000 - Train Loss: 0.302805, Val Loss: 0.304353
2025-09-01 19:52:50,773 - INFO - Epoch 343/5000 - Train Loss: 0.303689, Val Loss: 0.305591
2025-09-01 19:53:16,464 - INFO - Epoch 344/5000 - Train Loss: 0.307813, Val Loss: 0.324498
2025-09-01 19:53:42,267 - INFO - Epoch 345/5000 - Train Loss: 0.306012, Val Loss: 0.301781
2025-09-01 19:54:07,950 - INFO - Epoch 346/5000 - Train Loss: 0.302579, Val Loss: 0.306504
2025-09-01 19:54:33,655 - INFO - Epoch 347/5000 - Train Loss: 0.305204, Val Loss: 0.297571
2025-09-01 19:54:33,675 - INFO - New best model saved with Val Loss: 0.297571
2025-09-01 19:54:59,380 - INFO - Epoch 348/5000 - Train Loss: 0.302434, Val Loss: 0.304822
2025-09-01 19:55:24,834 - INFO - Epoch 349/5000 - Train Loss: 0.303598, Val Loss: 0.302907
2025-09-01 19:55:50,359 - INFO - Epoch 350/5000 - Train Loss: 0.299104, Val Loss: 0.308414
2025-09-01 19:56:16,109 - INFO - Epoch 351/5000 - Train Loss: 0.300542, Val Loss: 0.307043
2025-09-01 19:56:41,611 - INFO - Epoch 352/5000 - Train Loss: 0.301613, Val Loss: 0.307885
2025-09-01 19:57:07,151 - INFO - Epoch 353/5000 - Train Loss: 0.297836, Val Loss: 0.316301
2025-09-01 19:57:32,650 - INFO - Epoch 354/5000 - Train Loss: 0.300772, Val Loss: 0.298960
2025-09-01 19:57:58,474 - INFO - Epoch 355/5000 - Train Loss: 0.295882, Val Loss: 0.304983
2025-09-01 19:58:23,915 - INFO - Epoch 356/5000 - Train Loss: 0.298073, Val Loss: 0.310687
2025-09-01 19:58:49,572 - INFO - Epoch 357/5000 - Train Loss: 0.299656, Val Loss: 0.294207
2025-09-01 19:58:49,592 - INFO - New best model saved with Val Loss: 0.294207
2025-09-01 19:59:15,094 - INFO - Epoch 358/5000 - Train Loss: 0.299130, Val Loss: 0.307433
2025-09-01 19:59:40,831 - INFO - Epoch 359/5000 - Train Loss: 0.295477, Val Loss: 0.294851
2025-09-01 20:00:06,474 - INFO - Epoch 360/5000 - Train Loss: 0.297192, Val Loss: 0.298823
2025-09-01 20:00:32,336 - INFO - Epoch 361/5000 - Train Loss: 0.294951, Val Loss: 0.295367
2025-09-01 20:00:57,864 - INFO - Epoch 362/5000 - Train Loss: 0.298992, Val Loss: 0.327113
2025-09-01 20:01:23,354 - INFO - Epoch 363/5000 - Train Loss: 0.297562, Val Loss: 0.303156
2025-09-01 20:01:48,750 - INFO - Epoch 364/5000 - Train Loss: 0.297253, Val Loss: 0.293925
2025-09-01 20:01:48,771 - INFO - New best model saved with Val Loss: 0.293925
2025-09-01 20:02:14,111 - INFO - Epoch 365/5000 - Train Loss: 0.296326, Val Loss: 0.297908
2025-09-01 20:02:39,576 - INFO - Epoch 366/5000 - Train Loss: 0.293173, Val Loss: 0.296078
2025-09-01 20:03:05,228 - INFO - Epoch 367/5000 - Train Loss: 0.294018, Val Loss: 0.294993
2025-09-01 20:03:30,797 - INFO - Epoch 368/5000 - Train Loss: 0.292061, Val Loss: 0.290100
2025-09-01 20:03:30,817 - INFO - New best model saved with Val Loss: 0.290100
2025-09-01 20:03:56,639 - INFO - Epoch 369/5000 - Train Loss: 0.294144, Val Loss: 0.295901
2025-09-01 20:04:22,107 - INFO - Epoch 370/5000 - Train Loss: 0.291021, Val Loss: 0.291873
2025-09-01 20:04:47,788 - INFO - Epoch 371/5000 - Train Loss: 0.295862, Val Loss: 0.293639
2025-09-01 20:05:13,346 - INFO - Epoch 372/5000 - Train Loss: 0.291442, Val Loss: 0.282347
2025-09-01 20:05:13,366 - INFO - New best model saved with Val Loss: 0.282347
2025-09-01 20:05:39,125 - INFO - Epoch 373/5000 - Train Loss: 0.289129, Val Loss: 0.286466
2025-09-01 20:06:04,952 - INFO - Epoch 374/5000 - Train Loss: 0.298692, Val Loss: 0.310274
2025-09-01 20:06:30,441 - INFO - Epoch 375/5000 - Train Loss: 0.291338, Val Loss: 0.286314
2025-09-01 20:06:56,181 - INFO - Epoch 376/5000 - Train Loss: 0.290814, Val Loss: 0.291279
2025-09-01 20:07:21,899 - INFO - Epoch 377/5000 - Train Loss: 0.290375, Val Loss: 0.286429
2025-09-01 20:07:47,187 - INFO - Epoch 378/5000 - Train Loss: 0.286893, Val Loss: 0.283786
2025-09-01 20:08:12,930 - INFO - Epoch 379/5000 - Train Loss: 0.288542, Val Loss: 0.298047
2025-09-01 20:08:38,378 - INFO - Epoch 380/5000 - Train Loss: 0.291545, Val Loss: 0.281225
2025-09-01 20:08:38,412 - INFO - New best model saved with Val Loss: 0.281225
2025-09-01 20:09:04,346 - INFO - Epoch 381/5000 - Train Loss: 0.288700, Val Loss: 0.289505
2025-09-01 20:09:30,155 - INFO - Epoch 382/5000 - Train Loss: 0.288742, Val Loss: 0.283898
2025-09-01 20:09:55,786 - INFO - Epoch 383/5000 - Train Loss: 0.286699, Val Loss: 0.281086
2025-09-01 20:09:55,807 - INFO - New best model saved with Val Loss: 0.281086
2025-09-01 20:10:21,356 - INFO - Epoch 384/5000 - Train Loss: 0.288032, Val Loss: 0.287857
2025-09-01 20:10:47,248 - INFO - Epoch 385/5000 - Train Loss: 0.286678, Val Loss: 0.281263
2025-09-01 20:11:12,814 - INFO - Epoch 386/5000 - Train Loss: 0.286183, Val Loss: 0.293644
2025-09-01 20:11:38,444 - INFO - Epoch 387/5000 - Train Loss: 0.291518, Val Loss: 0.283321
2025-09-01 20:12:04,063 - INFO - Epoch 388/5000 - Train Loss: 0.287905, Val Loss: 0.281125
2025-09-01 20:12:29,876 - INFO - Epoch 389/5000 - Train Loss: 0.289772, Val Loss: 0.290662
2025-09-01 20:12:55,671 - INFO - Epoch 390/5000 - Train Loss: 0.285841, Val Loss: 0.298646
2025-09-01 20:13:21,293 - INFO - Epoch 391/5000 - Train Loss: 0.285137, Val Loss: 0.284615
2025-09-01 20:13:46,829 - INFO - Epoch 392/5000 - Train Loss: 0.290720, Val Loss: 0.283738
2025-09-01 20:14:12,310 - INFO - Epoch 393/5000 - Train Loss: 0.282637, Val Loss: 0.288524
2025-09-01 20:14:37,884 - INFO - Epoch 394/5000 - Train Loss: 0.284760, Val Loss: 0.278762
2025-09-01 20:14:37,904 - INFO - New best model saved with Val Loss: 0.278762
2025-09-01 20:15:03,451 - INFO - Epoch 395/5000 - Train Loss: 0.284939, Val Loss: 0.288196
2025-09-01 20:15:29,146 - INFO - Epoch 396/5000 - Train Loss: 0.290222, Val Loss: 0.279908
2025-09-01 20:15:54,680 - INFO - Epoch 397/5000 - Train Loss: 0.286304, Val Loss: 0.282979
2025-09-01 20:16:20,293 - INFO - Epoch 398/5000 - Train Loss: 0.282677, Val Loss: 0.289912
2025-09-01 20:16:45,934 - INFO - Epoch 399/5000 - Train Loss: 0.284210, Val Loss: 0.296298
2025-09-01 20:17:11,773 - INFO - Epoch 400/5000 - Train Loss: 0.283688, Val Loss: 0.288548
2025-09-01 20:17:37,752 - INFO - Epoch 401/5000 - Train Loss: 0.278655, Val Loss: 0.285724
2025-09-01 20:18:03,258 - INFO - Epoch 402/5000 - Train Loss: 0.280087, Val Loss: 0.274723
2025-09-01 20:18:03,278 - INFO - New best model saved with Val Loss: 0.274723
2025-09-01 20:18:28,976 - INFO - Epoch 403/5000 - Train Loss: 0.281330, Val Loss: 0.280060
2025-09-01 20:18:54,473 - INFO - Epoch 404/5000 - Train Loss: 0.283696, Val Loss: 0.276495
2025-09-01 20:19:19,976 - INFO - Epoch 405/5000 - Train Loss: 0.283579, Val Loss: 0.270466
2025-09-01 20:19:19,998 - INFO - New best model saved with Val Loss: 0.270466
2025-09-01 20:19:45,510 - INFO - Epoch 406/5000 - Train Loss: 0.277845, Val Loss: 0.274268
2025-09-01 20:20:10,999 - INFO - Epoch 407/5000 - Train Loss: 0.277185, Val Loss: 0.274778
2025-09-01 20:20:36,700 - INFO - Epoch 408/5000 - Train Loss: 0.280253, Val Loss: 0.274323
2025-09-01 20:21:02,451 - INFO - Epoch 409/5000 - Train Loss: 0.277972, Val Loss: 0.267149
2025-09-01 20:21:02,472 - INFO - New best model saved with Val Loss: 0.267149
2025-09-01 20:21:27,963 - INFO - Epoch 410/5000 - Train Loss: 0.280688, Val Loss: 0.283814
2025-09-01 20:21:53,893 - INFO - Epoch 411/5000 - Train Loss: 0.277543, Val Loss: 0.276059
2025-09-01 20:22:19,495 - INFO - Epoch 412/5000 - Train Loss: 0.278324, Val Loss: 0.277477
2025-09-01 20:22:45,216 - INFO - Epoch 413/5000 - Train Loss: 0.278907, Val Loss: 0.267258
2025-09-01 20:23:10,798 - INFO - Epoch 414/5000 - Train Loss: 0.276928, Val Loss: 0.277298
2025-09-01 20:23:36,438 - INFO - Epoch 415/5000 - Train Loss: 0.275466, Val Loss: 0.273535
2025-09-01 20:24:01,984 - INFO - Epoch 416/5000 - Train Loss: 0.276304, Val Loss: 0.271786
2025-09-01 20:24:27,610 - INFO - Epoch 417/5000 - Train Loss: 0.277408, Val Loss: 0.276505
2025-09-01 20:24:53,302 - INFO - Epoch 418/5000 - Train Loss: 0.273624, Val Loss: 0.265517
2025-09-01 20:24:53,324 - INFO - New best model saved with Val Loss: 0.265517
2025-09-01 20:25:19,182 - INFO - Epoch 419/5000 - Train Loss: 0.272482, Val Loss: 0.282304
2025-09-01 20:25:44,721 - INFO - Epoch 420/5000 - Train Loss: 0.274806, Val Loss: 0.270036
2025-09-01 20:26:10,309 - INFO - Epoch 421/5000 - Train Loss: 0.272785, Val Loss: 0.273018
2025-09-01 20:26:35,887 - INFO - Epoch 422/5000 - Train Loss: 0.273512, Val Loss: 0.268366
2025-09-01 20:27:01,358 - INFO - Epoch 423/5000 - Train Loss: 0.272245, Val Loss: 0.272317
2025-09-01 20:27:26,932 - INFO - Epoch 424/5000 - Train Loss: 0.273113, Val Loss: 0.265308
2025-09-01 20:27:26,970 - INFO - New best model saved with Val Loss: 0.265308
2025-09-01 20:27:52,760 - INFO - Epoch 425/5000 - Train Loss: 0.271529, Val Loss: 0.269215
2025-09-01 20:28:18,308 - INFO - Epoch 426/5000 - Train Loss: 0.270795, Val Loss: 0.259112
2025-09-01 20:28:18,328 - INFO - New best model saved with Val Loss: 0.259112
2025-09-01 20:28:44,037 - INFO - Epoch 427/5000 - Train Loss: 0.271339, Val Loss: 0.273103
2025-09-01 20:29:09,769 - INFO - Epoch 428/5000 - Train Loss: 0.271803, Val Loss: 0.264919
2025-09-01 20:29:35,406 - INFO - Epoch 429/5000 - Train Loss: 0.273624, Val Loss: 0.265407
2025-09-01 20:30:01,079 - INFO - Epoch 430/5000 - Train Loss: 0.270986, Val Loss: 0.263294
2025-09-01 20:30:26,663 - INFO - Epoch 431/5000 - Train Loss: 0.271907, Val Loss: 0.265198
2025-09-01 20:30:52,326 - INFO - Epoch 432/5000 - Train Loss: 0.268047, Val Loss: 0.262145
2025-09-01 20:31:18,053 - INFO - Epoch 433/5000 - Train Loss: 0.270715, Val Loss: 0.263013
2025-09-01 20:31:43,487 - INFO - Epoch 434/5000 - Train Loss: 0.271131, Val Loss: 0.265779
2025-09-01 20:32:09,266 - INFO - Epoch 435/5000 - Train Loss: 0.268374, Val Loss: 0.258322
2025-09-01 20:32:09,286 - INFO - New best model saved with Val Loss: 0.258322
2025-09-01 20:32:34,934 - INFO - Epoch 436/5000 - Train Loss: 0.268559, Val Loss: 0.265146
2025-09-01 20:33:00,542 - INFO - Epoch 437/5000 - Train Loss: 0.268116, Val Loss: 0.270524
2025-09-01 20:33:26,069 - INFO - Epoch 438/5000 - Train Loss: 0.268060, Val Loss: 0.260250
2025-09-01 20:33:51,639 - INFO - Epoch 439/5000 - Train Loss: 0.267621, Val Loss: 0.259760
2025-09-01 20:34:17,364 - INFO - Epoch 440/5000 - Train Loss: 0.266025, Val Loss: 0.268859
2025-09-01 20:34:42,999 - INFO - Epoch 441/5000 - Train Loss: 0.268556, Val Loss: 0.263000
2025-09-01 20:35:08,530 - INFO - Epoch 442/5000 - Train Loss: 0.267368, Val Loss: 0.264478
2025-09-01 20:35:34,124 - INFO - Epoch 443/5000 - Train Loss: 0.265640, Val Loss: 0.263453
2025-09-01 20:35:59,675 - INFO - Epoch 444/5000 - Train Loss: 0.266688, Val Loss: 0.264030
2025-09-01 20:36:25,148 - INFO - Epoch 445/5000 - Train Loss: 0.265188, Val Loss: 0.251099
2025-09-01 20:36:25,186 - INFO - New best model saved with Val Loss: 0.251099
2025-09-01 20:36:50,877 - INFO - Epoch 446/5000 - Train Loss: 0.264159, Val Loss: 0.263072
2025-09-01 20:37:16,486 - INFO - Epoch 447/5000 - Train Loss: 0.267691, Val Loss: 0.265661
2025-09-01 20:37:41,991 - INFO - Epoch 448/5000 - Train Loss: 0.267110, Val Loss: 0.254129
2025-09-01 20:38:07,464 - INFO - Epoch 449/5000 - Train Loss: 0.263540, Val Loss: 0.262493
2025-09-01 20:38:33,148 - INFO - Epoch 450/5000 - Train Loss: 0.264808, Val Loss: 0.256745
2025-09-01 20:38:59,155 - INFO - Epoch 451/5000 - Train Loss: 0.263643, Val Loss: 0.266019
2025-09-01 20:39:24,831 - INFO - Epoch 452/5000 - Train Loss: 0.262982, Val Loss: 0.251474
2025-09-01 20:39:50,425 - INFO - Epoch 453/5000 - Train Loss: 0.261053, Val Loss: 0.251261
2025-09-01 20:40:15,914 - INFO - Epoch 454/5000 - Train Loss: 0.261836, Val Loss: 0.258797
2025-09-01 20:40:41,769 - INFO - Epoch 455/5000 - Train Loss: 0.257671, Val Loss: 0.263057
2025-09-01 20:41:07,548 - INFO - Epoch 456/5000 - Train Loss: 0.263963, Val Loss: 0.251152
2025-09-01 20:41:33,244 - INFO - Epoch 457/5000 - Train Loss: 0.264448, Val Loss: 0.252632
2025-09-01 20:41:58,911 - INFO - Epoch 458/5000 - Train Loss: 0.262719, Val Loss: 0.256812
2025-09-01 20:42:24,459 - INFO - Epoch 459/5000 - Train Loss: 0.262490, Val Loss: 0.245226
2025-09-01 20:42:24,491 - INFO - New best model saved with Val Loss: 0.245226
2025-09-01 20:42:50,256 - INFO - Epoch 460/5000 - Train Loss: 0.258202, Val Loss: 0.255898
2025-09-01 20:43:16,082 - INFO - Epoch 461/5000 - Train Loss: 0.261645, Val Loss: 0.250023
2025-09-01 20:43:41,583 - INFO - Epoch 462/5000 - Train Loss: 0.262272, Val Loss: 0.252372
2025-09-01 20:44:07,253 - INFO - Epoch 463/5000 - Train Loss: 0.260015, Val Loss: 0.250900
2025-09-01 20:44:32,816 - INFO - Epoch 464/5000 - Train Loss: 0.259517, Val Loss: 0.245757
2025-09-01 20:44:58,471 - INFO - Epoch 465/5000 - Train Loss: 0.257020, Val Loss: 0.252777
2025-09-01 20:45:23,971 - INFO - Epoch 466/5000 - Train Loss: 0.258853, Val Loss: 0.253881
2025-09-01 20:45:49,463 - INFO - Epoch 467/5000 - Train Loss: 0.259752, Val Loss: 0.243684
2025-09-01 20:45:49,501 - INFO - New best model saved with Val Loss: 0.243684
2025-09-01 20:46:15,452 - INFO - Epoch 468/5000 - Train Loss: 0.258710, Val Loss: 0.251780
2025-09-01 20:46:40,918 - INFO - Epoch 469/5000 - Train Loss: 0.256686, Val Loss: 0.246284
2025-09-01 20:47:06,635 - INFO - Epoch 470/5000 - Train Loss: 0.255289, Val Loss: 0.244089
2025-09-01 20:47:32,392 - INFO - Epoch 471/5000 - Train Loss: 0.257748, Val Loss: 0.267583
2025-09-01 20:47:58,280 - INFO - Epoch 472/5000 - Train Loss: 0.257630, Val Loss: 0.240475
2025-09-01 20:47:58,302 - INFO - New best model saved with Val Loss: 0.240475
2025-09-01 20:48:23,985 - INFO - Epoch 473/5000 - Train Loss: 0.254096, Val Loss: 0.246586
2025-09-01 20:48:49,839 - INFO - Epoch 474/5000 - Train Loss: 0.257206, Val Loss: 0.243069
2025-09-01 20:49:15,271 - INFO - Epoch 475/5000 - Train Loss: 0.253424, Val Loss: 0.244332
2025-09-01 20:49:41,025 - INFO - Epoch 476/5000 - Train Loss: 0.254980, Val Loss: 0.239857
2025-09-01 20:49:41,054 - INFO - New best model saved with Val Loss: 0.239857
2025-09-01 20:50:06,624 - INFO - Epoch 477/5000 - Train Loss: 0.253863, Val Loss: 0.238548
2025-09-01 20:50:06,644 - INFO - New best model saved with Val Loss: 0.238548
2025-09-01 20:50:32,178 - INFO - Epoch 478/5000 - Train Loss: 0.252652, Val Loss: 0.243391
2025-09-01 20:50:57,622 - INFO - Epoch 479/5000 - Train Loss: 0.253823, Val Loss: 0.250382
2025-09-01 20:51:22,930 - INFO - Epoch 480/5000 - Train Loss: 0.251043, Val Loss: 0.240940
2025-09-01 20:51:48,813 - INFO - Epoch 481/5000 - Train Loss: 0.253039, Val Loss: 0.250789
2025-09-01 20:52:14,427 - INFO - Epoch 482/5000 - Train Loss: 0.253840, Val Loss: 0.247017
2025-09-01 20:52:40,045 - INFO - Epoch 483/5000 - Train Loss: 0.251863, Val Loss: 0.241831
2025-09-01 20:53:05,611 - INFO - Epoch 484/5000 - Train Loss: 0.251199, Val Loss: 0.242225
2025-09-01 20:53:31,189 - INFO - Epoch 485/5000 - Train Loss: 0.251971, Val Loss: 0.248824
2025-09-01 20:53:56,718 - INFO - Epoch 486/5000 - Train Loss: 0.250483, Val Loss: 0.241562
2025-09-01 20:54:22,207 - INFO - Epoch 487/5000 - Train Loss: 0.252017, Val Loss: 0.239036
2025-09-01 20:54:48,055 - INFO - Epoch 488/5000 - Train Loss: 0.250598, Val Loss: 0.239737
2025-09-01 20:55:13,672 - INFO - Epoch 489/5000 - Train Loss: 0.250048, Val Loss: 0.234948
2025-09-01 20:55:13,693 - INFO - New best model saved with Val Loss: 0.234948
2025-09-01 20:55:39,104 - INFO - Epoch 490/5000 - Train Loss: 0.248135, Val Loss: 0.246426
2025-09-01 20:56:04,867 - INFO - Epoch 491/5000 - Train Loss: 0.250525, Val Loss: 0.234109
2025-09-01 20:56:05,029 - INFO - New best model saved with Val Loss: 0.234109
2025-09-01 20:56:30,696 - INFO - Epoch 492/5000 - Train Loss: 0.248447, Val Loss: 0.237377
2025-09-01 20:56:56,715 - INFO - Epoch 493/5000 - Train Loss: 0.251653, Val Loss: 0.242261
2025-09-01 20:57:22,285 - INFO - Epoch 494/5000 - Train Loss: 0.248411, Val Loss: 0.242182
2025-09-01 20:57:47,841 - INFO - Epoch 495/5000 - Train Loss: 0.247569, Val Loss: 0.236688
2025-09-01 20:58:13,252 - INFO - Epoch 496/5000 - Train Loss: 0.247496, Val Loss: 0.241999
2025-09-01 20:58:38,778 - INFO - Epoch 497/5000 - Train Loss: 0.245292, Val Loss: 0.239510
2025-09-01 20:59:04,433 - INFO - Epoch 498/5000 - Train Loss: 0.249757, Val Loss: 0.237381
2025-09-01 20:59:29,916 - INFO - Epoch 499/5000 - Train Loss: 0.246125, Val Loss: 0.235700
2025-09-01 20:59:55,450 - INFO - Epoch 500/5000 - Train Loss: 0.247769, Val Loss: 0.239964
2025-09-01 21:00:21,279 - INFO - Epoch 501/5000 - Train Loss: 0.246780, Val Loss: 0.233677
2025-09-01 21:00:21,300 - INFO - New best model saved with Val Loss: 0.233677
2025-09-01 21:00:46,910 - INFO - Epoch 502/5000 - Train Loss: 0.245534, Val Loss: 0.230077
2025-09-01 21:00:46,930 - INFO - New best model saved with Val Loss: 0.230077
2025-09-01 21:01:12,452 - INFO - Epoch 503/5000 - Train Loss: 0.246840, Val Loss: 0.240365
2025-09-01 21:01:38,006 - INFO - Epoch 504/5000 - Train Loss: 0.245949, Val Loss: 0.238173
2025-09-01 21:02:03,582 - INFO - Epoch 505/5000 - Train Loss: 0.246371, Val Loss: 0.232695
2025-09-01 21:02:29,044 - INFO - Epoch 506/5000 - Train Loss: 0.245262, Val Loss: 0.230764
2025-09-01 21:02:54,699 - INFO - Epoch 507/5000 - Train Loss: 0.243781, Val Loss: 0.233343
2025-09-01 21:03:20,622 - INFO - Epoch 508/5000 - Train Loss: 0.245752, Val Loss: 0.240187
2025-09-01 21:03:46,084 - INFO - Epoch 509/5000 - Train Loss: 0.247920, Val Loss: 0.239148
2025-09-01 21:04:11,770 - INFO - Epoch 510/5000 - Train Loss: 0.243895, Val Loss: 0.226677
2025-09-01 21:04:11,791 - INFO - New best model saved with Val Loss: 0.226677
2025-09-01 21:04:37,383 - INFO - Epoch 511/5000 - Train Loss: 0.241724, Val Loss: 0.243646
2025-09-01 21:05:02,994 - INFO - Epoch 512/5000 - Train Loss: 0.250273, Val Loss: 0.249423
2025-09-01 21:05:28,713 - INFO - Epoch 513/5000 - Train Loss: 0.244782, Val Loss: 0.228510
2025-09-01 21:05:54,160 - INFO - Epoch 514/5000 - Train Loss: 0.241095, Val Loss: 0.233793
2025-09-01 21:06:19,855 - INFO - Epoch 515/5000 - Train Loss: 0.242679, Val Loss: 0.229507
2025-09-01 21:06:45,233 - INFO - Epoch 516/5000 - Train Loss: 0.245104, Val Loss: 0.231897
2025-09-01 21:07:10,491 - INFO - Epoch 517/5000 - Train Loss: 0.245346, Val Loss: 0.230290
2025-09-01 21:07:36,229 - INFO - Epoch 518/5000 - Train Loss: 0.243575, Val Loss: 0.241028
2025-09-01 21:08:01,964 - INFO - Epoch 519/5000 - Train Loss: 0.240616, Val Loss: 0.238859
2025-09-01 21:08:27,553 - INFO - Epoch 520/5000 - Train Loss: 0.243772, Val Loss: 0.229272
2025-09-01 21:08:53,375 - INFO - Epoch 521/5000 - Train Loss: 0.240508, Val Loss: 0.225000
2025-09-01 21:08:53,396 - INFO - New best model saved with Val Loss: 0.225000
2025-09-01 21:09:19,176 - INFO - Epoch 522/5000 - Train Loss: 0.239257, Val Loss: 0.230338
2025-09-01 21:09:44,733 - INFO - Epoch 523/5000 - Train Loss: 0.237714, Val Loss: 0.228933
2025-09-01 21:10:10,385 - INFO - Epoch 524/5000 - Train Loss: 0.239674, Val Loss: 0.230462
2025-09-01 21:10:36,169 - INFO - Epoch 525/5000 - Train Loss: 0.239406, Val Loss: 0.230335
2025-09-01 21:11:01,725 - INFO - Epoch 526/5000 - Train Loss: 0.239186, Val Loss: 0.226203
2025-09-01 21:11:27,283 - INFO - Epoch 527/5000 - Train Loss: 0.238268, Val Loss: 0.226665
2025-09-01 21:11:52,870 - INFO - Epoch 528/5000 - Train Loss: 0.240914, Val Loss: 0.222643
2025-09-01 21:11:52,891 - INFO - New best model saved with Val Loss: 0.222643
2025-09-01 21:12:18,402 - INFO - Epoch 529/5000 - Train Loss: 0.239137, Val Loss: 0.234206
2025-09-01 21:12:43,876 - INFO - Epoch 530/5000 - Train Loss: 0.237326, Val Loss: 0.231830
2025-09-01 21:13:09,686 - INFO - Epoch 531/5000 - Train Loss: 0.241313, Val Loss: 0.226197
2025-09-01 21:13:35,400 - INFO - Epoch 532/5000 - Train Loss: 0.237949, Val Loss: 0.224414
2025-09-01 21:14:00,994 - INFO - Epoch 533/5000 - Train Loss: 0.237482, Val Loss: 0.225418
2025-09-01 21:14:26,296 - INFO - Epoch 534/5000 - Train Loss: 0.234039, Val Loss: 0.224859
2025-09-01 21:14:51,817 - INFO - Epoch 535/5000 - Train Loss: 0.243726, Val Loss: 0.236818
2025-09-01 21:15:17,250 - INFO - Epoch 536/5000 - Train Loss: 0.238154, Val Loss: 0.232274
2025-09-01 21:15:42,983 - INFO - Epoch 537/5000 - Train Loss: 0.234995, Val Loss: 0.225134
2025-09-01 21:16:08,630 - INFO - Epoch 538/5000 - Train Loss: 0.234683, Val Loss: 0.223278
2025-09-01 21:16:34,488 - INFO - Epoch 539/5000 - Train Loss: 0.234111, Val Loss: 0.222388
2025-09-01 21:16:34,509 - INFO - New best model saved with Val Loss: 0.222388
2025-09-01 21:17:00,023 - INFO - Epoch 540/5000 - Train Loss: 0.236843, Val Loss: 0.224198
2025-09-01 21:17:25,981 - INFO - Epoch 541/5000 - Train Loss: 0.236557, Val Loss: 0.224646
2025-09-01 21:17:51,668 - INFO - Epoch 542/5000 - Train Loss: 0.236665, Val Loss: 0.222155
2025-09-01 21:17:51,687 - INFO - New best model saved with Val Loss: 0.222155
2025-09-01 21:18:17,318 - INFO - Epoch 543/5000 - Train Loss: 0.238096, Val Loss: 0.226964
2025-09-01 21:18:42,987 - INFO - Epoch 544/5000 - Train Loss: 0.236506, Val Loss: 0.224698
2025-09-01 21:19:08,526 - INFO - Epoch 545/5000 - Train Loss: 0.236429, Val Loss: 0.234645
2025-09-01 21:19:34,159 - INFO - Epoch 546/5000 - Train Loss: 0.234007, Val Loss: 0.220118
2025-09-01 21:19:34,180 - INFO - New best model saved with Val Loss: 0.220118
2025-09-01 21:20:00,064 - INFO - Epoch 547/5000 - Train Loss: 0.233262, Val Loss: 0.221202
2025-09-01 21:20:25,507 - INFO - Epoch 548/5000 - Train Loss: 0.232087, Val Loss: 0.219656
2025-09-01 21:20:25,527 - INFO - New best model saved with Val Loss: 0.219656
2025-09-01 21:20:51,037 - INFO - Epoch 549/5000 - Train Loss: 0.233827, Val Loss: 0.218659
2025-09-01 21:20:51,057 - INFO - New best model saved with Val Loss: 0.218659
2025-09-01 21:21:16,678 - INFO - Epoch 550/5000 - Train Loss: 0.230568, Val Loss: 0.216952
2025-09-01 21:21:16,698 - INFO - New best model saved with Val Loss: 0.216952
2025-09-01 21:21:42,009 - INFO - Epoch 551/5000 - Train Loss: 0.231209, Val Loss: 0.221679
2025-09-01 21:22:07,697 - INFO - Epoch 552/5000 - Train Loss: 0.232443, Val Loss: 0.218747
2025-09-01 21:22:33,351 - INFO - Epoch 553/5000 - Train Loss: 0.232626, Val Loss: 0.219259
2025-09-01 21:22:58,972 - INFO - Epoch 554/5000 - Train Loss: 0.232102, Val Loss: 0.225925
2025-09-01 21:23:24,351 - INFO - Epoch 555/5000 - Train Loss: 0.231635, Val Loss: 0.220757
2025-09-01 21:23:50,013 - INFO - Epoch 556/5000 - Train Loss: 0.229842, Val Loss: 0.217130
2025-09-01 21:24:15,679 - INFO - Epoch 557/5000 - Train Loss: 0.231050, Val Loss: 0.217773
2025-09-01 21:24:41,388 - INFO - Epoch 558/5000 - Train Loss: 0.231108, Val Loss: 0.230017
2025-09-01 21:25:06,897 - INFO - Epoch 559/5000 - Train Loss: 0.229117, Val Loss: 0.215197
2025-09-01 21:25:06,918 - INFO - New best model saved with Val Loss: 0.215197
2025-09-01 21:25:32,326 - INFO - Epoch 560/5000 - Train Loss: 0.230872, Val Loss: 0.222955
2025-09-01 21:25:57,958 - INFO - Epoch 561/5000 - Train Loss: 0.231372, Val Loss: 0.217888
2025-09-01 21:26:23,539 - INFO - Epoch 562/5000 - Train Loss: 0.230506, Val Loss: 0.218006
2025-09-01 21:26:49,108 - INFO - Epoch 563/5000 - Train Loss: 0.230288, Val Loss: 0.219500
2025-09-01 21:27:14,790 - INFO - Epoch 564/5000 - Train Loss: 0.230042, Val Loss: 0.234489
2025-09-01 21:27:40,718 - INFO - Epoch 565/5000 - Train Loss: 0.233070, Val Loss: 0.241336
2025-09-01 21:28:06,238 - INFO - Epoch 566/5000 - Train Loss: 0.230799, Val Loss: 0.215962
2025-09-01 21:28:31,931 - INFO - Epoch 567/5000 - Train Loss: 0.229041, Val Loss: 0.219187
2025-09-01 21:28:57,739 - INFO - Epoch 568/5000 - Train Loss: 0.227048, Val Loss: 0.214215
2025-09-01 21:28:57,761 - INFO - New best model saved with Val Loss: 0.214215
2025-09-01 21:29:23,478 - INFO - Epoch 569/5000 - Train Loss: 0.227726, Val Loss: 0.219890
2025-09-01 21:29:49,077 - INFO - Epoch 570/5000 - Train Loss: 0.228580, Val Loss: 0.216630
2025-09-01 21:30:15,016 - INFO - Epoch 571/5000 - Train Loss: 0.229577, Val Loss: 0.217948
2025-09-01 21:30:40,573 - INFO - Epoch 572/5000 - Train Loss: 0.226267, Val Loss: 0.215792
2025-09-01 21:31:06,214 - INFO - Epoch 573/5000 - Train Loss: 0.226989, Val Loss: 0.219251
2025-09-01 21:31:31,717 - INFO - Epoch 574/5000 - Train Loss: 0.225522, Val Loss: 0.212903
2025-09-01 21:31:31,738 - INFO - New best model saved with Val Loss: 0.212903
2025-09-01 21:31:57,225 - INFO - Epoch 575/5000 - Train Loss: 0.227048, Val Loss: 0.221605
2025-09-01 21:32:23,154 - INFO - Epoch 576/5000 - Train Loss: 0.226991, Val Loss: 0.218202
2025-09-01 21:32:49,147 - INFO - Epoch 577/5000 - Train Loss: 0.225831, Val Loss: 0.213097
2025-09-01 21:33:14,930 - INFO - Epoch 578/5000 - Train Loss: 0.226220, Val Loss: 0.222612
2025-09-01 21:33:40,726 - INFO - Epoch 579/5000 - Train Loss: 0.226816, Val Loss: 0.219979
2025-09-01 21:34:06,186 - INFO - Epoch 580/5000 - Train Loss: 0.226286, Val Loss: 0.212400
2025-09-01 21:34:06,206 - INFO - New best model saved with Val Loss: 0.212400
2025-09-01 21:34:31,895 - INFO - Epoch 581/5000 - Train Loss: 0.225202, Val Loss: 0.209754
2025-09-01 21:34:31,915 - INFO - New best model saved with Val Loss: 0.209754
2025-09-01 21:34:57,611 - INFO - Epoch 582/5000 - Train Loss: 0.223117, Val Loss: 0.206124
2025-09-01 21:34:57,630 - INFO - New best model saved with Val Loss: 0.206124
2025-09-01 21:35:23,372 - INFO - Epoch 583/5000 - Train Loss: 0.225102, Val Loss: 0.233324
2025-09-01 21:35:48,738 - INFO - Epoch 584/5000 - Train Loss: 0.227022, Val Loss: 0.220267
2025-09-01 21:36:14,471 - INFO - Epoch 585/5000 - Train Loss: 0.225937, Val Loss: 0.228716
2025-09-01 21:36:40,239 - INFO - Epoch 586/5000 - Train Loss: 0.228090, Val Loss: 0.218276
2025-09-01 21:37:05,846 - INFO - Epoch 587/5000 - Train Loss: 0.224280, Val Loss: 0.216193
2025-09-01 21:37:31,582 - INFO - Epoch 588/5000 - Train Loss: 0.225008, Val Loss: 0.214895
2025-09-01 21:37:57,411 - INFO - Epoch 589/5000 - Train Loss: 0.222684, Val Loss: 0.208261
2025-09-01 21:38:22,988 - INFO - Epoch 590/5000 - Train Loss: 0.226873, Val Loss: 0.227161
2025-09-01 21:38:48,744 - INFO - Epoch 591/5000 - Train Loss: 0.225745, Val Loss: 0.217840
2025-09-01 21:39:14,298 - INFO - Epoch 592/5000 - Train Loss: 0.220567, Val Loss: 0.210173
2025-09-01 21:39:39,905 - INFO - Epoch 593/5000 - Train Loss: 0.224561, Val Loss: 0.217647
2025-09-01 21:40:05,653 - INFO - Epoch 594/5000 - Train Loss: 0.224203, Val Loss: 0.211458
2025-09-01 21:40:30,923 - INFO - Epoch 595/5000 - Train Loss: 0.220624, Val Loss: 0.216597
2025-09-01 21:40:56,716 - INFO - Epoch 596/5000 - Train Loss: 0.220135, Val Loss: 0.225764
2025-09-01 21:41:22,233 - INFO - Epoch 597/5000 - Train Loss: 0.220791, Val Loss: 0.214717
2025-09-01 21:41:47,613 - INFO - Epoch 598/5000 - Train Loss: 0.225522, Val Loss: 0.211161
2025-09-01 21:42:13,289 - INFO - Epoch 599/5000 - Train Loss: 0.222413, Val Loss: 0.206508
2025-09-01 21:42:39,064 - INFO - Epoch 600/5000 - Train Loss: 0.221357, Val Loss: 0.206785
2025-09-01 21:43:04,732 - INFO - Epoch 601/5000 - Train Loss: 0.218847, Val Loss: 0.211560
2025-09-01 21:43:30,424 - INFO - Epoch 602/5000 - Train Loss: 0.220126, Val Loss: 0.211876
2025-09-01 21:43:56,268 - INFO - Epoch 603/5000 - Train Loss: 0.222380, Val Loss: 0.214012
2025-09-01 21:44:22,190 - INFO - Epoch 604/5000 - Train Loss: 0.219194, Val Loss: 0.209251
2025-09-01 21:44:47,917 - INFO - Epoch 605/5000 - Train Loss: 0.221587, Val Loss: 0.214120
2025-09-01 21:45:13,438 - INFO - Epoch 606/5000 - Train Loss: 0.221793, Val Loss: 0.213545
2025-09-01 21:45:39,099 - INFO - Epoch 607/5000 - Train Loss: 0.218414, Val Loss: 0.204647
2025-09-01 21:45:39,120 - INFO - New best model saved with Val Loss: 0.204647
2025-09-01 21:46:04,731 - INFO - Epoch 608/5000 - Train Loss: 0.217091, Val Loss: 0.204810
2025-09-01 21:46:30,522 - INFO - Epoch 609/5000 - Train Loss: 0.220359, Val Loss: 0.210610
2025-09-01 21:46:56,091 - INFO - Epoch 610/5000 - Train Loss: 0.218940, Val Loss: 0.213572
2025-09-01 21:47:22,089 - INFO - Epoch 611/5000 - Train Loss: 0.218105, Val Loss: 0.216886
2025-09-01 21:47:47,463 - INFO - Epoch 612/5000 - Train Loss: 0.219209, Val Loss: 0.213154
2025-09-01 21:48:13,070 - INFO - Epoch 613/5000 - Train Loss: 0.215440, Val Loss: 0.203738
2025-09-01 21:48:13,091 - INFO - New best model saved with Val Loss: 0.203738
2025-09-01 21:48:38,780 - INFO - Epoch 614/5000 - Train Loss: 0.216258, Val Loss: 0.204705
2025-09-01 21:49:04,512 - INFO - Epoch 615/5000 - Train Loss: 0.216170, Val Loss: 0.206375
2025-09-01 21:49:30,097 - INFO - Epoch 616/5000 - Train Loss: 0.216296, Val Loss: 0.201656
2025-09-01 21:49:30,117 - INFO - New best model saved with Val Loss: 0.201656
2025-09-01 21:49:55,840 - INFO - Epoch 617/5000 - Train Loss: 0.215791, Val Loss: 0.205428
2025-09-01 21:50:21,572 - INFO - Epoch 618/5000 - Train Loss: 0.216543, Val Loss: 0.207622
2025-09-01 21:50:47,412 - INFO - Epoch 619/5000 - Train Loss: 0.217466, Val Loss: 0.208127
2025-09-01 21:51:12,905 - INFO - Epoch 620/5000 - Train Loss: 0.215365, Val Loss: 0.202696
2025-09-01 21:51:38,974 - INFO - Epoch 621/5000 - Train Loss: 0.215963, Val Loss: 0.198653
2025-09-01 21:51:38,996 - INFO - New best model saved with Val Loss: 0.198653
2025-09-01 21:52:04,601 - INFO - Epoch 622/5000 - Train Loss: 0.217163, Val Loss: 0.211741
2025-09-01 21:52:30,349 - INFO - Epoch 623/5000 - Train Loss: 0.216094, Val Loss: 0.198406
2025-09-01 21:52:30,369 - INFO - New best model saved with Val Loss: 0.198406
2025-09-01 21:52:56,261 - INFO - Epoch 624/5000 - Train Loss: 0.213534, Val Loss: 0.209514
2025-09-01 21:53:21,979 - INFO - Epoch 625/5000 - Train Loss: 0.214645, Val Loss: 0.203905
2025-09-01 21:53:47,505 - INFO - Epoch 626/5000 - Train Loss: 0.215591, Val Loss: 0.213711
2025-09-01 21:54:13,264 - INFO - Epoch 627/5000 - Train Loss: 0.218246, Val Loss: 0.198580
2025-09-01 21:54:38,859 - INFO - Epoch 628/5000 - Train Loss: 0.213389, Val Loss: 0.202764
2025-09-01 21:55:04,383 - INFO - Epoch 629/5000 - Train Loss: 0.213924, Val Loss: 0.204181
2025-09-01 21:55:30,001 - INFO - Epoch 630/5000 - Train Loss: 0.213613, Val Loss: 0.200186
2025-09-01 21:55:55,625 - INFO - Epoch 631/5000 - Train Loss: 0.216275, Val Loss: 0.210749
2025-09-01 21:56:21,487 - INFO - Epoch 632/5000 - Train Loss: 0.213460, Val Loss: 0.206686
2025-09-01 21:56:46,735 - INFO - Epoch 633/5000 - Train Loss: 0.215561, Val Loss: 0.199452
2025-09-01 21:57:12,319 - INFO - Epoch 634/5000 - Train Loss: 0.212274, Val Loss: 0.199484
2025-09-01 21:57:38,057 - INFO - Epoch 635/5000 - Train Loss: 0.212645, Val Loss: 0.205928
2025-09-01 21:58:03,705 - INFO - Epoch 636/5000 - Train Loss: 0.216288, Val Loss: 0.201647
2025-09-01 21:58:29,371 - INFO - Epoch 637/5000 - Train Loss: 0.213468, Val Loss: 0.200829
2025-09-01 21:58:54,990 - INFO - Epoch 638/5000 - Train Loss: 0.212876, Val Loss: 0.199564
2025-09-01 21:59:20,581 - INFO - Epoch 639/5000 - Train Loss: 0.211496, Val Loss: 0.197992
2025-09-01 21:59:20,653 - INFO - New best model saved with Val Loss: 0.197992
2025-09-01 21:59:46,139 - INFO - Epoch 640/5000 - Train Loss: 0.211442, Val Loss: 0.200443
2025-09-01 22:00:11,929 - INFO - Epoch 641/5000 - Train Loss: 0.212211, Val Loss: 0.203542
2025-09-01 22:00:37,378 - INFO - Epoch 642/5000 - Train Loss: 0.212048, Val Loss: 0.206549
2025-09-01 22:01:02,868 - INFO - Epoch 643/5000 - Train Loss: 0.212186, Val Loss: 0.203583
2025-09-01 22:01:28,590 - INFO - Epoch 644/5000 - Train Loss: 0.215395, Val Loss: 0.208025
2025-09-01 22:01:54,039 - INFO - Epoch 645/5000 - Train Loss: 0.216578, Val Loss: 0.201175
2025-09-01 22:02:19,610 - INFO - Epoch 646/5000 - Train Loss: 0.211961, Val Loss: 0.203581
2025-09-01 22:02:45,333 - INFO - Epoch 647/5000 - Train Loss: 0.211829, Val Loss: 0.201201
2025-09-01 22:03:10,771 - INFO - Epoch 648/5000 - Train Loss: 0.209981, Val Loss: 0.197841
2025-09-01 22:03:10,791 - INFO - New best model saved with Val Loss: 0.197841
2025-09-01 22:03:36,454 - INFO - Epoch 649/5000 - Train Loss: 0.212303, Val Loss: 0.198759
2025-09-01 22:04:02,006 - INFO - Epoch 650/5000 - Train Loss: 0.210909, Val Loss: 0.197638
2025-09-01 22:04:02,026 - INFO - New best model saved with Val Loss: 0.197638
2025-09-01 22:04:27,941 - INFO - Epoch 651/5000 - Train Loss: 0.212196, Val Loss: 0.197615
2025-09-01 22:04:27,961 - INFO - New best model saved with Val Loss: 0.197615
2025-09-01 22:04:53,661 - INFO - Epoch 652/5000 - Train Loss: 0.211334, Val Loss: 0.194249
2025-09-01 22:04:53,680 - INFO - New best model saved with Val Loss: 0.194249
2025-09-01 22:05:19,322 - INFO - Epoch 653/5000 - Train Loss: 0.209526, Val Loss: 0.197732
2025-09-01 22:05:44,926 - INFO - Epoch 654/5000 - Train Loss: 0.212537, Val Loss: 0.209681
2025-09-01 22:06:10,670 - INFO - Epoch 655/5000 - Train Loss: 0.211684, Val Loss: 0.193745
2025-09-01 22:06:10,690 - INFO - New best model saved with Val Loss: 0.193745
2025-09-01 22:06:36,215 - INFO - Epoch 656/5000 - Train Loss: 0.210431, Val Loss: 0.193335
2025-09-01 22:06:36,235 - INFO - New best model saved with Val Loss: 0.193335
2025-09-01 22:07:02,105 - INFO - Epoch 657/5000 - Train Loss: 0.208918, Val Loss: 0.193775
2025-09-01 22:07:27,766 - INFO - Epoch 658/5000 - Train Loss: 0.208364, Val Loss: 0.207247
2025-09-01 22:07:53,298 - INFO - Epoch 659/5000 - Train Loss: 0.206361, Val Loss: 0.195994
2025-09-01 22:08:18,943 - INFO - Epoch 660/5000 - Train Loss: 0.208538, Val Loss: 0.196691
2025-09-01 22:08:44,961 - INFO - Epoch 661/5000 - Train Loss: 0.208979, Val Loss: 0.197182
2025-09-01 22:09:10,388 - INFO - Epoch 662/5000 - Train Loss: 0.207530, Val Loss: 0.193763
2025-09-01 22:09:35,990 - INFO - Epoch 663/5000 - Train Loss: 0.207628, Val Loss: 0.195757
2025-09-01 22:10:01,995 - INFO - Epoch 664/5000 - Train Loss: 0.208893, Val Loss: 0.201018
2025-09-01 22:10:27,938 - INFO - Epoch 665/5000 - Train Loss: 0.207511, Val Loss: 0.189693
2025-09-01 22:10:27,968 - INFO - New best model saved with Val Loss: 0.189693
2025-09-01 22:10:54,298 - INFO - Epoch 666/5000 - Train Loss: 0.205694, Val Loss: 0.197508
2025-09-01 22:11:19,995 - INFO - Epoch 667/5000 - Train Loss: 0.206005, Val Loss: 0.198571
2025-09-01 22:11:45,725 - INFO - Epoch 668/5000 - Train Loss: 0.208644, Val Loss: 0.195146
2025-09-01 22:12:11,597 - INFO - Epoch 669/5000 - Train Loss: 0.207224, Val Loss: 0.196644
2025-09-01 22:12:37,175 - INFO - Epoch 670/5000 - Train Loss: 0.209600, Val Loss: 0.196166
2025-09-01 22:13:03,034 - INFO - Epoch 671/5000 - Train Loss: 0.211184, Val Loss: 0.198377
2025-09-01 22:13:28,623 - INFO - Epoch 672/5000 - Train Loss: 0.210235, Val Loss: 0.192375
2025-09-01 22:13:54,229 - INFO - Epoch 673/5000 - Train Loss: 0.206151, Val Loss: 0.192792
2025-09-01 22:14:20,051 - INFO - Epoch 674/5000 - Train Loss: 0.207240, Val Loss: 0.197684
2025-09-01 22:14:45,699 - INFO - Epoch 675/5000 - Train Loss: 0.207943, Val Loss: 0.198971
2025-09-01 22:15:11,104 - INFO - Epoch 676/5000 - Train Loss: 0.207244, Val Loss: 0.194845
2025-09-01 22:15:36,513 - INFO - Epoch 677/5000 - Train Loss: 0.205586, Val Loss: 0.191630
2025-09-01 22:16:02,161 - INFO - Epoch 678/5000 - Train Loss: 0.207171, Val Loss: 0.193929
2025-09-01 22:16:27,599 - INFO - Epoch 679/5000 - Train Loss: 0.204201, Val Loss: 0.191260
2025-09-01 22:16:53,273 - INFO - Epoch 680/5000 - Train Loss: 0.206240, Val Loss: 0.199032
2025-09-01 22:17:19,138 - INFO - Epoch 681/5000 - Train Loss: 0.206619, Val Loss: 0.192078
2025-09-01 22:17:44,807 - INFO - Epoch 682/5000 - Train Loss: 0.206348, Val Loss: 0.196421
2025-09-01 22:18:10,418 - INFO - Epoch 683/5000 - Train Loss: 0.208222, Val Loss: 0.202250
2025-09-01 22:18:36,126 - INFO - Epoch 684/5000 - Train Loss: 0.205561, Val Loss: 0.199767
2025-09-01 22:19:01,617 - INFO - Epoch 685/5000 - Train Loss: 0.205663, Val Loss: 0.192917
2025-09-01 22:19:27,423 - INFO - Epoch 686/5000 - Train Loss: 0.204369, Val Loss: 0.191924
2025-09-01 22:19:52,959 - INFO - Epoch 687/5000 - Train Loss: 0.205281, Val Loss: 0.193870
2025-09-01 22:20:18,530 - INFO - Epoch 688/5000 - Train Loss: 0.208625, Val Loss: 0.199476
2025-09-01 22:20:44,022 - INFO - Epoch 689/5000 - Train Loss: 0.208369, Val Loss: 0.192256
2025-09-01 22:21:09,561 - INFO - Epoch 690/5000 - Train Loss: 0.204075, Val Loss: 0.186762
2025-09-01 22:21:09,600 - INFO - New best model saved with Val Loss: 0.186762
2025-09-01 22:21:35,535 - INFO - Epoch 691/5000 - Train Loss: 0.203287, Val Loss: 0.189096
2025-09-01 22:22:00,971 - INFO - Epoch 692/5000 - Train Loss: 0.205673, Val Loss: 0.195104
2025-09-01 22:22:26,782 - INFO - Epoch 693/5000 - Train Loss: 0.205339, Val Loss: 0.199503
2025-09-01 22:22:51,993 - INFO - Epoch 694/5000 - Train Loss: 0.209083, Val Loss: 0.196225
2025-09-01 22:23:17,925 - INFO - Epoch 695/5000 - Train Loss: 0.205129, Val Loss: 0.198698
2025-09-01 22:23:43,342 - INFO - Epoch 696/5000 - Train Loss: 0.204998, Val Loss: 0.193563
2025-09-01 22:24:08,944 - INFO - Epoch 697/5000 - Train Loss: 0.202900, Val Loss: 0.191193
2025-09-01 22:24:34,481 - INFO - Epoch 698/5000 - Train Loss: 0.202903, Val Loss: 0.194049
2025-09-01 22:25:00,124 - INFO - Epoch 699/5000 - Train Loss: 0.205649, Val Loss: 0.192252
2025-09-01 22:25:25,720 - INFO - Epoch 700/5000 - Train Loss: 0.203186, Val Loss: 0.190981
2025-09-01 22:25:51,371 - INFO - Epoch 701/5000 - Train Loss: 0.202826, Val Loss: 0.191179
2025-09-01 22:26:17,030 - INFO - Epoch 702/5000 - Train Loss: 0.203313, Val Loss: 0.197585
2025-09-01 22:26:42,708 - INFO - Epoch 703/5000 - Train Loss: 0.203337, Val Loss: 0.189424
2025-09-01 22:27:08,591 - INFO - Epoch 704/5000 - Train Loss: 0.202894, Val Loss: 0.194308
2025-09-01 22:27:34,229 - INFO - Epoch 705/5000 - Train Loss: 0.201463, Val Loss: 0.189341
2025-09-01 22:28:00,482 - INFO - Epoch 706/5000 - Train Loss: 0.206972, Val Loss: 0.196529
2025-09-01 22:28:26,036 - INFO - Epoch 707/5000 - Train Loss: 0.204815, Val Loss: 0.188772
2025-09-01 22:28:51,638 - INFO - Epoch 708/5000 - Train Loss: 0.203217, Val Loss: 0.186661
2025-09-01 22:28:51,660 - INFO - New best model saved with Val Loss: 0.186661
2025-09-01 22:29:17,283 - INFO - Epoch 709/5000 - Train Loss: 0.200901, Val Loss: 0.197050
2025-09-01 22:29:43,025 - INFO - Epoch 710/5000 - Train Loss: 0.202972, Val Loss: 0.197491
2025-09-01 22:30:08,584 - INFO - Epoch 711/5000 - Train Loss: 0.201468, Val Loss: 0.188019
2025-09-01 22:30:34,311 - INFO - Epoch 712/5000 - Train Loss: 0.201810, Val Loss: 0.188430
2025-09-01 22:31:00,063 - INFO - Epoch 713/5000 - Train Loss: 0.201335, Val Loss: 0.197367
2025-09-01 22:31:25,633 - INFO - Epoch 714/5000 - Train Loss: 0.202081, Val Loss: 0.196729
2025-09-01 22:31:51,223 - INFO - Epoch 715/5000 - Train Loss: 0.199642, Val Loss: 0.184650
2025-09-01 22:31:51,243 - INFO - New best model saved with Val Loss: 0.184650
2025-09-01 22:32:16,928 - INFO - Epoch 716/5000 - Train Loss: 0.201672, Val Loss: 0.189503
2025-09-01 22:32:42,518 - INFO - Epoch 717/5000 - Train Loss: 0.200390, Val Loss: 0.196001
2025-09-01 22:33:08,038 - INFO - Epoch 718/5000 - Train Loss: 0.200919, Val Loss: 0.188118
2025-09-01 22:33:33,749 - INFO - Epoch 719/5000 - Train Loss: 0.200508, Val Loss: 0.188762
2025-09-01 22:33:59,372 - INFO - Epoch 720/5000 - Train Loss: 0.200140, Val Loss: 0.190243
2025-09-01 22:34:25,180 - INFO - Epoch 721/5000 - Train Loss: 0.203598, Val Loss: 0.192371
2025-09-01 22:34:50,854 - INFO - Epoch 722/5000 - Train Loss: 0.203516, Val Loss: 0.188139
2025-09-01 22:35:16,463 - INFO - Epoch 723/5000 - Train Loss: 0.199863, Val Loss: 0.195335
2025-09-01 22:35:41,986 - INFO - Epoch 724/5000 - Train Loss: 0.199624, Val Loss: 0.184298
2025-09-01 22:35:42,023 - INFO - New best model saved with Val Loss: 0.184298
2025-09-01 22:36:07,581 - INFO - Epoch 725/5000 - Train Loss: 0.199475, Val Loss: 0.191222
2025-09-01 22:36:33,383 - INFO - Epoch 726/5000 - Train Loss: 0.200277, Val Loss: 0.186514
2025-09-01 22:36:58,958 - INFO - Epoch 727/5000 - Train Loss: 0.201636, Val Loss: 0.188642
2025-09-01 22:37:24,742 - INFO - Epoch 728/5000 - Train Loss: 0.199839, Val Loss: 0.189956
2025-09-01 22:37:50,644 - INFO - Epoch 729/5000 - Train Loss: 0.199880, Val Loss: 0.182052
2025-09-01 22:37:50,664 - INFO - New best model saved with Val Loss: 0.182052
2025-09-01 22:38:16,312 - INFO - Epoch 730/5000 - Train Loss: 0.195919, Val Loss: 0.180506
2025-09-01 22:38:16,331 - INFO - New best model saved with Val Loss: 0.180506
2025-09-01 22:38:42,243 - INFO - Epoch 731/5000 - Train Loss: 0.198804, Val Loss: 0.191337
2025-09-01 22:39:08,102 - INFO - Epoch 732/5000 - Train Loss: 0.198863, Val Loss: 0.192102
2025-09-01 22:39:33,848 - INFO - Epoch 733/5000 - Train Loss: 0.203713, Val Loss: 0.188496
2025-09-01 22:39:59,623 - INFO - Epoch 734/5000 - Train Loss: 0.200670, Val Loss: 0.185991
2025-09-01 22:40:25,345 - INFO - Epoch 735/5000 - Train Loss: 0.199591, Val Loss: 0.194498
2025-09-01 22:40:50,904 - INFO - Epoch 736/5000 - Train Loss: 0.198570, Val Loss: 0.188718
2025-09-01 22:41:16,738 - INFO - Epoch 737/5000 - Train Loss: 0.195346, Val Loss: 0.186273
2025-09-01 22:41:42,616 - INFO - Epoch 738/5000 - Train Loss: 0.198337, Val Loss: 0.187000
2025-09-01 22:42:08,302 - INFO - Epoch 739/5000 - Train Loss: 0.197805, Val Loss: 0.183042
2025-09-01 22:42:33,880 - INFO - Epoch 740/5000 - Train Loss: 0.198682, Val Loss: 0.191604
2025-09-01 22:42:59,845 - INFO - Epoch 741/5000 - Train Loss: 0.196993, Val Loss: 0.194271
2025-09-01 22:43:25,854 - INFO - Epoch 742/5000 - Train Loss: 0.200370, Val Loss: 0.181702
2025-09-01 22:43:51,692 - INFO - Epoch 743/5000 - Train Loss: 0.199462, Val Loss: 0.184059
2025-09-01 22:44:17,397 - INFO - Epoch 744/5000 - Train Loss: 0.199623, Val Loss: 0.184158
2025-09-01 22:44:42,964 - INFO - Epoch 745/5000 - Train Loss: 0.198130, Val Loss: 0.183470
2025-09-01 22:45:08,388 - INFO - Epoch 746/5000 - Train Loss: 0.196549, Val Loss: 0.189859
2025-09-01 22:45:33,834 - INFO - Epoch 747/5000 - Train Loss: 0.197383, Val Loss: 0.185490
2025-09-01 22:45:59,088 - INFO - Epoch 748/5000 - Train Loss: 0.198572, Val Loss: 0.183309
2025-09-01 22:46:24,487 - INFO - Epoch 749/5000 - Train Loss: 0.199623, Val Loss: 0.192958
2025-09-01 22:46:49,992 - INFO - Epoch 750/5000 - Train Loss: 0.200233, Val Loss: 0.188914
2025-09-01 22:47:15,573 - INFO - Epoch 751/5000 - Train Loss: 0.199154, Val Loss: 0.186626
2025-09-01 22:47:41,175 - INFO - Epoch 752/5000 - Train Loss: 0.196550, Val Loss: 0.180032
2025-09-01 22:47:41,195 - INFO - New best model saved with Val Loss: 0.180032
2025-09-01 22:48:06,600 - INFO - Epoch 753/5000 - Train Loss: 0.194306, Val Loss: 0.184669
2025-09-01 22:48:32,421 - INFO - Epoch 754/5000 - Train Loss: 0.193493, Val Loss: 0.187846
2025-09-01 22:48:57,880 - INFO - Epoch 755/5000 - Train Loss: 0.194541, Val Loss: 0.182653
2025-09-01 22:49:23,326 - INFO - Epoch 756/5000 - Train Loss: 0.195043, Val Loss: 0.187639
2025-09-01 22:49:49,001 - INFO - Epoch 757/5000 - Train Loss: 0.194957, Val Loss: 0.187264
2025-09-01 22:50:14,815 - INFO - Epoch 758/5000 - Train Loss: 0.195683, Val Loss: 0.179944
2025-09-01 22:50:14,835 - INFO - New best model saved with Val Loss: 0.179944
2025-09-01 22:50:40,601 - INFO - Epoch 759/5000 - Train Loss: 0.197419, Val Loss: 0.185360
2025-09-01 22:51:06,003 - INFO - Epoch 760/5000 - Train Loss: 0.200314, Val Loss: 0.182624
2025-09-01 22:51:31,681 - INFO - Epoch 761/5000 - Train Loss: 0.194830, Val Loss: 0.181279
2025-09-01 22:51:56,965 - INFO - Epoch 762/5000 - Train Loss: 0.194037, Val Loss: 0.185078
2025-09-01 22:52:22,676 - INFO - Epoch 763/5000 - Train Loss: 0.196849, Val Loss: 0.183913
2025-09-01 22:52:48,068 - INFO - Epoch 764/5000 - Train Loss: 0.198962, Val Loss: 0.184352
2025-09-01 22:53:13,497 - INFO - Epoch 765/5000 - Train Loss: 0.197647, Val Loss: 0.185740
2025-09-01 22:53:39,057 - INFO - Epoch 766/5000 - Train Loss: 0.196670, Val Loss: 0.188480
2025-09-01 22:54:04,632 - INFO - Epoch 767/5000 - Train Loss: 0.194743, Val Loss: 0.184066
2025-09-01 22:54:30,405 - INFO - Epoch 768/5000 - Train Loss: 0.195780, Val Loss: 0.188224
2025-09-01 22:54:55,921 - INFO - Epoch 769/5000 - Train Loss: 0.193529, Val Loss: 0.181636
2025-09-01 22:55:21,168 - INFO - Epoch 770/5000 - Train Loss: 0.193592, Val Loss: 0.180271
2025-09-01 22:55:46,964 - INFO - Epoch 771/5000 - Train Loss: 0.196603, Val Loss: 0.187142
2025-09-01 22:56:12,604 - INFO - Epoch 772/5000 - Train Loss: 0.195242, Val Loss: 0.178724
2025-09-01 22:56:12,624 - INFO - New best model saved with Val Loss: 0.178724
2025-09-01 22:56:38,306 - INFO - Epoch 773/5000 - Train Loss: 0.193464, Val Loss: 0.182977
2025-09-01 22:57:04,098 - INFO - Epoch 774/5000 - Train Loss: 0.197970, Val Loss: 0.177679
2025-09-01 22:57:04,117 - INFO - New best model saved with Val Loss: 0.177679
2025-09-01 22:57:29,650 - INFO - Epoch 775/5000 - Train Loss: 0.194584, Val Loss: 0.180337
2025-09-01 22:57:55,259 - INFO - Epoch 776/5000 - Train Loss: 0.196212, Val Loss: 0.184325
2025-09-01 22:58:20,762 - INFO - Epoch 777/5000 - Train Loss: 0.199210, Val Loss: 0.189906
2025-09-01 22:58:46,558 - INFO - Epoch 778/5000 - Train Loss: 0.197601, Val Loss: 0.181012
2025-09-01 22:59:12,209 - INFO - Epoch 779/5000 - Train Loss: 0.195137, Val Loss: 0.182778
2025-09-01 22:59:38,003 - INFO - Epoch 780/5000 - Train Loss: 0.195098, Val Loss: 0.179813
2025-09-01 23:00:03,692 - INFO - Epoch 781/5000 - Train Loss: 0.194054, Val Loss: 0.179853
2025-09-01 23:00:29,401 - INFO - Epoch 782/5000 - Train Loss: 0.193105, Val Loss: 0.179494
2025-09-01 23:00:54,741 - INFO - Epoch 783/5000 - Train Loss: 0.192941, Val Loss: 0.186349
2025-09-01 23:01:20,358 - INFO - Epoch 784/5000 - Train Loss: 0.194097, Val Loss: 0.179904
2025-09-01 23:01:45,856 - INFO - Epoch 785/5000 - Train Loss: 0.193428, Val Loss: 0.177566
2025-09-01 23:01:45,876 - INFO - New best model saved with Val Loss: 0.177566
2025-09-01 23:02:11,559 - INFO - Epoch 786/5000 - Train Loss: 0.192116, Val Loss: 0.181951
2025-09-01 23:02:37,070 - INFO - Epoch 787/5000 - Train Loss: 0.192518, Val Loss: 0.178981
2025-09-01 23:03:02,642 - INFO - Epoch 788/5000 - Train Loss: 0.192251, Val Loss: 0.178284
2025-09-01 23:03:28,319 - INFO - Epoch 789/5000 - Train Loss: 0.193496, Val Loss: 0.176931
2025-09-01 23:03:28,339 - INFO - New best model saved with Val Loss: 0.176931
2025-09-01 23:03:54,148 - INFO - Epoch 790/5000 - Train Loss: 0.193684, Val Loss: 0.179686
2025-09-01 23:04:19,945 - INFO - Epoch 791/5000 - Train Loss: 0.193091, Val Loss: 0.185530
2025-09-01 23:04:45,561 - INFO - Epoch 792/5000 - Train Loss: 0.192335, Val Loss: 0.178492
2025-09-01 23:05:11,380 - INFO - Epoch 793/5000 - Train Loss: 0.193774, Val Loss: 0.186848
2025-09-01 23:05:37,006 - INFO - Epoch 794/5000 - Train Loss: 0.194394, Val Loss: 0.175324
2025-09-01 23:05:37,027 - INFO - New best model saved with Val Loss: 0.175324
2025-09-01 23:06:02,565 - INFO - Epoch 795/5000 - Train Loss: 0.195272, Val Loss: 0.180523
2025-09-01 23:06:28,135 - INFO - Epoch 796/5000 - Train Loss: 0.190782, Val Loss: 0.175206
2025-09-01 23:06:28,165 - INFO - New best model saved with Val Loss: 0.175206
2025-09-01 23:06:53,698 - INFO - Epoch 797/5000 - Train Loss: 0.190210, Val Loss: 0.179788
2025-09-01 23:07:19,416 - INFO - Epoch 798/5000 - Train Loss: 0.190465, Val Loss: 0.175250
2025-09-01 23:07:45,401 - INFO - Epoch 799/5000 - Train Loss: 0.190866, Val Loss: 0.177591
2025-09-01 23:08:11,403 - INFO - Epoch 800/5000 - Train Loss: 0.190187, Val Loss: 0.180430
2025-09-01 23:08:37,270 - INFO - Epoch 801/5000 - Train Loss: 0.191761, Val Loss: 0.176465
2025-09-01 23:09:02,653 - INFO - Epoch 802/5000 - Train Loss: 0.191325, Val Loss: 0.178505
2025-09-01 23:09:28,238 - INFO - Epoch 803/5000 - Train Loss: 0.192131, Val Loss: 0.182355
2025-09-01 23:09:53,748 - INFO - Epoch 804/5000 - Train Loss: 0.190961, Val Loss: 0.177799
2025-09-01 23:10:19,417 - INFO - Epoch 805/5000 - Train Loss: 0.189509, Val Loss: 0.184695
2025-09-01 23:10:45,168 - INFO - Epoch 806/5000 - Train Loss: 0.190273, Val Loss: 0.175019
2025-09-01 23:10:45,189 - INFO - New best model saved with Val Loss: 0.175019
2025-09-01 23:11:10,877 - INFO - Epoch 807/5000 - Train Loss: 0.188990, Val Loss: 0.182943
2025-09-01 23:11:36,633 - INFO - Epoch 808/5000 - Train Loss: 0.190488, Val Loss: 0.178128
2025-09-01 23:12:02,425 - INFO - Epoch 809/5000 - Train Loss: 0.190232, Val Loss: 0.176024
2025-09-01 23:12:28,086 - INFO - Epoch 810/5000 - Train Loss: 0.190630, Val Loss: 0.183261
2025-09-01 23:12:54,043 - INFO - Epoch 811/5000 - Train Loss: 0.194361, Val Loss: 0.176497
2025-09-01 23:13:19,669 - INFO - Epoch 812/5000 - Train Loss: 0.189148, Val Loss: 0.176730
2025-09-01 23:13:45,362 - INFO - Epoch 813/5000 - Train Loss: 0.188823, Val Loss: 0.179011
2025-09-01 23:14:11,005 - INFO - Epoch 814/5000 - Train Loss: 0.189402, Val Loss: 0.176386
2025-09-01 23:14:36,599 - INFO - Epoch 815/5000 - Train Loss: 0.192117, Val Loss: 0.175461
2025-09-01 23:15:02,402 - INFO - Epoch 816/5000 - Train Loss: 0.188235, Val Loss: 0.176878
2025-09-01 23:15:27,971 - INFO - Epoch 817/5000 - Train Loss: 0.190581, Val Loss: 0.175057
2025-09-01 23:15:53,700 - INFO - Epoch 818/5000 - Train Loss: 0.189004, Val Loss: 0.175105
2025-09-01 23:16:19,409 - INFO - Epoch 819/5000 - Train Loss: 0.188294, Val Loss: 0.173076
2025-09-01 23:16:19,437 - INFO - New best model saved with Val Loss: 0.173076
2025-09-01 23:16:45,061 - INFO - Epoch 820/5000 - Train Loss: 0.188068, Val Loss: 0.176094
2025-09-01 23:17:10,879 - INFO - Epoch 821/5000 - Train Loss: 0.188707, Val Loss: 0.178502
2025-09-01 23:17:36,399 - INFO - Epoch 822/5000 - Train Loss: 0.189406, Val Loss: 0.174101
2025-09-01 23:18:01,880 - INFO - Epoch 823/5000 - Train Loss: 0.188257, Val Loss: 0.180966
2025-09-01 23:18:27,886 - INFO - Epoch 824/5000 - Train Loss: 0.188024, Val Loss: 0.173038
2025-09-01 23:18:27,907 - INFO - New best model saved with Val Loss: 0.173038
2025-09-01 23:18:53,875 - INFO - Epoch 825/5000 - Train Loss: 0.185630, Val Loss: 0.173283
2025-09-01 23:19:19,332 - INFO - Epoch 826/5000 - Train Loss: 0.187586, Val Loss: 0.178520
2025-09-01 23:19:44,943 - INFO - Epoch 827/5000 - Train Loss: 0.190469, Val Loss: 0.180846
2025-09-01 23:20:10,857 - INFO - Epoch 828/5000 - Train Loss: 0.190964, Val Loss: 0.174880
2025-09-01 23:20:36,384 - INFO - Epoch 829/5000 - Train Loss: 0.186359, Val Loss: 0.177238
2025-09-01 23:21:01,982 - INFO - Epoch 830/5000 - Train Loss: 0.187004, Val Loss: 0.172032
2025-09-01 23:21:02,003 - INFO - New best model saved with Val Loss: 0.172032
2025-09-01 23:21:27,862 - INFO - Epoch 831/5000 - Train Loss: 0.187018, Val Loss: 0.176904
2025-09-01 23:21:53,384 - INFO - Epoch 832/5000 - Train Loss: 0.191745, Val Loss: 0.174019
2025-09-01 23:22:18,832 - INFO - Epoch 833/5000 - Train Loss: 0.188773, Val Loss: 0.176874
2025-09-01 23:22:44,566 - INFO - Epoch 834/5000 - Train Loss: 0.187317, Val Loss: 0.175456
2025-09-01 23:23:10,596 - INFO - Epoch 835/5000 - Train Loss: 0.187831, Val Loss: 0.175865
2025-09-01 23:23:35,809 - INFO - Epoch 836/5000 - Train Loss: 0.187767, Val Loss: 0.171879
2025-09-01 23:23:35,829 - INFO - New best model saved with Val Loss: 0.171879
2025-09-01 23:24:01,824 - INFO - Epoch 837/5000 - Train Loss: 0.186059, Val Loss: 0.174203
2025-09-01 23:24:27,355 - INFO - Epoch 838/5000 - Train Loss: 0.187431, Val Loss: 0.174965
2025-09-01 23:24:53,191 - INFO - Epoch 839/5000 - Train Loss: 0.185887, Val Loss: 0.176197
2025-09-01 23:25:18,910 - INFO - Epoch 840/5000 - Train Loss: 0.186576, Val Loss: 0.174870
2025-09-01 23:25:44,641 - INFO - Epoch 841/5000 - Train Loss: 0.190533, Val Loss: 0.170092
2025-09-01 23:25:44,661 - INFO - New best model saved with Val Loss: 0.170092
2025-09-01 23:26:10,474 - INFO - Epoch 842/5000 - Train Loss: 0.187780, Val Loss: 0.181105
2025-09-01 23:26:35,962 - INFO - Epoch 843/5000 - Train Loss: 0.185165, Val Loss: 0.168942
2025-09-01 23:26:35,981 - INFO - New best model saved with Val Loss: 0.168942
2025-09-01 23:27:01,607 - INFO - Epoch 844/5000 - Train Loss: 0.187865, Val Loss: 0.174293
2025-09-01 23:27:27,494 - INFO - Epoch 845/5000 - Train Loss: 0.188490, Val Loss: 0.184790
2025-09-01 23:27:53,271 - INFO - Epoch 846/5000 - Train Loss: 0.185558, Val Loss: 0.170922
2025-09-01 23:28:18,999 - INFO - Epoch 847/5000 - Train Loss: 0.184581, Val Loss: 0.171585
2025-09-01 23:28:44,958 - INFO - Epoch 848/5000 - Train Loss: 0.189411, Val Loss: 0.174197
2025-09-01 23:29:10,697 - INFO - Epoch 849/5000 - Train Loss: 0.185834, Val Loss: 0.170538
2025-09-01 23:29:36,468 - INFO - Epoch 850/5000 - Train Loss: 0.184421, Val Loss: 0.174285
2025-09-01 23:30:02,464 - INFO - Epoch 851/5000 - Train Loss: 0.186969, Val Loss: 0.173121
2025-09-01 23:30:28,025 - INFO - Epoch 852/5000 - Train Loss: 0.184519, Val Loss: 0.171143
2025-09-01 23:30:53,586 - INFO - Epoch 853/5000 - Train Loss: 0.188477, Val Loss: 0.182307
2025-09-01 23:31:19,371 - INFO - Epoch 854/5000 - Train Loss: 0.186970, Val Loss: 0.171649
2025-09-01 23:31:45,257 - INFO - Epoch 855/5000 - Train Loss: 0.186054, Val Loss: 0.171054
2025-09-01 23:32:10,763 - INFO - Epoch 856/5000 - Train Loss: 0.184539, Val Loss: 0.174929
2025-09-01 23:32:36,480 - INFO - Epoch 857/5000 - Train Loss: 0.185053, Val Loss: 0.169969
2025-09-01 23:33:02,266 - INFO - Epoch 858/5000 - Train Loss: 0.184272, Val Loss: 0.172159
2025-09-01 23:33:28,056 - INFO - Epoch 859/5000 - Train Loss: 0.184449, Val Loss: 0.169367
2025-09-01 23:33:53,707 - INFO - Epoch 860/5000 - Train Loss: 0.184021, Val Loss: 0.171480
2025-09-01 23:34:19,240 - INFO - Epoch 861/5000 - Train Loss: 0.184705, Val Loss: 0.168990
2025-09-01 23:34:44,957 - INFO - Epoch 862/5000 - Train Loss: 0.184124, Val Loss: 0.172265
2025-09-01 23:35:10,718 - INFO - Epoch 863/5000 - Train Loss: 0.183137, Val Loss: 0.168030
2025-09-01 23:35:10,878 - INFO - New best model saved with Val Loss: 0.168030
2025-09-01 23:35:36,425 - INFO - Epoch 864/5000 - Train Loss: 0.183613, Val Loss: 0.174543
2025-09-01 23:36:02,128 - INFO - Epoch 865/5000 - Train Loss: 0.183870, Val Loss: 0.176612
2025-09-01 23:36:27,904 - INFO - Epoch 866/5000 - Train Loss: 0.186502, Val Loss: 0.168517
2025-09-01 23:36:53,642 - INFO - Epoch 867/5000 - Train Loss: 0.183285, Val Loss: 0.171643
2025-09-01 23:37:19,650 - INFO - Epoch 868/5000 - Train Loss: 0.183158, Val Loss: 0.167492
2025-09-01 23:37:19,670 - INFO - New best model saved with Val Loss: 0.167492
2025-09-01 23:37:45,467 - INFO - Epoch 869/5000 - Train Loss: 0.183121, Val Loss: 0.168801
2025-09-01 23:38:11,117 - INFO - Epoch 870/5000 - Train Loss: 0.185496, Val Loss: 0.176208
2025-09-01 23:38:37,132 - INFO - Epoch 871/5000 - Train Loss: 0.183728, Val Loss: 0.166790
2025-09-01 23:38:37,152 - INFO - New best model saved with Val Loss: 0.166790
2025-09-01 23:39:02,654 - INFO - Epoch 872/5000 - Train Loss: 0.183246, Val Loss: 0.166852
2025-09-01 23:39:28,348 - INFO - Epoch 873/5000 - Train Loss: 0.183485, Val Loss: 0.170155
2025-09-01 23:39:54,256 - INFO - Epoch 874/5000 - Train Loss: 0.183767, Val Loss: 0.171351
2025-09-01 23:40:19,790 - INFO - Epoch 875/5000 - Train Loss: 0.185062, Val Loss: 0.168067
2025-09-01 23:40:45,366 - INFO - Epoch 876/5000 - Train Loss: 0.181813, Val Loss: 0.170865
2025-09-01 23:41:11,015 - INFO - Epoch 877/5000 - Train Loss: 0.180727, Val Loss: 0.172164
2025-09-01 23:41:36,307 - INFO - Epoch 878/5000 - Train Loss: 0.183892, Val Loss: 0.173924
2025-09-01 23:42:02,072 - INFO - Epoch 879/5000 - Train Loss: 0.183039, Val Loss: 0.169991
2025-09-01 23:42:27,801 - INFO - Epoch 880/5000 - Train Loss: 0.186558, Val Loss: 0.170586
2025-09-01 23:42:53,730 - INFO - Epoch 881/5000 - Train Loss: 0.183544, Val Loss: 0.170947
2025-09-01 23:43:19,595 - INFO - Epoch 882/5000 - Train Loss: 0.183236, Val Loss: 0.168785
2025-09-01 23:43:45,371 - INFO - Epoch 883/5000 - Train Loss: 0.187235, Val Loss: 0.172904
2025-09-01 23:44:10,891 - INFO - Epoch 884/5000 - Train Loss: 0.185751, Val Loss: 0.172677
2025-09-01 23:44:36,843 - INFO - Epoch 885/5000 - Train Loss: 0.182241, Val Loss: 0.167320
2025-09-01 23:45:02,619 - INFO - Epoch 886/5000 - Train Loss: 0.183003, Val Loss: 0.172349
2025-09-01 23:45:28,562 - INFO - Epoch 887/5000 - Train Loss: 0.182135, Val Loss: 0.164338
2025-09-01 23:45:28,582 - INFO - New best model saved with Val Loss: 0.164338
2025-09-01 23:45:54,191 - INFO - Epoch 888/5000 - Train Loss: 0.180043, Val Loss: 0.164445
2025-09-01 23:46:19,939 - INFO - Epoch 889/5000 - Train Loss: 0.179730, Val Loss: 0.176940
2025-09-01 23:46:45,704 - INFO - Epoch 890/5000 - Train Loss: 0.181119, Val Loss: 0.167981
2025-09-01 23:47:11,540 - INFO - Epoch 891/5000 - Train Loss: 0.179380, Val Loss: 0.171000
2025-09-01 23:47:37,362 - INFO - Epoch 892/5000 - Train Loss: 0.181476, Val Loss: 0.166895
2025-09-01 23:48:03,040 - INFO - Epoch 893/5000 - Train Loss: 0.182368, Val Loss: 0.164971
2025-09-01 23:48:28,889 - INFO - Epoch 894/5000 - Train Loss: 0.180977, Val Loss: 0.168652
2025-09-01 23:48:54,613 - INFO - Epoch 895/5000 - Train Loss: 0.180297, Val Loss: 0.173871
2025-09-01 23:49:20,415 - INFO - Epoch 896/5000 - Train Loss: 0.182596, Val Loss: 0.169206
2025-09-01 23:49:46,203 - INFO - Epoch 897/5000 - Train Loss: 0.178518, Val Loss: 0.167078
2025-09-01 23:50:12,005 - INFO - Epoch 898/5000 - Train Loss: 0.178280, Val Loss: 0.163216
2025-09-01 23:50:12,025 - INFO - New best model saved with Val Loss: 0.163216
2025-09-01 23:50:37,427 - INFO - Epoch 899/5000 - Train Loss: 0.185449, Val Loss: 0.169973
2025-09-01 23:51:03,168 - INFO - Epoch 900/5000 - Train Loss: 0.180749, Val Loss: 0.167124
2025-09-01 23:51:29,174 - INFO - Epoch 901/5000 - Train Loss: 0.180737, Val Loss: 0.173029
2025-09-01 23:51:54,750 - INFO - Epoch 902/5000 - Train Loss: 0.181817, Val Loss: 0.166691
2025-09-01 23:52:20,351 - INFO - Epoch 903/5000 - Train Loss: 0.180613, Val Loss: 0.164769
2025-09-01 23:52:45,963 - INFO - Epoch 904/5000 - Train Loss: 0.178798, Val Loss: 0.164071
2025-09-01 23:53:11,468 - INFO - Epoch 905/5000 - Train Loss: 0.180089, Val Loss: 0.167194
2025-09-01 23:53:37,072 - INFO - Epoch 906/5000 - Train Loss: 0.181585, Val Loss: 0.169576
2025-09-01 23:54:02,600 - INFO - Epoch 907/5000 - Train Loss: 0.179953, Val Loss: 0.167203
2025-09-01 23:54:28,154 - INFO - Epoch 908/5000 - Train Loss: 0.180748, Val Loss: 0.163966
2025-09-01 23:54:53,985 - INFO - Epoch 909/5000 - Train Loss: 0.179369, Val Loss: 0.165532
2025-09-01 23:55:19,749 - INFO - Epoch 910/5000 - Train Loss: 0.179315, Val Loss: 0.166159
2025-09-01 23:55:45,680 - INFO - Epoch 911/5000 - Train Loss: 0.179099, Val Loss: 0.168340
2025-09-01 23:56:11,429 - INFO - Epoch 912/5000 - Train Loss: 0.179562, Val Loss: 0.163666
2025-09-01 23:56:37,222 - INFO - Epoch 913/5000 - Train Loss: 0.180519, Val Loss: 0.164543
2025-09-01 23:57:02,829 - INFO - Epoch 914/5000 - Train Loss: 0.180034, Val Loss: 0.162948
2025-09-01 23:57:02,849 - INFO - New best model saved with Val Loss: 0.162948
2025-09-01 23:57:28,612 - INFO - Epoch 915/5000 - Train Loss: 0.178684, Val Loss: 0.165018
2025-09-01 23:57:54,176 - INFO - Epoch 916/5000 - Train Loss: 0.182060, Val Loss: 0.169783
2025-09-01 23:58:19,703 - INFO - Epoch 917/5000 - Train Loss: 0.180800, Val Loss: 0.167628
2025-09-01 23:58:45,342 - INFO - Epoch 918/5000 - Train Loss: 0.179200, Val Loss: 0.167219
2025-09-01 23:59:11,151 - INFO - Epoch 919/5000 - Train Loss: 0.179384, Val Loss: 0.165087
2025-09-01 23:59:36,833 - INFO - Epoch 920/5000 - Train Loss: 0.177892, Val Loss: 0.164800
2025-09-02 00:00:02,721 - INFO - Epoch 921/5000 - Train Loss: 0.180190, Val Loss: 0.165157
2025-09-02 00:00:28,134 - INFO - Epoch 922/5000 - Train Loss: 0.176941, Val Loss: 0.162102
2025-09-02 00:00:28,154 - INFO - New best model saved with Val Loss: 0.162102
2025-09-02 00:00:53,745 - INFO - Epoch 923/5000 - Train Loss: 0.176417, Val Loss: 0.167443
2025-09-02 00:01:19,620 - INFO - Epoch 924/5000 - Train Loss: 0.177469, Val Loss: 0.165997
2025-09-02 00:01:45,120 - INFO - Epoch 925/5000 - Train Loss: 0.177141, Val Loss: 0.166385
2025-09-02 00:02:10,834 - INFO - Epoch 926/5000 - Train Loss: 0.176673, Val Loss: 0.164746
2025-09-02 00:02:36,710 - INFO - Epoch 927/5000 - Train Loss: 0.177190, Val Loss: 0.163402
2025-09-02 00:03:02,499 - INFO - Epoch 928/5000 - Train Loss: 0.179473, Val Loss: 0.165156
2025-09-02 00:03:28,192 - INFO - Epoch 929/5000 - Train Loss: 0.177559, Val Loss: 0.163729
2025-09-02 00:03:53,970 - INFO - Epoch 930/5000 - Train Loss: 0.176820, Val Loss: 0.161733
2025-09-02 00:03:54,006 - INFO - New best model saved with Val Loss: 0.161733
2025-09-02 00:04:19,967 - INFO - Epoch 931/5000 - Train Loss: 0.178081, Val Loss: 0.162581
2025-09-02 00:04:45,470 - INFO - Epoch 932/5000 - Train Loss: 0.177421, Val Loss: 0.177575
2025-09-02 00:05:11,014 - INFO - Epoch 933/5000 - Train Loss: 0.179470, Val Loss: 0.161937
2025-09-02 00:05:36,873 - INFO - Epoch 934/5000 - Train Loss: 0.177276, Val Loss: 0.162204
2025-09-02 00:06:02,422 - INFO - Epoch 935/5000 - Train Loss: 0.175239, Val Loss: 0.160735
2025-09-02 00:06:02,443 - INFO - New best model saved with Val Loss: 0.160735
2025-09-02 00:06:27,940 - INFO - Epoch 936/5000 - Train Loss: 0.175935, Val Loss: 0.167013
2025-09-02 00:06:53,566 - INFO - Epoch 937/5000 - Train Loss: 0.179443, Val Loss: 0.164673
2025-09-02 00:07:19,410 - INFO - Epoch 938/5000 - Train Loss: 0.176853, Val Loss: 0.162540
2025-09-02 00:07:44,894 - INFO - Epoch 939/5000 - Train Loss: 0.176622, Val Loss: 0.162991
2025-09-02 00:08:10,648 - INFO - Epoch 940/5000 - Train Loss: 0.178735, Val Loss: 0.173236
2025-09-02 00:08:36,597 - INFO - Epoch 941/5000 - Train Loss: 0.178998, Val Loss: 0.161791
2025-09-02 00:09:02,229 - INFO - Epoch 942/5000 - Train Loss: 0.176809, Val Loss: 0.164793
2025-09-02 00:09:27,992 - INFO - Epoch 943/5000 - Train Loss: 0.176756, Val Loss: 0.163455
2025-09-02 00:09:53,417 - INFO - Epoch 944/5000 - Train Loss: 0.177503, Val Loss: 0.161462
2025-09-02 00:10:19,129 - INFO - Epoch 945/5000 - Train Loss: 0.174610, Val Loss: 0.168423
2025-09-02 00:10:44,723 - INFO - Epoch 946/5000 - Train Loss: 0.177153, Val Loss: 0.161942
2025-09-02 00:11:10,417 - INFO - Epoch 947/5000 - Train Loss: 0.174711, Val Loss: 0.164582
2025-09-02 00:11:36,041 - INFO - Epoch 948/5000 - Train Loss: 0.175374, Val Loss: 0.161068
2025-09-02 00:12:01,767 - INFO - Epoch 949/5000 - Train Loss: 0.175920, Val Loss: 0.164050
2025-09-02 00:12:27,304 - INFO - Epoch 950/5000 - Train Loss: 0.177414, Val Loss: 0.169314
2025-09-02 00:12:53,078 - INFO - Epoch 951/5000 - Train Loss: 0.176589, Val Loss: 0.165124
2025-09-02 00:13:18,715 - INFO - Epoch 952/5000 - Train Loss: 0.175366, Val Loss: 0.160011
2025-09-02 00:13:18,743 - INFO - New best model saved with Val Loss: 0.160011
2025-09-02 00:13:44,570 - INFO - Epoch 953/5000 - Train Loss: 0.176048, Val Loss: 0.163162
2025-09-02 00:14:10,199 - INFO - Epoch 954/5000 - Train Loss: 0.173443, Val Loss: 0.159204
2025-09-02 00:14:10,219 - INFO - New best model saved with Val Loss: 0.159204
2025-09-02 00:14:35,927 - INFO - Epoch 955/5000 - Train Loss: 0.173202, Val Loss: 0.159448
2025-09-02 00:15:01,721 - INFO - Epoch 956/5000 - Train Loss: 0.175157, Val Loss: 0.159700
2025-09-02 00:15:27,251 - INFO - Epoch 957/5000 - Train Loss: 0.174360, Val Loss: 0.161763
2025-09-02 00:15:53,367 - INFO - Epoch 958/5000 - Train Loss: 0.174424, Val Loss: 0.158839
2025-09-02 00:15:53,386 - INFO - New best model saved with Val Loss: 0.158839
2025-09-02 00:16:19,045 - INFO - Epoch 959/5000 - Train Loss: 0.172497, Val Loss: 0.156747
2025-09-02 00:16:19,065 - INFO - New best model saved with Val Loss: 0.156747
2025-09-02 00:16:44,629 - INFO - Epoch 960/5000 - Train Loss: 0.174814, Val Loss: 0.161473
2025-09-02 00:17:10,498 - INFO - Epoch 961/5000 - Train Loss: 0.176138, Val Loss: 0.160162
2025-09-02 00:17:36,366 - INFO - Epoch 962/5000 - Train Loss: 0.175143, Val Loss: 0.159647
2025-09-02 00:18:02,322 - INFO - Epoch 963/5000 - Train Loss: 0.174466, Val Loss: 0.174751
2025-09-02 00:18:27,873 - INFO - Epoch 964/5000 - Train Loss: 0.175194, Val Loss: 0.158321
2025-09-02 00:18:53,655 - INFO - Epoch 965/5000 - Train Loss: 0.174147, Val Loss: 0.160272
2025-09-02 00:19:18,773 - INFO - Epoch 966/5000 - Train Loss: 0.173520, Val Loss: 0.159550
2025-09-02 00:19:44,362 - INFO - Epoch 967/5000 - Train Loss: 0.175654, Val Loss: 0.162715
2025-09-02 00:20:10,105 - INFO - Epoch 968/5000 - Train Loss: 0.175297, Val Loss: 0.159595
2025-09-02 00:20:35,522 - INFO - Epoch 969/5000 - Train Loss: 0.174161, Val Loss: 0.158630
2025-09-02 00:21:01,290 - INFO - Epoch 970/5000 - Train Loss: 0.173866, Val Loss: 0.167118
2025-09-02 00:21:26,980 - INFO - Epoch 971/5000 - Train Loss: 0.180090, Val Loss: 0.160430
2025-09-02 00:21:52,612 - INFO - Epoch 972/5000 - Train Loss: 0.175474, Val Loss: 0.165828
2025-09-02 00:22:18,459 - INFO - Epoch 973/5000 - Train Loss: 0.173545, Val Loss: 0.156903
2025-09-02 00:22:44,002 - INFO - Epoch 974/5000 - Train Loss: 0.175585, Val Loss: 0.161316
2025-09-02 00:23:09,795 - INFO - Epoch 975/5000 - Train Loss: 0.174675, Val Loss: 0.163202
2025-09-02 00:23:35,330 - INFO - Epoch 976/5000 - Train Loss: 0.172697, Val Loss: 0.157682
2025-09-02 00:24:01,369 - INFO - Epoch 977/5000 - Train Loss: 0.172895, Val Loss: 0.158911
2025-09-02 00:24:26,953 - INFO - Epoch 978/5000 - Train Loss: 0.172410, Val Loss: 0.157279
2025-09-02 00:24:52,923 - INFO - Epoch 979/5000 - Train Loss: 0.172206, Val Loss: 0.158734
2025-09-02 00:25:18,367 - INFO - Epoch 980/5000 - Train Loss: 0.172848, Val Loss: 0.158026
2025-09-02 00:25:44,151 - INFO - Epoch 981/5000 - Train Loss: 0.171693, Val Loss: 0.157541
2025-09-02 00:26:09,815 - INFO - Epoch 982/5000 - Train Loss: 0.171093, Val Loss: 0.156499
2025-09-02 00:26:09,835 - INFO - New best model saved with Val Loss: 0.156499
2025-09-02 00:26:35,521 - INFO - Epoch 983/5000 - Train Loss: 0.171087, Val Loss: 0.158168
2025-09-02 00:27:01,365 - INFO - Epoch 984/5000 - Train Loss: 0.173045, Val Loss: 0.167969
2025-09-02 00:27:27,158 - INFO - Epoch 985/5000 - Train Loss: 0.172568, Val Loss: 0.160261
2025-09-02 00:27:52,676 - INFO - Epoch 986/5000 - Train Loss: 0.172536, Val Loss: 0.164955
2025-09-02 00:28:18,433 - INFO - Epoch 987/5000 - Train Loss: 0.174912, Val Loss: 0.161584
2025-09-02 00:28:43,835 - INFO - Epoch 988/5000 - Train Loss: 0.173538, Val Loss: 0.161513
2025-09-02 00:29:09,377 - INFO - Epoch 989/5000 - Train Loss: 0.174763, Val Loss: 0.162871
2025-09-02 00:29:34,989 - INFO - Epoch 990/5000 - Train Loss: 0.175292, Val Loss: 0.166969
2025-09-02 00:30:00,584 - INFO - Epoch 991/5000 - Train Loss: 0.171966, Val Loss: 0.156271
2025-09-02 00:30:00,604 - INFO - New best model saved with Val Loss: 0.156271
2025-09-02 00:30:26,120 - INFO - Epoch 992/5000 - Train Loss: 0.172805, Val Loss: 0.157463
2025-09-02 00:30:51,725 - INFO - Epoch 993/5000 - Train Loss: 0.174139, Val Loss: 0.159527
2025-09-02 00:31:17,249 - INFO - Epoch 994/5000 - Train Loss: 0.171479, Val Loss: 0.157638
2025-09-02 00:31:43,026 - INFO - Epoch 995/5000 - Train Loss: 0.171119, Val Loss: 0.159095
2025-09-02 00:32:08,541 - INFO - Epoch 996/5000 - Train Loss: 0.171349, Val Loss: 0.154912
2025-09-02 00:32:08,583 - INFO - New best model saved with Val Loss: 0.154912
2025-09-02 00:32:34,158 - INFO - Epoch 997/5000 - Train Loss: 0.170196, Val Loss: 0.158679
2025-09-02 00:32:59,562 - INFO - Epoch 998/5000 - Train Loss: 0.171146, Val Loss: 0.156702
2025-09-02 00:33:25,061 - INFO - Epoch 999/5000 - Train Loss: 0.170605, Val Loss: 0.155417
2025-09-02 00:33:50,569 - INFO - Epoch 1000/5000 - Train Loss: 0.171566, Val Loss: 0.159787
2025-09-02 00:34:16,326 - INFO - Epoch 1001/5000 - Train Loss: 0.170978, Val Loss: 0.156102
2025-09-02 00:34:41,370 - INFO - Epoch 1002/5000 - Train Loss: 0.169573, Val Loss: 0.155179
2025-09-02 00:35:06,770 - INFO - Epoch 1003/5000 - Train Loss: 0.171295, Val Loss: 0.156846
2025-09-02 00:35:32,320 - INFO - Epoch 1004/5000 - Train Loss: 0.171320, Val Loss: 0.155924
2025-09-02 00:35:57,326 - INFO - Epoch 1005/5000 - Train Loss: 0.170226, Val Loss: 0.157910
2025-09-02 00:36:23,181 - INFO - Epoch 1006/5000 - Train Loss: 0.169516, Val Loss: 0.154960
2025-09-02 00:36:48,617 - INFO - Epoch 1007/5000 - Train Loss: 0.171234, Val Loss: 0.161973
2025-09-02 00:37:14,060 - INFO - Epoch 1008/5000 - Train Loss: 0.171214, Val Loss: 0.155158
2025-09-02 00:37:39,443 - INFO - Epoch 1009/5000 - Train Loss: 0.169833, Val Loss: 0.156227
2025-09-02 00:38:05,182 - INFO - Epoch 1010/5000 - Train Loss: 0.172488, Val Loss: 0.159348
2025-09-02 00:38:30,985 - INFO - Epoch 1011/5000 - Train Loss: 0.169972, Val Loss: 0.157328
2025-09-02 00:38:56,597 - INFO - Epoch 1012/5000 - Train Loss: 0.173118, Val Loss: 0.156604
2025-09-02 00:39:22,345 - INFO - Epoch 1013/5000 - Train Loss: 0.171527, Val Loss: 0.158088
2025-09-02 00:39:47,926 - INFO - Epoch 1014/5000 - Train Loss: 0.172039, Val Loss: 0.157702
2025-09-02 00:40:13,542 - INFO - Epoch 1015/5000 - Train Loss: 0.170353, Val Loss: 0.156727
2025-09-02 00:40:39,342 - INFO - Epoch 1016/5000 - Train Loss: 0.170755, Val Loss: 0.158293
2025-09-02 00:41:05,081 - INFO - Epoch 1017/5000 - Train Loss: 0.170478, Val Loss: 0.155128
2025-09-02 00:41:30,913 - INFO - Epoch 1018/5000 - Train Loss: 0.170006, Val Loss: 0.154979
2025-09-02 00:41:56,586 - INFO - Epoch 1019/5000 - Train Loss: 0.167981, Val Loss: 0.158032
2025-09-02 00:42:22,446 - INFO - Epoch 1020/5000 - Train Loss: 0.170515, Val Loss: 0.157579
2025-09-02 00:42:48,211 - INFO - Epoch 1021/5000 - Train Loss: 0.172582, Val Loss: 0.158875
2025-09-02 00:43:13,523 - INFO - Epoch 1022/5000 - Train Loss: 0.168810, Val Loss: 0.155171
2025-09-02 00:43:39,382 - INFO - Epoch 1023/5000 - Train Loss: 0.169675, Val Loss: 0.161523
2025-09-02 00:44:05,000 - INFO - Epoch 1024/5000 - Train Loss: 0.170561, Val Loss: 0.157419
2025-09-02 00:44:30,697 - INFO - Epoch 1025/5000 - Train Loss: 0.169229, Val Loss: 0.156823
2025-09-02 00:44:56,419 - INFO - Epoch 1026/5000 - Train Loss: 0.169231, Val Loss: 0.155217
2025-09-02 00:45:22,217 - INFO - Epoch 1027/5000 - Train Loss: 0.167960, Val Loss: 0.157476
2025-09-02 00:45:48,021 - INFO - Epoch 1028/5000 - Train Loss: 0.170638, Val Loss: 0.158818
2025-09-02 00:46:13,794 - INFO - Epoch 1029/5000 - Train Loss: 0.167759, Val Loss: 0.153451
2025-09-02 00:46:13,832 - INFO - New best model saved with Val Loss: 0.153451
2025-09-02 00:46:39,526 - INFO - Epoch 1030/5000 - Train Loss: 0.168902, Val Loss: 0.156819
2025-09-02 00:47:05,286 - INFO - Epoch 1031/5000 - Train Loss: 0.169197, Val Loss: 0.156409
2025-09-02 00:47:31,088 - INFO - Epoch 1032/5000 - Train Loss: 0.168480, Val Loss: 0.154740
2025-09-02 00:47:56,934 - INFO - Epoch 1033/5000 - Train Loss: 0.168971, Val Loss: 0.152481
2025-09-02 00:47:56,955 - INFO - New best model saved with Val Loss: 0.152481
2025-09-02 00:48:22,596 - INFO - Epoch 1034/5000 - Train Loss: 0.168561, Val Loss: 0.156284
2025-09-02 00:48:48,354 - INFO - Epoch 1035/5000 - Train Loss: 0.171586, Val Loss: 0.154432
2025-09-02 00:49:13,896 - INFO - Epoch 1036/5000 - Train Loss: 0.168391, Val Loss: 0.153866
2025-09-02 00:49:39,467 - INFO - Epoch 1037/5000 - Train Loss: 0.169368, Val Loss: 0.152911
2025-09-02 00:50:05,227 - INFO - Epoch 1038/5000 - Train Loss: 0.168508, Val Loss: 0.154759
2025-09-02 00:50:30,862 - INFO - Epoch 1039/5000 - Train Loss: 0.169248, Val Loss: 0.154959
2025-09-02 00:50:56,623 - INFO - Epoch 1040/5000 - Train Loss: 0.168826, Val Loss: 0.157250
2025-09-02 00:51:22,658 - INFO - Epoch 1041/5000 - Train Loss: 0.169477, Val Loss: 0.153079
2025-09-02 00:51:48,309 - INFO - Epoch 1042/5000 - Train Loss: 0.167697, Val Loss: 0.152754
2025-09-02 00:52:14,025 - INFO - Epoch 1043/5000 - Train Loss: 0.168205, Val Loss: 0.153487
2025-09-02 00:52:39,666 - INFO - Epoch 1044/5000 - Train Loss: 0.165893, Val Loss: 0.154020
2025-09-02 00:53:05,061 - INFO - Epoch 1045/5000 - Train Loss: 0.167845, Val Loss: 0.151670
2025-09-02 00:53:05,081 - INFO - New best model saved with Val Loss: 0.151670
2025-09-02 00:53:31,055 - INFO - Epoch 1046/5000 - Train Loss: 0.170081, Val Loss: 0.152970
2025-09-02 00:53:56,991 - INFO - Epoch 1047/5000 - Train Loss: 0.169141, Val Loss: 0.153855
2025-09-02 00:54:22,649 - INFO - Epoch 1048/5000 - Train Loss: 0.169148, Val Loss: 0.155886
2025-09-02 00:54:48,314 - INFO - Epoch 1049/5000 - Train Loss: 0.168711, Val Loss: 0.152985
2025-09-02 00:55:13,691 - INFO - Epoch 1050/5000 - Train Loss: 0.168931, Val Loss: 0.155117
2025-09-02 00:55:39,574 - INFO - Epoch 1051/5000 - Train Loss: 0.165879, Val Loss: 0.154155
2025-09-02 00:56:05,181 - INFO - Epoch 1052/5000 - Train Loss: 0.167516, Val Loss: 0.158453
2025-09-02 00:56:31,018 - INFO - Epoch 1053/5000 - Train Loss: 0.166612, Val Loss: 0.155858
2025-09-02 00:56:56,611 - INFO - Epoch 1054/5000 - Train Loss: 0.166292, Val Loss: 0.151375
2025-09-02 00:56:56,631 - INFO - New best model saved with Val Loss: 0.151375
2025-09-02 00:57:22,185 - INFO - Epoch 1055/5000 - Train Loss: 0.167228, Val Loss: 0.154008
2025-09-02 00:57:47,691 - INFO - Epoch 1056/5000 - Train Loss: 0.167609, Val Loss: 0.155754
2025-09-02 00:58:13,286 - INFO - Epoch 1057/5000 - Train Loss: 0.168401, Val Loss: 0.152065
2025-09-02 00:58:38,796 - INFO - Epoch 1058/5000 - Train Loss: 0.168288, Val Loss: 0.152096
2025-09-02 00:59:04,343 - INFO - Epoch 1059/5000 - Train Loss: 0.168105, Val Loss: 0.152227
2025-09-02 00:59:30,121 - INFO - Epoch 1060/5000 - Train Loss: 0.165643, Val Loss: 0.152929
2025-09-02 00:59:55,838 - INFO - Epoch 1061/5000 - Train Loss: 0.166529, Val Loss: 0.152672
2025-09-02 01:00:21,534 - INFO - Epoch 1062/5000 - Train Loss: 0.165710, Val Loss: 0.153978
2025-09-02 01:00:47,348 - INFO - Epoch 1063/5000 - Train Loss: 0.166419, Val Loss: 0.152276
2025-09-02 01:01:13,125 - INFO - Epoch 1064/5000 - Train Loss: 0.165676, Val Loss: 0.154249
2025-09-02 01:01:39,011 - INFO - Epoch 1065/5000 - Train Loss: 0.167581, Val Loss: 0.153619
2025-09-02 01:02:04,505 - INFO - Epoch 1066/5000 - Train Loss: 0.165801, Val Loss: 0.153300
2025-09-02 01:02:30,039 - INFO - Epoch 1067/5000 - Train Loss: 0.165388, Val Loss: 0.154004
2025-09-02 01:02:55,667 - INFO - Epoch 1068/5000 - Train Loss: 0.167829, Val Loss: 0.158097
2025-09-02 01:03:21,347 - INFO - Epoch 1069/5000 - Train Loss: 0.166964, Val Loss: 0.153511
2025-09-02 01:03:47,017 - INFO - Epoch 1070/5000 - Train Loss: 0.167909, Val Loss: 0.158889
2025-09-02 01:04:13,154 - INFO - Epoch 1071/5000 - Train Loss: 0.166774, Val Loss: 0.150128
2025-09-02 01:04:13,174 - INFO - New best model saved with Val Loss: 0.150128
2025-09-02 01:04:38,977 - INFO - Epoch 1072/5000 - Train Loss: 0.164779, Val Loss: 0.152613
2025-09-02 01:05:04,794 - INFO - Epoch 1073/5000 - Train Loss: 0.164925, Val Loss: 0.150825
2025-09-02 01:05:30,788 - INFO - Epoch 1074/5000 - Train Loss: 0.167182, Val Loss: 0.151583
2025-09-02 01:05:56,487 - INFO - Epoch 1075/5000 - Train Loss: 0.166192, Val Loss: 0.156709
2025-09-02 01:06:22,218 - INFO - Epoch 1076/5000 - Train Loss: 0.164977, Val Loss: 0.148977
2025-09-02 01:06:22,237 - INFO - New best model saved with Val Loss: 0.148977
2025-09-02 01:06:48,068 - INFO - Epoch 1077/5000 - Train Loss: 0.164921, Val Loss: 0.151111
2025-09-02 01:07:13,679 - INFO - Epoch 1078/5000 - Train Loss: 0.166444, Val Loss: 0.148819
2025-09-02 01:07:13,718 - INFO - New best model saved with Val Loss: 0.148819
2025-09-02 01:07:39,612 - INFO - Epoch 1079/5000 - Train Loss: 0.165082, Val Loss: 0.158140
2025-09-02 01:08:05,390 - INFO - Epoch 1080/5000 - Train Loss: 0.166351, Val Loss: 0.152171
2025-09-02 01:08:31,210 - INFO - Epoch 1081/5000 - Train Loss: 0.164948, Val Loss: 0.151196
2025-09-02 01:08:56,921 - INFO - Epoch 1082/5000 - Train Loss: 0.164618, Val Loss: 0.157621
2025-09-02 01:09:22,403 - INFO - Epoch 1083/5000 - Train Loss: 0.165318, Val Loss: 0.151638
2025-09-02 01:09:48,150 - INFO - Epoch 1084/5000 - Train Loss: 0.165555, Val Loss: 0.152372
2025-09-02 01:10:13,679 - INFO - Epoch 1085/5000 - Train Loss: 0.164385, Val Loss: 0.150234
2025-09-02 01:10:39,283 - INFO - Epoch 1086/5000 - Train Loss: 0.163039, Val Loss: 0.152003
2025-09-02 01:11:04,845 - INFO - Epoch 1087/5000 - Train Loss: 0.163715, Val Loss: 0.150328
2025-09-02 01:11:30,440 - INFO - Epoch 1088/5000 - Train Loss: 0.164273, Val Loss: 0.150293
2025-09-02 01:11:55,896 - INFO - Epoch 1089/5000 - Train Loss: 0.164359, Val Loss: 0.151976
2025-09-02 01:12:21,600 - INFO - Epoch 1090/5000 - Train Loss: 0.166125, Val Loss: 0.149522
2025-09-02 01:12:47,487 - INFO - Epoch 1091/5000 - Train Loss: 0.164921, Val Loss: 0.154493
2025-09-02 01:13:13,141 - INFO - Epoch 1092/5000 - Train Loss: 0.163183, Val Loss: 0.153659
2025-09-02 01:13:39,074 - INFO - Epoch 1093/5000 - Train Loss: 0.165937, Val Loss: 0.148307
2025-09-02 01:13:39,094 - INFO - New best model saved with Val Loss: 0.148307
2025-09-02 01:14:04,632 - INFO - Epoch 1094/5000 - Train Loss: 0.163880, Val Loss: 0.151427
2025-09-02 01:14:29,947 - INFO - Epoch 1095/5000 - Train Loss: 0.162809, Val Loss: 0.149456
2025-09-02 01:14:55,653 - INFO - Epoch 1096/5000 - Train Loss: 0.162544, Val Loss: 0.153795
2025-09-02 01:15:21,104 - INFO - Epoch 1097/5000 - Train Loss: 0.162175, Val Loss: 0.146750
2025-09-02 01:15:21,124 - INFO - New best model saved with Val Loss: 0.146750
2025-09-02 01:15:46,706 - INFO - Epoch 1098/5000 - Train Loss: 0.163306, Val Loss: 0.150917
2025-09-02 01:16:12,267 - INFO - Epoch 1099/5000 - Train Loss: 0.163628, Val Loss: 0.151619
2025-09-02 01:16:37,895 - INFO - Epoch 1100/5000 - Train Loss: 0.164481, Val Loss: 0.149335
2025-09-02 01:17:03,649 - INFO - Epoch 1101/5000 - Train Loss: 0.162332, Val Loss: 0.147303
2025-09-02 01:17:29,468 - INFO - Epoch 1102/5000 - Train Loss: 0.162829, Val Loss: 0.152442
2025-09-02 01:17:55,226 - INFO - Epoch 1103/5000 - Train Loss: 0.163203, Val Loss: 0.148335
2025-09-02 01:18:20,799 - INFO - Epoch 1104/5000 - Train Loss: 0.163699, Val Loss: 0.150355
2025-09-02 01:18:46,376 - INFO - Epoch 1105/5000 - Train Loss: 0.163383, Val Loss: 0.149283
2025-09-02 01:19:11,816 - INFO - Epoch 1106/5000 - Train Loss: 0.162620, Val Loss: 0.146980
2025-09-02 01:19:37,579 - INFO - Epoch 1107/5000 - Train Loss: 0.162246, Val Loss: 0.150429
2025-09-02 01:20:03,656 - INFO - Epoch 1108/5000 - Train Loss: 0.165047, Val Loss: 0.154714
2025-09-02 01:20:29,448 - INFO - Epoch 1109/5000 - Train Loss: 0.166399, Val Loss: 0.147680
2025-09-02 01:20:54,871 - INFO - Epoch 1110/5000 - Train Loss: 0.165118, Val Loss: 0.147906
2025-09-02 01:21:20,432 - INFO - Epoch 1111/5000 - Train Loss: 0.163988, Val Loss: 0.148046
2025-09-02 01:21:46,251 - INFO - Epoch 1112/5000 - Train Loss: 0.162273, Val Loss: 0.147826
2025-09-02 01:22:11,877 - INFO - Epoch 1113/5000 - Train Loss: 0.160781, Val Loss: 0.145424
2025-09-02 01:22:11,897 - INFO - New best model saved with Val Loss: 0.145424
2025-09-02 01:22:37,451 - INFO - Epoch 1114/5000 - Train Loss: 0.160177, Val Loss: 0.149228
2025-09-02 01:23:03,401 - INFO - Epoch 1115/5000 - Train Loss: 0.162524, Val Loss: 0.150049
2025-09-02 01:23:29,061 - INFO - Epoch 1116/5000 - Train Loss: 0.162986, Val Loss: 0.147215
2025-09-02 01:23:54,918 - INFO - Epoch 1117/5000 - Train Loss: 0.161111, Val Loss: 0.148851
2025-09-02 01:24:20,428 - INFO - Epoch 1118/5000 - Train Loss: 0.161511, Val Loss: 0.149894
2025-09-02 01:24:46,215 - INFO - Epoch 1119/5000 - Train Loss: 0.164486, Val Loss: 0.149391
2025-09-02 01:25:12,581 - INFO - Epoch 1120/5000 - Train Loss: 0.162889, Val Loss: 0.150697
2025-09-02 01:25:38,439 - INFO - Epoch 1121/5000 - Train Loss: 0.162740, Val Loss: 0.153292
2025-09-02 01:26:04,278 - INFO - Epoch 1122/5000 - Train Loss: 0.161468, Val Loss: 0.151171
2025-09-02 01:26:29,971 - INFO - Epoch 1123/5000 - Train Loss: 0.161564, Val Loss: 0.146562
2025-09-02 01:26:55,573 - INFO - Epoch 1124/5000 - Train Loss: 0.160526, Val Loss: 0.148342
2025-09-02 01:27:21,253 - INFO - Epoch 1125/5000 - Train Loss: 0.160561, Val Loss: 0.146463
2025-09-02 01:27:47,019 - INFO - Epoch 1126/5000 - Train Loss: 0.160970, Val Loss: 0.147484
2025-09-02 01:28:12,615 - INFO - Epoch 1127/5000 - Train Loss: 0.161141, Val Loss: 0.146562
2025-09-02 01:28:38,218 - INFO - Epoch 1128/5000 - Train Loss: 0.159586, Val Loss: 0.145319
2025-09-02 01:28:38,249 - INFO - New best model saved with Val Loss: 0.145319
2025-09-02 01:29:03,778 - INFO - Epoch 1129/5000 - Train Loss: 0.160164, Val Loss: 0.145139
2025-09-02 01:29:03,797 - INFO - New best model saved with Val Loss: 0.145139
2025-09-02 01:29:29,613 - INFO - Epoch 1130/5000 - Train Loss: 0.161750, Val Loss: 0.150050
2025-09-02 01:29:55,412 - INFO - Epoch 1131/5000 - Train Loss: 0.166631, Val Loss: 0.148708
2025-09-02 01:30:21,087 - INFO - Epoch 1132/5000 - Train Loss: 0.162320, Val Loss: 0.149628
2025-09-02 01:30:46,750 - INFO - Epoch 1133/5000 - Train Loss: 0.161076, Val Loss: 0.146213
2025-09-02 01:31:12,469 - INFO - Epoch 1134/5000 - Train Loss: 0.160615, Val Loss: 0.146859
2025-09-02 01:31:38,153 - INFO - Epoch 1135/5000 - Train Loss: 0.160356, Val Loss: 0.154725
2025-09-02 01:32:04,242 - INFO - Epoch 1136/5000 - Train Loss: 0.160628, Val Loss: 0.146900
2025-09-02 01:32:29,911 - INFO - Epoch 1137/5000 - Train Loss: 0.160321, Val Loss: 0.147987
2025-09-02 01:32:55,642 - INFO - Epoch 1138/5000 - Train Loss: 0.159033, Val Loss: 0.146228
2025-09-02 01:33:21,318 - INFO - Epoch 1139/5000 - Train Loss: 0.160826, Val Loss: 0.144436
2025-09-02 01:33:21,338 - INFO - New best model saved with Val Loss: 0.144436
2025-09-02 01:33:47,141 - INFO - Epoch 1140/5000 - Train Loss: 0.159803, Val Loss: 0.146613
2025-09-02 01:34:13,093 - INFO - Epoch 1141/5000 - Train Loss: 0.160579, Val Loss: 0.149825
2025-09-02 01:34:38,555 - INFO - Epoch 1142/5000 - Train Loss: 0.159403, Val Loss: 0.145945
2025-09-02 01:35:04,049 - INFO - Epoch 1143/5000 - Train Loss: 0.160868, Val Loss: 0.146229
2025-09-02 01:35:29,969 - INFO - Epoch 1144/5000 - Train Loss: 0.160458, Val Loss: 0.148077
2025-09-02 01:35:55,813 - INFO - Epoch 1145/5000 - Train Loss: 0.158382, Val Loss: 0.148471
2025-09-02 01:36:21,635 - INFO - Epoch 1146/5000 - Train Loss: 0.161098, Val Loss: 0.147729
2025-09-02 01:36:47,426 - INFO - Epoch 1147/5000 - Train Loss: 0.159161, Val Loss: 0.142650
2025-09-02 01:36:47,445 - INFO - New best model saved with Val Loss: 0.142650
2025-09-02 01:37:13,315 - INFO - Epoch 1148/5000 - Train Loss: 0.160907, Val Loss: 0.148728
2025-09-02 01:37:39,010 - INFO - Epoch 1149/5000 - Train Loss: 0.159289, Val Loss: 0.145577
2025-09-02 01:38:05,239 - INFO - Epoch 1150/5000 - Train Loss: 0.160560, Val Loss: 0.147208
2025-09-02 01:38:31,339 - INFO - Epoch 1151/5000 - Train Loss: 0.160549, Val Loss: 0.146616
2025-09-02 01:38:57,004 - INFO - Epoch 1152/5000 - Train Loss: 0.160463, Val Loss: 0.151241
2025-09-02 01:39:22,514 - INFO - Epoch 1153/5000 - Train Loss: 0.159687, Val Loss: 0.145298
2025-09-02 01:39:48,396 - INFO - Epoch 1154/5000 - Train Loss: 0.158755, Val Loss: 0.146827
2025-09-02 01:40:14,169 - INFO - Epoch 1155/5000 - Train Loss: 0.158537, Val Loss: 0.148204
2025-09-02 01:40:39,753 - INFO - Epoch 1156/5000 - Train Loss: 0.161101, Val Loss: 0.150167
2025-09-02 01:41:05,693 - INFO - Epoch 1157/5000 - Train Loss: 0.158347, Val Loss: 0.148855
2025-09-02 01:41:31,363 - INFO - Epoch 1158/5000 - Train Loss: 0.157949, Val Loss: 0.141532
2025-09-02 01:41:31,383 - INFO - New best model saved with Val Loss: 0.141532
2025-09-02 01:41:57,049 - INFO - Epoch 1159/5000 - Train Loss: 0.157642, Val Loss: 0.144658
2025-09-02 01:42:22,923 - INFO - Epoch 1160/5000 - Train Loss: 0.158117, Val Loss: 0.142151
2025-09-02 01:42:48,468 - INFO - Epoch 1161/5000 - Train Loss: 0.157111, Val Loss: 0.144614
2025-09-02 01:43:14,397 - INFO - Epoch 1162/5000 - Train Loss: 0.160502, Val Loss: 0.147821
2025-09-02 01:43:40,006 - INFO - Epoch 1163/5000 - Train Loss: 0.157322, Val Loss: 0.147350
2025-09-02 01:44:05,579 - INFO - Epoch 1164/5000 - Train Loss: 0.158710, Val Loss: 0.145182
2025-09-02 01:44:31,565 - INFO - Epoch 1165/5000 - Train Loss: 0.157790, Val Loss: 0.144383
2025-09-02 01:44:57,278 - INFO - Epoch 1166/5000 - Train Loss: 0.158122, Val Loss: 0.149418
2025-09-02 01:45:22,809 - INFO - Epoch 1167/5000 - Train Loss: 0.157043, Val Loss: 0.145485
2025-09-02 01:45:48,303 - INFO - Epoch 1168/5000 - Train Loss: 0.158425, Val Loss: 0.143200
2025-09-02 01:46:13,933 - INFO - Epoch 1169/5000 - Train Loss: 0.157188, Val Loss: 0.148301
2025-09-02 01:46:39,633 - INFO - Epoch 1170/5000 - Train Loss: 0.157279, Val Loss: 0.144916
2025-09-02 01:47:05,615 - INFO - Epoch 1171/5000 - Train Loss: 0.158419, Val Loss: 0.149382
2025-09-02 01:47:31,120 - INFO - Epoch 1172/5000 - Train Loss: 0.158736, Val Loss: 0.143819
2025-09-02 01:47:56,403 - INFO - Epoch 1173/5000 - Train Loss: 0.158173, Val Loss: 0.144042
2025-09-02 01:48:21,684 - INFO - Epoch 1174/5000 - Train Loss: 0.160606, Val Loss: 0.146370
2025-09-02 01:48:47,013 - INFO - Epoch 1175/5000 - Train Loss: 0.156710, Val Loss: 0.142313
2025-09-02 01:49:12,197 - INFO - Epoch 1176/5000 - Train Loss: 0.157025, Val Loss: 0.146400
2025-09-02 01:49:37,512 - INFO - Epoch 1177/5000 - Train Loss: 0.159364, Val Loss: 0.143322
2025-09-02 01:50:02,883 - INFO - Epoch 1178/5000 - Train Loss: 0.157406, Val Loss: 0.143339
2025-09-02 01:50:28,676 - INFO - Epoch 1179/5000 - Train Loss: 0.158068, Val Loss: 0.142042
2025-09-02 01:50:53,906 - INFO - Epoch 1180/5000 - Train Loss: 0.155546, Val Loss: 0.141434
2025-09-02 01:50:53,926 - INFO - New best model saved with Val Loss: 0.141434
2025-09-02 01:51:19,520 - INFO - Epoch 1181/5000 - Train Loss: 0.155649, Val Loss: 0.141517
2025-09-02 01:51:45,245 - INFO - Epoch 1182/5000 - Train Loss: 0.156842, Val Loss: 0.143653
2025-09-02 01:52:10,993 - INFO - Epoch 1183/5000 - Train Loss: 0.157244, Val Loss: 0.144029
2025-09-02 01:52:36,330 - INFO - Epoch 1184/5000 - Train Loss: 0.158807, Val Loss: 0.144838
2025-09-02 01:53:01,839 - INFO - Epoch 1185/5000 - Train Loss: 0.158716, Val Loss: 0.141406
2025-09-02 01:53:01,859 - INFO - New best model saved with Val Loss: 0.141406
2025-09-02 01:53:27,567 - INFO - Epoch 1186/5000 - Train Loss: 0.157157, Val Loss: 0.143202
2025-09-02 01:53:53,147 - INFO - Epoch 1187/5000 - Train Loss: 0.155719, Val Loss: 0.144904
2025-09-02 01:54:18,562 - INFO - Epoch 1188/5000 - Train Loss: 0.155810, Val Loss: 0.140493
2025-09-02 01:54:18,582 - INFO - New best model saved with Val Loss: 0.140493
2025-09-02 01:54:44,138 - INFO - Epoch 1189/5000 - Train Loss: 0.157364, Val Loss: 0.142247
2025-09-02 01:55:09,949 - INFO - Epoch 1190/5000 - Train Loss: 0.158763, Val Loss: 0.143017
2025-09-02 01:55:35,881 - INFO - Epoch 1191/5000 - Train Loss: 0.156785, Val Loss: 0.144425
2025-09-02 01:56:01,771 - INFO - Epoch 1192/5000 - Train Loss: 0.157745, Val Loss: 0.141845
2025-09-02 01:56:27,661 - INFO - Epoch 1193/5000 - Train Loss: 0.156875, Val Loss: 0.140836
2025-09-02 01:56:53,673 - INFO - Epoch 1194/5000 - Train Loss: 0.154735, Val Loss: 0.146086
2025-09-02 01:57:19,451 - INFO - Epoch 1195/5000 - Train Loss: 0.157196, Val Loss: 0.143826
2025-09-02 01:57:45,237 - INFO - Epoch 1196/5000 - Train Loss: 0.155420, Val Loss: 0.141797
2025-09-02 01:58:11,233 - INFO - Epoch 1197/5000 - Train Loss: 0.155071, Val Loss: 0.140893
2025-09-02 01:58:36,983 - INFO - Epoch 1198/5000 - Train Loss: 0.155619, Val Loss: 0.144450
2025-09-02 01:59:02,771 - INFO - Epoch 1199/5000 - Train Loss: 0.155816, Val Loss: 0.143021
2025-09-02 01:59:28,606 - INFO - Epoch 1200/5000 - Train Loss: 0.155336, Val Loss: 0.142290
2025-09-02 01:59:54,691 - INFO - Epoch 1201/5000 - Train Loss: 0.156340, Val Loss: 0.141681
2025-09-02 02:00:20,482 - INFO - Epoch 1202/5000 - Train Loss: 0.155227, Val Loss: 0.142919
2025-09-02 02:00:46,101 - INFO - Epoch 1203/5000 - Train Loss: 0.159096, Val Loss: 0.147808
2025-09-02 02:01:11,709 - INFO - Epoch 1204/5000 - Train Loss: 0.157600, Val Loss: 0.142411
2025-09-02 02:01:37,277 - INFO - Epoch 1205/5000 - Train Loss: 0.156047, Val Loss: 0.146838
2025-09-02 02:02:03,056 - INFO - Epoch 1206/5000 - Train Loss: 0.156184, Val Loss: 0.138944
2025-09-02 02:02:03,088 - INFO - New best model saved with Val Loss: 0.138944
2025-09-02 02:02:28,713 - INFO - Epoch 1207/5000 - Train Loss: 0.154567, Val Loss: 0.143905
2025-09-02 02:02:54,465 - INFO - Epoch 1208/5000 - Train Loss: 0.156057, Val Loss: 0.143210
2025-09-02 02:03:19,953 - INFO - Epoch 1209/5000 - Train Loss: 0.155514, Val Loss: 0.142501
2025-09-02 02:03:45,622 - INFO - Epoch 1210/5000 - Train Loss: 0.155921, Val Loss: 0.140108
2025-09-02 02:04:11,497 - INFO - Epoch 1211/5000 - Train Loss: 0.154432, Val Loss: 0.142653
2025-09-02 02:04:37,219 - INFO - Epoch 1212/5000 - Train Loss: 0.153700, Val Loss: 0.138646
2025-09-02 02:04:37,238 - INFO - New best model saved with Val Loss: 0.138646
2025-09-02 02:05:02,816 - INFO - Epoch 1213/5000 - Train Loss: 0.153364, Val Loss: 0.148908
2025-09-02 02:05:28,315 - INFO - Epoch 1214/5000 - Train Loss: 0.156343, Val Loss: 0.142962
2025-09-02 02:05:53,776 - INFO - Epoch 1215/5000 - Train Loss: 0.153201, Val Loss: 0.142475
2025-09-02 02:06:19,282 - INFO - Epoch 1216/5000 - Train Loss: 0.153349, Val Loss: 0.137782
2025-09-02 02:06:19,301 - INFO - New best model saved with Val Loss: 0.137782
2025-09-02 02:06:45,138 - INFO - Epoch 1217/5000 - Train Loss: 0.154379, Val Loss: 0.140554
2025-09-02 02:07:10,726 - INFO - Epoch 1218/5000 - Train Loss: 0.153414, Val Loss: 0.138981
2025-09-02 02:07:36,568 - INFO - Epoch 1219/5000 - Train Loss: 0.154376, Val Loss: 0.140903
2025-09-02 02:08:02,291 - INFO - Epoch 1220/5000 - Train Loss: 0.154611, Val Loss: 0.143181
2025-09-02 02:08:28,288 - INFO - Epoch 1221/5000 - Train Loss: 0.153655, Val Loss: 0.142342
2025-09-02 02:08:53,877 - INFO - Epoch 1222/5000 - Train Loss: 0.152804, Val Loss: 0.138082
2025-09-02 02:09:19,677 - INFO - Epoch 1223/5000 - Train Loss: 0.152276, Val Loss: 0.138669
2025-09-02 02:09:45,330 - INFO - Epoch 1224/5000 - Train Loss: 0.154549, Val Loss: 0.138712
2025-09-02 02:10:10,908 - INFO - Epoch 1225/5000 - Train Loss: 0.153080, Val Loss: 0.141599
2025-09-02 02:10:36,280 - INFO - Epoch 1226/5000 - Train Loss: 0.154757, Val Loss: 0.139638
2025-09-02 02:11:01,908 - INFO - Epoch 1227/5000 - Train Loss: 0.153789, Val Loss: 0.143351
2025-09-02 02:11:27,585 - INFO - Epoch 1228/5000 - Train Loss: 0.154158, Val Loss: 0.142517
2025-09-02 02:11:53,187 - INFO - Epoch 1229/5000 - Train Loss: 0.152981, Val Loss: 0.140516
2025-09-02 02:12:18,770 - INFO - Epoch 1230/5000 - Train Loss: 0.152817, Val Loss: 0.140400
2025-09-02 02:12:44,421 - INFO - Epoch 1231/5000 - Train Loss: 0.151417, Val Loss: 0.137936
2025-09-02 02:13:10,428 - INFO - Epoch 1232/5000 - Train Loss: 0.151519, Val Loss: 0.138669
2025-09-02 02:13:35,825 - INFO - Epoch 1233/5000 - Train Loss: 0.154190, Val Loss: 0.140364
2025-09-02 02:14:01,330 - INFO - Epoch 1234/5000 - Train Loss: 0.154527, Val Loss: 0.137128
2025-09-02 02:14:01,350 - INFO - New best model saved with Val Loss: 0.137128
2025-09-02 02:14:27,099 - INFO - Epoch 1235/5000 - Train Loss: 0.153950, Val Loss: 0.143406
2025-09-02 02:14:52,511 - INFO - Epoch 1236/5000 - Train Loss: 0.154121, Val Loss: 0.136556
2025-09-02 02:14:52,531 - INFO - New best model saved with Val Loss: 0.136556
2025-09-02 02:15:18,367 - INFO - Epoch 1237/5000 - Train Loss: 0.154132, Val Loss: 0.143365
2025-09-02 02:15:44,099 - INFO - Epoch 1238/5000 - Train Loss: 0.151622, Val Loss: 0.134624
2025-09-02 02:15:44,120 - INFO - New best model saved with Val Loss: 0.134624
2025-09-02 02:16:09,863 - INFO - Epoch 1239/5000 - Train Loss: 0.153797, Val Loss: 0.148846
2025-09-02 02:16:35,300 - INFO - Epoch 1240/5000 - Train Loss: 0.153559, Val Loss: 0.141304
2025-09-02 02:17:01,043 - INFO - Epoch 1241/5000 - Train Loss: 0.153423, Val Loss: 0.138256
2025-09-02 02:17:26,762 - INFO - Epoch 1242/5000 - Train Loss: 0.151044, Val Loss: 0.135749
2025-09-02 02:17:52,344 - INFO - Epoch 1243/5000 - Train Loss: 0.152011, Val Loss: 0.138326
2025-09-02 02:18:17,979 - INFO - Epoch 1244/5000 - Train Loss: 0.151515, Val Loss: 0.135432
2025-09-02 02:18:43,586 - INFO - Epoch 1245/5000 - Train Loss: 0.152196, Val Loss: 0.137784
2025-09-02 02:19:09,158 - INFO - Epoch 1246/5000 - Train Loss: 0.152475, Val Loss: 0.138592
2025-09-02 02:19:34,753 - INFO - Epoch 1247/5000 - Train Loss: 0.152717, Val Loss: 0.144320
2025-09-02 02:20:00,354 - INFO - Epoch 1248/5000 - Train Loss: 0.152710, Val Loss: 0.136143
2025-09-02 02:20:25,748 - INFO - Epoch 1249/5000 - Train Loss: 0.151916, Val Loss: 0.137149
2025-09-02 02:20:51,530 - INFO - Epoch 1250/5000 - Train Loss: 0.149268, Val Loss: 0.132962
2025-09-02 02:20:51,551 - INFO - New best model saved with Val Loss: 0.132962
2025-09-02 02:21:17,404 - INFO - Epoch 1251/5000 - Train Loss: 0.149841, Val Loss: 0.141572
2025-09-02 02:21:43,249 - INFO - Epoch 1252/5000 - Train Loss: 0.150945, Val Loss: 0.134625
2025-09-02 02:22:09,135 - INFO - Epoch 1253/5000 - Train Loss: 0.149837, Val Loss: 0.136242
2025-09-02 02:22:34,802 - INFO - Epoch 1254/5000 - Train Loss: 0.149879, Val Loss: 0.134722
2025-09-02 02:23:00,278 - INFO - Epoch 1255/5000 - Train Loss: 0.149646, Val Loss: 0.134573
2025-09-02 02:23:25,916 - INFO - Epoch 1256/5000 - Train Loss: 0.151827, Val Loss: 0.138586
2025-09-02 02:23:51,524 - INFO - Epoch 1257/5000 - Train Loss: 0.150843, Val Loss: 0.134335
2025-09-02 02:24:17,256 - INFO - Epoch 1258/5000 - Train Loss: 0.150917, Val Loss: 0.135645
2025-09-02 02:24:42,805 - INFO - Epoch 1259/5000 - Train Loss: 0.149089, Val Loss: 0.136377
2025-09-02 02:25:08,505 - INFO - Epoch 1260/5000 - Train Loss: 0.150533, Val Loss: 0.137673
2025-09-02 02:25:34,167 - INFO - Epoch 1261/5000 - Train Loss: 0.151030, Val Loss: 0.135302
2025-09-02 02:25:59,721 - INFO - Epoch 1262/5000 - Train Loss: 0.152133, Val Loss: 0.136743
2025-09-02 02:26:25,335 - INFO - Epoch 1263/5000 - Train Loss: 0.151721, Val Loss: 0.145549
2025-09-02 02:26:50,851 - INFO - Epoch 1264/5000 - Train Loss: 0.151223, Val Loss: 0.133741
2025-09-02 02:27:16,597 - INFO - Epoch 1265/5000 - Train Loss: 0.149116, Val Loss: 0.134268
2025-09-02 02:27:42,597 - INFO - Epoch 1266/5000 - Train Loss: 0.150689, Val Loss: 0.137905
2025-09-02 02:28:08,136 - INFO - Epoch 1267/5000 - Train Loss: 0.149736, Val Loss: 0.140923
2025-09-02 02:28:33,819 - INFO - Epoch 1268/5000 - Train Loss: 0.149484, Val Loss: 0.135062
2025-09-02 02:28:59,199 - INFO - Epoch 1269/5000 - Train Loss: 0.151081, Val Loss: 0.135999
2025-09-02 02:29:25,062 - INFO - Epoch 1270/5000 - Train Loss: 0.148685, Val Loss: 0.136041
2025-09-02 02:29:50,686 - INFO - Epoch 1271/5000 - Train Loss: 0.148397, Val Loss: 0.134255
2025-09-02 02:30:16,168 - INFO - Epoch 1272/5000 - Train Loss: 0.150292, Val Loss: 0.132866
2025-09-02 02:30:16,188 - INFO - New best model saved with Val Loss: 0.132866
2025-09-02 02:30:41,949 - INFO - Epoch 1273/5000 - Train Loss: 0.148703, Val Loss: 0.133810
2025-09-02 02:31:07,487 - INFO - Epoch 1274/5000 - Train Loss: 0.149515, Val Loss: 0.136083
2025-09-02 02:31:33,152 - INFO - Epoch 1275/5000 - Train Loss: 0.147111, Val Loss: 0.135485
2025-09-02 02:31:58,804 - INFO - Epoch 1276/5000 - Train Loss: 0.149074, Val Loss: 0.134271
2025-09-02 02:32:24,854 - INFO - Epoch 1277/5000 - Train Loss: 0.148945, Val Loss: 0.139107
2025-09-02 02:32:50,521 - INFO - Epoch 1278/5000 - Train Loss: 0.149115, Val Loss: 0.137098
2025-09-02 02:33:16,107 - INFO - Epoch 1279/5000 - Train Loss: 0.147206, Val Loss: 0.134807
2025-09-02 02:33:41,734 - INFO - Epoch 1280/5000 - Train Loss: 0.148769, Val Loss: 0.137680
2025-09-02 02:34:07,528 - INFO - Epoch 1281/5000 - Train Loss: 0.147723, Val Loss: 0.133725
2025-09-02 02:34:33,075 - INFO - Epoch 1282/5000 - Train Loss: 0.148661, Val Loss: 0.138887
2025-09-02 02:34:58,593 - INFO - Epoch 1283/5000 - Train Loss: 0.147928, Val Loss: 0.133518
2025-09-02 02:35:24,374 - INFO - Epoch 1284/5000 - Train Loss: 0.147912, Val Loss: 0.135642
2025-09-02 02:35:49,890 - INFO - Epoch 1285/5000 - Train Loss: 0.149927, Val Loss: 0.136086
2025-09-02 02:36:15,591 - INFO - Epoch 1286/5000 - Train Loss: 0.149875, Val Loss: 0.135061
2025-09-02 02:36:41,233 - INFO - Epoch 1287/5000 - Train Loss: 0.147664, Val Loss: 0.134301
2025-09-02 02:37:06,727 - INFO - Epoch 1288/5000 - Train Loss: 0.147394, Val Loss: 0.133758
2025-09-02 02:37:32,329 - INFO - Epoch 1289/5000 - Train Loss: 0.147781, Val Loss: 0.135640
2025-09-02 02:37:57,981 - INFO - Epoch 1290/5000 - Train Loss: 0.147738, Val Loss: 0.132991
2025-09-02 02:38:23,544 - INFO - Epoch 1291/5000 - Train Loss: 0.149716, Val Loss: 0.132379
2025-09-02 02:38:23,576 - INFO - New best model saved with Val Loss: 0.132379
2025-09-02 02:38:48,821 - INFO - Epoch 1292/5000 - Train Loss: 0.149187, Val Loss: 0.132308
2025-09-02 02:38:48,841 - INFO - New best model saved with Val Loss: 0.132308
2025-09-02 02:39:14,642 - INFO - Epoch 1293/5000 - Train Loss: 0.147574, Val Loss: 0.133514
2025-09-02 02:39:40,177 - INFO - Epoch 1294/5000 - Train Loss: 0.148561, Val Loss: 0.131585
2025-09-02 02:39:40,197 - INFO - New best model saved with Val Loss: 0.131585
2025-09-02 02:40:05,637 - INFO - Epoch 1295/5000 - Train Loss: 0.146412, Val Loss: 0.132127
2025-09-02 02:40:31,230 - INFO - Epoch 1296/5000 - Train Loss: 0.149136, Val Loss: 0.134234
2025-09-02 02:40:56,648 - INFO - Epoch 1297/5000 - Train Loss: 0.145991, Val Loss: 0.130370
2025-09-02 02:40:56,668 - INFO - New best model saved with Val Loss: 0.130370
2025-09-02 02:41:22,395 - INFO - Epoch 1298/5000 - Train Loss: 0.146059, Val Loss: 0.132087
2025-09-02 02:41:47,868 - INFO - Epoch 1299/5000 - Train Loss: 0.147050, Val Loss: 0.135127
2025-09-02 02:42:13,197 - INFO - Epoch 1300/5000 - Train Loss: 0.146160, Val Loss: 0.129407
2025-09-02 02:42:13,217 - INFO - New best model saved with Val Loss: 0.129407
2025-09-02 02:42:38,889 - INFO - Epoch 1301/5000 - Train Loss: 0.146984, Val Loss: 0.131804
2025-09-02 02:43:04,390 - INFO - Epoch 1302/5000 - Train Loss: 0.146188, Val Loss: 0.132833
2025-09-02 02:43:30,073 - INFO - Epoch 1303/5000 - Train Loss: 0.147171, Val Loss: 0.134490
2025-09-02 02:43:55,707 - INFO - Epoch 1304/5000 - Train Loss: 0.146247, Val Loss: 0.129491
2025-09-02 02:44:21,273 - INFO - Epoch 1305/5000 - Train Loss: 0.145979, Val Loss: 0.131182
2025-09-02 02:44:46,789 - INFO - Epoch 1306/5000 - Train Loss: 0.146823, Val Loss: 0.132453
2025-09-02 02:45:12,446 - INFO - Epoch 1307/5000 - Train Loss: 0.146199, Val Loss: 0.130652
2025-09-02 02:45:38,044 - INFO - Epoch 1308/5000 - Train Loss: 0.145830, Val Loss: 0.130188
2025-09-02 02:46:03,738 - INFO - Epoch 1309/5000 - Train Loss: 0.145615, Val Loss: 0.130477
2025-09-02 02:46:29,789 - INFO - Epoch 1310/5000 - Train Loss: 0.146078, Val Loss: 0.130581
2025-09-02 02:46:55,432 - INFO - Epoch 1311/5000 - Train Loss: 0.145621, Val Loss: 0.133346
2025-09-02 02:47:20,934 - INFO - Epoch 1312/5000 - Train Loss: 0.145317, Val Loss: 0.129285
2025-09-02 02:47:20,972 - INFO - New best model saved with Val Loss: 0.129285
2025-09-02 02:47:46,396 - INFO - Epoch 1313/5000 - Train Loss: 0.144918, Val Loss: 0.133227
2025-09-02 02:48:12,061 - INFO - Epoch 1314/5000 - Train Loss: 0.148192, Val Loss: 0.135981
2025-09-02 02:48:37,489 - INFO - Epoch 1315/5000 - Train Loss: 0.146026, Val Loss: 0.128660
2025-09-02 02:48:37,509 - INFO - New best model saved with Val Loss: 0.128660
2025-09-02 02:49:03,282 - INFO - Epoch 1316/5000 - Train Loss: 0.146351, Val Loss: 0.131601
2025-09-02 02:49:28,938 - INFO - Epoch 1317/5000 - Train Loss: 0.145451, Val Loss: 0.131808
2025-09-02 02:49:54,574 - INFO - Epoch 1318/5000 - Train Loss: 0.146301, Val Loss: 0.130176
2025-09-02 02:50:20,428 - INFO - Epoch 1319/5000 - Train Loss: 0.146617, Val Loss: 0.136901
2025-09-02 02:50:46,197 - INFO - Epoch 1320/5000 - Train Loss: 0.145748, Val Loss: 0.131793
2025-09-02 02:51:11,951 - INFO - Epoch 1321/5000 - Train Loss: 0.145190, Val Loss: 0.128235
2025-09-02 02:51:11,981 - INFO - New best model saved with Val Loss: 0.128235
2025-09-02 02:51:37,623 - INFO - Epoch 1322/5000 - Train Loss: 0.143082, Val Loss: 0.128790
2025-09-02 02:52:03,025 - INFO - Epoch 1323/5000 - Train Loss: 0.143162, Val Loss: 0.130422
2025-09-02 02:52:28,393 - INFO - Epoch 1324/5000 - Train Loss: 0.145260, Val Loss: 0.133195
2025-09-02 02:52:54,059 - INFO - Epoch 1325/5000 - Train Loss: 0.144476, Val Loss: 0.132143
2025-09-02 02:53:19,841 - INFO - Epoch 1326/5000 - Train Loss: 0.144280, Val Loss: 0.132310
2025-09-02 02:53:45,442 - INFO - Epoch 1327/5000 - Train Loss: 0.144593, Val Loss: 0.129027
2025-09-02 02:54:11,050 - INFO - Epoch 1328/5000 - Train Loss: 0.144869, Val Loss: 0.128106
2025-09-02 02:54:11,070 - INFO - New best model saved with Val Loss: 0.128106
2025-09-02 02:54:36,754 - INFO - Epoch 1329/5000 - Train Loss: 0.145370, Val Loss: 0.130009
2025-09-02 02:55:02,273 - INFO - Epoch 1330/5000 - Train Loss: 0.143426, Val Loss: 0.128162
2025-09-02 02:55:27,996 - INFO - Epoch 1331/5000 - Train Loss: 0.144305, Val Loss: 0.133480
2025-09-02 02:55:53,765 - INFO - Epoch 1332/5000 - Train Loss: 0.144862, Val Loss: 0.136012
2025-09-02 02:56:19,460 - INFO - Epoch 1333/5000 - Train Loss: 0.145612, Val Loss: 0.130076
2025-09-02 02:56:45,002 - INFO - Epoch 1334/5000 - Train Loss: 0.145720, Val Loss: 0.133846
2025-09-02 02:57:10,720 - INFO - Epoch 1335/5000 - Train Loss: 0.146534, Val Loss: 0.140950
2025-09-02 02:57:36,493 - INFO - Epoch 1336/5000 - Train Loss: 0.145517, Val Loss: 0.133083
2025-09-02 02:58:02,070 - INFO - Epoch 1337/5000 - Train Loss: 0.143794, Val Loss: 0.129773
2025-09-02 02:58:27,690 - INFO - Epoch 1338/5000 - Train Loss: 0.144305, Val Loss: 0.127177
2025-09-02 02:58:27,741 - INFO - New best model saved with Val Loss: 0.127177
2025-09-02 02:58:53,411 - INFO - Epoch 1339/5000 - Train Loss: 0.144221, Val Loss: 0.129445
2025-09-02 02:59:19,044 - INFO - Epoch 1340/5000 - Train Loss: 0.142555, Val Loss: 0.127201
2025-09-02 02:59:44,820 - INFO - Epoch 1341/5000 - Train Loss: 0.143136, Val Loss: 0.131981
2025-09-02 03:00:10,625 - INFO - Epoch 1342/5000 - Train Loss: 0.143972, Val Loss: 0.132499
2025-09-02 03:00:36,247 - INFO - Epoch 1343/5000 - Train Loss: 0.144798, Val Loss: 0.129920
2025-09-02 03:01:01,920 - INFO - Epoch 1344/5000 - Train Loss: 0.143471, Val Loss: 0.136580
2025-09-02 03:01:27,436 - INFO - Epoch 1345/5000 - Train Loss: 0.145031, Val Loss: 0.131366
2025-09-02 03:01:53,033 - INFO - Epoch 1346/5000 - Train Loss: 0.144340, Val Loss: 0.131429
2025-09-02 03:02:18,579 - INFO - Epoch 1347/5000 - Train Loss: 0.142743, Val Loss: 0.127642
2025-09-02 03:02:44,090 - INFO - Epoch 1348/5000 - Train Loss: 0.141859, Val Loss: 0.127675
2025-09-02 03:03:09,717 - INFO - Epoch 1349/5000 - Train Loss: 0.143980, Val Loss: 0.126137
2025-09-02 03:03:09,737 - INFO - New best model saved with Val Loss: 0.126137
2025-09-02 03:03:35,484 - INFO - Epoch 1350/5000 - Train Loss: 0.144726, Val Loss: 0.133061
2025-09-02 03:04:01,132 - INFO - Epoch 1351/5000 - Train Loss: 0.144961, Val Loss: 0.130503
2025-09-02 03:04:27,026 - INFO - Epoch 1352/5000 - Train Loss: 0.143783, Val Loss: 0.130234
2025-09-02 03:04:52,873 - INFO - Epoch 1353/5000 - Train Loss: 0.143403, Val Loss: 0.128010
2025-09-02 03:05:18,496 - INFO - Epoch 1354/5000 - Train Loss: 0.141921, Val Loss: 0.125394
2025-09-02 03:05:18,516 - INFO - New best model saved with Val Loss: 0.125394
2025-09-02 03:05:44,214 - INFO - Epoch 1355/5000 - Train Loss: 0.143087, Val Loss: 0.127350
2025-09-02 03:06:09,949 - INFO - Epoch 1356/5000 - Train Loss: 0.141541, Val Loss: 0.132526
2025-09-02 03:06:35,341 - INFO - Epoch 1357/5000 - Train Loss: 0.143324, Val Loss: 0.130435
2025-09-02 03:07:01,039 - INFO - Epoch 1358/5000 - Train Loss: 0.141472, Val Loss: 0.126168
2025-09-02 03:07:26,718 - INFO - Epoch 1359/5000 - Train Loss: 0.142367, Val Loss: 0.125172
2025-09-02 03:07:26,738 - INFO - New best model saved with Val Loss: 0.125172
2025-09-02 03:07:52,471 - INFO - Epoch 1360/5000 - Train Loss: 0.141149, Val Loss: 0.127752
2025-09-02 03:08:18,187 - INFO - Epoch 1361/5000 - Train Loss: 0.142484, Val Loss: 0.127441
2025-09-02 03:08:43,834 - INFO - Epoch 1362/5000 - Train Loss: 0.145337, Val Loss: 0.130200
2025-09-02 03:09:09,501 - INFO - Epoch 1363/5000 - Train Loss: 0.143199, Val Loss: 0.125564
2025-09-02 03:09:35,027 - INFO - Epoch 1364/5000 - Train Loss: 0.141084, Val Loss: 0.129852
2025-09-02 03:10:00,500 - INFO - Epoch 1365/5000 - Train Loss: 0.144069, Val Loss: 0.128155
2025-09-02 03:10:26,211 - INFO - Epoch 1366/5000 - Train Loss: 0.141525, Val Loss: 0.126256
2025-09-02 03:10:51,878 - INFO - Epoch 1367/5000 - Train Loss: 0.142027, Val Loss: 0.126619
2025-09-02 03:11:17,565 - INFO - Epoch 1368/5000 - Train Loss: 0.140113, Val Loss: 0.127332
2025-09-02 03:11:43,236 - INFO - Epoch 1369/5000 - Train Loss: 0.141202, Val Loss: 0.130290
2025-09-02 03:12:09,038 - INFO - Epoch 1370/5000 - Train Loss: 0.143496, Val Loss: 0.129135
2025-09-02 03:12:34,876 - INFO - Epoch 1371/5000 - Train Loss: 0.143833, Val Loss: 0.130157
2025-09-02 03:13:00,695 - INFO - Epoch 1372/5000 - Train Loss: 0.140834, Val Loss: 0.125202
2025-09-02 03:13:26,132 - INFO - Epoch 1373/5000 - Train Loss: 0.140199, Val Loss: 0.126880
2025-09-02 03:13:51,861 - INFO - Epoch 1374/5000 - Train Loss: 0.141392, Val Loss: 0.127978
2025-09-02 03:14:17,367 - INFO - Epoch 1375/5000 - Train Loss: 0.140896, Val Loss: 0.126067
2025-09-02 03:14:42,823 - INFO - Epoch 1376/5000 - Train Loss: 0.144227, Val Loss: 0.132588
2025-09-02 03:15:08,378 - INFO - Epoch 1377/5000 - Train Loss: 0.141380, Val Loss: 0.129807
2025-09-02 03:15:33,896 - INFO - Epoch 1378/5000 - Train Loss: 0.142686, Val Loss: 0.123244
2025-09-02 03:15:33,917 - INFO - New best model saved with Val Loss: 0.123244
2025-09-02 03:15:59,588 - INFO - Epoch 1379/5000 - Train Loss: 0.140546, Val Loss: 0.126127
2025-09-02 03:16:25,212 - INFO - Epoch 1380/5000 - Train Loss: 0.139070, Val Loss: 0.127570
2025-09-02 03:16:51,404 - INFO - Epoch 1381/5000 - Train Loss: 0.140061, Val Loss: 0.125343
2025-09-02 03:17:17,110 - INFO - Epoch 1382/5000 - Train Loss: 0.141078, Val Loss: 0.123828
2025-09-02 03:17:42,753 - INFO - Epoch 1383/5000 - Train Loss: 0.139792, Val Loss: 0.125274
2025-09-02 03:18:08,254 - INFO - Epoch 1384/5000 - Train Loss: 0.140424, Val Loss: 0.125929
2025-09-02 03:18:33,943 - INFO - Epoch 1385/5000 - Train Loss: 0.139677, Val Loss: 0.122552
2025-09-02 03:18:33,963 - INFO - New best model saved with Val Loss: 0.122552
2025-09-02 03:18:59,448 - INFO - Epoch 1386/5000 - Train Loss: 0.140274, Val Loss: 0.133361
2025-09-02 03:19:24,895 - INFO - Epoch 1387/5000 - Train Loss: 0.141410, Val Loss: 0.125757
2025-09-02 03:19:50,415 - INFO - Epoch 1388/5000 - Train Loss: 0.139474, Val Loss: 0.125164
2025-09-02 03:20:15,855 - INFO - Epoch 1389/5000 - Train Loss: 0.140636, Val Loss: 0.123881
2025-09-02 03:20:41,704 - INFO - Epoch 1390/5000 - Train Loss: 0.140630, Val Loss: 0.123395
2025-09-02 03:21:07,592 - INFO - Epoch 1391/5000 - Train Loss: 0.142084, Val Loss: 0.128280
2025-09-02 03:21:33,213 - INFO - Epoch 1392/5000 - Train Loss: 0.139903, Val Loss: 0.123952
2025-09-02 03:21:59,061 - INFO - Epoch 1393/5000 - Train Loss: 0.138853, Val Loss: 0.124699
2025-09-02 03:22:24,936 - INFO - Epoch 1394/5000 - Train Loss: 0.141094, Val Loss: 0.122449
2025-09-02 03:22:24,956 - INFO - New best model saved with Val Loss: 0.122449
2025-09-02 03:22:50,745 - INFO - Epoch 1395/5000 - Train Loss: 0.139666, Val Loss: 0.124089
2025-09-02 03:23:16,321 - INFO - Epoch 1396/5000 - Train Loss: 0.138660, Val Loss: 0.125340
2025-09-02 03:23:41,969 - INFO - Epoch 1397/5000 - Train Loss: 0.142424, Val Loss: 0.131069
2025-09-02 03:24:07,584 - INFO - Epoch 1398/5000 - Train Loss: 0.141007, Val Loss: 0.124589
2025-09-02 03:24:33,113 - INFO - Epoch 1399/5000 - Train Loss: 0.139324, Val Loss: 0.128920
2025-09-02 03:24:58,842 - INFO - Epoch 1400/5000 - Train Loss: 0.138255, Val Loss: 0.124233
2025-09-02 03:25:24,850 - INFO - Epoch 1401/5000 - Train Loss: 0.139807, Val Loss: 0.123842
2025-09-02 03:25:50,582 - INFO - Epoch 1402/5000 - Train Loss: 0.139188, Val Loss: 0.123650
2025-09-02 03:26:16,338 - INFO - Epoch 1403/5000 - Train Loss: 0.138729, Val Loss: 0.126999
2025-09-02 03:26:42,000 - INFO - Epoch 1404/5000 - Train Loss: 0.137983, Val Loss: 0.122707
2025-09-02 03:27:07,678 - INFO - Epoch 1405/5000 - Train Loss: 0.138971, Val Loss: 0.121643
2025-09-02 03:27:07,698 - INFO - New best model saved with Val Loss: 0.121643
2025-09-02 03:27:33,279 - INFO - Epoch 1406/5000 - Train Loss: 0.139037, Val Loss: 0.122143
2025-09-02 03:27:58,759 - INFO - Epoch 1407/5000 - Train Loss: 0.137836, Val Loss: 0.120659
2025-09-02 03:27:58,779 - INFO - New best model saved with Val Loss: 0.120659
2025-09-02 03:28:24,641 - INFO - Epoch 1408/5000 - Train Loss: 0.137732, Val Loss: 0.126560
2025-09-02 03:28:50,004 - INFO - Epoch 1409/5000 - Train Loss: 0.139051, Val Loss: 0.125622
2025-09-02 03:29:15,523 - INFO - Epoch 1410/5000 - Train Loss: 0.138502, Val Loss: 0.123872
2025-09-02 03:29:41,354 - INFO - Epoch 1411/5000 - Train Loss: 0.138195, Val Loss: 0.128541
2025-09-02 03:30:06,908 - INFO - Epoch 1412/5000 - Train Loss: 0.138684, Val Loss: 0.121966
2025-09-02 03:30:32,657 - INFO - Epoch 1413/5000 - Train Loss: 0.137682, Val Loss: 0.125226
2025-09-02 03:30:58,243 - INFO - Epoch 1414/5000 - Train Loss: 0.137952, Val Loss: 0.121745
2025-09-02 03:31:23,765 - INFO - Epoch 1415/5000 - Train Loss: 0.138656, Val Loss: 0.122317
2025-09-02 03:31:49,374 - INFO - Epoch 1416/5000 - Train Loss: 0.137016, Val Loss: 0.121127
2025-09-02 03:32:15,283 - INFO - Epoch 1417/5000 - Train Loss: 0.139347, Val Loss: 0.133922
2025-09-02 03:32:41,014 - INFO - Epoch 1418/5000 - Train Loss: 0.138511, Val Loss: 0.120826
2025-09-02 03:33:06,743 - INFO - Epoch 1419/5000 - Train Loss: 0.136553, Val Loss: 0.126345
2025-09-02 03:33:32,303 - INFO - Epoch 1420/5000 - Train Loss: 0.139207, Val Loss: 0.126509
2025-09-02 03:33:58,080 - INFO - Epoch 1421/5000 - Train Loss: 0.139898, Val Loss: 0.123880
2025-09-02 03:34:23,613 - INFO - Epoch 1422/5000 - Train Loss: 0.137796, Val Loss: 0.123576
2025-09-02 03:34:49,268 - INFO - Epoch 1423/5000 - Train Loss: 0.138237, Val Loss: 0.123385
2025-09-02 03:35:15,144 - INFO - Epoch 1424/5000 - Train Loss: 0.137034, Val Loss: 0.123397
2025-09-02 03:35:40,634 - INFO - Epoch 1425/5000 - Train Loss: 0.137607, Val Loss: 0.121876
2025-09-02 03:36:06,161 - INFO - Epoch 1426/5000 - Train Loss: 0.138097, Val Loss: 0.123066
2025-09-02 03:36:31,775 - INFO - Epoch 1427/5000 - Train Loss: 0.138530, Val Loss: 0.123354
2025-09-02 03:36:57,546 - INFO - Epoch 1428/5000 - Train Loss: 0.137874, Val Loss: 0.120869
2025-09-02 03:37:23,073 - INFO - Epoch 1429/5000 - Train Loss: 0.135355, Val Loss: 0.121361
2025-09-02 03:37:48,509 - INFO - Epoch 1430/5000 - Train Loss: 0.137013, Val Loss: 0.122255
2025-09-02 03:38:14,355 - INFO - Epoch 1431/5000 - Train Loss: 0.137285, Val Loss: 0.121137
2025-09-02 03:38:39,902 - INFO - Epoch 1432/5000 - Train Loss: 0.137648, Val Loss: 0.124814
2025-09-02 03:39:05,677 - INFO - Epoch 1433/5000 - Train Loss: 0.135390, Val Loss: 0.120125
2025-09-02 03:39:05,698 - INFO - New best model saved with Val Loss: 0.120125
2025-09-02 03:39:31,277 - INFO - Epoch 1434/5000 - Train Loss: 0.136519, Val Loss: 0.125801
2025-09-02 03:39:56,869 - INFO - Epoch 1435/5000 - Train Loss: 0.136524, Val Loss: 0.122326
2025-09-02 03:40:22,693 - INFO - Epoch 1436/5000 - Train Loss: 0.136450, Val Loss: 0.122537
2025-09-02 03:40:48,397 - INFO - Epoch 1437/5000 - Train Loss: 0.136529, Val Loss: 0.120835
2025-09-02 03:41:14,031 - INFO - Epoch 1438/5000 - Train Loss: 0.138849, Val Loss: 0.119083
2025-09-02 03:41:14,052 - INFO - New best model saved with Val Loss: 0.119083
2025-09-02 03:41:39,719 - INFO - Epoch 1439/5000 - Train Loss: 0.137543, Val Loss: 0.123474
2025-09-02 03:42:05,593 - INFO - Epoch 1440/5000 - Train Loss: 0.137365, Val Loss: 0.120178
2025-09-02 03:42:31,378 - INFO - Epoch 1441/5000 - Train Loss: 0.133898, Val Loss: 0.121881
2025-09-02 03:42:57,208 - INFO - Epoch 1442/5000 - Train Loss: 0.136161, Val Loss: 0.119405
2025-09-02 03:43:22,758 - INFO - Epoch 1443/5000 - Train Loss: 0.135765, Val Loss: 0.121935
2025-09-02 03:43:48,441 - INFO - Epoch 1444/5000 - Train Loss: 0.135236, Val Loss: 0.118451
2025-09-02 03:43:48,480 - INFO - New best model saved with Val Loss: 0.118451
2025-09-02 03:44:14,463 - INFO - Epoch 1445/5000 - Train Loss: 0.136513, Val Loss: 0.119656
2025-09-02 03:44:40,057 - INFO - Epoch 1446/5000 - Train Loss: 0.137175, Val Loss: 0.120308
2025-09-02 03:45:05,758 - INFO - Epoch 1447/5000 - Train Loss: 0.135858, Val Loss: 0.119163
2025-09-02 03:45:31,415 - INFO - Epoch 1448/5000 - Train Loss: 0.133880, Val Loss: 0.118891
2025-09-02 03:45:56,803 - INFO - Epoch 1449/5000 - Train Loss: 0.135199, Val Loss: 0.121328
2025-09-02 03:46:22,591 - INFO - Epoch 1450/5000 - Train Loss: 0.135615, Val Loss: 0.122026
2025-09-02 03:46:48,397 - INFO - Epoch 1451/5000 - Train Loss: 0.135851, Val Loss: 0.123951
2025-09-02 03:47:14,114 - INFO - Epoch 1452/5000 - Train Loss: 0.135278, Val Loss: 0.121488
2025-09-02 03:47:39,724 - INFO - Epoch 1453/5000 - Train Loss: 0.137452, Val Loss: 0.127594
2025-09-02 03:48:05,477 - INFO - Epoch 1454/5000 - Train Loss: 0.135153, Val Loss: 0.119191
2025-09-02 03:48:31,242 - INFO - Epoch 1455/5000 - Train Loss: 0.136692, Val Loss: 0.123396
2025-09-02 03:48:56,963 - INFO - Epoch 1456/5000 - Train Loss: 0.137007, Val Loss: 0.119850
2025-09-02 03:49:22,482 - INFO - Epoch 1457/5000 - Train Loss: 0.135123, Val Loss: 0.120808
2025-09-02 03:49:47,878 - INFO - Epoch 1458/5000 - Train Loss: 0.135181, Val Loss: 0.118011
2025-09-02 03:49:47,899 - INFO - New best model saved with Val Loss: 0.118011
2025-09-02 03:50:13,549 - INFO - Epoch 1459/5000 - Train Loss: 0.135594, Val Loss: 0.120150
2025-09-02 03:50:39,440 - INFO - Epoch 1460/5000 - Train Loss: 0.136215, Val Loss: 0.119440
2025-09-02 03:51:05,122 - INFO - Epoch 1461/5000 - Train Loss: 0.134641, Val Loss: 0.119475
2025-09-02 03:51:30,557 - INFO - Epoch 1462/5000 - Train Loss: 0.134013, Val Loss: 0.119197
2025-09-02 03:51:56,161 - INFO - Epoch 1463/5000 - Train Loss: 0.134182, Val Loss: 0.118451
2025-09-02 03:52:21,787 - INFO - Epoch 1464/5000 - Train Loss: 0.133994, Val Loss: 0.121752
2025-09-02 03:52:47,559 - INFO - Epoch 1465/5000 - Train Loss: 0.133744, Val Loss: 0.117131
2025-09-02 03:52:47,599 - INFO - New best model saved with Val Loss: 0.117131
2025-09-02 03:53:13,345 - INFO - Epoch 1466/5000 - Train Loss: 0.135858, Val Loss: 0.120277
2025-09-02 03:53:39,193 - INFO - Epoch 1467/5000 - Train Loss: 0.134180, Val Loss: 0.119086
2025-09-02 03:54:04,990 - INFO - Epoch 1468/5000 - Train Loss: 0.133324, Val Loss: 0.120564
2025-09-02 03:54:30,273 - INFO - Epoch 1469/5000 - Train Loss: 0.134609, Val Loss: 0.123509
2025-09-02 03:54:56,096 - INFO - Epoch 1470/5000 - Train Loss: 0.135405, Val Loss: 0.120457
2025-09-02 03:55:21,706 - INFO - Epoch 1471/5000 - Train Loss: 0.133969, Val Loss: 0.118073
2025-09-02 03:55:47,464 - INFO - Epoch 1472/5000 - Train Loss: 0.134750, Val Loss: 0.121895
2025-09-02 03:56:13,142 - INFO - Epoch 1473/5000 - Train Loss: 0.136251, Val Loss: 0.121493
2025-09-02 03:56:38,680 - INFO - Epoch 1474/5000 - Train Loss: 0.133466, Val Loss: 0.116167
2025-09-02 03:56:38,700 - INFO - New best model saved with Val Loss: 0.116167
2025-09-02 03:57:04,457 - INFO - Epoch 1475/5000 - Train Loss: 0.134104, Val Loss: 0.121852
2025-09-02 03:57:30,125 - INFO - Epoch 1476/5000 - Train Loss: 0.133316, Val Loss: 0.115521
2025-09-02 03:57:30,145 - INFO - New best model saved with Val Loss: 0.115521
2025-09-02 03:57:55,764 - INFO - Epoch 1477/5000 - Train Loss: 0.133434, Val Loss: 0.118192
2025-09-02 03:58:21,290 - INFO - Epoch 1478/5000 - Train Loss: 0.133755, Val Loss: 0.121747
2025-09-02 03:58:47,079 - INFO - Epoch 1479/5000 - Train Loss: 0.134874, Val Loss: 0.117082
2025-09-02 03:59:12,903 - INFO - Epoch 1480/5000 - Train Loss: 0.132421, Val Loss: 0.116390
2025-09-02 03:59:38,770 - INFO - Epoch 1481/5000 - Train Loss: 0.133027, Val Loss: 0.116170
2025-09-02 04:00:04,538 - INFO - Epoch 1482/5000 - Train Loss: 0.132978, Val Loss: 0.116299
2025-09-02 04:00:30,618 - INFO - Epoch 1483/5000 - Train Loss: 0.132665, Val Loss: 0.116718
2025-09-02 04:00:56,347 - INFO - Epoch 1484/5000 - Train Loss: 0.132814, Val Loss: 0.121525
2025-09-02 04:01:21,822 - INFO - Epoch 1485/5000 - Train Loss: 0.132600, Val Loss: 0.117392
2025-09-02 04:01:47,433 - INFO - Epoch 1486/5000 - Train Loss: 0.133390, Val Loss: 0.116826
2025-09-02 04:02:13,145 - INFO - Epoch 1487/5000 - Train Loss: 0.131395, Val Loss: 0.116390
2025-09-02 04:02:39,086 - INFO - Epoch 1488/5000 - Train Loss: 0.133026, Val Loss: 0.118254
2025-09-02 04:03:04,268 - INFO - Epoch 1489/5000 - Train Loss: 0.134081, Val Loss: 0.119053
2025-09-02 04:03:30,026 - INFO - Epoch 1490/5000 - Train Loss: 0.132415, Val Loss: 0.116475
2025-09-02 04:03:55,481 - INFO - Epoch 1491/5000 - Train Loss: 0.131633, Val Loss: 0.118237
2025-09-02 04:04:21,233 - INFO - Epoch 1492/5000 - Train Loss: 0.133230, Val Loss: 0.122946
2025-09-02 04:04:46,851 - INFO - Epoch 1493/5000 - Train Loss: 0.133777, Val Loss: 0.117259
2025-09-02 04:05:12,516 - INFO - Epoch 1494/5000 - Train Loss: 0.134559, Val Loss: 0.115780
2025-09-02 04:05:38,385 - INFO - Epoch 1495/5000 - Train Loss: 0.131917, Val Loss: 0.118639
2025-09-02 04:06:04,089 - INFO - Epoch 1496/5000 - Train Loss: 0.132590, Val Loss: 0.115575
2025-09-02 04:06:29,797 - INFO - Epoch 1497/5000 - Train Loss: 0.131021, Val Loss: 0.114663
2025-09-02 04:06:29,818 - INFO - New best model saved with Val Loss: 0.114663
2025-09-02 04:06:55,788 - INFO - Epoch 1498/5000 - Train Loss: 0.131680, Val Loss: 0.117526
2025-09-02 04:07:21,382 - INFO - Epoch 1499/5000 - Train Loss: 0.132158, Val Loss: 0.116247
2025-09-02 04:07:47,049 - INFO - Epoch 1500/5000 - Train Loss: 0.131733, Val Loss: 0.115062
2025-09-02 04:08:12,916 - INFO - Epoch 1501/5000 - Train Loss: 0.132007, Val Loss: 0.114341
2025-09-02 04:08:12,935 - INFO - New best model saved with Val Loss: 0.114341
2025-09-02 04:08:38,644 - INFO - Epoch 1502/5000 - Train Loss: 0.130890, Val Loss: 0.115701
2025-09-02 04:09:04,195 - INFO - Epoch 1503/5000 - Train Loss: 0.132249, Val Loss: 0.117945
2025-09-02 04:09:29,823 - INFO - Epoch 1504/5000 - Train Loss: 0.131665, Val Loss: 0.116033
2025-09-02 04:09:55,604 - INFO - Epoch 1505/5000 - Train Loss: 0.132265, Val Loss: 0.117852
2025-09-02 04:10:21,419 - INFO - Epoch 1506/5000 - Train Loss: 0.133850, Val Loss: 0.122007
2025-09-02 04:10:47,173 - INFO - Epoch 1507/5000 - Train Loss: 0.133429, Val Loss: 0.115793
2025-09-02 04:11:12,824 - INFO - Epoch 1508/5000 - Train Loss: 0.130626, Val Loss: 0.117467
2025-09-02 04:11:38,870 - INFO - Epoch 1509/5000 - Train Loss: 0.130864, Val Loss: 0.112652
2025-09-02 04:11:38,891 - INFO - New best model saved with Val Loss: 0.112652
2025-09-02 04:12:04,669 - INFO - Epoch 1510/5000 - Train Loss: 0.132512, Val Loss: 0.117053
2025-09-02 04:12:30,509 - INFO - Epoch 1511/5000 - Train Loss: 0.131889, Val Loss: 0.117380
2025-09-02 04:12:56,272 - INFO - Epoch 1512/5000 - Train Loss: 0.131503, Val Loss: 0.115102
2025-09-02 04:13:21,837 - INFO - Epoch 1513/5000 - Train Loss: 0.131170, Val Loss: 0.114002
2025-09-02 04:13:47,491 - INFO - Epoch 1514/5000 - Train Loss: 0.132312, Val Loss: 0.125281
2025-09-02 04:14:13,115 - INFO - Epoch 1515/5000 - Train Loss: 0.132944, Val Loss: 0.111840
2025-09-02 04:14:13,134 - INFO - New best model saved with Val Loss: 0.111840
2025-09-02 04:14:38,732 - INFO - Epoch 1516/5000 - Train Loss: 0.130567, Val Loss: 0.115161
2025-09-02 04:15:04,409 - INFO - Epoch 1517/5000 - Train Loss: 0.131245, Val Loss: 0.115463
2025-09-02 04:15:29,822 - INFO - Epoch 1518/5000 - Train Loss: 0.130986, Val Loss: 0.113784
2025-09-02 04:15:55,586 - INFO - Epoch 1519/5000 - Train Loss: 0.130601, Val Loss: 0.115070
2025-09-02 04:16:21,179 - INFO - Epoch 1520/5000 - Train Loss: 0.130908, Val Loss: 0.115884
2025-09-02 04:16:46,992 - INFO - Epoch 1521/5000 - Train Loss: 0.133084, Val Loss: 0.116060
2025-09-02 04:17:12,596 - INFO - Epoch 1522/5000 - Train Loss: 0.132456, Val Loss: 0.114570
2025-09-02 04:17:38,109 - INFO - Epoch 1523/5000 - Train Loss: 0.130218, Val Loss: 0.117536
2025-09-02 04:18:03,741 - INFO - Epoch 1524/5000 - Train Loss: 0.131242, Val Loss: 0.118211
2025-09-02 04:18:29,379 - INFO - Epoch 1525/5000 - Train Loss: 0.132746, Val Loss: 0.116790
2025-09-02 04:18:55,132 - INFO - Epoch 1526/5000 - Train Loss: 0.129923, Val Loss: 0.112934
2025-09-02 04:19:20,584 - INFO - Epoch 1527/5000 - Train Loss: 0.129670, Val Loss: 0.115917
2025-09-02 04:19:46,282 - INFO - Epoch 1528/5000 - Train Loss: 0.131199, Val Loss: 0.115960
2025-09-02 04:20:11,990 - INFO - Epoch 1529/5000 - Train Loss: 0.130223, Val Loss: 0.116707
2025-09-02 04:20:37,637 - INFO - Epoch 1530/5000 - Train Loss: 0.129494, Val Loss: 0.114909
2025-09-02 04:21:03,324 - INFO - Epoch 1531/5000 - Train Loss: 0.129365, Val Loss: 0.114875
2025-09-02 04:21:29,147 - INFO - Epoch 1532/5000 - Train Loss: 0.128144, Val Loss: 0.111029
2025-09-02 04:21:29,167 - INFO - New best model saved with Val Loss: 0.111029
2025-09-02 04:21:55,133 - INFO - Epoch 1533/5000 - Train Loss: 0.129007, Val Loss: 0.114359
2025-09-02 04:22:20,823 - INFO - Epoch 1534/5000 - Train Loss: 0.129030, Val Loss: 0.118530
2025-09-02 04:22:46,696 - INFO - Epoch 1535/5000 - Train Loss: 0.129314, Val Loss: 0.114099
2025-09-02 04:23:12,585 - INFO - Epoch 1536/5000 - Train Loss: 0.130356, Val Loss: 0.119115
2025-09-02 04:23:38,404 - INFO - Epoch 1537/5000 - Train Loss: 0.129527, Val Loss: 0.113915
2025-09-02 04:24:03,808 - INFO - Epoch 1538/5000 - Train Loss: 0.130742, Val Loss: 0.114830
2025-09-02 04:24:29,613 - INFO - Epoch 1539/5000 - Train Loss: 0.130600, Val Loss: 0.117558
2025-09-02 04:24:55,021 - INFO - Epoch 1540/5000 - Train Loss: 0.130142, Val Loss: 0.115643
2025-09-02 04:25:20,815 - INFO - Epoch 1541/5000 - Train Loss: 0.129691, Val Loss: 0.114678
2025-09-02 04:25:46,637 - INFO - Epoch 1542/5000 - Train Loss: 0.129979, Val Loss: 0.114207
2025-09-02 04:26:12,013 - INFO - Epoch 1543/5000 - Train Loss: 0.129211, Val Loss: 0.115304
2025-09-02 04:26:37,446 - INFO - Epoch 1544/5000 - Train Loss: 0.128546, Val Loss: 0.114086
2025-09-02 04:27:03,251 - INFO - Epoch 1545/5000 - Train Loss: 0.128342, Val Loss: 0.113043
2025-09-02 04:27:28,610 - INFO - Epoch 1546/5000 - Train Loss: 0.128878, Val Loss: 0.117016
2025-09-02 04:27:54,257 - INFO - Epoch 1547/5000 - Train Loss: 0.128905, Val Loss: 0.113313
2025-09-02 04:28:19,771 - INFO - Epoch 1548/5000 - Train Loss: 0.129293, Val Loss: 0.113850
2025-09-02 04:28:45,783 - INFO - Epoch 1549/5000 - Train Loss: 0.129246, Val Loss: 0.113590
2025-09-02 04:29:11,421 - INFO - Epoch 1550/5000 - Train Loss: 0.128380, Val Loss: 0.116436
2025-09-02 04:29:37,408 - INFO - Epoch 1551/5000 - Train Loss: 0.129156, Val Loss: 0.109482
2025-09-02 04:29:37,440 - INFO - New best model saved with Val Loss: 0.109482
2025-09-02 04:30:02,961 - INFO - Epoch 1552/5000 - Train Loss: 0.128070, Val Loss: 0.111404
2025-09-02 04:30:28,585 - INFO - Epoch 1553/5000 - Train Loss: 0.127381, Val Loss: 0.112437
2025-09-02 04:30:54,070 - INFO - Epoch 1554/5000 - Train Loss: 0.126654, Val Loss: 0.114762
2025-09-02 04:31:19,566 - INFO - Epoch 1555/5000 - Train Loss: 0.129082, Val Loss: 0.117030
2025-09-02 04:31:45,438 - INFO - Epoch 1556/5000 - Train Loss: 0.129948, Val Loss: 0.115697
2025-09-02 04:32:11,244 - INFO - Epoch 1557/5000 - Train Loss: 0.127498, Val Loss: 0.110960
2025-09-02 04:32:36,977 - INFO - Epoch 1558/5000 - Train Loss: 0.128118, Val Loss: 0.112040
2025-09-02 04:33:02,613 - INFO - Epoch 1559/5000 - Train Loss: 0.126762, Val Loss: 0.112414
2025-09-02 04:33:28,473 - INFO - Epoch 1560/5000 - Train Loss: 0.126848, Val Loss: 0.114606
2025-09-02 04:33:54,269 - INFO - Epoch 1561/5000 - Train Loss: 0.126121, Val Loss: 0.111765
2025-09-02 04:34:19,816 - INFO - Epoch 1562/5000 - Train Loss: 0.127135, Val Loss: 0.111075
2025-09-02 04:34:45,522 - INFO - Epoch 1563/5000 - Train Loss: 0.127597, Val Loss: 0.111166
2025-09-02 04:35:11,315 - INFO - Epoch 1564/5000 - Train Loss: 0.127434, Val Loss: 0.110485
2025-09-02 04:35:37,093 - INFO - Epoch 1565/5000 - Train Loss: 0.128314, Val Loss: 0.110680
2025-09-02 04:36:02,680 - INFO - Epoch 1566/5000 - Train Loss: 0.127217, Val Loss: 0.115390
2025-09-02 04:36:28,224 - INFO - Epoch 1567/5000 - Train Loss: 0.127055, Val Loss: 0.113188
2025-09-02 04:36:53,931 - INFO - Epoch 1568/5000 - Train Loss: 0.126544, Val Loss: 0.109999
2025-09-02 04:37:19,647 - INFO - Epoch 1569/5000 - Train Loss: 0.126168, Val Loss: 0.112767
2025-09-02 04:37:45,263 - INFO - Epoch 1570/5000 - Train Loss: 0.126787, Val Loss: 0.109630
2025-09-02 04:38:11,176 - INFO - Epoch 1571/5000 - Train Loss: 0.125914, Val Loss: 0.111994
2025-09-02 04:38:36,943 - INFO - Epoch 1572/5000 - Train Loss: 0.126399, Val Loss: 0.110277
2025-09-02 04:39:02,465 - INFO - Epoch 1573/5000 - Train Loss: 0.126472, Val Loss: 0.110357
2025-09-02 04:39:28,264 - INFO - Epoch 1574/5000 - Train Loss: 0.126497, Val Loss: 0.113544
2025-09-02 04:39:53,957 - INFO - Epoch 1575/5000 - Train Loss: 0.128204, Val Loss: 0.111074
2025-09-02 04:40:19,694 - INFO - Epoch 1576/5000 - Train Loss: 0.126270, Val Loss: 0.111518
2025-09-02 04:40:45,343 - INFO - Epoch 1577/5000 - Train Loss: 0.128539, Val Loss: 0.112562
2025-09-02 04:41:10,920 - INFO - Epoch 1578/5000 - Train Loss: 0.125709, Val Loss: 0.110254
2025-09-02 04:41:36,687 - INFO - Epoch 1579/5000 - Train Loss: 0.125215, Val Loss: 0.115051
2025-09-02 04:42:02,164 - INFO - Epoch 1580/5000 - Train Loss: 0.126502, Val Loss: 0.115484
2025-09-02 04:42:27,899 - INFO - Epoch 1581/5000 - Train Loss: 0.127507, Val Loss: 0.110699
2025-09-02 04:42:53,530 - INFO - Epoch 1582/5000 - Train Loss: 0.126898, Val Loss: 0.111114
2025-09-02 04:43:19,270 - INFO - Epoch 1583/5000 - Train Loss: 0.125808, Val Loss: 0.111920
2025-09-02 04:43:45,026 - INFO - Epoch 1584/5000 - Train Loss: 0.127261, Val Loss: 0.113864
2025-09-02 04:44:10,634 - INFO - Epoch 1585/5000 - Train Loss: 0.126459, Val Loss: 0.110984
2025-09-02 04:44:36,234 - INFO - Epoch 1586/5000 - Train Loss: 0.125391, Val Loss: 0.108548
2025-09-02 04:44:36,256 - INFO - New best model saved with Val Loss: 0.108548
2025-09-02 04:45:02,217 - INFO - Epoch 1587/5000 - Train Loss: 0.126090, Val Loss: 0.110081
2025-09-02 04:45:28,343 - INFO - Epoch 1588/5000 - Train Loss: 0.124793, Val Loss: 0.111176
2025-09-02 04:45:53,941 - INFO - Epoch 1589/5000 - Train Loss: 0.125661, Val Loss: 0.114262
2025-09-02 04:46:19,505 - INFO - Epoch 1590/5000 - Train Loss: 0.125699, Val Loss: 0.109126
2025-09-02 04:46:45,130 - INFO - Epoch 1591/5000 - Train Loss: 0.125133, Val Loss: 0.109749
2025-09-02 04:47:11,084 - INFO - Epoch 1592/5000 - Train Loss: 0.124792, Val Loss: 0.108544
2025-09-02 04:47:11,105 - INFO - New best model saved with Val Loss: 0.108544
2025-09-02 04:47:36,843 - INFO - Epoch 1593/5000 - Train Loss: 0.124831, Val Loss: 0.110157
2025-09-02 04:48:02,303 - INFO - Epoch 1594/5000 - Train Loss: 0.125387, Val Loss: 0.111120
2025-09-02 04:48:27,908 - INFO - Epoch 1595/5000 - Train Loss: 0.127949, Val Loss: 0.112570
2025-09-02 04:48:53,574 - INFO - Epoch 1596/5000 - Train Loss: 0.129107, Val Loss: 0.110343
2025-09-02 04:49:18,881 - INFO - Epoch 1597/5000 - Train Loss: 0.123538, Val Loss: 0.109958
2025-09-02 04:49:44,205 - INFO - Epoch 1598/5000 - Train Loss: 0.125164, Val Loss: 0.110618
2025-09-02 04:50:09,594 - INFO - Epoch 1599/5000 - Train Loss: 0.125495, Val Loss: 0.107791
2025-09-02 04:50:09,616 - INFO - New best model saved with Val Loss: 0.107791
2025-09-02 04:50:35,144 - INFO - Epoch 1600/5000 - Train Loss: 0.124570, Val Loss: 0.114056
2025-09-02 04:51:00,923 - INFO - Epoch 1601/5000 - Train Loss: 0.123550, Val Loss: 0.109760
2025-09-02 04:51:26,746 - INFO - Epoch 1602/5000 - Train Loss: 0.124320, Val Loss: 0.109975
2025-09-02 04:51:52,578 - INFO - Epoch 1603/5000 - Train Loss: 0.126111, Val Loss: 0.109791
2025-09-02 04:52:18,292 - INFO - Epoch 1604/5000 - Train Loss: 0.126392, Val Loss: 0.110032
2025-09-02 04:52:44,195 - INFO - Epoch 1605/5000 - Train Loss: 0.124197, Val Loss: 0.108759
2025-09-02 04:53:09,932 - INFO - Epoch 1606/5000 - Train Loss: 0.123902, Val Loss: 0.106470
2025-09-02 04:53:09,952 - INFO - New best model saved with Val Loss: 0.106470
2025-09-02 04:53:35,436 - INFO - Epoch 1607/5000 - Train Loss: 0.125163, Val Loss: 0.108981
2025-09-02 04:54:01,154 - INFO - Epoch 1608/5000 - Train Loss: 0.122932, Val Loss: 0.110420
2025-09-02 04:54:26,929 - INFO - Epoch 1609/5000 - Train Loss: 0.121496, Val Loss: 0.105844
2025-09-02 04:54:26,950 - INFO - New best model saved with Val Loss: 0.105844
2025-09-02 04:54:52,722 - INFO - Epoch 1610/5000 - Train Loss: 0.124123, Val Loss: 0.107266
2025-09-02 04:55:18,515 - INFO - Epoch 1611/5000 - Train Loss: 0.124765, Val Loss: 0.109994
2025-09-02 04:55:44,072 - INFO - Epoch 1612/5000 - Train Loss: 0.124436, Val Loss: 0.108995
2025-09-02 04:56:09,880 - INFO - Epoch 1613/5000 - Train Loss: 0.124512, Val Loss: 0.109830
2025-09-02 04:56:35,151 - INFO - Epoch 1614/5000 - Train Loss: 0.124384, Val Loss: 0.107023
2025-09-02 04:57:00,687 - INFO - Epoch 1615/5000 - Train Loss: 0.125592, Val Loss: 0.106210
2025-09-02 04:57:26,350 - INFO - Epoch 1616/5000 - Train Loss: 0.124018, Val Loss: 0.109297
2025-09-02 04:57:51,887 - INFO - Epoch 1617/5000 - Train Loss: 0.124763, Val Loss: 0.109845
2025-09-02 04:58:17,234 - INFO - Epoch 1618/5000 - Train Loss: 0.125299, Val Loss: 0.110143
2025-09-02 04:58:42,843 - INFO - Epoch 1619/5000 - Train Loss: 0.123286, Val Loss: 0.105929
2025-09-02 04:59:08,561 - INFO - Epoch 1620/5000 - Train Loss: 0.122704, Val Loss: 0.108311
2025-09-02 04:59:34,462 - INFO - Epoch 1621/5000 - Train Loss: 0.122264, Val Loss: 0.108856
2025-09-02 05:00:00,358 - INFO - Epoch 1622/5000 - Train Loss: 0.123502, Val Loss: 0.107366
2025-09-02 05:00:25,684 - INFO - Epoch 1623/5000 - Train Loss: 0.123167, Val Loss: 0.108499
2025-09-02 05:00:51,415 - INFO - Epoch 1624/5000 - Train Loss: 0.124067, Val Loss: 0.107991
2025-09-02 05:01:17,127 - INFO - Epoch 1625/5000 - Train Loss: 0.121569, Val Loss: 0.104889
2025-09-02 05:01:17,148 - INFO - New best model saved with Val Loss: 0.104889
2025-09-02 05:01:42,663 - INFO - Epoch 1626/5000 - Train Loss: 0.121654, Val Loss: 0.106088
2025-09-02 05:02:08,082 - INFO - Epoch 1627/5000 - Train Loss: 0.121397, Val Loss: 0.106206
2025-09-02 05:02:33,450 - INFO - Epoch 1628/5000 - Train Loss: 0.122295, Val Loss: 0.103426
2025-09-02 05:02:33,470 - INFO - New best model saved with Val Loss: 0.103426
2025-09-02 05:02:59,238 - INFO - Epoch 1629/5000 - Train Loss: 0.124029, Val Loss: 0.111224
2025-09-02 05:03:24,784 - INFO - Epoch 1630/5000 - Train Loss: 0.122885, Val Loss: 0.106169
2025-09-02 05:03:50,757 - INFO - Epoch 1631/5000 - Train Loss: 0.122591, Val Loss: 0.105256
2025-09-02 05:04:16,245 - INFO - Epoch 1632/5000 - Train Loss: 0.122884, Val Loss: 0.107246
2025-09-02 05:04:41,767 - INFO - Epoch 1633/5000 - Train Loss: 0.122036, Val Loss: 0.107707
2025-09-02 05:05:07,343 - INFO - Epoch 1634/5000 - Train Loss: 0.122031, Val Loss: 0.108432
2025-09-02 05:05:32,801 - INFO - Epoch 1635/5000 - Train Loss: 0.122623, Val Loss: 0.105770
2025-09-02 05:05:58,544 - INFO - Epoch 1636/5000 - Train Loss: 0.123372, Val Loss: 0.111517
2025-09-02 05:06:24,070 - INFO - Epoch 1637/5000 - Train Loss: 0.121672, Val Loss: 0.108735
2025-09-02 05:06:49,810 - INFO - Epoch 1638/5000 - Train Loss: 0.121860, Val Loss: 0.109734
2025-09-02 05:07:15,302 - INFO - Epoch 1639/5000 - Train Loss: 0.123223, Val Loss: 0.106345
2025-09-02 05:07:40,768 - INFO - Epoch 1640/5000 - Train Loss: 0.121052, Val Loss: 0.106612
2025-09-02 05:08:06,229 - INFO - Epoch 1641/5000 - Train Loss: 0.124086, Val Loss: 0.107615
2025-09-02 05:08:31,803 - INFO - Epoch 1642/5000 - Train Loss: 0.121866, Val Loss: 0.109705
2025-09-02 05:08:57,370 - INFO - Epoch 1643/5000 - Train Loss: 0.123908, Val Loss: 0.110111
2025-09-02 05:09:22,990 - INFO - Epoch 1644/5000 - Train Loss: 0.122857, Val Loss: 0.104482
2025-09-02 05:09:48,429 - INFO - Epoch 1645/5000 - Train Loss: 0.121837, Val Loss: 0.109163
2025-09-02 05:10:13,938 - INFO - Epoch 1646/5000 - Train Loss: 0.120780, Val Loss: 0.102378
2025-09-02 05:10:13,958 - INFO - New best model saved with Val Loss: 0.102378
2025-09-02 05:10:39,261 - INFO - Epoch 1647/5000 - Train Loss: 0.120974, Val Loss: 0.105043
2025-09-02 05:11:04,948 - INFO - Epoch 1648/5000 - Train Loss: 0.120967, Val Loss: 0.106445
2025-09-02 05:11:30,514 - INFO - Epoch 1649/5000 - Train Loss: 0.121200, Val Loss: 0.105595
2025-09-02 05:11:56,133 - INFO - Epoch 1650/5000 - Train Loss: 0.121234, Val Loss: 0.107313
2025-09-02 05:12:21,846 - INFO - Epoch 1651/5000 - Train Loss: 0.121759, Val Loss: 0.106005
2025-09-02 05:12:47,453 - INFO - Epoch 1652/5000 - Train Loss: 0.122107, Val Loss: 0.104463
2025-09-02 05:13:13,297 - INFO - Epoch 1653/5000 - Train Loss: 0.120728, Val Loss: 0.102712
2025-09-02 05:13:39,122 - INFO - Epoch 1654/5000 - Train Loss: 0.119906, Val Loss: 0.104839
2025-09-02 05:14:04,832 - INFO - Epoch 1655/5000 - Train Loss: 0.121631, Val Loss: 0.103517
2025-09-02 05:14:30,412 - INFO - Epoch 1656/5000 - Train Loss: 0.121231, Val Loss: 0.103179
2025-09-02 05:14:55,886 - INFO - Epoch 1657/5000 - Train Loss: 0.120894, Val Loss: 0.107831
2025-09-02 05:15:21,457 - INFO - Epoch 1658/5000 - Train Loss: 0.120351, Val Loss: 0.105927
2025-09-02 05:15:46,939 - INFO - Epoch 1659/5000 - Train Loss: 0.119048, Val Loss: 0.106147
2025-09-02 05:16:12,437 - INFO - Epoch 1660/5000 - Train Loss: 0.120365, Val Loss: 0.104877
2025-09-02 05:16:37,822 - INFO - Epoch 1661/5000 - Train Loss: 0.121830, Val Loss: 0.108324
2025-09-02 05:17:03,242 - INFO - Epoch 1662/5000 - Train Loss: 0.121148, Val Loss: 0.105259
2025-09-02 05:17:28,853 - INFO - Epoch 1663/5000 - Train Loss: 0.119891, Val Loss: 0.103390
2025-09-02 05:17:54,276 - INFO - Epoch 1664/5000 - Train Loss: 0.119634, Val Loss: 0.103071
2025-09-02 05:18:19,617 - INFO - Epoch 1665/5000 - Train Loss: 0.120404, Val Loss: 0.105375
2025-09-02 05:18:45,136 - INFO - Epoch 1666/5000 - Train Loss: 0.121573, Val Loss: 0.104180
2025-09-02 05:19:10,789 - INFO - Epoch 1667/5000 - Train Loss: 0.120299, Val Loss: 0.107592
2025-09-02 05:19:36,422 - INFO - Epoch 1668/5000 - Train Loss: 0.120258, Val Loss: 0.103554
2025-09-02 05:20:02,095 - INFO - Epoch 1669/5000 - Train Loss: 0.119951, Val Loss: 0.103528
2025-09-02 05:20:27,494 - INFO - Epoch 1670/5000 - Train Loss: 0.120433, Val Loss: 0.106540
2025-09-02 05:20:53,070 - INFO - Epoch 1671/5000 - Train Loss: 0.120646, Val Loss: 0.104383
2025-09-02 05:21:18,689 - INFO - Epoch 1672/5000 - Train Loss: 0.119635, Val Loss: 0.106319
2025-09-02 05:21:43,888 - INFO - Epoch 1673/5000 - Train Loss: 0.119624, Val Loss: 0.105848
2025-09-02 05:22:09,353 - INFO - Epoch 1674/5000 - Train Loss: 0.118849, Val Loss: 0.105009
2025-09-02 05:22:34,923 - INFO - Epoch 1675/5000 - Train Loss: 0.119558, Val Loss: 0.103778
2025-09-02 05:23:00,189 - INFO - Epoch 1676/5000 - Train Loss: 0.119138, Val Loss: 0.105789
2025-09-02 05:23:25,541 - INFO - Epoch 1677/5000 - Train Loss: 0.120858, Val Loss: 0.105177
2025-09-02 05:23:51,158 - INFO - Epoch 1678/5000 - Train Loss: 0.119246, Val Loss: 0.103978
2025-09-02 05:24:16,521 - INFO - Epoch 1679/5000 - Train Loss: 0.119621, Val Loss: 0.104439
2025-09-02 05:24:42,168 - INFO - Epoch 1680/5000 - Train Loss: 0.119307, Val Loss: 0.106377
2025-09-02 05:25:07,825 - INFO - Epoch 1681/5000 - Train Loss: 0.119345, Val Loss: 0.104093
2025-09-02 05:25:33,363 - INFO - Epoch 1682/5000 - Train Loss: 0.118855, Val Loss: 0.103532
2025-09-02 05:25:58,649 - INFO - Epoch 1683/5000 - Train Loss: 0.119212, Val Loss: 0.103989
2025-09-02 05:26:23,943 - INFO - Epoch 1684/5000 - Train Loss: 0.119403, Val Loss: 0.103093
2025-09-02 05:26:49,191 - INFO - Epoch 1685/5000 - Train Loss: 0.119084, Val Loss: 0.102885
2025-09-02 05:27:14,666 - INFO - Epoch 1686/5000 - Train Loss: 0.119669, Val Loss: 0.102295
2025-09-02 05:27:14,704 - INFO - New best model saved with Val Loss: 0.102295
2025-09-02 05:27:40,504 - INFO - Epoch 1687/5000 - Train Loss: 0.119127, Val Loss: 0.107760
2025-09-02 05:28:05,968 - INFO - Epoch 1688/5000 - Train Loss: 0.119067, Val Loss: 0.101715
2025-09-02 05:28:05,988 - INFO - New best model saved with Val Loss: 0.101715
2025-09-02 05:28:31,518 - INFO - Epoch 1689/5000 - Train Loss: 0.118678, Val Loss: 0.102843
2025-09-02 05:28:57,227 - INFO - Epoch 1690/5000 - Train Loss: 0.120413, Val Loss: 0.102088
2025-09-02 05:29:22,825 - INFO - Epoch 1691/5000 - Train Loss: 0.117122, Val Loss: 0.101371
2025-09-02 05:29:22,862 - INFO - New best model saved with Val Loss: 0.101371
2025-09-02 05:29:48,306 - INFO - Epoch 1692/5000 - Train Loss: 0.118567, Val Loss: 0.104958
2025-09-02 05:30:13,572 - INFO - Epoch 1693/5000 - Train Loss: 0.119760, Val Loss: 0.107534
2025-09-02 05:30:39,256 - INFO - Epoch 1694/5000 - Train Loss: 0.118838, Val Loss: 0.103091
2025-09-02 05:31:05,033 - INFO - Epoch 1695/5000 - Train Loss: 0.119628, Val Loss: 0.103398
2025-09-02 05:31:30,385 - INFO - Epoch 1696/5000 - Train Loss: 0.118152, Val Loss: 0.103506
2025-09-02 05:31:56,321 - INFO - Epoch 1697/5000 - Train Loss: 0.117794, Val Loss: 0.104687
2025-09-02 05:32:21,884 - INFO - Epoch 1698/5000 - Train Loss: 0.119266, Val Loss: 0.102744
2025-09-02 05:32:47,652 - INFO - Epoch 1699/5000 - Train Loss: 0.120249, Val Loss: 0.102895
2025-09-02 05:33:13,419 - INFO - Epoch 1700/5000 - Train Loss: 0.117341, Val Loss: 0.102596
2025-09-02 05:33:39,004 - INFO - Epoch 1701/5000 - Train Loss: 0.118472, Val Loss: 0.101410
2025-09-02 05:34:04,637 - INFO - Epoch 1702/5000 - Train Loss: 0.118737, Val Loss: 0.102403
2025-09-02 05:34:30,101 - INFO - Epoch 1703/5000 - Train Loss: 0.119291, Val Loss: 0.102499
2025-09-02 05:34:55,632 - INFO - Epoch 1704/5000 - Train Loss: 0.117547, Val Loss: 0.102752
2025-09-02 05:35:21,005 - INFO - Epoch 1705/5000 - Train Loss: 0.118995, Val Loss: 0.101185
2025-09-02 05:35:21,025 - INFO - New best model saved with Val Loss: 0.101185
2025-09-02 05:35:46,346 - INFO - Epoch 1706/5000 - Train Loss: 0.118829, Val Loss: 0.103976
2025-09-02 05:36:11,965 - INFO - Epoch 1707/5000 - Train Loss: 0.117539, Val Loss: 0.102559
2025-09-02 05:36:37,564 - INFO - Epoch 1708/5000 - Train Loss: 0.117385, Val Loss: 0.102233
2025-09-02 05:37:03,199 - INFO - Epoch 1709/5000 - Train Loss: 0.117055, Val Loss: 0.098023
2025-09-02 05:37:03,220 - INFO - New best model saved with Val Loss: 0.098023
2025-09-02 05:37:28,723 - INFO - Epoch 1710/5000 - Train Loss: 0.117654, Val Loss: 0.107326
2025-09-02 05:37:54,487 - INFO - Epoch 1711/5000 - Train Loss: 0.119083, Val Loss: 0.104604
2025-09-02 05:38:20,110 - INFO - Epoch 1712/5000 - Train Loss: 0.117688, Val Loss: 0.104476
2025-09-02 05:38:45,891 - INFO - Epoch 1713/5000 - Train Loss: 0.117683, Val Loss: 0.103557
2025-09-02 05:39:11,463 - INFO - Epoch 1714/5000 - Train Loss: 0.121620, Val Loss: 0.112629
2025-09-02 05:39:36,962 - INFO - Epoch 1715/5000 - Train Loss: 0.119939, Val Loss: 0.102530
2025-09-02 05:40:03,131 - INFO - Epoch 1716/5000 - Train Loss: 0.117446, Val Loss: 0.100257
2025-09-02 05:40:28,395 - INFO - Epoch 1717/5000 - Train Loss: 0.117924, Val Loss: 0.102158
2025-09-02 05:40:53,866 - INFO - Epoch 1718/5000 - Train Loss: 0.118499, Val Loss: 0.102202
2025-09-02 05:41:19,746 - INFO - Epoch 1719/5000 - Train Loss: 0.117954, Val Loss: 0.100552
2025-09-02 05:41:45,510 - INFO - Epoch 1720/5000 - Train Loss: 0.117550, Val Loss: 0.102221
2025-09-02 05:42:11,446 - INFO - Epoch 1721/5000 - Train Loss: 0.116724, Val Loss: 0.104029
2025-09-02 05:42:36,960 - INFO - Epoch 1722/5000 - Train Loss: 0.118295, Val Loss: 0.102451
2025-09-02 05:43:02,681 - INFO - Epoch 1723/5000 - Train Loss: 0.117661, Val Loss: 0.105088
2025-09-02 05:43:28,006 - INFO - Epoch 1724/5000 - Train Loss: 0.118222, Val Loss: 0.104480
2025-09-02 05:43:53,201 - INFO - Epoch 1725/5000 - Train Loss: 0.116459, Val Loss: 0.098607
2025-09-02 05:44:18,992 - INFO - Epoch 1726/5000 - Train Loss: 0.115138, Val Loss: 0.098829
2025-09-02 05:44:44,860 - INFO - Epoch 1727/5000 - Train Loss: 0.116928, Val Loss: 0.101408
2025-09-02 05:45:10,357 - INFO - Epoch 1728/5000 - Train Loss: 0.118252, Val Loss: 0.106272
2025-09-02 05:45:35,657 - INFO - Epoch 1729/5000 - Train Loss: 0.116576, Val Loss: 0.101186
2025-09-02 05:46:01,340 - INFO - Epoch 1730/5000 - Train Loss: 0.118760, Val Loss: 0.102333
2025-09-02 05:46:27,616 - INFO - Epoch 1731/5000 - Train Loss: 0.116533, Val Loss: 0.101026
2025-09-02 05:46:53,172 - INFO - Epoch 1732/5000 - Train Loss: 0.116791, Val Loss: 0.104362
2025-09-02 05:47:18,830 - INFO - Epoch 1733/5000 - Train Loss: 0.116451, Val Loss: 0.098477
2025-09-02 05:47:44,338 - INFO - Epoch 1734/5000 - Train Loss: 0.114306, Val Loss: 0.098128
2025-09-02 05:48:10,208 - INFO - Epoch 1735/5000 - Train Loss: 0.115698, Val Loss: 0.108182
2025-09-02 05:48:35,745 - INFO - Epoch 1736/5000 - Train Loss: 0.116565, Val Loss: 0.099768
2025-09-02 05:49:01,402 - INFO - Epoch 1737/5000 - Train Loss: 0.116338, Val Loss: 0.097674
2025-09-02 05:49:01,442 - INFO - New best model saved with Val Loss: 0.097674
2025-09-02 05:49:27,171 - INFO - Epoch 1738/5000 - Train Loss: 0.117479, Val Loss: 0.101042
2025-09-02 05:49:52,852 - INFO - Epoch 1739/5000 - Train Loss: 0.118510, Val Loss: 0.101618
2025-09-02 05:50:18,423 - INFO - Epoch 1740/5000 - Train Loss: 0.118223, Val Loss: 0.100889
2025-09-02 05:50:44,172 - INFO - Epoch 1741/5000 - Train Loss: 0.116702, Val Loss: 0.107603
2025-09-02 05:51:09,621 - INFO - Epoch 1742/5000 - Train Loss: 0.116738, Val Loss: 0.102895
2025-09-02 05:51:35,251 - INFO - Epoch 1743/5000 - Train Loss: 0.114920, Val Loss: 0.101075
2025-09-02 05:52:01,109 - INFO - Epoch 1744/5000 - Train Loss: 0.113961, Val Loss: 0.098762
2025-09-02 05:52:26,809 - INFO - Epoch 1745/5000 - Train Loss: 0.116258, Val Loss: 0.100862
2025-09-02 05:52:52,501 - INFO - Epoch 1746/5000 - Train Loss: 0.114805, Val Loss: 0.099905
2025-09-02 05:53:18,096 - INFO - Epoch 1747/5000 - Train Loss: 0.115644, Val Loss: 0.100542
2025-09-02 05:53:43,657 - INFO - Epoch 1748/5000 - Train Loss: 0.115570, Val Loss: 0.097613
2025-09-02 05:53:43,677 - INFO - New best model saved with Val Loss: 0.097613
2025-09-02 05:54:09,356 - INFO - Epoch 1749/5000 - Train Loss: 0.115330, Val Loss: 0.101004
2025-09-02 05:54:35,053 - INFO - Epoch 1750/5000 - Train Loss: 0.117493, Val Loss: 0.100411
2025-09-02 05:55:00,899 - INFO - Epoch 1751/5000 - Train Loss: 0.116750, Val Loss: 0.099919
2025-09-02 05:55:26,288 - INFO - Epoch 1752/5000 - Train Loss: 0.115224, Val Loss: 0.100134
2025-09-02 05:55:51,869 - INFO - Epoch 1753/5000 - Train Loss: 0.115133, Val Loss: 0.100859
2025-09-02 05:56:17,701 - INFO - Epoch 1754/5000 - Train Loss: 0.116126, Val Loss: 0.100319
2025-09-02 05:56:43,448 - INFO - Epoch 1755/5000 - Train Loss: 0.117078, Val Loss: 0.105512
2025-09-02 05:57:08,848 - INFO - Epoch 1756/5000 - Train Loss: 0.114831, Val Loss: 0.099028
2025-09-02 05:57:34,274 - INFO - Epoch 1757/5000 - Train Loss: 0.114637, Val Loss: 0.100682
2025-09-02 05:57:59,755 - INFO - Epoch 1758/5000 - Train Loss: 0.114520, Val Loss: 0.098805
2025-09-02 05:58:25,597 - INFO - Epoch 1759/5000 - Train Loss: 0.114805, Val Loss: 0.101020
2025-09-02 05:58:50,977 - INFO - Epoch 1760/5000 - Train Loss: 0.116050, Val Loss: 0.102281
2025-09-02 05:59:16,965 - INFO - Epoch 1761/5000 - Train Loss: 0.115748, Val Loss: 0.097714
2025-09-02 05:59:42,815 - INFO - Epoch 1762/5000 - Train Loss: 0.114398, Val Loss: 0.099766
2025-09-02 06:00:08,405 - INFO - Epoch 1763/5000 - Train Loss: 0.113392, Val Loss: 0.098091
2025-09-02 06:00:34,063 - INFO - Epoch 1764/5000 - Train Loss: 0.114490, Val Loss: 0.098686
2025-09-02 06:00:59,983 - INFO - Epoch 1765/5000 - Train Loss: 0.115773, Val Loss: 0.099034
2025-09-02 06:01:25,644 - INFO - Epoch 1766/5000 - Train Loss: 0.115236, Val Loss: 0.099546
2025-09-02 06:01:51,328 - INFO - Epoch 1767/5000 - Train Loss: 0.113559, Val Loss: 0.097881
2025-09-02 06:02:17,035 - INFO - Epoch 1768/5000 - Train Loss: 0.113015, Val Loss: 0.098766
2025-09-02 06:02:42,636 - INFO - Epoch 1769/5000 - Train Loss: 0.112601, Val Loss: 0.097681
2025-09-02 06:03:08,402 - INFO - Epoch 1770/5000 - Train Loss: 0.113805, Val Loss: 0.098411
2025-09-02 06:03:34,085 - INFO - Epoch 1771/5000 - Train Loss: 0.113442, Val Loss: 0.097458
2025-09-02 06:03:34,107 - INFO - New best model saved with Val Loss: 0.097458
2025-09-02 06:03:59,836 - INFO - Epoch 1772/5000 - Train Loss: 0.113368, Val Loss: 0.098557
2025-09-02 06:04:25,367 - INFO - Epoch 1773/5000 - Train Loss: 0.114058, Val Loss: 0.098624
2025-09-02 06:04:50,976 - INFO - Epoch 1774/5000 - Train Loss: 0.113586, Val Loss: 0.102374
2025-09-02 06:05:16,407 - INFO - Epoch 1775/5000 - Train Loss: 0.113934, Val Loss: 0.102412
2025-09-02 06:05:42,008 - INFO - Epoch 1776/5000 - Train Loss: 0.114121, Val Loss: 0.098234
2025-09-02 06:06:07,514 - INFO - Epoch 1777/5000 - Train Loss: 0.113490, Val Loss: 0.098391
2025-09-02 06:06:33,141 - INFO - Epoch 1778/5000 - Train Loss: 0.114552, Val Loss: 0.099571
2025-09-02 06:06:58,871 - INFO - Epoch 1779/5000 - Train Loss: 0.113515, Val Loss: 0.099543
2025-09-02 06:07:24,517 - INFO - Epoch 1780/5000 - Train Loss: 0.114983, Val Loss: 0.099152
2025-09-02 06:07:50,280 - INFO - Epoch 1781/5000 - Train Loss: 0.115420, Val Loss: 0.096853
2025-09-02 06:07:50,302 - INFO - New best model saved with Val Loss: 0.096853
2025-09-02 06:08:16,056 - INFO - Epoch 1782/5000 - Train Loss: 0.113109, Val Loss: 0.097077
2025-09-02 06:08:41,546 - INFO - Epoch 1783/5000 - Train Loss: 0.114088, Val Loss: 0.099071
2025-09-02 06:09:06,939 - INFO - Epoch 1784/5000 - Train Loss: 0.113195, Val Loss: 0.096646
2025-09-02 06:09:06,977 - INFO - New best model saved with Val Loss: 0.096646
2025-09-02 06:09:32,651 - INFO - Epoch 1785/5000 - Train Loss: 0.113768, Val Loss: 0.096797
2025-09-02 06:09:58,478 - INFO - Epoch 1786/5000 - Train Loss: 0.113231, Val Loss: 0.096109
2025-09-02 06:09:58,500 - INFO - New best model saved with Val Loss: 0.096109
2025-09-02 06:10:24,155 - INFO - Epoch 1787/5000 - Train Loss: 0.115543, Val Loss: 0.102575
2025-09-02 06:10:49,948 - INFO - Epoch 1788/5000 - Train Loss: 0.114877, Val Loss: 0.096663
2025-09-02 06:11:15,636 - INFO - Epoch 1789/5000 - Train Loss: 0.113312, Val Loss: 0.098250
2025-09-02 06:11:41,042 - INFO - Epoch 1790/5000 - Train Loss: 0.116165, Val Loss: 0.100048
2025-09-02 06:12:07,183 - INFO - Epoch 1791/5000 - Train Loss: 0.112995, Val Loss: 0.100681
2025-09-02 06:12:32,919 - INFO - Epoch 1792/5000 - Train Loss: 0.113257, Val Loss: 0.096872
2025-09-02 06:12:58,318 - INFO - Epoch 1793/5000 - Train Loss: 0.112947, Val Loss: 0.097926
2025-09-02 06:13:23,730 - INFO - Epoch 1794/5000 - Train Loss: 0.111881, Val Loss: 0.097108
2025-09-02 06:13:49,389 - INFO - Epoch 1795/5000 - Train Loss: 0.112515, Val Loss: 0.098881
2025-09-02 06:14:15,212 - INFO - Epoch 1796/5000 - Train Loss: 0.117569, Val Loss: 0.096852
2025-09-02 06:14:40,777 - INFO - Epoch 1797/5000 - Train Loss: 0.112523, Val Loss: 0.100109
2025-09-02 06:15:06,515 - INFO - Epoch 1798/5000 - Train Loss: 0.113255, Val Loss: 0.100926
2025-09-02 06:15:32,314 - INFO - Epoch 1799/5000 - Train Loss: 0.113914, Val Loss: 0.100513
2025-09-02 06:15:57,817 - INFO - Epoch 1800/5000 - Train Loss: 0.115521, Val Loss: 0.100170
2025-09-02 06:16:23,840 - INFO - Epoch 1801/5000 - Train Loss: 0.112822, Val Loss: 0.102099
2025-09-02 06:16:49,357 - INFO - Epoch 1802/5000 - Train Loss: 0.113864, Val Loss: 0.105818
2025-09-02 06:17:15,630 - INFO - Epoch 1803/5000 - Train Loss: 0.113881, Val Loss: 0.096346
2025-09-02 06:17:41,373 - INFO - Epoch 1804/5000 - Train Loss: 0.111628, Val Loss: 0.095919
2025-09-02 06:17:41,406 - INFO - New best model saved with Val Loss: 0.095919
2025-09-02 06:18:06,987 - INFO - Epoch 1805/5000 - Train Loss: 0.112676, Val Loss: 0.100115
2025-09-02 06:18:32,762 - INFO - Epoch 1806/5000 - Train Loss: 0.112672, Val Loss: 0.096932
2025-09-02 06:18:58,519 - INFO - Epoch 1807/5000 - Train Loss: 0.113967, Val Loss: 0.095704
2025-09-02 06:18:58,541 - INFO - New best model saved with Val Loss: 0.095704
2025-09-02 06:19:24,089 - INFO - Epoch 1808/5000 - Train Loss: 0.113796, Val Loss: 0.098762
2025-09-02 06:19:49,862 - INFO - Epoch 1809/5000 - Train Loss: 0.112997, Val Loss: 0.095350
2025-09-02 06:19:49,883 - INFO - New best model saved with Val Loss: 0.095350
2025-09-02 06:20:15,616 - INFO - Epoch 1810/5000 - Train Loss: 0.111829, Val Loss: 0.095443
2025-09-02 06:20:41,790 - INFO - Epoch 1811/5000 - Train Loss: 0.112970, Val Loss: 0.097044
2025-09-02 06:21:07,696 - INFO - Epoch 1812/5000 - Train Loss: 0.111767, Val Loss: 0.095705
2025-09-02 06:21:33,350 - INFO - Epoch 1813/5000 - Train Loss: 0.114046, Val Loss: 0.100093
2025-09-02 06:21:59,261 - INFO - Epoch 1814/5000 - Train Loss: 0.113172, Val Loss: 0.096295
2025-09-02 06:22:25,023 - INFO - Epoch 1815/5000 - Train Loss: 0.111501, Val Loss: 0.100255
2025-09-02 06:22:50,712 - INFO - Epoch 1816/5000 - Train Loss: 0.112632, Val Loss: 0.095865
2025-09-02 06:23:16,183 - INFO - Epoch 1817/5000 - Train Loss: 0.111414, Val Loss: 0.095049
2025-09-02 06:23:16,205 - INFO - New best model saved with Val Loss: 0.095049
2025-09-02 06:23:41,906 - INFO - Epoch 1818/5000 - Train Loss: 0.111794, Val Loss: 0.099227
2025-09-02 06:24:07,308 - INFO - Epoch 1819/5000 - Train Loss: 0.112549, Val Loss: 0.097926
2025-09-02 06:24:32,893 - INFO - Epoch 1820/5000 - Train Loss: 0.111701, Val Loss: 0.093182
2025-09-02 06:24:32,916 - INFO - New best model saved with Val Loss: 0.093182
2025-09-02 06:24:58,800 - INFO - Epoch 1821/5000 - Train Loss: 0.111373, Val Loss: 0.094450
2025-09-02 06:25:24,473 - INFO - Epoch 1822/5000 - Train Loss: 0.112869, Val Loss: 0.097808
2025-09-02 06:25:50,047 - INFO - Epoch 1823/5000 - Train Loss: 0.110795, Val Loss: 0.096580
2025-09-02 06:26:15,642 - INFO - Epoch 1824/5000 - Train Loss: 0.112718, Val Loss: 0.099271
2025-09-02 06:26:41,242 - INFO - Epoch 1825/5000 - Train Loss: 0.112799, Val Loss: 0.097530
2025-09-02 06:27:07,026 - INFO - Epoch 1826/5000 - Train Loss: 0.111656, Val Loss: 0.101018
2025-09-02 06:27:32,764 - INFO - Epoch 1827/5000 - Train Loss: 0.111979, Val Loss: 0.094153
2025-09-02 06:27:58,544 - INFO - Epoch 1828/5000 - Train Loss: 0.110721, Val Loss: 0.096363
2025-09-02 06:28:24,104 - INFO - Epoch 1829/5000 - Train Loss: 0.111791, Val Loss: 0.096597
2025-09-02 06:28:49,749 - INFO - Epoch 1830/5000 - Train Loss: 0.111552, Val Loss: 0.096525
2025-09-02 06:29:15,592 - INFO - Epoch 1831/5000 - Train Loss: 0.111769, Val Loss: 0.098656
2025-09-02 06:29:41,561 - INFO - Epoch 1832/5000 - Train Loss: 0.115468, Val Loss: 0.098626
2025-09-02 06:30:06,948 - INFO - Epoch 1833/5000 - Train Loss: 0.111154, Val Loss: 0.097015
2025-09-02 06:30:32,526 - INFO - Epoch 1834/5000 - Train Loss: 0.110933, Val Loss: 0.093767
2025-09-02 06:30:57,929 - INFO - Epoch 1835/5000 - Train Loss: 0.111036, Val Loss: 0.095760
2025-09-02 06:31:23,723 - INFO - Epoch 1836/5000 - Train Loss: 0.111875, Val Loss: 0.094608
2025-09-02 06:31:49,654 - INFO - Epoch 1837/5000 - Train Loss: 0.110443, Val Loss: 0.094873
2025-09-02 06:32:15,261 - INFO - Epoch 1838/5000 - Train Loss: 0.111384, Val Loss: 0.096314
2025-09-02 06:32:40,878 - INFO - Epoch 1839/5000 - Train Loss: 0.110364, Val Loss: 0.095864
2025-09-02 06:33:06,563 - INFO - Epoch 1840/5000 - Train Loss: 0.110989, Val Loss: 0.096035
2025-09-02 06:33:32,543 - INFO - Epoch 1841/5000 - Train Loss: 0.110498, Val Loss: 0.094324
2025-09-02 06:33:58,288 - INFO - Epoch 1842/5000 - Train Loss: 0.112048, Val Loss: 0.103080
2025-09-02 06:34:23,830 - INFO - Epoch 1843/5000 - Train Loss: 0.111913, Val Loss: 0.095408
2025-09-02 06:34:49,562 - INFO - Epoch 1844/5000 - Train Loss: 0.111563, Val Loss: 0.095195
2025-09-02 06:35:15,345 - INFO - Epoch 1845/5000 - Train Loss: 0.110448, Val Loss: 0.097327
2025-09-02 06:35:40,900 - INFO - Epoch 1846/5000 - Train Loss: 0.112815, Val Loss: 0.100923
2025-09-02 06:36:06,448 - INFO - Epoch 1847/5000 - Train Loss: 0.111924, Val Loss: 0.097391
2025-09-02 06:36:32,061 - INFO - Epoch 1848/5000 - Train Loss: 0.110677, Val Loss: 0.093189
2025-09-02 06:36:57,775 - INFO - Epoch 1849/5000 - Train Loss: 0.109868, Val Loss: 0.096568
2025-09-02 06:37:23,421 - INFO - Epoch 1850/5000 - Train Loss: 0.110351, Val Loss: 0.096596
2025-09-02 06:37:48,952 - INFO - Epoch 1851/5000 - Train Loss: 0.111089, Val Loss: 0.096843
2025-09-02 06:38:14,504 - INFO - Epoch 1852/5000 - Train Loss: 0.112180, Val Loss: 0.097189
2025-09-02 06:38:40,276 - INFO - Epoch 1853/5000 - Train Loss: 0.111542, Val Loss: 0.097166
2025-09-02 06:39:05,650 - INFO - Epoch 1854/5000 - Train Loss: 0.109915, Val Loss: 0.093793
2025-09-02 06:39:31,122 - INFO - Epoch 1855/5000 - Train Loss: 0.108741, Val Loss: 0.094585
2025-09-02 06:39:56,580 - INFO - Epoch 1856/5000 - Train Loss: 0.112024, Val Loss: 0.100065
2025-09-02 06:40:22,131 - INFO - Epoch 1857/5000 - Train Loss: 0.111428, Val Loss: 0.095185
2025-09-02 06:40:47,567 - INFO - Epoch 1858/5000 - Train Loss: 0.111423, Val Loss: 0.093033
2025-09-02 06:40:47,589 - INFO - New best model saved with Val Loss: 0.093033
2025-09-02 06:41:13,237 - INFO - Epoch 1859/5000 - Train Loss: 0.109158, Val Loss: 0.094061
2025-09-02 06:41:39,240 - INFO - Epoch 1860/5000 - Train Loss: 0.109526, Val Loss: 0.100116
2025-09-02 06:42:05,113 - INFO - Epoch 1861/5000 - Train Loss: 0.113125, Val Loss: 0.095747
2025-09-02 06:42:31,030 - INFO - Epoch 1862/5000 - Train Loss: 0.110045, Val Loss: 0.098146
2025-09-02 06:42:56,559 - INFO - Epoch 1863/5000 - Train Loss: 0.112301, Val Loss: 0.095282
2025-09-02 06:43:22,062 - INFO - Epoch 1864/5000 - Train Loss: 0.109882, Val Loss: 0.094728
2025-09-02 06:43:47,686 - INFO - Epoch 1865/5000 - Train Loss: 0.110541, Val Loss: 0.095039
2025-09-02 06:44:13,169 - INFO - Epoch 1866/5000 - Train Loss: 0.109861, Val Loss: 0.092535
2025-09-02 06:44:13,190 - INFO - New best model saved with Val Loss: 0.092535
2025-09-02 06:44:38,689 - INFO - Epoch 1867/5000 - Train Loss: 0.109816, Val Loss: 0.096370
2025-09-02 06:45:04,261 - INFO - Epoch 1868/5000 - Train Loss: 0.110049, Val Loss: 0.096043
2025-09-02 06:45:29,714 - INFO - Epoch 1869/5000 - Train Loss: 0.110879, Val Loss: 0.095554
2025-09-02 06:45:55,057 - INFO - Epoch 1870/5000 - Train Loss: 0.110449, Val Loss: 0.094788
2025-09-02 06:46:20,802 - INFO - Epoch 1871/5000 - Train Loss: 0.110521, Val Loss: 0.094162
2025-09-02 06:46:46,195 - INFO - Epoch 1872/5000 - Train Loss: 0.109862, Val Loss: 0.095849
2025-09-02 06:47:11,648 - INFO - Epoch 1873/5000 - Train Loss: 0.109826, Val Loss: 0.097447
2025-09-02 06:47:37,235 - INFO - Epoch 1874/5000 - Train Loss: 0.109553, Val Loss: 0.094412
2025-09-02 06:48:02,979 - INFO - Epoch 1875/5000 - Train Loss: 0.109776, Val Loss: 0.095577
2025-09-02 06:48:28,593 - INFO - Epoch 1876/5000 - Train Loss: 0.110150, Val Loss: 0.095800
2025-09-02 06:48:54,050 - INFO - Epoch 1877/5000 - Train Loss: 0.109496, Val Loss: 0.093557
2025-09-02 06:49:19,544 - INFO - Epoch 1878/5000 - Train Loss: 0.108830, Val Loss: 0.095502
2025-09-02 06:49:45,016 - INFO - Epoch 1879/5000 - Train Loss: 0.110321, Val Loss: 0.094787
2025-09-02 06:50:10,495 - INFO - Epoch 1880/5000 - Train Loss: 0.110199, Val Loss: 0.095113
2025-09-02 06:50:36,062 - INFO - Epoch 1881/5000 - Train Loss: 0.108204, Val Loss: 0.093122
2025-09-02 06:51:01,928 - INFO - Epoch 1882/5000 - Train Loss: 0.108450, Val Loss: 0.093833
2025-09-02 06:51:27,660 - INFO - Epoch 1883/5000 - Train Loss: 0.110281, Val Loss: 0.096651
2025-09-02 06:51:53,217 - INFO - Epoch 1884/5000 - Train Loss: 0.108581, Val Loss: 0.092879
2025-09-02 06:52:19,049 - INFO - Epoch 1885/5000 - Train Loss: 0.109638, Val Loss: 0.093251
2025-09-02 06:52:45,077 - INFO - Epoch 1886/5000 - Train Loss: 0.108366, Val Loss: 0.093513
2025-09-02 06:53:10,850 - INFO - Epoch 1887/5000 - Train Loss: 0.109701, Val Loss: 0.100877
2025-09-02 06:53:36,144 - INFO - Epoch 1888/5000 - Train Loss: 0.111097, Val Loss: 0.094954
2025-09-02 06:54:01,749 - INFO - Epoch 1889/5000 - Train Loss: 0.109390, Val Loss: 0.095862
2025-09-02 06:54:27,469 - INFO - Epoch 1890/5000 - Train Loss: 0.109284, Val Loss: 0.094239
2025-09-02 06:54:53,089 - INFO - Epoch 1891/5000 - Train Loss: 0.109141, Val Loss: 0.094485
2025-09-02 06:55:18,737 - INFO - Epoch 1892/5000 - Train Loss: 0.108317, Val Loss: 0.093128
2025-09-02 06:55:44,474 - INFO - Epoch 1893/5000 - Train Loss: 0.110528, Val Loss: 0.097528
2025-09-02 06:56:10,083 - INFO - Epoch 1894/5000 - Train Loss: 0.109794, Val Loss: 0.093706
2025-09-02 06:56:35,805 - INFO - Epoch 1895/5000 - Train Loss: 0.107406, Val Loss: 0.095993
2025-09-02 06:57:01,398 - INFO - Epoch 1896/5000 - Train Loss: 0.110393, Val Loss: 0.092759
2025-09-02 06:57:27,018 - INFO - Epoch 1897/5000 - Train Loss: 0.108158, Val Loss: 0.094325
2025-09-02 06:57:52,354 - INFO - Epoch 1898/5000 - Train Loss: 0.108544, Val Loss: 0.093504
2025-09-02 06:58:17,582 - INFO - Epoch 1899/5000 - Train Loss: 0.108034, Val Loss: 0.095443
2025-09-02 06:58:43,331 - INFO - Epoch 1900/5000 - Train Loss: 0.108742, Val Loss: 0.093241
2025-09-02 06:59:09,477 - INFO - Epoch 1901/5000 - Train Loss: 0.109838, Val Loss: 0.098142
2025-09-02 06:59:35,158 - INFO - Epoch 1902/5000 - Train Loss: 0.110086, Val Loss: 0.097129
2025-09-02 07:00:00,786 - INFO - Epoch 1903/5000 - Train Loss: 0.107785, Val Loss: 0.092573
2025-09-02 07:00:26,138 - INFO - Epoch 1904/5000 - Train Loss: 0.110012, Val Loss: 0.102805
2025-09-02 07:00:51,578 - INFO - Epoch 1905/5000 - Train Loss: 0.108783, Val Loss: 0.092145
2025-09-02 07:00:51,600 - INFO - New best model saved with Val Loss: 0.092145
2025-09-02 07:01:17,359 - INFO - Epoch 1906/5000 - Train Loss: 0.107389, Val Loss: 0.092997
2025-09-02 07:01:44,594 - INFO - Epoch 1907/5000 - Train Loss: 0.108146, Val Loss: 0.093947
2025-09-02 07:02:10,324 - INFO - Epoch 1908/5000 - Train Loss: 0.107346, Val Loss: 0.092946
2025-09-02 07:02:36,115 - INFO - Epoch 1909/5000 - Train Loss: 0.108654, Val Loss: 0.092126
2025-09-02 07:02:36,143 - INFO - New best model saved with Val Loss: 0.092126
2025-09-02 07:03:01,818 - INFO - Epoch 1910/5000 - Train Loss: 0.109424, Val Loss: 0.097191
2025-09-02 07:03:27,523 - INFO - Epoch 1911/5000 - Train Loss: 0.107292, Val Loss: 0.095690
2025-09-02 07:03:52,990 - INFO - Epoch 1912/5000 - Train Loss: 0.108203, Val Loss: 0.094704
2025-09-02 07:04:18,459 - INFO - Epoch 1913/5000 - Train Loss: 0.107232, Val Loss: 0.092474
2025-09-02 07:04:44,069 - INFO - Epoch 1914/5000 - Train Loss: 0.107519, Val Loss: 0.092823
2025-09-02 07:05:09,653 - INFO - Epoch 1915/5000 - Train Loss: 0.108662, Val Loss: 0.092752
2025-09-02 07:05:35,206 - INFO - Epoch 1916/5000 - Train Loss: 0.107447, Val Loss: 0.091121
2025-09-02 07:05:35,227 - INFO - New best model saved with Val Loss: 0.091121
2025-09-02 07:06:00,810 - INFO - Epoch 1917/5000 - Train Loss: 0.107505, Val Loss: 0.091050
2025-09-02 07:06:00,830 - INFO - New best model saved with Val Loss: 0.091050
2025-09-02 07:06:26,390 - INFO - Epoch 1918/5000 - Train Loss: 0.107975, Val Loss: 0.093277
2025-09-02 07:06:52,339 - INFO - Epoch 1919/5000 - Train Loss: 0.108458, Val Loss: 0.095022
2025-09-02 07:07:17,602 - INFO - Epoch 1920/5000 - Train Loss: 0.108762, Val Loss: 0.096571
2025-09-02 07:07:43,136 - INFO - Epoch 1921/5000 - Train Loss: 0.109688, Val Loss: 0.092213
2025-09-02 07:08:08,776 - INFO - Epoch 1922/5000 - Train Loss: 0.108990, Val Loss: 0.092846
2025-09-02 07:08:34,354 - INFO - Epoch 1923/5000 - Train Loss: 0.108735, Val Loss: 0.095080
2025-09-02 07:09:00,040 - INFO - Epoch 1924/5000 - Train Loss: 0.108093, Val Loss: 0.096415
2025-09-02 07:09:25,423 - INFO - Epoch 1925/5000 - Train Loss: 0.109781, Val Loss: 0.094605
2025-09-02 07:09:51,098 - INFO - Epoch 1926/5000 - Train Loss: 0.109098, Val Loss: 0.096739
2025-09-02 07:10:16,607 - INFO - Epoch 1927/5000 - Train Loss: 0.107786, Val Loss: 0.095125
2025-09-02 07:10:42,259 - INFO - Epoch 1928/5000 - Train Loss: 0.108158, Val Loss: 0.094004
2025-09-02 07:11:08,182 - INFO - Epoch 1929/5000 - Train Loss: 0.106770, Val Loss: 0.091761
2025-09-02 07:11:33,619 - INFO - Epoch 1930/5000 - Train Loss: 0.106992, Val Loss: 0.092355
2025-09-02 07:11:59,155 - INFO - Epoch 1931/5000 - Train Loss: 0.107199, Val Loss: 0.093317
2025-09-02 07:12:24,757 - INFO - Epoch 1932/5000 - Train Loss: 0.107937, Val Loss: 0.095602
2025-09-02 07:12:50,273 - INFO - Epoch 1933/5000 - Train Loss: 0.107415, Val Loss: 0.092825
2025-09-02 07:13:15,930 - INFO - Epoch 1934/5000 - Train Loss: 0.107108, Val Loss: 0.092334
2025-09-02 07:13:41,522 - INFO - Epoch 1935/5000 - Train Loss: 0.107576, Val Loss: 0.095618
2025-09-02 07:14:07,298 - INFO - Epoch 1936/5000 - Train Loss: 0.110656, Val Loss: 0.093618
2025-09-02 07:14:32,944 - INFO - Epoch 1937/5000 - Train Loss: 0.108184, Val Loss: 0.091113
2025-09-02 07:14:58,508 - INFO - Epoch 1938/5000 - Train Loss: 0.105643, Val Loss: 0.091144
2025-09-02 07:15:23,927 - INFO - Epoch 1939/5000 - Train Loss: 0.106675, Val Loss: 0.092338
2025-09-02 07:15:49,616 - INFO - Epoch 1940/5000 - Train Loss: 0.106453, Val Loss: 0.091017
2025-09-02 07:15:49,649 - INFO - New best model saved with Val Loss: 0.091017
2025-09-02 07:16:15,372 - INFO - Epoch 1941/5000 - Train Loss: 0.107705, Val Loss: 0.091914
2025-09-02 07:16:40,946 - INFO - Epoch 1942/5000 - Train Loss: 0.106934, Val Loss: 0.093061
2025-09-02 07:17:06,439 - INFO - Epoch 1943/5000 - Train Loss: 0.107608, Val Loss: 0.095130
2025-09-02 07:17:31,958 - INFO - Epoch 1944/5000 - Train Loss: 0.107250, Val Loss: 0.092235
2025-09-02 07:17:57,711 - INFO - Epoch 1945/5000 - Train Loss: 0.107951, Val Loss: 0.092912
2025-09-02 07:18:23,123 - INFO - Epoch 1946/5000 - Train Loss: 0.106758, Val Loss: 0.095915
2025-09-02 07:18:48,970 - INFO - Epoch 1947/5000 - Train Loss: 0.107924, Val Loss: 0.094700
2025-09-02 07:19:14,891 - INFO - Epoch 1948/5000 - Train Loss: 0.107445, Val Loss: 0.092014
2025-09-02 07:19:40,510 - INFO - Epoch 1949/5000 - Train Loss: 0.105716, Val Loss: 0.094123
2025-09-02 07:20:06,130 - INFO - Epoch 1950/5000 - Train Loss: 0.107442, Val Loss: 0.089833
2025-09-02 07:20:06,151 - INFO - New best model saved with Val Loss: 0.089833
2025-09-02 07:20:31,954 - INFO - Epoch 1951/5000 - Train Loss: 0.106161, Val Loss: 0.091192
2025-09-02 07:20:57,486 - INFO - Epoch 1952/5000 - Train Loss: 0.105017, Val Loss: 0.091894
2025-09-02 07:21:23,044 - INFO - Epoch 1953/5000 - Train Loss: 0.107334, Val Loss: 0.093810
2025-09-02 07:21:48,375 - INFO - Epoch 1954/5000 - Train Loss: 0.108290, Val Loss: 0.093274
2025-09-02 07:22:13,917 - INFO - Epoch 1955/5000 - Train Loss: 0.105832, Val Loss: 0.092347
2025-09-02 07:22:39,743 - INFO - Epoch 1956/5000 - Train Loss: 0.105892, Val Loss: 0.092463
2025-09-02 07:23:05,585 - INFO - Epoch 1957/5000 - Train Loss: 0.105686, Val Loss: 0.091145
2025-09-02 07:23:31,287 - INFO - Epoch 1958/5000 - Train Loss: 0.105524, Val Loss: 0.090315
2025-09-02 07:23:57,049 - INFO - Epoch 1959/5000 - Train Loss: 0.105466, Val Loss: 0.093367
2025-09-02 07:24:22,666 - INFO - Epoch 1960/5000 - Train Loss: 0.108338, Val Loss: 0.093698
2025-09-02 07:24:48,647 - INFO - Epoch 1961/5000 - Train Loss: 0.105926, Val Loss: 0.091337
2025-09-02 07:25:14,240 - INFO - Epoch 1962/5000 - Train Loss: 0.106327, Val Loss: 0.094056
2025-09-02 07:25:39,883 - INFO - Epoch 1963/5000 - Train Loss: 0.107157, Val Loss: 0.090899
2025-09-02 07:26:05,676 - INFO - Epoch 1964/5000 - Train Loss: 0.105940, Val Loss: 0.092601
2025-09-02 07:26:31,243 - INFO - Epoch 1965/5000 - Train Loss: 0.105810, Val Loss: 0.091876
2025-09-02 07:26:56,977 - INFO - Epoch 1966/5000 - Train Loss: 0.106085, Val Loss: 0.088654
2025-09-02 07:26:56,998 - INFO - New best model saved with Val Loss: 0.088654
2025-09-02 07:27:22,665 - INFO - Epoch 1967/5000 - Train Loss: 0.104785, Val Loss: 0.091569
2025-09-02 07:27:48,491 - INFO - Epoch 1968/5000 - Train Loss: 0.106114, Val Loss: 0.098453
2025-09-02 07:28:14,015 - INFO - Epoch 1969/5000 - Train Loss: 0.106928, Val Loss: 0.089304
2025-09-02 07:28:39,607 - INFO - Epoch 1970/5000 - Train Loss: 0.105222, Val Loss: 0.089894
2025-09-02 07:29:05,554 - INFO - Epoch 1971/5000 - Train Loss: 0.105896, Val Loss: 0.091834
2025-09-02 07:29:31,114 - INFO - Epoch 1972/5000 - Train Loss: 0.105798, Val Loss: 0.091021
2025-09-02 07:29:56,851 - INFO - Epoch 1973/5000 - Train Loss: 0.106631, Val Loss: 0.090021
2025-09-02 07:30:22,341 - INFO - Epoch 1974/5000 - Train Loss: 0.105121, Val Loss: 0.088188
2025-09-02 07:30:22,361 - INFO - New best model saved with Val Loss: 0.088188
2025-09-02 07:30:47,947 - INFO - Epoch 1975/5000 - Train Loss: 0.105631, Val Loss: 0.090797
2025-09-02 07:31:13,548 - INFO - Epoch 1976/5000 - Train Loss: 0.107542, Val Loss: 0.092259
2025-09-02 07:31:39,059 - INFO - Epoch 1977/5000 - Train Loss: 0.106200, Val Loss: 0.088776
2025-09-02 07:32:04,461 - INFO - Epoch 1978/5000 - Train Loss: 0.105075, Val Loss: 0.091814
2025-09-02 07:32:30,212 - INFO - Epoch 1979/5000 - Train Loss: 0.106196, Val Loss: 0.089764
2025-09-02 07:32:55,801 - INFO - Epoch 1980/5000 - Train Loss: 0.105435, Val Loss: 0.089973
2025-09-02 07:33:21,507 - INFO - Epoch 1981/5000 - Train Loss: 0.104063, Val Loss: 0.089550
2025-09-02 07:33:47,099 - INFO - Epoch 1982/5000 - Train Loss: 0.105591, Val Loss: 0.089656
2025-09-02 07:34:12,666 - INFO - Epoch 1983/5000 - Train Loss: 0.104156, Val Loss: 0.092103
2025-09-02 07:34:38,312 - INFO - Epoch 1984/5000 - Train Loss: 0.106437, Val Loss: 0.095674
2025-09-02 07:35:03,745 - INFO - Epoch 1985/5000 - Train Loss: 0.105798, Val Loss: 0.088128
2025-09-02 07:35:03,765 - INFO - New best model saved with Val Loss: 0.088128
2025-09-02 07:35:29,244 - INFO - Epoch 1986/5000 - Train Loss: 0.105117, Val Loss: 0.090227
2025-09-02 07:35:54,675 - INFO - Epoch 1987/5000 - Train Loss: 0.106485, Val Loss: 0.097573
2025-09-02 07:36:20,391 - INFO - Epoch 1988/5000 - Train Loss: 0.105947, Val Loss: 0.094079
2025-09-02 07:36:46,205 - INFO - Epoch 1989/5000 - Train Loss: 0.106578, Val Loss: 0.089043
2025-09-02 07:37:11,910 - INFO - Epoch 1990/5000 - Train Loss: 0.105412, Val Loss: 0.090248
2025-09-02 07:37:37,450 - INFO - Epoch 1991/5000 - Train Loss: 0.104930, Val Loss: 0.091240
2025-09-02 07:38:02,882 - INFO - Epoch 1992/5000 - Train Loss: 0.105880, Val Loss: 0.093824
2025-09-02 07:38:28,599 - INFO - Epoch 1993/5000 - Train Loss: 0.105831, Val Loss: 0.092242
2025-09-02 07:38:53,858 - INFO - Epoch 1994/5000 - Train Loss: 0.105083, Val Loss: 0.090535
2025-09-02 07:39:19,347 - INFO - Epoch 1995/5000 - Train Loss: 0.106293, Val Loss: 0.097091
2025-09-02 07:39:44,772 - INFO - Epoch 1996/5000 - Train Loss: 0.105297, Val Loss: 0.091180
2025-09-02 07:40:10,596 - INFO - Epoch 1997/5000 - Train Loss: 0.106623, Val Loss: 0.096236
2025-09-02 07:40:36,183 - INFO - Epoch 1998/5000 - Train Loss: 0.106465, Val Loss: 0.090708
2025-09-02 07:41:01,399 - INFO - Epoch 1999/5000 - Train Loss: 0.106333, Val Loss: 0.094325
2025-09-02 07:41:27,274 - INFO - Epoch 2000/5000 - Train Loss: 0.105576, Val Loss: 0.090256
2025-09-02 07:41:53,227 - INFO - Epoch 2001/5000 - Train Loss: 0.103441, Val Loss: 0.089991
2025-09-02 07:42:18,401 - INFO - Epoch 2002/5000 - Train Loss: 0.105257, Val Loss: 0.091317
2025-09-02 07:42:43,889 - INFO - Epoch 2003/5000 - Train Loss: 0.104631, Val Loss: 0.091231
2025-09-02 07:43:09,541 - INFO - Epoch 2004/5000 - Train Loss: 0.103423, Val Loss: 0.090331
2025-09-02 07:43:34,780 - INFO - Epoch 2005/5000 - Train Loss: 0.103681, Val Loss: 0.087770
2025-09-02 07:43:34,810 - INFO - New best model saved with Val Loss: 0.087770
2025-09-02 07:44:00,233 - INFO - Epoch 2006/5000 - Train Loss: 0.102779, Val Loss: 0.088889
2025-09-02 07:44:25,587 - INFO - Epoch 2007/5000 - Train Loss: 0.103776, Val Loss: 0.090387
2025-09-02 07:44:50,901 - INFO - Epoch 2008/5000 - Train Loss: 0.104243, Val Loss: 0.093424
2025-09-02 07:45:16,491 - INFO - Epoch 2009/5000 - Train Loss: 0.106437, Val Loss: 0.090270
2025-09-02 07:45:41,820 - INFO - Epoch 2010/5000 - Train Loss: 0.103880, Val Loss: 0.091730
2025-09-02 07:46:07,654 - INFO - Epoch 2011/5000 - Train Loss: 0.104245, Val Loss: 0.091963
2025-09-02 07:46:33,196 - INFO - Epoch 2012/5000 - Train Loss: 0.105752, Val Loss: 0.089403
2025-09-02 07:46:58,483 - INFO - Epoch 2013/5000 - Train Loss: 0.105609, Val Loss: 0.091817
2025-09-02 07:47:24,008 - INFO - Epoch 2014/5000 - Train Loss: 0.104668, Val Loss: 0.090389
2025-09-02 07:47:49,111 - INFO - Epoch 2015/5000 - Train Loss: 0.103274, Val Loss: 0.088378
2025-09-02 07:48:14,587 - INFO - Epoch 2016/5000 - Train Loss: 0.102655, Val Loss: 0.089989
2025-09-02 07:48:40,284 - INFO - Epoch 2017/5000 - Train Loss: 0.103638, Val Loss: 0.092218
2025-09-02 07:49:05,864 - INFO - Epoch 2018/5000 - Train Loss: 0.103027, Val Loss: 0.088794
2025-09-02 07:49:31,201 - INFO - Epoch 2019/5000 - Train Loss: 0.104190, Val Loss: 0.090094
2025-09-02 07:49:56,917 - INFO - Epoch 2020/5000 - Train Loss: 0.103713, Val Loss: 0.093495
2025-09-02 07:50:22,573 - INFO - Epoch 2021/5000 - Train Loss: 0.104972, Val Loss: 0.089455
2025-09-02 07:50:48,174 - INFO - Epoch 2022/5000 - Train Loss: 0.103745, Val Loss: 0.094253
2025-09-02 07:51:13,932 - INFO - Epoch 2023/5000 - Train Loss: 0.104008, Val Loss: 0.088866
2025-09-02 07:51:39,560 - INFO - Epoch 2024/5000 - Train Loss: 0.104140, Val Loss: 0.089635
2025-09-02 07:52:05,050 - INFO - Epoch 2025/5000 - Train Loss: 0.104780, Val Loss: 0.094699
2025-09-02 07:52:30,553 - INFO - Epoch 2026/5000 - Train Loss: 0.104121, Val Loss: 0.088267
2025-09-02 07:52:55,780 - INFO - Epoch 2027/5000 - Train Loss: 0.105471, Val Loss: 0.090336
2025-09-02 07:53:21,418 - INFO - Epoch 2028/5000 - Train Loss: 0.104476, Val Loss: 0.089048
2025-09-02 07:53:47,257 - INFO - Epoch 2029/5000 - Train Loss: 0.103740, Val Loss: 0.090614
2025-09-02 07:54:12,969 - INFO - Epoch 2030/5000 - Train Loss: 0.104268, Val Loss: 0.089191
2025-09-02 07:54:38,853 - INFO - Epoch 2031/5000 - Train Loss: 0.103371, Val Loss: 0.091326
2025-09-02 07:55:04,738 - INFO - Epoch 2032/5000 - Train Loss: 0.104339, Val Loss: 0.090788
2025-09-02 07:55:30,527 - INFO - Epoch 2033/5000 - Train Loss: 0.102887, Val Loss: 0.088045
2025-09-02 07:55:55,901 - INFO - Epoch 2034/5000 - Train Loss: 0.102688, Val Loss: 0.086088
2025-09-02 07:55:55,923 - INFO - New best model saved with Val Loss: 0.086088
2025-09-02 07:56:21,448 - INFO - Epoch 2035/5000 - Train Loss: 0.102693, Val Loss: 0.088109
2025-09-02 07:56:47,174 - INFO - Epoch 2036/5000 - Train Loss: 0.104014, Val Loss: 0.091174
2025-09-02 07:57:12,802 - INFO - Epoch 2037/5000 - Train Loss: 0.104878, Val Loss: 0.093845
2025-09-02 07:57:38,330 - INFO - Epoch 2038/5000 - Train Loss: 0.104660, Val Loss: 0.090096
2025-09-02 07:58:03,912 - INFO - Epoch 2039/5000 - Train Loss: 0.103547, Val Loss: 0.090213
2025-09-02 07:58:29,555 - INFO - Epoch 2040/5000 - Train Loss: 0.103977, Val Loss: 0.088653
2025-09-02 07:58:55,325 - INFO - Epoch 2041/5000 - Train Loss: 0.102877, Val Loss: 0.089259
2025-09-02 07:59:20,947 - INFO - Epoch 2042/5000 - Train Loss: 0.103551, Val Loss: 0.088990
2025-09-02 07:59:46,546 - INFO - Epoch 2043/5000 - Train Loss: 0.103911, Val Loss: 0.088032
2025-09-02 08:00:12,076 - INFO - Epoch 2044/5000 - Train Loss: 0.102684, Val Loss: 0.088556
2025-09-02 08:00:37,756 - INFO - Epoch 2045/5000 - Train Loss: 0.103039, Val Loss: 0.088682
2025-09-02 08:01:03,615 - INFO - Epoch 2046/5000 - Train Loss: 0.103106, Val Loss: 0.089783
2025-09-02 08:01:29,447 - INFO - Epoch 2047/5000 - Train Loss: 0.105691, Val Loss: 0.092116
2025-09-02 08:01:54,957 - INFO - Epoch 2048/5000 - Train Loss: 0.105029, Val Loss: 0.089950
2025-09-02 08:02:20,576 - INFO - Epoch 2049/5000 - Train Loss: 0.102858, Val Loss: 0.087354
2025-09-02 08:02:46,333 - INFO - Epoch 2050/5000 - Train Loss: 0.101914, Val Loss: 0.089245
2025-09-02 08:03:11,948 - INFO - Epoch 2051/5000 - Train Loss: 0.103193, Val Loss: 0.089340
2025-09-02 08:03:37,555 - INFO - Epoch 2052/5000 - Train Loss: 0.103648, Val Loss: 0.091256
2025-09-02 08:04:03,118 - INFO - Epoch 2053/5000 - Train Loss: 0.103436, Val Loss: 0.088075
2025-09-02 08:04:28,782 - INFO - Epoch 2054/5000 - Train Loss: 0.103242, Val Loss: 0.089681
2025-09-02 08:04:54,001 - INFO - Epoch 2055/5000 - Train Loss: 0.103632, Val Loss: 0.087902
2025-09-02 08:05:19,633 - INFO - Epoch 2056/5000 - Train Loss: 0.102451, Val Loss: 0.088855
2025-09-02 08:05:45,170 - INFO - Epoch 2057/5000 - Train Loss: 0.104145, Val Loss: 0.089680
2025-09-02 08:06:10,820 - INFO - Epoch 2058/5000 - Train Loss: 0.102477, Val Loss: 0.086139
2025-09-02 08:06:36,434 - INFO - Epoch 2059/5000 - Train Loss: 0.102850, Val Loss: 0.089756
2025-09-02 08:07:01,981 - INFO - Epoch 2060/5000 - Train Loss: 0.104529, Val Loss: 0.087651
2025-09-02 08:07:27,610 - INFO - Epoch 2061/5000 - Train Loss: 0.101130, Val Loss: 0.089614
2025-09-02 08:07:52,947 - INFO - Epoch 2062/5000 - Train Loss: 0.102649, Val Loss: 0.088088
2025-09-02 08:08:18,301 - INFO - Epoch 2063/5000 - Train Loss: 0.102168, Val Loss: 0.089895
2025-09-02 08:08:43,983 - INFO - Epoch 2064/5000 - Train Loss: 0.102036, Val Loss: 0.086834
2025-09-02 08:09:09,284 - INFO - Epoch 2065/5000 - Train Loss: 0.102056, Val Loss: 0.087812
2025-09-02 08:09:35,165 - INFO - Epoch 2066/5000 - Train Loss: 0.103118, Val Loss: 0.091467
2025-09-02 08:10:00,624 - INFO - Epoch 2067/5000 - Train Loss: 0.103398, Val Loss: 0.088125
2025-09-02 08:10:26,223 - INFO - Epoch 2068/5000 - Train Loss: 0.102320, Val Loss: 0.088480
2025-09-02 08:10:51,723 - INFO - Epoch 2069/5000 - Train Loss: 0.101602, Val Loss: 0.087817
2025-09-02 08:11:17,287 - INFO - Epoch 2070/5000 - Train Loss: 0.102244, Val Loss: 0.089800
2025-09-02 08:11:42,965 - INFO - Epoch 2071/5000 - Train Loss: 0.103518, Val Loss: 0.092165
2025-09-02 08:12:08,456 - INFO - Epoch 2072/5000 - Train Loss: 0.102689, Val Loss: 0.091872
2025-09-02 08:12:33,779 - INFO - Epoch 2073/5000 - Train Loss: 0.102774, Val Loss: 0.087734
2025-09-02 08:12:59,073 - INFO - Epoch 2074/5000 - Train Loss: 0.101798, Val Loss: 0.087285
2025-09-02 08:13:24,447 - INFO - Epoch 2075/5000 - Train Loss: 0.102020, Val Loss: 0.086428
2025-09-02 08:13:50,257 - INFO - Epoch 2076/5000 - Train Loss: 0.102364, Val Loss: 0.086961
2025-09-02 08:14:15,739 - INFO - Epoch 2077/5000 - Train Loss: 0.102169, Val Loss: 0.090988
2025-09-02 08:14:41,511 - INFO - Epoch 2078/5000 - Train Loss: 0.102039, Val Loss: 0.089093
2025-09-02 08:15:07,198 - INFO - Epoch 2079/5000 - Train Loss: 0.102638, Val Loss: 0.091344
2025-09-02 08:15:32,590 - INFO - Epoch 2080/5000 - Train Loss: 0.102714, Val Loss: 0.091991
2025-09-02 08:15:58,152 - INFO - Epoch 2081/5000 - Train Loss: 0.102674, Val Loss: 0.089661
2025-09-02 08:16:23,446 - INFO - Epoch 2082/5000 - Train Loss: 0.102422, Val Loss: 0.091452
2025-09-02 08:16:49,028 - INFO - Epoch 2083/5000 - Train Loss: 0.102381, Val Loss: 0.088755
2025-09-02 08:17:14,731 - INFO - Epoch 2084/5000 - Train Loss: 0.101971, Val Loss: 0.087886
2025-09-02 08:17:40,119 - INFO - Epoch 2085/5000 - Train Loss: 0.102038, Val Loss: 0.086516
2025-09-02 08:18:05,493 - INFO - Epoch 2086/5000 - Train Loss: 0.101260, Val Loss: 0.087560
2025-09-02 08:18:31,332 - INFO - Epoch 2087/5000 - Train Loss: 0.102920, Val Loss: 0.089130
2025-09-02 08:18:56,798 - INFO - Epoch 2088/5000 - Train Loss: 0.101226, Val Loss: 0.086317
2025-09-02 08:19:22,371 - INFO - Epoch 2089/5000 - Train Loss: 0.101354, Val Loss: 0.087166
2025-09-02 08:19:47,859 - INFO - Epoch 2090/5000 - Train Loss: 0.100714, Val Loss: 0.089874
2025-09-02 08:20:13,418 - INFO - Epoch 2091/5000 - Train Loss: 0.099459, Val Loss: 0.088655
2025-09-02 08:20:38,984 - INFO - Epoch 2092/5000 - Train Loss: 0.101954, Val Loss: 0.090302
2025-09-02 08:21:04,491 - INFO - Epoch 2093/5000 - Train Loss: 0.102190, Val Loss: 0.087345
2025-09-02 08:21:30,067 - INFO - Epoch 2094/5000 - Train Loss: 0.100665, Val Loss: 0.087376
2025-09-02 08:21:55,752 - INFO - Epoch 2095/5000 - Train Loss: 0.101891, Val Loss: 0.086881
2025-09-02 08:22:21,340 - INFO - Epoch 2096/5000 - Train Loss: 0.101715, Val Loss: 0.089491
2025-09-02 08:22:47,256 - INFO - Epoch 2097/5000 - Train Loss: 0.101300, Val Loss: 0.088806
2025-09-02 08:23:13,072 - INFO - Epoch 2098/5000 - Train Loss: 0.101299, Val Loss: 0.086784
2025-09-02 08:23:38,832 - INFO - Epoch 2099/5000 - Train Loss: 0.101706, Val Loss: 0.089879
2025-09-02 08:24:04,564 - INFO - Epoch 2100/5000 - Train Loss: 0.103766, Val Loss: 0.088162
2025-09-02 08:24:30,340 - INFO - Epoch 2101/5000 - Train Loss: 0.100957, Val Loss: 0.085775
2025-09-02 08:24:30,370 - INFO - New best model saved with Val Loss: 0.085775
2025-09-02 08:24:56,046 - INFO - Epoch 2102/5000 - Train Loss: 0.101386, Val Loss: 0.088058
2025-09-02 08:25:21,921 - INFO - Epoch 2103/5000 - Train Loss: 0.100867, Val Loss: 0.085454
2025-09-02 08:25:21,941 - INFO - New best model saved with Val Loss: 0.085454
2025-09-02 08:25:47,583 - INFO - Epoch 2104/5000 - Train Loss: 0.101659, Val Loss: 0.086249
2025-09-02 08:26:13,364 - INFO - Epoch 2105/5000 - Train Loss: 0.100570, Val Loss: 0.086657
2025-09-02 08:26:39,293 - INFO - Epoch 2106/5000 - Train Loss: 0.101578, Val Loss: 0.086047
2025-09-02 08:27:04,980 - INFO - Epoch 2107/5000 - Train Loss: 0.100750, Val Loss: 0.089066
2025-09-02 08:27:30,826 - INFO - Epoch 2108/5000 - Train Loss: 0.101173, Val Loss: 0.088573
2025-09-02 08:27:56,302 - INFO - Epoch 2109/5000 - Train Loss: 0.100791, Val Loss: 0.086192
2025-09-02 08:28:22,079 - INFO - Epoch 2110/5000 - Train Loss: 0.100993, Val Loss: 0.088236
2025-09-02 08:28:48,257 - INFO - Epoch 2111/5000 - Train Loss: 0.101227, Val Loss: 0.086165
2025-09-02 08:29:13,853 - INFO - Epoch 2112/5000 - Train Loss: 0.100918, Val Loss: 0.088369
2025-09-02 08:29:39,633 - INFO - Epoch 2113/5000 - Train Loss: 0.101310, Val Loss: 0.086667
2025-09-02 08:30:05,148 - INFO - Epoch 2114/5000 - Train Loss: 0.100749, Val Loss: 0.089422
2025-09-02 08:30:30,768 - INFO - Epoch 2115/5000 - Train Loss: 0.100324, Val Loss: 0.086148
2025-09-02 08:30:56,524 - INFO - Epoch 2116/5000 - Train Loss: 0.101101, Val Loss: 0.087938
2025-09-02 08:31:22,161 - INFO - Epoch 2117/5000 - Train Loss: 0.100608, Val Loss: 0.088716
2025-09-02 08:31:47,877 - INFO - Epoch 2118/5000 - Train Loss: 0.100622, Val Loss: 0.088970
2025-09-02 08:32:13,463 - INFO - Epoch 2119/5000 - Train Loss: 0.100924, Val Loss: 0.087211
2025-09-02 08:32:39,103 - INFO - Epoch 2120/5000 - Train Loss: 0.100540, Val Loss: 0.089986
2025-09-02 08:33:04,520 - INFO - Epoch 2121/5000 - Train Loss: 0.102610, Val Loss: 0.089083
2025-09-02 08:33:30,288 - INFO - Epoch 2122/5000 - Train Loss: 0.099819, Val Loss: 0.086579
2025-09-02 08:33:55,905 - INFO - Epoch 2123/5000 - Train Loss: 0.100768, Val Loss: 0.089031
2025-09-02 08:34:21,597 - INFO - Epoch 2124/5000 - Train Loss: 0.101194, Val Loss: 0.088979
2025-09-02 08:34:47,279 - INFO - Epoch 2125/5000 - Train Loss: 0.101355, Val Loss: 0.085908
2025-09-02 08:35:12,366 - INFO - Epoch 2126/5000 - Train Loss: 0.099576, Val Loss: 0.086932
2025-09-02 08:35:37,960 - INFO - Epoch 2127/5000 - Train Loss: 0.100537, Val Loss: 0.092910
2025-09-02 08:36:03,330 - INFO - Epoch 2128/5000 - Train Loss: 0.102466, Val Loss: 0.087929
2025-09-02 08:36:28,800 - INFO - Epoch 2129/5000 - Train Loss: 0.099594, Val Loss: 0.087945
2025-09-02 08:36:54,466 - INFO - Epoch 2130/5000 - Train Loss: 0.100028, Val Loss: 0.089577
2025-09-02 08:37:20,512 - INFO - Epoch 2131/5000 - Train Loss: 0.099995, Val Loss: 0.085169
2025-09-02 08:37:20,548 - INFO - New best model saved with Val Loss: 0.085169
2025-09-02 08:37:46,135 - INFO - Epoch 2132/5000 - Train Loss: 0.099869, Val Loss: 0.089016
2025-09-02 08:38:12,044 - INFO - Epoch 2133/5000 - Train Loss: 0.101677, Val Loss: 0.090424
2025-09-02 08:38:37,910 - INFO - Epoch 2134/5000 - Train Loss: 0.100620, Val Loss: 0.086125
2025-09-02 08:39:03,576 - INFO - Epoch 2135/5000 - Train Loss: 0.101037, Val Loss: 0.086763
2025-09-02 08:39:29,046 - INFO - Epoch 2136/5000 - Train Loss: 0.100902, Val Loss: 0.088419
2025-09-02 08:39:54,666 - INFO - Epoch 2137/5000 - Train Loss: 0.100122, Val Loss: 0.089670
2025-09-02 08:40:20,445 - INFO - Epoch 2138/5000 - Train Loss: 0.101032, Val Loss: 0.085717
2025-09-02 08:40:46,198 - INFO - Epoch 2139/5000 - Train Loss: 0.101606, Val Loss: 0.087595
2025-09-02 08:41:11,755 - INFO - Epoch 2140/5000 - Train Loss: 0.100210, Val Loss: 0.084961
2025-09-02 08:41:11,776 - INFO - New best model saved with Val Loss: 0.084961
2025-09-02 08:41:37,572 - INFO - Epoch 2141/5000 - Train Loss: 0.099450, Val Loss: 0.087529
2025-09-02 08:42:03,224 - INFO - Epoch 2142/5000 - Train Loss: 0.100551, Val Loss: 0.086853
2025-09-02 08:42:29,031 - INFO - Epoch 2143/5000 - Train Loss: 0.099584, Val Loss: 0.084854
2025-09-02 08:42:29,051 - INFO - New best model saved with Val Loss: 0.084854
2025-09-02 08:42:54,441 - INFO - Epoch 2144/5000 - Train Loss: 0.099346, Val Loss: 0.086863
2025-09-02 08:43:20,000 - INFO - Epoch 2145/5000 - Train Loss: 0.101772, Val Loss: 0.087263
2025-09-02 08:43:45,462 - INFO - Epoch 2146/5000 - Train Loss: 0.100434, Val Loss: 0.085631
2025-09-02 08:44:11,088 - INFO - Epoch 2147/5000 - Train Loss: 0.100271, Val Loss: 0.085522
2025-09-02 08:44:36,640 - INFO - Epoch 2148/5000 - Train Loss: 0.099827, Val Loss: 0.086277
2025-09-02 08:45:01,938 - INFO - Epoch 2149/5000 - Train Loss: 0.098977, Val Loss: 0.086281
2025-09-02 08:45:27,588 - INFO - Epoch 2150/5000 - Train Loss: 0.099331, Val Loss: 0.084920
2025-09-02 08:45:53,258 - INFO - Epoch 2151/5000 - Train Loss: 0.099915, Val Loss: 0.084969
2025-09-02 08:46:18,797 - INFO - Epoch 2152/5000 - Train Loss: 0.099353, Val Loss: 0.085162
2025-09-02 08:46:44,448 - INFO - Epoch 2153/5000 - Train Loss: 0.099986, Val Loss: 0.086408
2025-09-02 08:47:10,018 - INFO - Epoch 2154/5000 - Train Loss: 0.100765, Val Loss: 0.086413
2025-09-02 08:47:35,611 - INFO - Epoch 2155/5000 - Train Loss: 0.099158, Val Loss: 0.084973
2025-09-02 08:48:01,256 - INFO - Epoch 2156/5000 - Train Loss: 0.100130, Val Loss: 0.088539
2025-09-02 08:48:26,830 - INFO - Epoch 2157/5000 - Train Loss: 0.098516, Val Loss: 0.084788
2025-09-02 08:48:26,850 - INFO - New best model saved with Val Loss: 0.084788
2025-09-02 08:48:52,269 - INFO - Epoch 2158/5000 - Train Loss: 0.099484, Val Loss: 0.085137
2025-09-02 08:49:18,035 - INFO - Epoch 2159/5000 - Train Loss: 0.099258, Val Loss: 0.086138
2025-09-02 08:49:43,624 - INFO - Epoch 2160/5000 - Train Loss: 0.098772, Val Loss: 0.084134
2025-09-02 08:49:43,667 - INFO - New best model saved with Val Loss: 0.084134
2025-09-02 08:50:09,468 - INFO - Epoch 2161/5000 - Train Loss: 0.099689, Val Loss: 0.086467
2025-09-02 08:50:35,335 - INFO - Epoch 2162/5000 - Train Loss: 0.100040, Val Loss: 0.085875
2025-09-02 08:51:01,002 - INFO - Epoch 2163/5000 - Train Loss: 0.099581, Val Loss: 0.088017
2025-09-02 08:51:26,723 - INFO - Epoch 2164/5000 - Train Loss: 0.098850, Val Loss: 0.085745
2025-09-02 08:51:52,342 - INFO - Epoch 2165/5000 - Train Loss: 0.098907, Val Loss: 0.085752
2025-09-02 08:52:17,944 - INFO - Epoch 2166/5000 - Train Loss: 0.100975, Val Loss: 0.086413
2025-09-02 08:52:43,828 - INFO - Epoch 2167/5000 - Train Loss: 0.099818, Val Loss: 0.086128
2025-09-02 08:53:09,410 - INFO - Epoch 2168/5000 - Train Loss: 0.098386, Val Loss: 0.085489
2025-09-02 08:53:35,220 - INFO - Epoch 2169/5000 - Train Loss: 0.099720, Val Loss: 0.085965
2025-09-02 08:54:00,851 - INFO - Epoch 2170/5000 - Train Loss: 0.098856, Val Loss: 0.084003
2025-09-02 08:54:00,872 - INFO - New best model saved with Val Loss: 0.084003
2025-09-02 08:54:26,748 - INFO - Epoch 2171/5000 - Train Loss: 0.099894, Val Loss: 0.089577
2025-09-02 08:54:52,312 - INFO - Epoch 2172/5000 - Train Loss: 0.099641, Val Loss: 0.089559
2025-09-02 08:55:18,171 - INFO - Epoch 2173/5000 - Train Loss: 0.102483, Val Loss: 0.087434
2025-09-02 08:55:43,679 - INFO - Epoch 2174/5000 - Train Loss: 0.099866, Val Loss: 0.086953
2025-09-02 08:56:09,584 - INFO - Epoch 2175/5000 - Train Loss: 0.099202, Val Loss: 0.085622
2025-09-02 08:56:35,360 - INFO - Epoch 2176/5000 - Train Loss: 0.100487, Val Loss: 0.091391
2025-09-02 08:57:00,731 - INFO - Epoch 2177/5000 - Train Loss: 0.098004, Val Loss: 0.084867
2025-09-02 08:57:26,249 - INFO - Epoch 2178/5000 - Train Loss: 0.098280, Val Loss: 0.086711
2025-09-02 08:57:51,868 - INFO - Epoch 2179/5000 - Train Loss: 0.098369, Val Loss: 0.083557
2025-09-02 08:57:51,891 - INFO - New best model saved with Val Loss: 0.083557
2025-09-02 08:58:17,583 - INFO - Epoch 2180/5000 - Train Loss: 0.098749, Val Loss: 0.087905
2025-09-02 08:58:43,340 - INFO - Epoch 2181/5000 - Train Loss: 0.099377, Val Loss: 0.086098
2025-09-02 08:59:08,802 - INFO - Epoch 2182/5000 - Train Loss: 0.099404, Val Loss: 0.086334
2025-09-02 08:59:34,777 - INFO - Epoch 2183/5000 - Train Loss: 0.099074, Val Loss: 0.085669
2025-09-02 09:00:00,615 - INFO - Epoch 2184/5000 - Train Loss: 0.099498, Val Loss: 0.089386
2025-09-02 09:00:26,097 - INFO - Epoch 2185/5000 - Train Loss: 0.098908, Val Loss: 0.087798
2025-09-02 09:00:51,930 - INFO - Epoch 2186/5000 - Train Loss: 0.099679, Val Loss: 0.091243
2025-09-02 09:01:17,721 - INFO - Epoch 2187/5000 - Train Loss: 0.099083, Val Loss: 0.088071
2025-09-02 09:01:43,267 - INFO - Epoch 2188/5000 - Train Loss: 0.098787, Val Loss: 0.086190
2025-09-02 09:02:08,858 - INFO - Epoch 2189/5000 - Train Loss: 0.098737, Val Loss: 0.083872
2025-09-02 09:02:34,679 - INFO - Epoch 2190/5000 - Train Loss: 0.098833, Val Loss: 0.086797
2025-09-02 09:03:00,337 - INFO - Epoch 2191/5000 - Train Loss: 0.098818, Val Loss: 0.087145
2025-09-02 09:03:26,052 - INFO - Epoch 2192/5000 - Train Loss: 0.098927, Val Loss: 0.084709
2025-09-02 09:03:51,421 - INFO - Epoch 2193/5000 - Train Loss: 0.097437, Val Loss: 0.085607
2025-09-02 09:04:16,995 - INFO - Epoch 2194/5000 - Train Loss: 0.098797, Val Loss: 0.085955
2025-09-02 09:04:42,309 - INFO - Epoch 2195/5000 - Train Loss: 0.098248, Val Loss: 0.085286
2025-09-02 09:05:08,021 - INFO - Epoch 2196/5000 - Train Loss: 0.098118, Val Loss: 0.085671
2025-09-02 09:05:33,683 - INFO - Epoch 2197/5000 - Train Loss: 0.098873, Val Loss: 0.084064
2025-09-02 09:05:59,368 - INFO - Epoch 2198/5000 - Train Loss: 0.097837, Val Loss: 0.085848
2025-09-02 09:06:24,870 - INFO - Epoch 2199/5000 - Train Loss: 0.099110, Val Loss: 0.086984
2025-09-02 09:06:50,576 - INFO - Epoch 2200/5000 - Train Loss: 0.098250, Val Loss: 0.086188
2025-09-02 09:07:16,491 - INFO - Epoch 2201/5000 - Train Loss: 0.099008, Val Loss: 0.086147
2025-09-02 09:07:42,355 - INFO - Epoch 2202/5000 - Train Loss: 0.098676, Val Loss: 0.083832
2025-09-02 09:08:08,002 - INFO - Epoch 2203/5000 - Train Loss: 0.098573, Val Loss: 0.084335
2025-09-02 09:11:47,915 - INFO - args.exp_name : Test
2025-09-02 09:11:47,918 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 5000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-02 09:11:47,918 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-02 09:11:48,296 - INFO - Total trainable parameters: 2286017
2025-09-02 09:11:48,548 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-02 09:11:48,549 - INFO - Staring training for 5000 epochs
2025-09-02 09:11:54,552 - INFO - [35m x.shape: torch.Size([6, 10000, 515]) [0m
2025-09-02 09:13:07,014 - INFO - args.exp_name : Test
2025-09-02 09:13:07,015 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 5000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-02 09:13:07,015 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-02 09:13:07,381 - INFO - Total trainable parameters: 2289857
2025-09-02 09:13:07,622 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-02 09:13:07,623 - INFO - Staring training for 5000 epochs
2025-09-02 09:15:50,449 - INFO - args.exp_name : Test
2025-09-02 09:15:50,455 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 5000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-02 09:15:50,455 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-02 09:15:51,106 - INFO - Total trainable parameters: 2289857
2025-09-02 09:15:51,475 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-02 09:15:51,479 - INFO - Staring training for 5000 epochs
2025-09-02 09:16:55,174 - INFO - args.exp_name : Test
2025-09-02 09:16:55,178 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 5000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-02 09:16:55,178 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-02 09:16:55,749 - INFO - Total trainable parameters: 2289857
2025-09-02 09:16:56,117 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-02 09:16:56,122 - INFO - Staring training for 5000 epochs
2025-09-02 09:19:14,771 - INFO - args.exp_name : Test
2025-09-02 09:19:14,777 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM/Cache_data',
  'dataset_path': '/work/mae-zhangbj/DrivAriNet_dataset/Pressure_Field/E_S_WWC_WM',
  'downsample': 5,
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 5000,
  'exp_name': 'Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'max_grad_norm': 0.1,
  'mlp_ratio': 1,
  'model': 'Transolver_Irregular_Mesh',
  'n_heads': 8,
  'n_hidden': 128,
  'n_layers': 8,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'ref': 8,
  'seed': 1,
  'slice_num': 64,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/Current_Work/Pressure_Field/train_val_test_splits',
  'test_only': 0,
  'unified_pos': 1,
  'weight_decay': 1e-05}
2025-09-02 09:19:14,777 - INFO - [31m*******************************Starting training with 1 GPUs[0m
2025-09-02 09:19:15,381 - INFO - Total trainable parameters: 2289857
2025-09-02 09:19:15,754 - INFO - Data loaded: 77 training batches, 17 validation batches, 19 test batches
2025-09-02 09:19:15,758 - INFO - Staring training for 5000 epochs
2025-09-02 09:19:54,450 - INFO - Epoch 1/5000 - Train Loss: 1.061547, Val Loss: 1.023116
2025-09-02 09:19:54,504 - INFO - New best model saved with Val Loss: 1.023116
2025-09-02 09:20:32,166 - INFO - Epoch 2/5000 - Train Loss: 0.899642, Val Loss: 0.745629
2025-09-02 09:20:32,201 - INFO - New best model saved with Val Loss: 0.745629
2025-09-02 09:21:09,679 - INFO - Epoch 3/5000 - Train Loss: 0.715130, Val Loss: 0.672672
2025-09-02 09:21:09,715 - INFO - New best model saved with Val Loss: 0.672672
2025-09-02 09:21:47,348 - INFO - Epoch 4/5000 - Train Loss: 0.659714, Val Loss: 0.663620
2025-09-02 09:21:47,383 - INFO - New best model saved with Val Loss: 0.663620
2025-09-02 09:22:26,775 - INFO - Epoch 5/5000 - Train Loss: 0.642227, Val Loss: 0.636938
2025-09-02 09:22:26,811 - INFO - New best model saved with Val Loss: 0.636938
2025-09-02 09:23:04,569 - INFO - Epoch 6/5000 - Train Loss: 0.624438, Val Loss: 0.617383
2025-09-02 09:23:04,604 - INFO - New best model saved with Val Loss: 0.617383
2025-09-02 09:23:42,278 - INFO - Epoch 7/5000 - Train Loss: 0.608651, Val Loss: 0.608165
2025-09-02 09:23:42,312 - INFO - New best model saved with Val Loss: 0.608165
2025-09-02 09:24:20,402 - INFO - Epoch 8/5000 - Train Loss: 0.600870, Val Loss: 0.588570
2025-09-02 09:24:20,437 - INFO - New best model saved with Val Loss: 0.588570
2025-09-02 09:24:58,078 - INFO - Epoch 9/5000 - Train Loss: 0.582603, Val Loss: 0.586546
2025-09-02 09:24:58,113 - INFO - New best model saved with Val Loss: 0.586546
2025-09-02 09:25:35,112 - INFO - Epoch 10/5000 - Train Loss: 0.575182, Val Loss: 0.568984
2025-09-02 09:25:35,148 - INFO - New best model saved with Val Loss: 0.568984
2025-09-02 09:26:13,422 - INFO - Epoch 11/5000 - Train Loss: 0.565400, Val Loss: 0.558393
2025-09-02 09:26:13,458 - INFO - New best model saved with Val Loss: 0.558393
2025-09-02 09:26:51,476 - INFO - Epoch 12/5000 - Train Loss: 0.561100, Val Loss: 0.553744
2025-09-02 09:26:51,511 - INFO - New best model saved with Val Loss: 0.553744
2025-09-02 09:27:28,893 - INFO - Epoch 13/5000 - Train Loss: 0.552990, Val Loss: 0.548885
2025-09-02 09:27:28,929 - INFO - New best model saved with Val Loss: 0.548885
2025-09-02 09:28:07,293 - INFO - Epoch 14/5000 - Train Loss: 0.547529, Val Loss: 0.545516
2025-09-02 09:28:07,328 - INFO - New best model saved with Val Loss: 0.545516
2025-09-02 09:28:45,656 - INFO - Epoch 15/5000 - Train Loss: 0.541506, Val Loss: 0.537185
2025-09-02 09:28:45,689 - INFO - New best model saved with Val Loss: 0.537185
2025-09-02 09:29:22,392 - INFO - Epoch 16/5000 - Train Loss: 0.541237, Val Loss: 0.533496
2025-09-02 09:29:22,426 - INFO - New best model saved with Val Loss: 0.533496
2025-09-02 09:30:00,057 - INFO - Epoch 17/5000 - Train Loss: 0.532935, Val Loss: 0.529623
2025-09-02 09:30:00,092 - INFO - New best model saved with Val Loss: 0.529623
2025-09-02 09:30:37,687 - INFO - Epoch 18/5000 - Train Loss: 0.529858, Val Loss: 0.518180
2025-09-02 09:30:37,736 - INFO - New best model saved with Val Loss: 0.518180
2025-09-02 09:31:15,730 - INFO - Epoch 19/5000 - Train Loss: 0.522536, Val Loss: 0.514190
2025-09-02 09:31:15,781 - INFO - New best model saved with Val Loss: 0.514190
2025-09-02 09:31:53,219 - INFO - Epoch 20/5000 - Train Loss: 0.517915, Val Loss: 0.505744
2025-09-02 09:31:53,253 - INFO - New best model saved with Val Loss: 0.505744
2025-09-02 09:32:31,520 - INFO - Epoch 21/5000 - Train Loss: 0.516164, Val Loss: 0.515786
2025-09-02 09:33:10,716 - INFO - Epoch 22/5000 - Train Loss: 0.512932, Val Loss: 0.501573
2025-09-02 09:33:10,751 - INFO - New best model saved with Val Loss: 0.501573
2025-09-02 09:33:48,562 - INFO - Epoch 23/5000 - Train Loss: 0.509424, Val Loss: 0.517192
2025-09-02 09:34:26,075 - INFO - Epoch 24/5000 - Train Loss: 0.511783, Val Loss: 0.498084
2025-09-02 09:34:26,109 - INFO - New best model saved with Val Loss: 0.498084
2025-09-02 09:35:03,588 - INFO - Epoch 25/5000 - Train Loss: 0.501604, Val Loss: 0.489816
2025-09-02 09:35:03,622 - INFO - New best model saved with Val Loss: 0.489816
2025-09-02 09:35:41,871 - INFO - Epoch 26/5000 - Train Loss: 0.500068, Val Loss: 0.515652
2025-09-02 09:36:20,014 - INFO - Epoch 27/5000 - Train Loss: 0.498936, Val Loss: 0.496972
2025-09-02 09:36:58,090 - INFO - Epoch 28/5000 - Train Loss: 0.497842, Val Loss: 0.496082
2025-09-02 09:37:35,978 - INFO - Epoch 29/5000 - Train Loss: 0.494554, Val Loss: 0.489483
2025-09-02 09:37:36,029 - INFO - New best model saved with Val Loss: 0.489483
2025-09-02 09:38:13,174 - INFO - Epoch 30/5000 - Train Loss: 0.488900, Val Loss: 0.485122
2025-09-02 09:38:13,208 - INFO - New best model saved with Val Loss: 0.485122
2025-09-02 09:38:50,052 - INFO - Epoch 31/5000 - Train Loss: 0.486475, Val Loss: 0.478877
2025-09-02 09:38:50,087 - INFO - New best model saved with Val Loss: 0.478877
2025-09-02 09:39:27,722 - INFO - Epoch 32/5000 - Train Loss: 0.494374, Val Loss: 0.478183
2025-09-02 09:39:27,755 - INFO - New best model saved with Val Loss: 0.478183
2025-09-02 09:40:05,673 - INFO - Epoch 33/5000 - Train Loss: 0.487270, Val Loss: 0.478619
2025-09-02 09:40:43,102 - INFO - Epoch 34/5000 - Train Loss: 0.486291, Val Loss: 0.483144
2025-09-02 09:41:20,498 - INFO - Epoch 35/5000 - Train Loss: 0.485177, Val Loss: 0.479013
2025-09-02 09:41:57,407 - INFO - Epoch 36/5000 - Train Loss: 0.483900, Val Loss: 0.492507
2025-09-02 09:42:34,129 - INFO - Epoch 37/5000 - Train Loss: 0.488882, Val Loss: 0.479906
2025-09-02 09:43:10,923 - INFO - Epoch 38/5000 - Train Loss: 0.481515, Val Loss: 0.472324
2025-09-02 09:43:10,983 - INFO - New best model saved with Val Loss: 0.472324
2025-09-02 09:43:48,089 - INFO - Epoch 39/5000 - Train Loss: 0.476565, Val Loss: 0.471686
2025-09-02 09:43:48,122 - INFO - New best model saved with Val Loss: 0.471686
2025-09-02 09:44:25,725 - INFO - Epoch 40/5000 - Train Loss: 0.475514, Val Loss: 0.472823
2025-09-02 09:45:03,255 - INFO - Epoch 41/5000 - Train Loss: 0.473430, Val Loss: 0.468034
2025-09-02 09:45:03,290 - INFO - New best model saved with Val Loss: 0.468034
2025-09-02 09:45:40,594 - INFO - Epoch 42/5000 - Train Loss: 0.474007, Val Loss: 0.482726
2025-09-02 09:46:18,937 - INFO - Epoch 43/5000 - Train Loss: 0.474740, Val Loss: 0.465259
2025-09-02 09:46:18,970 - INFO - New best model saved with Val Loss: 0.465259
2025-09-02 09:46:58,456 - INFO - Epoch 44/5000 - Train Loss: 0.470803, Val Loss: 0.465708
2025-09-02 09:47:36,657 - INFO - Epoch 45/5000 - Train Loss: 0.473530, Val Loss: 0.463029
2025-09-02 09:47:36,692 - INFO - New best model saved with Val Loss: 0.463029
2025-09-02 09:48:13,506 - INFO - Epoch 46/5000 - Train Loss: 0.467628, Val Loss: 0.472009
2025-09-02 09:48:51,311 - INFO - Epoch 47/5000 - Train Loss: 0.470032, Val Loss: 0.465063
2025-09-02 09:49:29,418 - INFO - Epoch 48/5000 - Train Loss: 0.468664, Val Loss: 0.471989
2025-09-02 09:50:06,764 - INFO - Epoch 49/5000 - Train Loss: 0.471180, Val Loss: 0.464487
2025-09-02 09:50:45,094 - INFO - Epoch 50/5000 - Train Loss: 0.466334, Val Loss: 0.461579
2025-09-02 09:50:45,129 - INFO - New best model saved with Val Loss: 0.461579
2025-09-02 09:51:22,947 - INFO - Epoch 51/5000 - Train Loss: 0.466315, Val Loss: 0.458711
2025-09-02 09:51:22,981 - INFO - New best model saved with Val Loss: 0.458711
2025-09-02 09:52:01,360 - INFO - Epoch 52/5000 - Train Loss: 0.464935, Val Loss: 0.458151
2025-09-02 09:52:01,396 - INFO - New best model saved with Val Loss: 0.458151
2025-09-02 09:52:39,794 - INFO - Epoch 53/5000 - Train Loss: 0.467291, Val Loss: 0.455315
2025-09-02 09:52:39,827 - INFO - New best model saved with Val Loss: 0.455315
2025-09-02 09:53:17,845 - INFO - Epoch 54/5000 - Train Loss: 0.460796, Val Loss: 0.465940
2025-09-02 09:53:56,288 - INFO - Epoch 55/5000 - Train Loss: 0.458739, Val Loss: 0.456478
2025-09-02 09:54:33,947 - INFO - Epoch 56/5000 - Train Loss: 0.459626, Val Loss: 0.458760
2025-09-02 09:55:12,142 - INFO - Epoch 57/5000 - Train Loss: 0.458748, Val Loss: 0.457125
2025-09-02 09:55:50,445 - INFO - Epoch 58/5000 - Train Loss: 0.458489, Val Loss: 0.453858
2025-09-02 09:55:50,480 - INFO - New best model saved with Val Loss: 0.453858
2025-09-02 09:56:28,112 - INFO - Epoch 59/5000 - Train Loss: 0.455907, Val Loss: 0.448728
2025-09-02 09:56:28,145 - INFO - New best model saved with Val Loss: 0.448728
2025-09-02 09:57:08,175 - INFO - Epoch 60/5000 - Train Loss: 0.455033, Val Loss: 0.445598
2025-09-02 09:57:08,208 - INFO - New best model saved with Val Loss: 0.445598
2025-09-02 09:57:46,955 - INFO - Epoch 61/5000 - Train Loss: 0.456410, Val Loss: 0.454831
2025-09-02 09:58:25,770 - INFO - Epoch 62/5000 - Train Loss: 0.454319, Val Loss: 0.457748
2025-09-02 09:59:04,463 - INFO - Epoch 63/5000 - Train Loss: 0.451683, Val Loss: 0.447287
2025-09-02 09:59:41,379 - INFO - Epoch 64/5000 - Train Loss: 0.453574, Val Loss: 0.448328
2025-09-02 10:00:18,753 - INFO - Epoch 65/5000 - Train Loss: 0.452561, Val Loss: 0.450666
2025-09-02 10:00:57,431 - INFO - Epoch 66/5000 - Train Loss: 0.453600, Val Loss: 0.465525
2025-09-02 10:01:36,266 - INFO - Epoch 67/5000 - Train Loss: 0.450279, Val Loss: 0.456446
2025-09-02 10:02:15,912 - INFO - Epoch 68/5000 - Train Loss: 0.452759, Val Loss: 0.452553
2025-09-02 10:02:54,855 - INFO - Epoch 69/5000 - Train Loss: 0.449513, Val Loss: 0.447333
2025-09-02 10:03:33,057 - INFO - Epoch 70/5000 - Train Loss: 0.447033, Val Loss: 0.438826
2025-09-02 10:03:33,092 - INFO - New best model saved with Val Loss: 0.438826
2025-09-02 10:04:11,200 - INFO - Epoch 71/5000 - Train Loss: 0.444311, Val Loss: 0.441608
2025-09-02 10:04:49,122 - INFO - Epoch 72/5000 - Train Loss: 0.447404, Val Loss: 0.451389
2025-09-02 10:05:26,819 - INFO - Epoch 73/5000 - Train Loss: 0.444644, Val Loss: 0.437146
2025-09-02 10:05:26,852 - INFO - New best model saved with Val Loss: 0.437146
2025-09-02 10:06:05,722 - INFO - Epoch 74/5000 - Train Loss: 0.449065, Val Loss: 0.454651
2025-09-02 10:06:44,487 - INFO - Epoch 75/5000 - Train Loss: 0.443031, Val Loss: 0.436829
2025-09-02 10:06:44,520 - INFO - New best model saved with Val Loss: 0.436829
2025-09-02 10:07:22,244 - INFO - Epoch 76/5000 - Train Loss: 0.451699, Val Loss: 0.441291
2025-09-02 10:08:01,042 - INFO - Epoch 77/5000 - Train Loss: 0.444742, Val Loss: 0.441609
2025-09-02 10:08:39,910 - INFO - Epoch 78/5000 - Train Loss: 0.439588, Val Loss: 0.436618
2025-09-02 10:08:39,945 - INFO - New best model saved with Val Loss: 0.436618
2025-09-02 10:09:18,197 - INFO - Epoch 79/5000 - Train Loss: 0.437168, Val Loss: 0.432535
2025-09-02 10:09:18,230 - INFO - New best model saved with Val Loss: 0.432535
2025-09-02 10:09:56,366 - INFO - Epoch 80/5000 - Train Loss: 0.438018, Val Loss: 0.439033
2025-09-02 10:10:34,993 - INFO - Epoch 81/5000 - Train Loss: 0.436594, Val Loss: 0.433232
2025-09-02 10:11:13,962 - INFO - Epoch 82/5000 - Train Loss: 0.434339, Val Loss: 0.453307
2025-09-02 10:11:53,107 - INFO - Epoch 83/5000 - Train Loss: 0.437914, Val Loss: 0.456331
2025-09-02 10:12:31,353 - INFO - Epoch 84/5000 - Train Loss: 0.491445, Val Loss: 0.444967
2025-09-02 10:13:11,179 - INFO - Epoch 85/5000 - Train Loss: 0.434135, Val Loss: 0.432407
2025-09-02 10:13:11,212 - INFO - New best model saved with Val Loss: 0.432407
2025-09-02 10:13:49,443 - INFO - Epoch 86/5000 - Train Loss: 0.430418, Val Loss: 0.434314
2025-09-02 10:14:28,908 - INFO - Epoch 87/5000 - Train Loss: 0.432106, Val Loss: 0.431006
2025-09-02 10:14:28,941 - INFO - New best model saved with Val Loss: 0.431006
2025-09-02 10:15:07,404 - INFO - Epoch 88/5000 - Train Loss: 0.431551, Val Loss: 0.427545
2025-09-02 10:15:07,439 - INFO - New best model saved with Val Loss: 0.427545
2025-09-02 10:15:45,449 - INFO - Epoch 89/5000 - Train Loss: 0.428915, Val Loss: 0.433231
2025-09-02 10:16:23,789 - INFO - Epoch 90/5000 - Train Loss: 0.433309, Val Loss: 0.421681
2025-09-02 10:16:23,822 - INFO - New best model saved with Val Loss: 0.421681
2025-09-02 10:17:03,570 - INFO - Epoch 91/5000 - Train Loss: 0.426633, Val Loss: 0.425146
2025-09-02 10:17:43,378 - INFO - Epoch 92/5000 - Train Loss: 0.426541, Val Loss: 0.419066
2025-09-02 10:17:43,411 - INFO - New best model saved with Val Loss: 0.419066
2025-09-02 10:18:21,875 - INFO - Epoch 93/5000 - Train Loss: 0.426042, Val Loss: 0.419804
2025-09-02 10:19:00,336 - INFO - Epoch 94/5000 - Train Loss: 0.432611, Val Loss: 0.422773
2025-09-02 10:19:39,381 - INFO - Epoch 95/5000 - Train Loss: 0.429117, Val Loss: 0.438159
2025-09-02 10:20:19,211 - INFO - Epoch 96/5000 - Train Loss: 0.426038, Val Loss: 0.421971
2025-09-02 10:20:58,340 - INFO - Epoch 97/5000 - Train Loss: 0.442701, Val Loss: 0.420879
2025-09-02 10:21:36,490 - INFO - Epoch 98/5000 - Train Loss: 0.426669, Val Loss: 0.425901
2025-09-02 10:22:14,245 - INFO - Epoch 99/5000 - Train Loss: 0.422608, Val Loss: 0.418174
2025-09-02 10:22:14,299 - INFO - New best model saved with Val Loss: 0.418174
2025-09-02 10:22:52,583 - INFO - Epoch 100/5000 - Train Loss: 0.420234, Val Loss: 0.421449
2025-09-02 10:23:31,352 - INFO - Epoch 101/5000 - Train Loss: 0.421993, Val Loss: 0.426647
2025-09-02 10:24:08,392 - INFO - Epoch 102/5000 - Train Loss: 0.421414, Val Loss: 0.414111
2025-09-02 10:24:08,425 - INFO - New best model saved with Val Loss: 0.414111
2025-09-02 10:24:46,781 - INFO - Epoch 103/5000 - Train Loss: 0.422269, Val Loss: 0.431574
2025-09-02 10:25:25,037 - INFO - Epoch 104/5000 - Train Loss: 0.424981, Val Loss: 0.423924
2025-09-02 10:26:02,539 - INFO - Epoch 105/5000 - Train Loss: 0.420583, Val Loss: 0.422578
2025-09-02 10:26:40,683 - INFO - Epoch 106/5000 - Train Loss: 0.425855, Val Loss: 0.424666
2025-09-02 10:27:17,843 - INFO - Epoch 107/5000 - Train Loss: 0.420895, Val Loss: 0.415678
2025-09-02 10:27:55,292 - INFO - Epoch 108/5000 - Train Loss: 0.419314, Val Loss: 0.411585
2025-09-02 10:27:55,351 - INFO - New best model saved with Val Loss: 0.411585
2025-09-02 10:28:33,850 - INFO - Epoch 109/5000 - Train Loss: 0.413087, Val Loss: 0.414219
2025-09-02 10:29:11,956 - INFO - Epoch 110/5000 - Train Loss: 0.417384, Val Loss: 0.414078
2025-09-02 10:29:49,249 - INFO - Epoch 111/5000 - Train Loss: 0.415742, Val Loss: 0.415189
2025-09-02 10:30:28,261 - INFO - Epoch 112/5000 - Train Loss: 0.424662, Val Loss: 0.449238
2025-09-02 10:31:06,894 - INFO - Epoch 113/5000 - Train Loss: 0.466062, Val Loss: 0.418327
2025-09-02 10:31:45,132 - INFO - Epoch 114/5000 - Train Loss: 0.420435, Val Loss: 0.419781
2025-09-02 10:32:22,238 - INFO - Epoch 115/5000 - Train Loss: 0.416008, Val Loss: 0.417186
2025-09-02 10:33:00,084 - INFO - Epoch 116/5000 - Train Loss: 0.412918, Val Loss: 0.411701
2025-09-02 10:33:38,822 - INFO - Epoch 117/5000 - Train Loss: 0.410845, Val Loss: 0.408756
2025-09-02 10:33:38,857 - INFO - New best model saved with Val Loss: 0.408756
2025-09-02 10:34:17,102 - INFO - Epoch 118/5000 - Train Loss: 0.412114, Val Loss: 0.407667
2025-09-02 10:34:17,134 - INFO - New best model saved with Val Loss: 0.407667
2025-09-02 10:34:55,999 - INFO - Epoch 119/5000 - Train Loss: 0.411929, Val Loss: 0.413107
2025-09-02 10:35:34,199 - INFO - Epoch 120/5000 - Train Loss: 0.414025, Val Loss: 0.434542
2025-09-02 10:36:12,064 - INFO - Epoch 121/5000 - Train Loss: 0.415271, Val Loss: 0.412209
2025-09-02 10:36:50,703 - INFO - Epoch 122/5000 - Train Loss: 0.409461, Val Loss: 0.400318
2025-09-02 10:36:50,736 - INFO - New best model saved with Val Loss: 0.400318
2025-09-02 10:37:28,282 - INFO - Epoch 123/5000 - Train Loss: 0.411730, Val Loss: 0.403322
2025-09-02 10:38:06,392 - INFO - Epoch 124/5000 - Train Loss: 0.416079, Val Loss: 0.420389
2025-09-02 10:38:44,714 - INFO - Epoch 125/5000 - Train Loss: 0.410329, Val Loss: 0.415340
2025-09-02 10:39:22,260 - INFO - Epoch 126/5000 - Train Loss: 0.407263, Val Loss: 0.404372
2025-09-02 10:40:01,119 - INFO - Epoch 127/5000 - Train Loss: 0.409986, Val Loss: 0.408565
2025-09-02 10:40:40,181 - INFO - Epoch 128/5000 - Train Loss: 0.411349, Val Loss: 0.402784
2025-09-02 10:41:19,534 - INFO - Epoch 129/5000 - Train Loss: 0.406211, Val Loss: 0.410812
2025-09-02 10:41:57,860 - INFO - Epoch 130/5000 - Train Loss: 0.410225, Val Loss: 0.401976
2025-09-02 10:42:37,276 - INFO - Epoch 131/5000 - Train Loss: 0.409908, Val Loss: 0.410329
2025-09-02 10:43:15,893 - INFO - Epoch 132/5000 - Train Loss: 0.405761, Val Loss: 0.399094
2025-09-02 10:43:15,927 - INFO - New best model saved with Val Loss: 0.399094
2025-09-02 10:43:54,242 - INFO - Epoch 133/5000 - Train Loss: 0.406100, Val Loss: 0.407827
2025-09-02 10:44:32,905 - INFO - Epoch 134/5000 - Train Loss: 0.406599, Val Loss: 0.399997
2025-09-02 10:45:10,546 - INFO - Epoch 135/5000 - Train Loss: 0.409941, Val Loss: 0.399907
2025-09-02 10:45:47,881 - INFO - Epoch 136/5000 - Train Loss: 0.402517, Val Loss: 0.411665
2025-09-02 10:46:25,786 - INFO - Epoch 137/5000 - Train Loss: 0.406041, Val Loss: 0.412915
2025-09-02 10:47:04,427 - INFO - Epoch 138/5000 - Train Loss: 0.414708, Val Loss: 0.406503
2025-09-02 10:47:42,795 - INFO - Epoch 139/5000 - Train Loss: 0.405968, Val Loss: 0.403864
2025-09-02 10:48:21,395 - INFO - Epoch 140/5000 - Train Loss: 0.404163, Val Loss: 0.400625
2025-09-02 10:48:58,905 - INFO - Epoch 141/5000 - Train Loss: 0.402644, Val Loss: 0.403365
2025-09-02 10:49:36,599 - INFO - Epoch 142/5000 - Train Loss: 0.403545, Val Loss: 0.407938
2025-09-02 10:50:14,222 - INFO - Epoch 143/5000 - Train Loss: 0.403390, Val Loss: 0.413895
2025-09-02 10:50:53,503 - INFO - Epoch 144/5000 - Train Loss: 0.403811, Val Loss: 0.398813
2025-09-02 10:50:53,537 - INFO - New best model saved with Val Loss: 0.398813
2025-09-02 10:51:31,896 - INFO - Epoch 145/5000 - Train Loss: 0.404824, Val Loss: 0.402180
2025-09-02 10:52:10,253 - INFO - Epoch 146/5000 - Train Loss: 0.404729, Val Loss: 0.410536
2025-09-02 10:52:48,986 - INFO - Epoch 147/5000 - Train Loss: 0.401637, Val Loss: 0.399617
2025-09-02 10:53:28,838 - INFO - Epoch 148/5000 - Train Loss: 0.402476, Val Loss: 0.412618
2025-09-02 10:54:07,264 - INFO - Epoch 149/5000 - Train Loss: 0.400831, Val Loss: 0.393147
2025-09-02 10:54:07,298 - INFO - New best model saved with Val Loss: 0.393147
2025-09-02 10:54:45,916 - INFO - Epoch 150/5000 - Train Loss: 0.398172, Val Loss: 0.398390
2025-09-02 10:55:24,512 - INFO - Epoch 151/5000 - Train Loss: 0.402937, Val Loss: 0.432227
2025-09-02 10:56:02,774 - INFO - Epoch 152/5000 - Train Loss: 0.403723, Val Loss: 0.396757
2025-09-02 10:56:40,237 - INFO - Epoch 153/5000 - Train Loss: 0.402724, Val Loss: 0.401338
2025-09-02 10:57:19,459 - INFO - Epoch 154/5000 - Train Loss: 0.402688, Val Loss: 0.389589
2025-09-02 10:57:19,492 - INFO - New best model saved with Val Loss: 0.389589
2025-09-02 10:57:57,730 - INFO - Epoch 155/5000 - Train Loss: 0.401843, Val Loss: 0.393412
2025-09-02 10:58:35,789 - INFO - Epoch 156/5000 - Train Loss: 0.398381, Val Loss: 0.402801
2025-09-02 10:59:13,808 - INFO - Epoch 157/5000 - Train Loss: 0.401286, Val Loss: 0.387557
2025-09-02 10:59:13,841 - INFO - New best model saved with Val Loss: 0.387557
2025-09-02 10:59:51,496 - INFO - Epoch 158/5000 - Train Loss: 0.395751, Val Loss: 0.403316
2025-09-02 11:00:29,931 - INFO - Epoch 159/5000 - Train Loss: 0.396865, Val Loss: 0.387974
2025-09-02 11:01:07,864 - INFO - Epoch 160/5000 - Train Loss: 0.396748, Val Loss: 0.394177
2025-09-02 11:01:46,750 - INFO - Epoch 161/5000 - Train Loss: 0.394703, Val Loss: 0.398361
2025-09-02 11:02:23,811 - INFO - Epoch 162/5000 - Train Loss: 0.401178, Val Loss: 0.391860
2025-09-02 11:03:01,983 - INFO - Epoch 163/5000 - Train Loss: 0.397934, Val Loss: 0.405753
2025-09-02 11:03:39,005 - INFO - Epoch 164/5000 - Train Loss: 0.398475, Val Loss: 0.388408
2025-09-02 11:04:17,173 - INFO - Epoch 165/5000 - Train Loss: 0.394518, Val Loss: 0.398281
2025-09-02 11:05:01,949 - INFO - Epoch 166/5000 - Train Loss: 0.412509, Val Loss: 0.397042
2025-09-02 11:05:40,775 - INFO - Epoch 167/5000 - Train Loss: 0.398995, Val Loss: 0.394592
2025-09-02 11:06:19,869 - INFO - Epoch 168/5000 - Train Loss: 0.394248, Val Loss: 0.395845
2025-09-02 11:06:59,586 - INFO - Epoch 169/5000 - Train Loss: 0.393829, Val Loss: 0.396098
2025-09-02 11:07:39,477 - INFO - Epoch 170/5000 - Train Loss: 0.394331, Val Loss: 0.392197
2025-09-02 11:08:17,839 - INFO - Epoch 171/5000 - Train Loss: 0.395646, Val Loss: 0.401576
2025-09-02 11:08:57,193 - INFO - Epoch 172/5000 - Train Loss: 0.392379, Val Loss: 0.384671
2025-09-02 11:08:57,227 - INFO - New best model saved with Val Loss: 0.384671
2025-09-02 11:09:36,370 - INFO - Epoch 173/5000 - Train Loss: 0.389706, Val Loss: 0.385468
2025-09-02 11:10:14,344 - INFO - Epoch 174/5000 - Train Loss: 0.390348, Val Loss: 0.386307
2025-09-02 11:10:53,815 - INFO - Epoch 175/5000 - Train Loss: 0.393501, Val Loss: 0.388112
2025-09-02 11:11:32,418 - INFO - Epoch 176/5000 - Train Loss: 0.394019, Val Loss: 0.406365
2025-09-02 11:12:09,730 - INFO - Epoch 177/5000 - Train Loss: 0.411430, Val Loss: 0.411639
2025-09-02 11:12:47,705 - INFO - Epoch 178/5000 - Train Loss: 0.398735, Val Loss: 0.389844
2025-09-02 11:13:25,690 - INFO - Epoch 179/5000 - Train Loss: 0.390514, Val Loss: 0.384908
2025-09-02 11:14:03,919 - INFO - Epoch 180/5000 - Train Loss: 0.392293, Val Loss: 0.387603
2025-09-02 11:14:42,438 - INFO - Epoch 181/5000 - Train Loss: 0.389226, Val Loss: 0.392739
2025-09-02 11:15:20,273 - INFO - Epoch 182/5000 - Train Loss: 0.388572, Val Loss: 0.389906
2025-09-02 11:15:58,832 - INFO - Epoch 183/5000 - Train Loss: 0.392652, Val Loss: 0.396191
2025-09-02 11:16:36,340 - INFO - Epoch 184/5000 - Train Loss: 0.389036, Val Loss: 0.385267
2025-09-02 11:17:13,833 - INFO - Epoch 185/5000 - Train Loss: 0.390311, Val Loss: 0.415910
2025-09-02 11:17:52,366 - INFO - Epoch 186/5000 - Train Loss: 0.390131, Val Loss: 0.389621
2025-09-02 11:18:30,545 - INFO - Epoch 187/5000 - Train Loss: 0.387450, Val Loss: 0.379368
2025-09-02 11:18:30,596 - INFO - New best model saved with Val Loss: 0.379368
2025-09-02 11:19:08,501 - INFO - Epoch 188/5000 - Train Loss: 0.387554, Val Loss: 0.380068
2025-09-02 11:19:46,272 - INFO - Epoch 189/5000 - Train Loss: 0.390423, Val Loss: 0.386396
2025-09-02 11:20:24,675 - INFO - Epoch 190/5000 - Train Loss: 0.387459, Val Loss: 0.381681
2025-09-02 11:21:05,957 - INFO - Epoch 191/5000 - Train Loss: 0.389458, Val Loss: 0.379820
2025-09-02 11:21:42,764 - INFO - Epoch 192/5000 - Train Loss: 0.386407, Val Loss: 0.388446
2025-09-02 11:22:20,583 - INFO - Epoch 193/5000 - Train Loss: 0.387504, Val Loss: 0.387697
2025-09-02 11:22:57,617 - INFO - Epoch 194/5000 - Train Loss: 0.389465, Val Loss: 0.381940
2025-09-02 11:23:35,687 - INFO - Epoch 195/5000 - Train Loss: 0.386729, Val Loss: 0.381006
2025-09-02 11:24:14,425 - INFO - Epoch 196/5000 - Train Loss: 0.388604, Val Loss: 0.384647
2025-09-02 11:24:52,928 - INFO - Epoch 197/5000 - Train Loss: 0.387397, Val Loss: 0.384489
2025-09-02 11:25:32,020 - INFO - Epoch 198/5000 - Train Loss: 0.387546, Val Loss: 0.380340
2025-09-02 11:26:10,172 - INFO - Epoch 199/5000 - Train Loss: 0.383749, Val Loss: 0.387220
2025-09-02 11:26:47,761 - INFO - Epoch 200/5000 - Train Loss: 0.383847, Val Loss: 0.385147
2025-09-02 11:27:28,888 - INFO - Epoch 201/5000 - Train Loss: 0.384880, Val Loss: 0.379604
2025-09-02 11:28:09,287 - INFO - Epoch 202/5000 - Train Loss: 0.383982, Val Loss: 0.389966
2025-09-02 11:28:48,703 - INFO - Epoch 203/5000 - Train Loss: 0.382759, Val Loss: 0.378609
2025-09-02 11:28:48,737 - INFO - New best model saved with Val Loss: 0.378609
2025-09-02 11:29:29,838 - INFO - Epoch 204/5000 - Train Loss: 0.382060, Val Loss: 0.380802
2025-09-02 11:30:11,958 - INFO - Epoch 205/5000 - Train Loss: 0.383014, Val Loss: 0.376533
2025-09-02 11:30:11,992 - INFO - New best model saved with Val Loss: 0.376533
2025-09-02 11:30:49,711 - INFO - Epoch 206/5000 - Train Loss: 0.383551, Val Loss: 0.387282
2025-09-02 11:31:30,398 - INFO - Epoch 207/5000 - Train Loss: 0.383261, Val Loss: 0.373872
2025-09-02 11:31:30,431 - INFO - New best model saved with Val Loss: 0.373872
2025-09-02 11:32:08,958 - INFO - Epoch 208/5000 - Train Loss: 0.380101, Val Loss: 0.378978
2025-09-02 11:32:45,852 - INFO - Epoch 209/5000 - Train Loss: 0.380541, Val Loss: 0.376214
2025-09-02 11:33:23,709 - INFO - Epoch 210/5000 - Train Loss: 0.384362, Val Loss: 0.372172
2025-09-02 11:33:23,751 - INFO - New best model saved with Val Loss: 0.372172
2025-09-02 11:34:02,173 - INFO - Epoch 211/5000 - Train Loss: 0.379523, Val Loss: 0.396816
2025-09-02 11:34:39,413 - INFO - Epoch 212/5000 - Train Loss: 0.382323, Val Loss: 0.374945
2025-09-02 11:35:17,213 - INFO - Epoch 213/5000 - Train Loss: 0.382537, Val Loss: 0.386878
2025-09-02 11:36:02,328 - INFO - Epoch 214/5000 - Train Loss: 0.382944, Val Loss: 0.373643
2025-09-02 11:36:42,156 - INFO - Epoch 215/5000 - Train Loss: 0.380735, Val Loss: 0.391340
2025-09-02 11:37:23,442 - INFO - Epoch 216/5000 - Train Loss: 0.378221, Val Loss: 0.372356
2025-09-02 11:38:01,045 - INFO - Epoch 217/5000 - Train Loss: 0.380705, Val Loss: 0.372050
2025-09-02 11:38:01,080 - INFO - New best model saved with Val Loss: 0.372050
2025-09-02 11:38:39,104 - INFO - Epoch 218/5000 - Train Loss: 0.380928, Val Loss: 0.376968
2025-09-02 11:39:19,644 - INFO - Epoch 219/5000 - Train Loss: 0.378035, Val Loss: 0.378387
2025-09-02 11:39:57,447 - INFO - Epoch 220/5000 - Train Loss: 0.386408, Val Loss: 0.379228
2025-09-02 11:40:33,795 - INFO - Epoch 221/5000 - Train Loss: 0.381985, Val Loss: 0.380532
2025-09-02 11:41:10,811 - INFO - Epoch 222/5000 - Train Loss: 0.377491, Val Loss: 0.370613
2025-09-02 11:41:10,845 - INFO - New best model saved with Val Loss: 0.370613
2025-09-02 11:41:49,619 - INFO - Epoch 223/5000 - Train Loss: 0.375534, Val Loss: 0.371009
2025-09-02 11:42:26,981 - INFO - Epoch 224/5000 - Train Loss: 0.381746, Val Loss: 0.372734
2025-09-02 11:43:08,979 - INFO - Epoch 225/5000 - Train Loss: 0.380017, Val Loss: 0.377780
2025-09-02 11:43:56,357 - INFO - Epoch 226/5000 - Train Loss: 0.378876, Val Loss: 0.368666
2025-09-02 11:43:56,411 - INFO - New best model saved with Val Loss: 0.368666
2025-09-02 11:44:37,196 - INFO - Epoch 227/5000 - Train Loss: 0.374741, Val Loss: 0.371911
2025-09-02 11:45:14,500 - INFO - Epoch 228/5000 - Train Loss: 0.374243, Val Loss: 0.369052
2025-09-02 11:45:55,778 - INFO - Epoch 229/5000 - Train Loss: 0.373707, Val Loss: 0.381826
2025-09-02 11:46:34,366 - INFO - Epoch 230/5000 - Train Loss: 0.373557, Val Loss: 0.366274
2025-09-02 11:46:34,399 - INFO - New best model saved with Val Loss: 0.366274
2025-09-02 11:47:11,987 - INFO - Epoch 231/5000 - Train Loss: 0.374528, Val Loss: 0.373467
2025-09-02 11:47:49,023 - INFO - Epoch 232/5000 - Train Loss: 0.377907, Val Loss: 0.375040
2025-09-02 11:48:26,220 - INFO - Epoch 233/5000 - Train Loss: 0.373532, Val Loss: 0.366891
2025-09-02 11:49:03,330 - INFO - Epoch 234/5000 - Train Loss: 0.375813, Val Loss: 0.377477
2025-09-02 11:49:40,584 - INFO - Epoch 235/5000 - Train Loss: 0.374916, Val Loss: 0.359788
2025-09-02 11:49:40,618 - INFO - New best model saved with Val Loss: 0.359788
2025-09-02 11:50:17,821 - INFO - Epoch 236/5000 - Train Loss: 0.374619, Val Loss: 0.380687
2025-09-02 11:50:55,228 - INFO - Epoch 237/5000 - Train Loss: 0.372062, Val Loss: 0.368442
2025-09-02 11:51:33,718 - INFO - Epoch 238/5000 - Train Loss: 0.373202, Val Loss: 0.371466
2025-09-02 11:52:10,652 - INFO - Epoch 239/5000 - Train Loss: 0.371973, Val Loss: 0.365895
2025-09-02 11:52:47,896 - INFO - Epoch 240/5000 - Train Loss: 0.373804, Val Loss: 0.367891
2025-09-02 11:53:25,274 - INFO - Epoch 241/5000 - Train Loss: 0.372690, Val Loss: 0.364852
2025-09-02 11:54:02,769 - INFO - Epoch 242/5000 - Train Loss: 0.371519, Val Loss: 0.364615
2025-09-02 11:54:40,054 - INFO - Epoch 243/5000 - Train Loss: 0.370280, Val Loss: 0.367449
2025-09-02 11:55:18,255 - INFO - Epoch 244/5000 - Train Loss: 0.371893, Val Loss: 0.372149
2025-09-02 11:55:56,906 - INFO - Epoch 245/5000 - Train Loss: 0.370915, Val Loss: 0.365605
2025-09-02 11:56:34,468 - INFO - Epoch 246/5000 - Train Loss: 0.372223, Val Loss: 0.369254
2025-09-02 11:57:12,323 - INFO - Epoch 247/5000 - Train Loss: 0.371425, Val Loss: 0.372681
2025-09-02 11:57:50,216 - INFO - Epoch 248/5000 - Train Loss: 0.370175, Val Loss: 0.359934
2025-09-02 11:58:27,958 - INFO - Epoch 249/5000 - Train Loss: 0.369698, Val Loss: 0.370070
2025-09-02 11:59:05,842 - INFO - Epoch 250/5000 - Train Loss: 0.367475, Val Loss: 0.359654
2025-09-02 11:59:05,876 - INFO - New best model saved with Val Loss: 0.359654
2025-09-02 11:59:44,333 - INFO - Epoch 251/5000 - Train Loss: 0.369832, Val Loss: 0.365497
2025-09-02 12:00:21,698 - INFO - Epoch 252/5000 - Train Loss: 0.373611, Val Loss: 0.360190
2025-09-02 12:01:00,114 - INFO - Epoch 253/5000 - Train Loss: 0.367081, Val Loss: 0.360613
2025-09-02 12:01:39,851 - INFO - Epoch 254/5000 - Train Loss: 0.371721, Val Loss: 0.365346
2025-09-02 12:02:19,374 - INFO - Epoch 255/5000 - Train Loss: 0.366889, Val Loss: 0.366869
2025-09-02 12:02:57,148 - INFO - Epoch 256/5000 - Train Loss: 0.368980, Val Loss: 0.362014
2025-09-02 12:03:35,391 - INFO - Epoch 257/5000 - Train Loss: 0.365431, Val Loss: 0.360603
2025-09-02 12:04:13,594 - INFO - Epoch 258/5000 - Train Loss: 0.367441, Val Loss: 0.367128
2025-09-02 12:04:51,185 - INFO - Epoch 259/5000 - Train Loss: 0.367835, Val Loss: 0.376378
2025-09-02 12:05:29,658 - INFO - Epoch 260/5000 - Train Loss: 0.367824, Val Loss: 0.365822
2025-09-02 12:06:08,082 - INFO - Epoch 261/5000 - Train Loss: 0.367536, Val Loss: 0.369189
2025-09-02 12:06:47,426 - INFO - Epoch 262/5000 - Train Loss: 0.369709, Val Loss: 0.354142
2025-09-02 12:06:47,460 - INFO - New best model saved with Val Loss: 0.354142
2025-09-02 12:07:25,774 - INFO - Epoch 263/5000 - Train Loss: 0.366203, Val Loss: 0.370105
2025-09-02 12:08:04,399 - INFO - Epoch 264/5000 - Train Loss: 0.363868, Val Loss: 0.355230
2025-09-02 12:08:42,162 - INFO - Epoch 265/5000 - Train Loss: 0.364560, Val Loss: 0.361495
2025-09-02 12:09:18,964 - INFO - Epoch 266/5000 - Train Loss: 0.363172, Val Loss: 0.364177
2025-09-02 12:09:57,132 - INFO - Epoch 267/5000 - Train Loss: 0.363555, Val Loss: 0.352083
2025-09-02 12:09:57,166 - INFO - New best model saved with Val Loss: 0.352083
2025-09-02 12:10:35,926 - INFO - Epoch 268/5000 - Train Loss: 0.357870, Val Loss: 0.354793
2025-09-02 12:11:15,352 - INFO - Epoch 269/5000 - Train Loss: 0.359596, Val Loss: 0.362896
2025-09-02 12:11:55,216 - INFO - Epoch 270/5000 - Train Loss: 0.365270, Val Loss: 0.351561
2025-09-02 12:11:55,249 - INFO - New best model saved with Val Loss: 0.351561
2025-09-02 12:12:34,583 - INFO - Epoch 271/5000 - Train Loss: 0.363681, Val Loss: 0.356281
2025-09-02 12:13:12,338 - INFO - Epoch 272/5000 - Train Loss: 0.365000, Val Loss: 0.353707
2025-09-02 12:13:49,354 - INFO - Epoch 273/5000 - Train Loss: 0.359893, Val Loss: 0.357059
2025-09-02 12:14:27,413 - INFO - Epoch 274/5000 - Train Loss: 0.360788, Val Loss: 0.375478
2025-09-02 12:15:06,499 - INFO - Epoch 275/5000 - Train Loss: 0.360261, Val Loss: 0.356056
2025-09-02 12:15:43,934 - INFO - Epoch 276/5000 - Train Loss: 0.359687, Val Loss: 0.352481
2025-09-02 12:16:21,868 - INFO - Epoch 277/5000 - Train Loss: 0.365383, Val Loss: 0.359349
2025-09-02 12:16:59,441 - INFO - Epoch 278/5000 - Train Loss: 0.358227, Val Loss: 0.348166
2025-09-02 12:16:59,474 - INFO - New best model saved with Val Loss: 0.348166
2025-09-02 12:17:37,909 - INFO - Epoch 279/5000 - Train Loss: 0.355711, Val Loss: 0.361959
2025-09-02 12:18:15,396 - INFO - Epoch 280/5000 - Train Loss: 0.357078, Val Loss: 0.365953
2025-09-02 12:18:53,814 - INFO - Epoch 281/5000 - Train Loss: 0.360233, Val Loss: 0.350140
2025-09-02 12:19:31,958 - INFO - Epoch 282/5000 - Train Loss: 0.354131, Val Loss: 0.344716
2025-09-02 12:19:32,001 - INFO - New best model saved with Val Loss: 0.344716
2025-09-02 12:20:09,403 - INFO - Epoch 283/5000 - Train Loss: 0.355801, Val Loss: 0.350790
2025-09-02 12:20:47,319 - INFO - Epoch 284/5000 - Train Loss: 0.353624, Val Loss: 0.349914
2025-09-02 12:21:26,191 - INFO - Epoch 285/5000 - Train Loss: 0.355825, Val Loss: 0.344381
2025-09-02 12:21:26,225 - INFO - New best model saved with Val Loss: 0.344381
2025-09-02 12:22:04,452 - INFO - Epoch 286/5000 - Train Loss: 0.355158, Val Loss: 0.348767
2025-09-02 12:22:42,070 - INFO - Epoch 287/5000 - Train Loss: 0.357960, Val Loss: 0.355603
2025-09-02 12:23:20,990 - INFO - Epoch 288/5000 - Train Loss: 0.352281, Val Loss: 0.366710
2025-09-02 12:23:58,240 - INFO - Epoch 289/5000 - Train Loss: 0.356949, Val Loss: 0.347217
2025-09-02 12:24:37,592 - INFO - Epoch 290/5000 - Train Loss: 0.351125, Val Loss: 0.343302
2025-09-02 12:24:37,653 - INFO - New best model saved with Val Loss: 0.343302
2025-09-02 12:25:17,327 - INFO - Epoch 291/5000 - Train Loss: 0.351511, Val Loss: 0.364764
2025-09-02 12:25:54,349 - INFO - Epoch 292/5000 - Train Loss: 0.355891, Val Loss: 0.339459
2025-09-02 12:25:54,402 - INFO - New best model saved with Val Loss: 0.339459
2025-09-02 12:26:32,933 - INFO - Epoch 293/5000 - Train Loss: 0.350789, Val Loss: 0.355761
2025-09-02 12:27:10,127 - INFO - Epoch 294/5000 - Train Loss: 0.351207, Val Loss: 0.353890
2025-09-02 12:27:48,284 - INFO - Epoch 295/5000 - Train Loss: 0.352940, Val Loss: 0.366604
2025-09-02 12:28:27,560 - INFO - Epoch 296/5000 - Train Loss: 0.363051, Val Loss: 0.349419
2025-09-02 12:29:05,769 - INFO - Epoch 297/5000 - Train Loss: 0.350211, Val Loss: 0.347328
2025-09-02 12:29:43,677 - INFO - Epoch 298/5000 - Train Loss: 0.345956, Val Loss: 0.342019
2025-09-02 12:30:24,881 - INFO - Epoch 299/5000 - Train Loss: 0.344464, Val Loss: 0.343392
2025-09-02 12:31:02,834 - INFO - Epoch 300/5000 - Train Loss: 0.342805, Val Loss: 0.348354
2025-09-02 12:31:42,479 - INFO - Epoch 301/5000 - Train Loss: 0.346671, Val Loss: 0.350482
2025-09-02 12:32:19,494 - INFO - Epoch 302/5000 - Train Loss: 0.354808, Val Loss: 0.354845
2025-09-02 12:32:57,154 - INFO - Epoch 303/5000 - Train Loss: 0.348696, Val Loss: 0.338044
2025-09-02 12:32:57,187 - INFO - New best model saved with Val Loss: 0.338044
2025-09-02 12:33:35,614 - INFO - Epoch 304/5000 - Train Loss: 0.345066, Val Loss: 0.337604
2025-09-02 12:33:35,646 - INFO - New best model saved with Val Loss: 0.337604
2025-09-02 12:34:13,956 - INFO - Epoch 305/5000 - Train Loss: 0.342008, Val Loss: 0.332986
2025-09-02 12:34:13,988 - INFO - New best model saved with Val Loss: 0.332986
2025-09-02 12:34:52,803 - INFO - Epoch 306/5000 - Train Loss: 0.341396, Val Loss: 0.354993
2025-09-02 12:35:30,989 - INFO - Epoch 307/5000 - Train Loss: 0.343554, Val Loss: 0.336458
2025-09-02 12:36:09,297 - INFO - Epoch 308/5000 - Train Loss: 0.342432, Val Loss: 0.333995
2025-09-02 12:36:47,261 - INFO - Epoch 309/5000 - Train Loss: 0.345278, Val Loss: 0.341898
2025-09-02 12:37:25,820 - INFO - Epoch 310/5000 - Train Loss: 0.340270, Val Loss: 0.338085
2025-09-02 12:38:04,782 - INFO - Epoch 311/5000 - Train Loss: 0.338241, Val Loss: 0.333249
2025-09-02 12:38:43,404 - INFO - Epoch 312/5000 - Train Loss: 0.339486, Val Loss: 0.364648
2025-09-02 12:39:20,963 - INFO - Epoch 313/5000 - Train Loss: 0.342254, Val Loss: 0.340814
2025-09-02 12:39:59,182 - INFO - Epoch 314/5000 - Train Loss: 0.345520, Val Loss: 0.345923
2025-09-02 12:40:37,817 - INFO - Epoch 315/5000 - Train Loss: 0.343309, Val Loss: 0.335364
2025-09-02 12:41:15,529 - INFO - Epoch 316/5000 - Train Loss: 0.337069, Val Loss: 0.328224
2025-09-02 12:41:15,564 - INFO - New best model saved with Val Loss: 0.328224
2025-09-02 12:41:52,946 - INFO - Epoch 317/5000 - Train Loss: 0.338518, Val Loss: 0.334122
2025-09-02 12:42:30,664 - INFO - Epoch 318/5000 - Train Loss: 0.336337, Val Loss: 0.338840
2025-09-02 12:43:08,472 - INFO - Epoch 319/5000 - Train Loss: 0.338859, Val Loss: 0.333248
2025-09-02 12:43:46,127 - INFO - Epoch 320/5000 - Train Loss: 0.339784, Val Loss: 0.337731
2025-09-02 12:44:25,007 - INFO - Epoch 321/5000 - Train Loss: 0.336067, Val Loss: 0.327896
2025-09-02 12:44:25,040 - INFO - New best model saved with Val Loss: 0.327896
2025-09-02 12:45:02,505 - INFO - Epoch 322/5000 - Train Loss: 0.336280, Val Loss: 0.333696
2025-09-02 12:45:40,936 - INFO - Epoch 323/5000 - Train Loss: 0.341457, Val Loss: 0.328364
2025-09-02 12:46:17,946 - INFO - Epoch 324/5000 - Train Loss: 0.335208, Val Loss: 0.328493
2025-09-02 12:46:55,587 - INFO - Epoch 325/5000 - Train Loss: 0.331738, Val Loss: 0.331617
2025-09-02 12:47:34,292 - INFO - Epoch 326/5000 - Train Loss: 0.339960, Val Loss: 0.331490
2025-09-02 12:48:13,201 - INFO - Epoch 327/5000 - Train Loss: 0.333923, Val Loss: 0.334885
2025-09-02 12:48:50,811 - INFO - Epoch 328/5000 - Train Loss: 0.333391, Val Loss: 0.330659
2025-09-02 12:49:27,598 - INFO - Epoch 329/5000 - Train Loss: 0.328757, Val Loss: 0.320595
2025-09-02 12:49:27,632 - INFO - New best model saved with Val Loss: 0.320595
2025-09-02 12:50:05,239 - INFO - Epoch 330/5000 - Train Loss: 0.335173, Val Loss: 0.334133
2025-09-02 12:50:44,142 - INFO - Epoch 331/5000 - Train Loss: 0.329336, Val Loss: 0.323570
2025-09-02 12:51:22,456 - INFO - Epoch 332/5000 - Train Loss: 0.340261, Val Loss: 0.331090
2025-09-02 12:52:00,433 - INFO - Epoch 333/5000 - Train Loss: 0.329311, Val Loss: 0.319980
2025-09-02 12:52:00,468 - INFO - New best model saved with Val Loss: 0.319980
2025-09-02 12:52:37,735 - INFO - Epoch 334/5000 - Train Loss: 0.328972, Val Loss: 0.327582
2025-09-02 12:53:15,750 - INFO - Epoch 335/5000 - Train Loss: 0.330567, Val Loss: 0.324331
2025-09-02 12:53:54,132 - INFO - Epoch 336/5000 - Train Loss: 0.327144, Val Loss: 0.317367
2025-09-02 12:53:54,165 - INFO - New best model saved with Val Loss: 0.317367
2025-09-02 12:54:32,286 - INFO - Epoch 337/5000 - Train Loss: 0.328340, Val Loss: 0.330975
2025-09-02 12:55:09,685 - INFO - Epoch 338/5000 - Train Loss: 0.323134, Val Loss: 0.326267
2025-09-02 12:55:47,248 - INFO - Epoch 339/5000 - Train Loss: 0.325854, Val Loss: 0.318386
2025-09-02 12:56:24,554 - INFO - Epoch 340/5000 - Train Loss: 0.324995, Val Loss: 0.318349
2025-09-02 12:57:02,688 - INFO - Epoch 341/5000 - Train Loss: 0.328352, Val Loss: 0.329692
2025-09-02 12:57:40,757 - INFO - Epoch 342/5000 - Train Loss: 0.331203, Val Loss: 0.325749
2025-09-02 12:58:19,104 - INFO - Epoch 343/5000 - Train Loss: 0.323360, Val Loss: 0.314256
2025-09-02 12:58:19,138 - INFO - New best model saved with Val Loss: 0.314256
2025-09-02 12:58:56,559 - INFO - Epoch 344/5000 - Train Loss: 0.325501, Val Loss: 0.319445
2025-09-02 12:59:33,300 - INFO - Epoch 345/5000 - Train Loss: 0.323903, Val Loss: 0.314731
2025-09-02 13:00:12,461 - INFO - Epoch 346/5000 - Train Loss: 0.319415, Val Loss: 0.316388
2025-09-02 13:00:50,520 - INFO - Epoch 347/5000 - Train Loss: 0.322086, Val Loss: 0.313044
2025-09-02 13:00:50,556 - INFO - New best model saved with Val Loss: 0.313044
2025-09-02 13:01:29,621 - INFO - Epoch 348/5000 - Train Loss: 0.321602, Val Loss: 0.329707
2025-09-02 13:02:08,982 - INFO - Epoch 349/5000 - Train Loss: 0.322310, Val Loss: 0.315818
2025-09-02 13:02:46,277 - INFO - Epoch 350/5000 - Train Loss: 0.322552, Val Loss: 0.316790
2025-09-02 13:03:24,652 - INFO - Epoch 351/5000 - Train Loss: 0.319498, Val Loss: 0.306536
2025-09-02 13:03:24,685 - INFO - New best model saved with Val Loss: 0.306536
2025-09-02 13:04:02,436 - INFO - Epoch 352/5000 - Train Loss: 0.316279, Val Loss: 0.310008
2025-09-02 13:04:40,449 - INFO - Epoch 353/5000 - Train Loss: 0.313961, Val Loss: 0.306930
2025-09-02 13:05:17,719 - INFO - Epoch 354/5000 - Train Loss: 0.315661, Val Loss: 0.318552
2025-09-02 13:05:56,321 - INFO - Epoch 355/5000 - Train Loss: 0.316289, Val Loss: 0.323879
2025-09-02 13:06:36,935 - INFO - Epoch 356/5000 - Train Loss: 0.317512, Val Loss: 0.320771
2025-09-02 13:07:15,040 - INFO - Epoch 357/5000 - Train Loss: 0.320410, Val Loss: 0.316081
2025-09-02 13:07:52,898 - INFO - Epoch 358/5000 - Train Loss: 0.315350, Val Loss: 0.313168
2025-09-02 13:08:30,894 - INFO - Epoch 359/5000 - Train Loss: 0.315301, Val Loss: 0.314838
2025-09-02 13:09:09,912 - INFO - Epoch 360/5000 - Train Loss: 0.316262, Val Loss: 0.305174
2025-09-02 13:09:09,946 - INFO - New best model saved with Val Loss: 0.305174
2025-09-02 13:09:48,257 - INFO - Epoch 361/5000 - Train Loss: 0.319587, Val Loss: 0.306390
2025-09-02 13:10:26,669 - INFO - Epoch 362/5000 - Train Loss: 0.316746, Val Loss: 0.326463
2025-09-02 13:11:04,294 - INFO - Epoch 363/5000 - Train Loss: 0.317832, Val Loss: 0.324664
2025-09-02 13:11:41,970 - INFO - Epoch 364/5000 - Train Loss: 0.314558, Val Loss: 0.300653
2025-09-02 13:11:42,003 - INFO - New best model saved with Val Loss: 0.300653
2025-09-02 13:12:18,690 - INFO - Epoch 365/5000 - Train Loss: 0.312786, Val Loss: 0.320190
2025-09-02 13:12:55,493 - INFO - Epoch 366/5000 - Train Loss: 0.316904, Val Loss: 0.316097
2025-09-02 13:13:32,904 - INFO - Epoch 367/5000 - Train Loss: 0.311552, Val Loss: 0.305032
2025-09-02 13:14:11,816 - INFO - Epoch 368/5000 - Train Loss: 0.311853, Val Loss: 0.302439
2025-09-02 13:14:50,722 - INFO - Epoch 369/5000 - Train Loss: 0.314029, Val Loss: 0.316449
2025-09-02 13:15:29,332 - INFO - Epoch 370/5000 - Train Loss: 0.311454, Val Loss: 0.308813
2025-09-02 13:16:09,510 - INFO - Epoch 371/5000 - Train Loss: 0.313634, Val Loss: 0.302663
2025-09-02 13:16:47,417 - INFO - Epoch 372/5000 - Train Loss: 0.309906, Val Loss: 0.303177
2025-09-02 13:17:25,194 - INFO - Epoch 373/5000 - Train Loss: 0.308335, Val Loss: 0.303611
2025-09-02 13:18:04,406 - INFO - Epoch 374/5000 - Train Loss: 0.310177, Val Loss: 0.306387
2025-09-02 13:18:42,333 - INFO - Epoch 375/5000 - Train Loss: 0.311026, Val Loss: 0.306020
2025-09-02 13:19:21,228 - INFO - Epoch 376/5000 - Train Loss: 0.307901, Val Loss: 0.312962
2025-09-02 13:20:00,193 - INFO - Epoch 377/5000 - Train Loss: 0.310974, Val Loss: 0.299483
2025-09-02 13:20:00,228 - INFO - New best model saved with Val Loss: 0.299483
2025-09-02 13:20:39,497 - INFO - Epoch 378/5000 - Train Loss: 0.307931, Val Loss: 0.311462
2025-09-02 13:21:19,033 - INFO - Epoch 379/5000 - Train Loss: 0.308275, Val Loss: 0.304291
2025-09-02 13:21:57,155 - INFO - Epoch 380/5000 - Train Loss: 0.305402, Val Loss: 0.301502
2025-09-02 13:22:35,974 - INFO - Epoch 381/5000 - Train Loss: 0.307559, Val Loss: 0.302185
2025-09-02 13:23:14,646 - INFO - Epoch 382/5000 - Train Loss: 0.305626, Val Loss: 0.314478
2025-09-02 13:23:53,065 - INFO - Epoch 383/5000 - Train Loss: 0.306021, Val Loss: 0.307039
2025-09-02 13:24:31,917 - INFO - Epoch 384/5000 - Train Loss: 0.304833, Val Loss: 0.300753
2025-09-02 13:25:10,123 - INFO - Epoch 385/5000 - Train Loss: 0.304318, Val Loss: 0.301008
2025-09-02 13:25:47,644 - INFO - Epoch 386/5000 - Train Loss: 0.311890, Val Loss: 0.300829
2025-09-02 13:26:26,200 - INFO - Epoch 387/5000 - Train Loss: 0.305193, Val Loss: 0.297348
2025-09-02 13:26:26,233 - INFO - New best model saved with Val Loss: 0.297348
2025-09-02 13:27:03,210 - INFO - Epoch 388/5000 - Train Loss: 0.302104, Val Loss: 0.303882
2025-09-02 13:27:41,172 - INFO - Epoch 389/5000 - Train Loss: 0.302047, Val Loss: 0.302022
2025-09-02 13:28:19,831 - INFO - Epoch 390/5000 - Train Loss: 0.304227, Val Loss: 0.300775
2025-09-02 13:28:58,223 - INFO - Epoch 391/5000 - Train Loss: 0.302093, Val Loss: 0.302658
2025-09-02 13:29:36,136 - INFO - Epoch 392/5000 - Train Loss: 0.302557, Val Loss: 0.297821
2025-09-02 13:30:15,476 - INFO - Epoch 393/5000 - Train Loss: 0.300965, Val Loss: 0.297320
2025-09-02 13:30:15,509 - INFO - New best model saved with Val Loss: 0.297320
2025-09-02 13:30:53,444 - INFO - Epoch 394/5000 - Train Loss: 0.304674, Val Loss: 0.294685
2025-09-02 13:30:53,476 - INFO - New best model saved with Val Loss: 0.294685
2025-09-02 13:31:31,238 - INFO - Epoch 395/5000 - Train Loss: 0.301955, Val Loss: 0.296305
2025-09-02 13:32:09,442 - INFO - Epoch 396/5000 - Train Loss: 0.298785, Val Loss: 0.293179
2025-09-02 13:32:09,475 - INFO - New best model saved with Val Loss: 0.293179
2025-09-02 13:32:47,450 - INFO - Epoch 397/5000 - Train Loss: 0.302916, Val Loss: 0.312222
2025-09-02 13:33:26,030 - INFO - Epoch 398/5000 - Train Loss: 0.302164, Val Loss: 0.288949
2025-09-02 13:33:26,063 - INFO - New best model saved with Val Loss: 0.288949
2025-09-02 13:34:03,745 - INFO - Epoch 399/5000 - Train Loss: 0.298005, Val Loss: 0.296880
2025-09-02 13:34:42,135 - INFO - Epoch 400/5000 - Train Loss: 0.298713, Val Loss: 0.303391
2025-09-02 13:35:20,582 - INFO - Epoch 401/5000 - Train Loss: 0.299379, Val Loss: 0.299317
2025-09-02 13:35:58,146 - INFO - Epoch 402/5000 - Train Loss: 0.297825, Val Loss: 0.298569
2025-09-02 13:36:35,590 - INFO - Epoch 403/5000 - Train Loss: 0.300723, Val Loss: 0.299231
2025-09-02 13:37:13,761 - INFO - Epoch 404/5000 - Train Loss: 0.296472, Val Loss: 0.298481
2025-09-02 13:37:51,111 - INFO - Epoch 405/5000 - Train Loss: 0.298550, Val Loss: 0.294502
2025-09-02 13:38:28,235 - INFO - Epoch 406/5000 - Train Loss: 0.294293, Val Loss: 0.290805
2025-09-02 13:39:04,674 - INFO - Epoch 407/5000 - Train Loss: 0.296721, Val Loss: 0.288594
2025-09-02 13:39:04,710 - INFO - New best model saved with Val Loss: 0.288594
2025-09-02 13:39:44,375 - INFO - Epoch 408/5000 - Train Loss: 0.296241, Val Loss: 0.291059
2025-09-02 13:40:22,086 - INFO - Epoch 409/5000 - Train Loss: 0.297517, Val Loss: 0.295413
2025-09-02 13:41:00,007 - INFO - Epoch 410/5000 - Train Loss: 0.296567, Val Loss: 0.289850
2025-09-02 13:41:37,722 - INFO - Epoch 411/5000 - Train Loss: 0.295855, Val Loss: 0.294702
2025-09-02 13:42:14,870 - INFO - Epoch 412/5000 - Train Loss: 0.294277, Val Loss: 0.288044
2025-09-02 13:42:14,903 - INFO - New best model saved with Val Loss: 0.288044
2025-09-02 13:42:52,393 - INFO - Epoch 413/5000 - Train Loss: 0.294145, Val Loss: 0.295881
2025-09-02 13:43:29,668 - INFO - Epoch 414/5000 - Train Loss: 0.293644, Val Loss: 0.283122
2025-09-02 13:43:29,701 - INFO - New best model saved with Val Loss: 0.283122
2025-09-02 13:44:08,454 - INFO - Epoch 415/5000 - Train Loss: 0.291211, Val Loss: 0.289465
2025-09-02 13:44:45,961 - INFO - Epoch 416/5000 - Train Loss: 0.293007, Val Loss: 0.288935
2025-09-02 13:45:23,595 - INFO - Epoch 417/5000 - Train Loss: 0.291141, Val Loss: 0.286877
2025-09-02 13:46:00,985 - INFO - Epoch 418/5000 - Train Loss: 0.293098, Val Loss: 0.292676
2025-09-02 13:46:39,118 - INFO - Epoch 419/5000 - Train Loss: 0.293211, Val Loss: 0.290052
2025-09-02 13:47:17,807 - INFO - Epoch 420/5000 - Train Loss: 0.296103, Val Loss: 0.302831
2025-09-02 13:47:56,874 - INFO - Epoch 421/5000 - Train Loss: 0.291890, Val Loss: 0.293017
2025-09-02 13:48:36,424 - INFO - Epoch 422/5000 - Train Loss: 0.290056, Val Loss: 0.291852
2025-09-02 13:49:13,777 - INFO - Epoch 423/5000 - Train Loss: 0.291917, Val Loss: 0.291701
2025-09-02 13:49:52,239 - INFO - Epoch 424/5000 - Train Loss: 0.292068, Val Loss: 0.298790
2025-09-02 13:50:31,168 - INFO - Epoch 425/5000 - Train Loss: 0.294940, Val Loss: 0.291611
2025-09-02 13:51:09,971 - INFO - Epoch 426/5000 - Train Loss: 0.290217, Val Loss: 0.288878
2025-09-02 13:51:48,785 - INFO - Epoch 427/5000 - Train Loss: 0.289237, Val Loss: 0.289816
2025-09-02 13:52:27,913 - INFO - Epoch 428/5000 - Train Loss: 0.287799, Val Loss: 0.297294
2025-09-02 13:53:05,544 - INFO - Epoch 429/5000 - Train Loss: 0.287645, Val Loss: 0.282080
2025-09-02 13:53:05,578 - INFO - New best model saved with Val Loss: 0.282080
2025-09-02 13:53:43,647 - INFO - Epoch 430/5000 - Train Loss: 0.289177, Val Loss: 0.284445
2025-09-02 13:54:21,710 - INFO - Epoch 431/5000 - Train Loss: 0.289063, Val Loss: 0.284860
2025-09-02 13:54:59,078 - INFO - Epoch 432/5000 - Train Loss: 0.284909, Val Loss: 0.278257
2025-09-02 13:54:59,110 - INFO - New best model saved with Val Loss: 0.278257
2025-09-02 13:55:36,972 - INFO - Epoch 433/5000 - Train Loss: 0.284629, Val Loss: 0.277256
2025-09-02 13:55:37,005 - INFO - New best model saved with Val Loss: 0.277256
2025-09-02 13:56:15,214 - INFO - Epoch 434/5000 - Train Loss: 0.286826, Val Loss: 0.288561
2025-09-02 13:56:54,152 - INFO - Epoch 435/5000 - Train Loss: 0.284797, Val Loss: 0.283890
2025-09-02 13:57:31,084 - INFO - Epoch 436/5000 - Train Loss: 0.285641, Val Loss: 0.284663
2025-09-02 13:58:08,311 - INFO - Epoch 437/5000 - Train Loss: 0.287206, Val Loss: 0.284389
2025-09-02 13:58:46,251 - INFO - Epoch 438/5000 - Train Loss: 0.290985, Val Loss: 0.288701
2025-09-02 13:59:24,208 - INFO - Epoch 439/5000 - Train Loss: 0.283747, Val Loss: 0.287049
2025-09-02 14:00:04,035 - INFO - Epoch 440/5000 - Train Loss: 0.288333, Val Loss: 0.286730
2025-09-02 14:00:43,449 - INFO - Epoch 441/5000 - Train Loss: 0.283694, Val Loss: 0.275148
2025-09-02 14:00:43,484 - INFO - New best model saved with Val Loss: 0.275148
2025-09-02 14:01:22,149 - INFO - Epoch 442/5000 - Train Loss: 0.285137, Val Loss: 0.289899
2025-09-02 14:02:00,681 - INFO - Epoch 443/5000 - Train Loss: 0.286375, Val Loss: 0.275249
2025-09-02 14:02:49,708 - INFO - Epoch 444/5000 - Train Loss: 0.282611, Val Loss: 0.288260
2025-09-02 14:03:35,226 - INFO - Epoch 445/5000 - Train Loss: 0.284896, Val Loss: 0.282476
2025-09-02 14:04:22,361 - INFO - Epoch 446/5000 - Train Loss: 0.285020, Val Loss: 0.299698
2025-09-02 14:05:08,431 - INFO - Epoch 447/5000 - Train Loss: 0.283059, Val Loss: 0.281251
2025-09-02 14:05:56,522 - INFO - Epoch 448/5000 - Train Loss: 0.281123, Val Loss: 0.279758
2025-09-02 14:06:41,205 - INFO - Epoch 449/5000 - Train Loss: 0.279665, Val Loss: 0.280577
2025-09-02 14:07:29,622 - INFO - Epoch 450/5000 - Train Loss: 0.280398, Val Loss: 0.280790
2025-09-02 14:08:15,497 - INFO - Epoch 451/5000 - Train Loss: 0.279720, Val Loss: 0.278623
2025-09-02 14:08:54,948 - INFO - Epoch 452/5000 - Train Loss: 0.279316, Val Loss: 0.277993
2025-09-02 14:09:33,251 - INFO - Epoch 453/5000 - Train Loss: 0.283366, Val Loss: 0.281777
2025-09-02 14:10:12,037 - INFO - Epoch 454/5000 - Train Loss: 0.282494, Val Loss: 0.276659
2025-09-02 14:10:50,178 - INFO - Epoch 455/5000 - Train Loss: 0.278795, Val Loss: 0.275930
2025-09-02 14:11:28,847 - INFO - Epoch 456/5000 - Train Loss: 0.277700, Val Loss: 0.273226
2025-09-02 14:11:28,882 - INFO - New best model saved with Val Loss: 0.273226
2025-09-02 14:12:07,774 - INFO - Epoch 457/5000 - Train Loss: 0.281326, Val Loss: 0.274019
2025-09-02 14:12:46,713 - INFO - Epoch 458/5000 - Train Loss: 0.281325, Val Loss: 0.275304
2025-09-02 14:13:24,538 - INFO - Epoch 459/5000 - Train Loss: 0.277373, Val Loss: 0.265715
2025-09-02 14:13:24,572 - INFO - New best model saved with Val Loss: 0.265715
2025-09-02 14:14:02,048 - INFO - Epoch 460/5000 - Train Loss: 0.279501, Val Loss: 0.281147
2025-09-02 14:14:40,794 - INFO - Epoch 461/5000 - Train Loss: 0.279790, Val Loss: 0.286067
2025-09-02 14:15:18,955 - INFO - Epoch 462/5000 - Train Loss: 0.279954, Val Loss: 0.282941
2025-09-02 14:15:56,787 - INFO - Epoch 463/5000 - Train Loss: 0.278019, Val Loss: 0.273835
2025-09-02 14:16:35,112 - INFO - Epoch 464/5000 - Train Loss: 0.276543, Val Loss: 0.285978
2025-09-02 14:17:13,310 - INFO - Epoch 465/5000 - Train Loss: 0.275096, Val Loss: 0.278322
2025-09-02 14:17:50,715 - INFO - Epoch 466/5000 - Train Loss: 0.275279, Val Loss: 0.271823
2025-09-02 14:18:29,058 - INFO - Epoch 467/5000 - Train Loss: 0.274368, Val Loss: 0.273139
2025-09-02 14:19:07,400 - INFO - Epoch 468/5000 - Train Loss: 0.271674, Val Loss: 0.272515
2025-09-02 14:19:44,677 - INFO - Epoch 469/5000 - Train Loss: 0.273258, Val Loss: 0.277422
2025-09-02 14:20:23,282 - INFO - Epoch 470/5000 - Train Loss: 0.275724, Val Loss: 0.269361
2025-09-02 14:21:02,265 - INFO - Epoch 471/5000 - Train Loss: 0.275393, Val Loss: 0.268973
2025-09-02 14:21:39,482 - INFO - Epoch 472/5000 - Train Loss: 0.272223, Val Loss: 0.271854
2025-09-02 14:22:17,478 - INFO - Epoch 473/5000 - Train Loss: 0.270536, Val Loss: 0.270318
2025-09-02 14:22:56,291 - INFO - Epoch 474/5000 - Train Loss: 0.269103, Val Loss: 0.266243
2025-09-02 14:23:34,937 - INFO - Epoch 475/5000 - Train Loss: 0.272326, Val Loss: 0.272934
2025-09-02 14:24:15,031 - INFO - Epoch 476/5000 - Train Loss: 0.269325, Val Loss: 0.267670
2025-09-02 14:24:53,901 - INFO - Epoch 477/5000 - Train Loss: 0.268959, Val Loss: 0.263144
2025-09-02 14:24:53,955 - INFO - New best model saved with Val Loss: 0.263144
2025-09-02 14:25:33,215 - INFO - Epoch 478/5000 - Train Loss: 0.266862, Val Loss: 0.273635
2025-09-02 14:26:11,428 - INFO - Epoch 479/5000 - Train Loss: 0.268528, Val Loss: 0.262732
2025-09-02 14:26:11,473 - INFO - New best model saved with Val Loss: 0.262732
2025-09-02 14:26:48,200 - INFO - Epoch 480/5000 - Train Loss: 0.263386, Val Loss: 0.259229
2025-09-02 14:26:48,237 - INFO - New best model saved with Val Loss: 0.259229
2025-09-02 14:27:26,064 - INFO - Epoch 481/5000 - Train Loss: 0.266996, Val Loss: 0.287118
2025-09-02 14:28:05,103 - INFO - Epoch 482/5000 - Train Loss: 0.273356, Val Loss: 0.273345
2025-09-02 14:28:42,826 - INFO - Epoch 483/5000 - Train Loss: 0.268285, Val Loss: 0.265807
2025-09-02 14:29:20,165 - INFO - Epoch 484/5000 - Train Loss: 0.266223, Val Loss: 0.258789
2025-09-02 14:29:20,201 - INFO - New best model saved with Val Loss: 0.258789
2025-09-02 14:29:58,672 - INFO - Epoch 485/5000 - Train Loss: 0.264548, Val Loss: 0.270736
2025-09-02 14:30:36,362 - INFO - Epoch 486/5000 - Train Loss: 0.264838, Val Loss: 0.268660
2025-09-02 14:31:14,255 - INFO - Epoch 487/5000 - Train Loss: 0.265038, Val Loss: 0.264490
2025-09-02 14:31:52,430 - INFO - Epoch 488/5000 - Train Loss: 0.264916, Val Loss: 0.258913
2025-09-02 14:32:30,815 - INFO - Epoch 489/5000 - Train Loss: 0.267182, Val Loss: 0.279427
2025-09-02 14:33:09,635 - INFO - Epoch 490/5000 - Train Loss: 0.262429, Val Loss: 0.266074
2025-09-02 14:33:47,944 - INFO - Epoch 491/5000 - Train Loss: 0.262725, Val Loss: 0.252061
2025-09-02 14:33:47,979 - INFO - New best model saved with Val Loss: 0.252061
2025-09-02 14:34:25,214 - INFO - Epoch 492/5000 - Train Loss: 0.261423, Val Loss: 0.267946
2025-09-02 14:35:01,490 - INFO - Epoch 493/5000 - Train Loss: 0.259612, Val Loss: 0.256956
2025-09-02 14:35:40,800 - INFO - Epoch 494/5000 - Train Loss: 0.265463, Val Loss: 0.263121
2025-09-02 14:36:18,253 - INFO - Epoch 495/5000 - Train Loss: 0.260148, Val Loss: 0.255291
2025-09-02 14:36:56,770 - INFO - Epoch 496/5000 - Train Loss: 0.261529, Val Loss: 0.260899
2025-09-02 14:37:35,437 - INFO - Epoch 497/5000 - Train Loss: 0.257540, Val Loss: 0.257647
2025-09-02 14:38:13,679 - INFO - Epoch 498/5000 - Train Loss: 0.257390, Val Loss: 0.265221
2025-09-02 14:38:51,618 - INFO - Epoch 499/5000 - Train Loss: 0.258520, Val Loss: 0.261394
2025-09-02 14:39:30,718 - INFO - Epoch 500/5000 - Train Loss: 0.258912, Val Loss: 0.253832
2025-09-02 14:40:09,408 - INFO - Epoch 501/5000 - Train Loss: 0.257133, Val Loss: 0.254179
2025-09-02 14:40:47,494 - INFO - Epoch 502/5000 - Train Loss: 0.256754, Val Loss: 0.264186
2025-09-02 14:41:26,134 - INFO - Epoch 503/5000 - Train Loss: 0.260333, Val Loss: 0.271847
2025-09-02 14:42:04,501 - INFO - Epoch 504/5000 - Train Loss: 0.257976, Val Loss: 0.249818
2025-09-02 14:42:04,537 - INFO - New best model saved with Val Loss: 0.249818
2025-09-02 14:42:41,893 - INFO - Epoch 505/5000 - Train Loss: 0.256895, Val Loss: 0.249839
2025-09-02 14:43:20,343 - INFO - Epoch 506/5000 - Train Loss: 0.255779, Val Loss: 0.250724
2025-09-02 14:43:58,760 - INFO - Epoch 507/5000 - Train Loss: 0.256304, Val Loss: 0.247905
2025-09-02 14:43:58,817 - INFO - New best model saved with Val Loss: 0.247905
2025-09-02 14:44:37,849 - INFO - Epoch 508/5000 - Train Loss: 0.254390, Val Loss: 0.260374
2025-09-02 14:45:15,352 - INFO - Epoch 509/5000 - Train Loss: 0.253142, Val Loss: 0.254334
2025-09-02 14:45:54,326 - INFO - Epoch 510/5000 - Train Loss: 0.252486, Val Loss: 0.252587
2025-09-02 14:46:33,456 - INFO - Epoch 511/5000 - Train Loss: 0.255220, Val Loss: 0.245737
2025-09-02 14:46:33,678 - INFO - New best model saved with Val Loss: 0.245737
2025-09-02 14:47:12,359 - INFO - Epoch 512/5000 - Train Loss: 0.250564, Val Loss: 0.254668
2025-09-02 14:47:51,152 - INFO - Epoch 513/5000 - Train Loss: 0.253486, Val Loss: 0.255893
2025-09-02 14:48:29,404 - INFO - Epoch 514/5000 - Train Loss: 0.252360, Val Loss: 0.252702
2025-09-02 14:49:07,467 - INFO - Epoch 515/5000 - Train Loss: 0.253114, Val Loss: 0.245896
2025-09-02 14:49:45,344 - INFO - Epoch 516/5000 - Train Loss: 0.250797, Val Loss: 0.242861
2025-09-02 14:49:45,377 - INFO - New best model saved with Val Loss: 0.242861
2025-09-02 14:50:23,267 - INFO - Epoch 517/5000 - Train Loss: 0.252737, Val Loss: 0.265393
2025-09-02 14:51:02,082 - INFO - Epoch 518/5000 - Train Loss: 0.253400, Val Loss: 0.257402
2025-09-02 14:51:40,345 - INFO - Epoch 519/5000 - Train Loss: 0.250535, Val Loss: 0.252574
2025-09-02 14:52:17,463 - INFO - Epoch 520/5000 - Train Loss: 0.248659, Val Loss: 0.253615
2025-09-02 14:52:54,911 - INFO - Epoch 521/5000 - Train Loss: 0.248335, Val Loss: 0.248506
2025-09-02 14:53:32,214 - INFO - Epoch 522/5000 - Train Loss: 0.248208, Val Loss: 0.246213
2025-09-02 14:54:10,176 - INFO - Epoch 523/5000 - Train Loss: 0.247726, Val Loss: 0.255231
2025-09-02 14:54:47,122 - INFO - Epoch 524/5000 - Train Loss: 0.249988, Val Loss: 0.251217
2025-09-02 14:55:25,044 - INFO - Epoch 525/5000 - Train Loss: 0.247766, Val Loss: 0.244041
2025-09-02 14:56:03,817 - INFO - Epoch 526/5000 - Train Loss: 0.246429, Val Loss: 0.246292
2025-09-02 14:56:42,420 - INFO - Epoch 527/5000 - Train Loss: 0.247634, Val Loss: 0.246762
2025-09-02 14:57:20,990 - INFO - Epoch 528/5000 - Train Loss: 0.246871, Val Loss: 0.251860
2025-09-02 14:57:58,428 - INFO - Epoch 529/5000 - Train Loss: 0.249822, Val Loss: 0.243502
2025-09-02 14:58:36,319 - INFO - Epoch 530/5000 - Train Loss: 0.245594, Val Loss: 0.239282
2025-09-02 14:58:36,369 - INFO - New best model saved with Val Loss: 0.239282
2025-09-02 14:59:14,094 - INFO - Epoch 531/5000 - Train Loss: 0.248843, Val Loss: 0.244950
2025-09-02 14:59:51,937 - INFO - Epoch 532/5000 - Train Loss: 0.246122, Val Loss: 0.242228
2025-09-02 15:00:29,447 - INFO - Epoch 533/5000 - Train Loss: 0.247567, Val Loss: 0.243093
2025-09-02 15:01:06,747 - INFO - Epoch 534/5000 - Train Loss: 0.244926, Val Loss: 0.245296
2025-09-02 15:01:44,965 - INFO - Epoch 535/5000 - Train Loss: 0.246550, Val Loss: 0.260888
2025-09-02 15:02:22,654 - INFO - Epoch 536/5000 - Train Loss: 0.246445, Val Loss: 0.236031
2025-09-02 15:02:22,688 - INFO - New best model saved with Val Loss: 0.236031
2025-09-02 15:02:59,703 - INFO - Epoch 537/5000 - Train Loss: 0.243554, Val Loss: 0.236654
2025-09-02 15:03:37,140 - INFO - Epoch 538/5000 - Train Loss: 0.246512, Val Loss: 0.246014
2025-09-02 15:04:15,454 - INFO - Epoch 539/5000 - Train Loss: 0.246038, Val Loss: 0.240536
2025-09-02 15:04:54,015 - INFO - Epoch 540/5000 - Train Loss: 0.245359, Val Loss: 0.240690
2025-09-02 15:05:32,437 - INFO - Epoch 541/5000 - Train Loss: 0.245155, Val Loss: 0.240925
2025-09-02 15:06:09,202 - INFO - Epoch 542/5000 - Train Loss: 0.243314, Val Loss: 0.242305
2025-09-02 15:06:46,876 - INFO - Epoch 543/5000 - Train Loss: 0.240525, Val Loss: 0.240847
2025-09-02 15:07:25,097 - INFO - Epoch 544/5000 - Train Loss: 0.243475, Val Loss: 0.238157
2025-09-02 15:08:03,652 - INFO - Epoch 545/5000 - Train Loss: 0.246978, Val Loss: 0.247355
2025-09-02 15:08:41,445 - INFO - Epoch 546/5000 - Train Loss: 0.244216, Val Loss: 0.239465
2025-09-02 15:09:19,701 - INFO - Epoch 547/5000 - Train Loss: 0.244810, Val Loss: 0.241946
2025-09-02 15:09:57,717 - INFO - Epoch 548/5000 - Train Loss: 0.239757, Val Loss: 0.236712
2025-09-02 15:10:35,530 - INFO - Epoch 549/5000 - Train Loss: 0.242567, Val Loss: 0.237398
2025-09-02 15:11:13,484 - INFO - Epoch 550/5000 - Train Loss: 0.240689, Val Loss: 0.241757
2025-09-02 15:11:50,958 - INFO - Epoch 551/5000 - Train Loss: 0.241732, Val Loss: 0.235713
2025-09-02 15:11:50,992 - INFO - New best model saved with Val Loss: 0.235713
2025-09-02 15:12:27,947 - INFO - Epoch 552/5000 - Train Loss: 0.240383, Val Loss: 0.238104
2025-09-02 15:13:04,873 - INFO - Epoch 553/5000 - Train Loss: 0.240669, Val Loss: 0.238794
2025-09-02 15:13:43,362 - INFO - Epoch 554/5000 - Train Loss: 0.240446, Val Loss: 0.235281
2025-09-02 15:13:43,394 - INFO - New best model saved with Val Loss: 0.235281
2025-09-02 15:14:21,307 - INFO - Epoch 555/5000 - Train Loss: 0.240409, Val Loss: 0.235989
2025-09-02 15:14:59,438 - INFO - Epoch 556/5000 - Train Loss: 0.237840, Val Loss: 0.229364
2025-09-02 15:14:59,471 - INFO - New best model saved with Val Loss: 0.229364
2025-09-02 15:15:36,611 - INFO - Epoch 557/5000 - Train Loss: 0.237962, Val Loss: 0.232978
2025-09-02 15:16:14,394 - INFO - Epoch 558/5000 - Train Loss: 0.242002, Val Loss: 0.235620
2025-09-02 15:16:52,955 - INFO - Epoch 559/5000 - Train Loss: 0.241821, Val Loss: 0.237894
2025-09-02 15:17:31,082 - INFO - Epoch 560/5000 - Train Loss: 0.239979, Val Loss: 0.235931
2025-09-02 15:18:09,942 - INFO - Epoch 561/5000 - Train Loss: 0.240249, Val Loss: 0.236447
2025-09-02 15:18:48,165 - INFO - Epoch 562/5000 - Train Loss: 0.237926, Val Loss: 0.241335
2025-09-02 15:19:26,813 - INFO - Epoch 563/5000 - Train Loss: 0.240618, Val Loss: 0.240784
2025-09-02 15:20:05,420 - INFO - Epoch 564/5000 - Train Loss: 0.238775, Val Loss: 0.230043
2025-09-02 15:20:44,113 - INFO - Epoch 565/5000 - Train Loss: 0.234772, Val Loss: 0.238111
2025-09-02 15:21:22,448 - INFO - Epoch 566/5000 - Train Loss: 0.238281, Val Loss: 0.232773
2025-09-02 15:22:00,907 - INFO - Epoch 567/5000 - Train Loss: 0.237427, Val Loss: 0.233976
2025-09-02 15:22:39,095 - INFO - Epoch 568/5000 - Train Loss: 0.237484, Val Loss: 0.230085
2025-09-02 15:23:17,035 - INFO - Epoch 569/5000 - Train Loss: 0.236002, Val Loss: 0.236045
2025-09-02 15:23:54,688 - INFO - Epoch 570/5000 - Train Loss: 0.238631, Val Loss: 0.244651
2025-09-02 15:24:33,505 - INFO - Epoch 571/5000 - Train Loss: 0.238784, Val Loss: 0.228211
2025-09-02 15:24:33,539 - INFO - New best model saved with Val Loss: 0.228211
2025-09-02 15:25:12,003 - INFO - Epoch 572/5000 - Train Loss: 0.236452, Val Loss: 0.231615
2025-09-02 15:25:49,822 - INFO - Epoch 573/5000 - Train Loss: 0.237589, Val Loss: 0.232488
2025-09-02 15:26:27,645 - INFO - Epoch 574/5000 - Train Loss: 0.234997, Val Loss: 0.231214
2025-09-02 15:27:05,157 - INFO - Epoch 575/5000 - Train Loss: 0.235459, Val Loss: 0.234227
2025-09-02 15:27:43,971 - INFO - Epoch 576/5000 - Train Loss: 0.238065, Val Loss: 0.232823
2025-09-02 15:28:22,252 - INFO - Epoch 577/5000 - Train Loss: 0.236378, Val Loss: 0.234600
2025-09-02 15:29:00,432 - INFO - Epoch 578/5000 - Train Loss: 0.235865, Val Loss: 0.242614
2025-09-02 15:29:38,018 - INFO - Epoch 579/5000 - Train Loss: 0.234070, Val Loss: 0.229864
2025-09-02 15:30:16,797 - INFO - Epoch 580/5000 - Train Loss: 0.233253, Val Loss: 0.230008
2025-09-02 15:30:54,945 - INFO - Epoch 581/5000 - Train Loss: 0.234471, Val Loss: 0.226268
2025-09-02 15:30:54,978 - INFO - New best model saved with Val Loss: 0.226268
2025-09-02 15:31:32,634 - INFO - Epoch 582/5000 - Train Loss: 0.233032, Val Loss: 0.227780
2025-09-02 15:32:11,978 - INFO - Epoch 583/5000 - Train Loss: 0.232424, Val Loss: 0.230423
2025-09-02 15:32:50,716 - INFO - Epoch 584/5000 - Train Loss: 0.230969, Val Loss: 0.228269
2025-09-02 15:33:28,979 - INFO - Epoch 585/5000 - Train Loss: 0.233390, Val Loss: 0.226289
2025-09-02 15:34:07,774 - INFO - Epoch 586/5000 - Train Loss: 0.234819, Val Loss: 0.229624
2025-09-02 15:34:45,232 - INFO - Epoch 587/5000 - Train Loss: 0.233516, Val Loss: 0.232172
2025-09-02 15:35:22,924 - INFO - Epoch 588/5000 - Train Loss: 0.231642, Val Loss: 0.234409
2025-09-02 15:36:01,424 - INFO - Epoch 589/5000 - Train Loss: 0.232383, Val Loss: 0.236792
2025-09-02 15:36:39,231 - INFO - Epoch 590/5000 - Train Loss: 0.233121, Val Loss: 0.228638
2025-09-02 15:37:17,553 - INFO - Epoch 591/5000 - Train Loss: 0.231173, Val Loss: 0.223001
2025-09-02 15:37:17,588 - INFO - New best model saved with Val Loss: 0.223001
2025-09-02 15:37:54,906 - INFO - Epoch 592/5000 - Train Loss: 0.231783, Val Loss: 0.226513
2025-09-02 15:38:33,370 - INFO - Epoch 593/5000 - Train Loss: 0.231173, Val Loss: 0.231639
2025-09-02 15:39:12,041 - INFO - Epoch 594/5000 - Train Loss: 0.230119, Val Loss: 0.228608
2025-09-02 15:39:49,904 - INFO - Epoch 595/5000 - Train Loss: 0.231595, Val Loss: 0.226909
2025-09-02 15:40:28,701 - INFO - Epoch 596/5000 - Train Loss: 0.229797, Val Loss: 0.233179
2025-09-02 15:41:07,681 - INFO - Epoch 597/5000 - Train Loss: 0.231983, Val Loss: 0.223146
2025-09-02 15:41:47,194 - INFO - Epoch 598/5000 - Train Loss: 0.229726, Val Loss: 0.228321
2025-09-02 15:42:26,688 - INFO - Epoch 599/5000 - Train Loss: 0.233757, Val Loss: 0.227734
2025-09-02 15:43:05,891 - INFO - Epoch 600/5000 - Train Loss: 0.229807, Val Loss: 0.224083
2025-09-02 15:43:46,708 - INFO - Epoch 601/5000 - Train Loss: 0.230981, Val Loss: 0.222841
2025-09-02 15:43:46,741 - INFO - New best model saved with Val Loss: 0.222841
2025-09-02 15:44:26,446 - INFO - Epoch 602/5000 - Train Loss: 0.234895, Val Loss: 0.232964
2025-09-02 15:45:04,339 - INFO - Epoch 603/5000 - Train Loss: 0.228670, Val Loss: 0.228015
2025-09-02 15:45:41,439 - INFO - Epoch 604/5000 - Train Loss: 0.230479, Val Loss: 0.225382
2025-09-02 15:46:17,856 - INFO - Epoch 605/5000 - Train Loss: 0.228371, Val Loss: 0.227147
2025-09-02 15:46:54,258 - INFO - Epoch 606/5000 - Train Loss: 0.230131, Val Loss: 0.229692
2025-09-02 15:47:31,244 - INFO - Epoch 607/5000 - Train Loss: 0.229383, Val Loss: 0.233494
2025-09-02 15:48:07,731 - INFO - Epoch 608/5000 - Train Loss: 0.228595, Val Loss: 0.224403
2025-09-02 15:48:45,650 - INFO - Epoch 609/5000 - Train Loss: 0.226374, Val Loss: 0.219944
2025-09-02 15:48:45,684 - INFO - New best model saved with Val Loss: 0.219944
2025-09-02 15:49:22,717 - INFO - Epoch 610/5000 - Train Loss: 0.228281, Val Loss: 0.225873
2025-09-02 15:49:59,974 - INFO - Epoch 611/5000 - Train Loss: 0.227693, Val Loss: 0.226179
2025-09-02 15:50:37,208 - INFO - Epoch 612/5000 - Train Loss: 0.227491, Val Loss: 0.226158
2025-09-02 15:51:13,315 - INFO - Epoch 613/5000 - Train Loss: 0.225514, Val Loss: 0.220869
2025-09-02 15:51:50,457 - INFO - Epoch 614/5000 - Train Loss: 0.227820, Val Loss: 0.224687
2025-09-02 15:52:28,071 - INFO - Epoch 615/5000 - Train Loss: 0.226683, Val Loss: 0.220661
2025-09-02 15:53:04,461 - INFO - Epoch 616/5000 - Train Loss: 0.225506, Val Loss: 0.218643
2025-09-02 15:53:04,495 - INFO - New best model saved with Val Loss: 0.218643
2025-09-02 15:53:41,228 - INFO - Epoch 617/5000 - Train Loss: 0.226314, Val Loss: 0.224559
2025-09-02 15:54:18,229 - INFO - Epoch 618/5000 - Train Loss: 0.224740, Val Loss: 0.215515
2025-09-02 15:54:18,263 - INFO - New best model saved with Val Loss: 0.215515
2025-09-02 15:54:55,358 - INFO - Epoch 619/5000 - Train Loss: 0.227611, Val Loss: 0.228772
2025-09-02 15:55:32,943 - INFO - Epoch 620/5000 - Train Loss: 0.227589, Val Loss: 0.216431
2025-09-02 15:56:11,197 - INFO - Epoch 621/5000 - Train Loss: 0.224981, Val Loss: 0.216005
2025-09-02 15:56:49,003 - INFO - Epoch 622/5000 - Train Loss: 0.226121, Val Loss: 0.229489
2025-09-02 15:57:26,971 - INFO - Epoch 623/5000 - Train Loss: 0.225818, Val Loss: 0.215952
2025-09-02 15:58:05,272 - INFO - Epoch 624/5000 - Train Loss: 0.223098, Val Loss: 0.214365
2025-09-02 15:58:05,307 - INFO - New best model saved with Val Loss: 0.214365
2025-09-02 15:58:43,096 - INFO - Epoch 625/5000 - Train Loss: 0.227558, Val Loss: 0.224613
2025-09-02 15:59:20,566 - INFO - Epoch 626/5000 - Train Loss: 0.231845, Val Loss: 0.214310
2025-09-02 15:59:20,599 - INFO - New best model saved with Val Loss: 0.214310
2025-09-02 15:59:58,189 - INFO - Epoch 627/5000 - Train Loss: 0.223603, Val Loss: 0.217292
2025-09-02 16:00:35,328 - INFO - Epoch 628/5000 - Train Loss: 0.223442, Val Loss: 0.217255
2025-09-02 16:01:12,318 - INFO - Epoch 629/5000 - Train Loss: 0.221513, Val Loss: 0.221530
2025-09-02 16:01:49,286 - INFO - Epoch 630/5000 - Train Loss: 0.223341, Val Loss: 0.222354
2025-09-02 16:02:27,572 - INFO - Epoch 631/5000 - Train Loss: 0.225879, Val Loss: 0.219726
2025-09-02 16:03:05,521 - INFO - Epoch 632/5000 - Train Loss: 0.225118, Val Loss: 0.218891
2025-09-02 16:03:43,596 - INFO - Epoch 633/5000 - Train Loss: 0.225815, Val Loss: 0.220541
2025-09-02 16:04:20,323 - INFO - Epoch 634/5000 - Train Loss: 0.223371, Val Loss: 0.214179
2025-09-02 16:04:20,391 - INFO - New best model saved with Val Loss: 0.214179
2025-09-02 16:04:57,236 - INFO - Epoch 635/5000 - Train Loss: 0.220474, Val Loss: 0.219395
2025-09-02 16:05:34,691 - INFO - Epoch 636/5000 - Train Loss: 0.224710, Val Loss: 0.214775
2025-09-02 16:06:11,702 - INFO - Epoch 637/5000 - Train Loss: 0.223079, Val Loss: 0.213664
2025-09-02 16:06:11,753 - INFO - New best model saved with Val Loss: 0.213664
2025-09-02 16:06:50,118 - INFO - Epoch 638/5000 - Train Loss: 0.224222, Val Loss: 0.227342
2025-09-02 16:07:27,366 - INFO - Epoch 639/5000 - Train Loss: 0.227082, Val Loss: 0.237558
2025-09-02 16:08:03,866 - INFO - Epoch 640/5000 - Train Loss: 0.225380, Val Loss: 0.215017
2025-09-02 16:08:41,206 - INFO - Epoch 641/5000 - Train Loss: 0.220907, Val Loss: 0.217262
2025-09-02 16:09:19,065 - INFO - Epoch 642/5000 - Train Loss: 0.220324, Val Loss: 0.209416
2025-09-02 16:09:19,114 - INFO - New best model saved with Val Loss: 0.209416
2025-09-02 16:09:55,829 - INFO - Epoch 643/5000 - Train Loss: 0.222695, Val Loss: 0.211781
2025-09-02 16:10:32,890 - INFO - Epoch 644/5000 - Train Loss: 0.221112, Val Loss: 0.216768
2025-09-02 16:11:10,316 - INFO - Epoch 645/5000 - Train Loss: 0.223403, Val Loss: 0.219013
2025-09-02 16:11:48,210 - INFO - Epoch 646/5000 - Train Loss: 0.224619, Val Loss: 0.217656
2025-09-02 16:12:25,138 - INFO - Epoch 647/5000 - Train Loss: 0.219669, Val Loss: 0.217097
2025-09-02 16:13:01,440 - INFO - Epoch 648/5000 - Train Loss: 0.220801, Val Loss: 0.214776
2025-09-02 16:13:37,864 - INFO - Epoch 649/5000 - Train Loss: 0.219148, Val Loss: 0.214678
2025-09-02 16:14:14,056 - INFO - Epoch 650/5000 - Train Loss: 0.219653, Val Loss: 0.225401
2025-09-02 16:14:51,542 - INFO - Epoch 651/5000 - Train Loss: 0.222738, Val Loss: 0.213797
2025-09-02 16:15:28,411 - INFO - Epoch 652/5000 - Train Loss: 0.223510, Val Loss: 0.212807
2025-09-02 16:16:04,877 - INFO - Epoch 653/5000 - Train Loss: 0.221306, Val Loss: 0.213608
2025-09-02 16:16:41,233 - INFO - Epoch 654/5000 - Train Loss: 0.219045, Val Loss: 0.209833
2025-09-02 16:17:17,908 - INFO - Epoch 655/5000 - Train Loss: 0.218190, Val Loss: 0.214782
2025-09-02 16:17:54,921 - INFO - Epoch 656/5000 - Train Loss: 0.220672, Val Loss: 0.212996
2025-09-02 16:18:32,160 - INFO - Epoch 657/5000 - Train Loss: 0.217886, Val Loss: 0.205604
2025-09-02 16:18:32,194 - INFO - New best model saved with Val Loss: 0.205604
2025-09-02 16:19:09,286 - INFO - Epoch 658/5000 - Train Loss: 0.219526, Val Loss: 0.213649
2025-09-02 16:19:47,274 - INFO - Epoch 659/5000 - Train Loss: 0.219256, Val Loss: 0.209708
2025-09-02 16:20:24,170 - INFO - Epoch 660/5000 - Train Loss: 0.222332, Val Loss: 0.209667
2025-09-02 16:21:02,536 - INFO - Epoch 661/5000 - Train Loss: 0.219370, Val Loss: 0.209451
2025-09-02 16:21:39,365 - INFO - Epoch 662/5000 - Train Loss: 0.219708, Val Loss: 0.208516
2025-09-02 16:22:16,362 - INFO - Epoch 663/5000 - Train Loss: 0.219616, Val Loss: 0.211439
2025-09-02 16:22:53,763 - INFO - Epoch 664/5000 - Train Loss: 0.221048, Val Loss: 0.214353
2025-09-02 16:23:30,720 - INFO - Epoch 665/5000 - Train Loss: 0.218367, Val Loss: 0.206273
2025-09-02 16:24:07,704 - INFO - Epoch 666/5000 - Train Loss: 0.218879, Val Loss: 0.211556
2025-09-02 16:24:45,336 - INFO - Epoch 667/5000 - Train Loss: 0.218399, Val Loss: 0.213254
2025-09-02 16:25:22,367 - INFO - Epoch 668/5000 - Train Loss: 0.220634, Val Loss: 0.206631
2025-09-02 16:26:00,324 - INFO - Epoch 669/5000 - Train Loss: 0.217200, Val Loss: 0.212888
2025-09-02 16:26:37,550 - INFO - Epoch 670/5000 - Train Loss: 0.217627, Val Loss: 0.217708
2025-09-02 16:27:14,964 - INFO - Epoch 671/5000 - Train Loss: 0.220963, Val Loss: 0.207448
2025-09-02 16:27:53,046 - INFO - Epoch 672/5000 - Train Loss: 0.219727, Val Loss: 0.218286
2025-09-02 16:28:30,197 - INFO - Epoch 673/5000 - Train Loss: 0.218156, Val Loss: 0.211759
2025-09-02 16:29:06,704 - INFO - Epoch 674/5000 - Train Loss: 0.217563, Val Loss: 0.209587
2025-09-02 16:29:43,375 - INFO - Epoch 675/5000 - Train Loss: 0.216767, Val Loss: 0.208661
2025-09-02 16:30:20,901 - INFO - Epoch 676/5000 - Train Loss: 0.218944, Val Loss: 0.208048
2025-09-02 16:30:58,237 - INFO - Epoch 677/5000 - Train Loss: 0.217869, Val Loss: 0.211539
2025-09-02 16:31:34,961 - INFO - Epoch 678/5000 - Train Loss: 0.217444, Val Loss: 0.211144
2025-09-02 16:32:12,155 - INFO - Epoch 679/5000 - Train Loss: 0.213591, Val Loss: 0.207808
2025-09-02 16:32:49,442 - INFO - Epoch 680/5000 - Train Loss: 0.217249, Val Loss: 0.208002
2025-09-02 16:33:26,955 - INFO - Epoch 681/5000 - Train Loss: 0.216781, Val Loss: 0.205236
2025-09-02 16:33:27,008 - INFO - New best model saved with Val Loss: 0.205236
2025-09-02 16:34:03,851 - INFO - Epoch 682/5000 - Train Loss: 0.215679, Val Loss: 0.204096
2025-09-02 16:34:03,885 - INFO - New best model saved with Val Loss: 0.204096
2025-09-02 16:34:40,794 - INFO - Epoch 683/5000 - Train Loss: 0.217850, Val Loss: 0.212967
2025-09-02 16:35:17,602 - INFO - Epoch 684/5000 - Train Loss: 0.217349, Val Loss: 0.203829
2025-09-02 16:35:17,642 - INFO - New best model saved with Val Loss: 0.203829
2025-09-02 16:35:55,175 - INFO - Epoch 685/5000 - Train Loss: 0.214260, Val Loss: 0.206355
2025-09-02 16:36:32,356 - INFO - Epoch 686/5000 - Train Loss: 0.212603, Val Loss: 0.211065
2025-09-02 16:37:09,012 - INFO - Epoch 687/5000 - Train Loss: 0.214584, Val Loss: 0.204092
2025-09-02 16:37:46,408 - INFO - Epoch 688/5000 - Train Loss: 0.217594, Val Loss: 0.212321
2025-09-02 16:38:22,397 - INFO - Epoch 689/5000 - Train Loss: 0.212617, Val Loss: 0.204917
2025-09-02 16:38:58,253 - INFO - Epoch 690/5000 - Train Loss: 0.216096, Val Loss: 0.213073
2025-09-02 16:39:35,280 - INFO - Epoch 691/5000 - Train Loss: 0.217609, Val Loss: 0.206236
2025-09-02 16:40:11,635 - INFO - Epoch 692/5000 - Train Loss: 0.215874, Val Loss: 0.204526
2025-09-02 16:40:48,038 - INFO - Epoch 693/5000 - Train Loss: 0.216961, Val Loss: 0.209413
2025-09-02 16:41:24,595 - INFO - Epoch 694/5000 - Train Loss: 0.217217, Val Loss: 0.203947
2025-09-02 16:42:00,964 - INFO - Epoch 695/5000 - Train Loss: 0.213821, Val Loss: 0.211087
2025-09-02 16:42:37,809 - INFO - Epoch 696/5000 - Train Loss: 0.216259, Val Loss: 0.203662
2025-09-02 16:42:37,843 - INFO - New best model saved with Val Loss: 0.203662
2025-09-02 16:43:14,266 - INFO - Epoch 697/5000 - Train Loss: 0.212031, Val Loss: 0.204511
2025-09-02 16:43:50,419 - INFO - Epoch 698/5000 - Train Loss: 0.215434, Val Loss: 0.211118
2025-09-02 16:44:26,783 - INFO - Epoch 699/5000 - Train Loss: 0.215131, Val Loss: 0.206727
2025-09-02 16:45:04,106 - INFO - Epoch 700/5000 - Train Loss: 0.211666, Val Loss: 0.207532
2025-09-02 16:45:41,791 - INFO - Epoch 701/5000 - Train Loss: 0.214256, Val Loss: 0.210857
2025-09-02 16:46:21,927 - INFO - Epoch 702/5000 - Train Loss: 0.216777, Val Loss: 0.205651
2025-09-02 16:46:59,343 - INFO - Epoch 703/5000 - Train Loss: 0.213248, Val Loss: 0.206958
2025-09-02 16:47:36,762 - INFO - Epoch 704/5000 - Train Loss: 0.213755, Val Loss: 0.206211
2025-09-02 16:48:15,162 - INFO - Epoch 705/5000 - Train Loss: 0.211720, Val Loss: 0.200898
2025-09-02 16:48:15,196 - INFO - New best model saved with Val Loss: 0.200898
2025-09-02 16:48:53,656 - INFO - Epoch 706/5000 - Train Loss: 0.211640, Val Loss: 0.198917
2025-09-02 16:48:53,689 - INFO - New best model saved with Val Loss: 0.198917
2025-09-02 16:49:30,724 - INFO - Epoch 707/5000 - Train Loss: 0.216379, Val Loss: 0.203793
2025-09-02 16:50:08,520 - INFO - Epoch 708/5000 - Train Loss: 0.212940, Val Loss: 0.202791
2025-09-02 16:50:45,303 - INFO - Epoch 709/5000 - Train Loss: 0.212591, Val Loss: 0.208546
2025-09-02 16:51:23,103 - INFO - Epoch 710/5000 - Train Loss: 0.213482, Val Loss: 0.203759
2025-09-02 16:52:00,617 - INFO - Epoch 711/5000 - Train Loss: 0.211650, Val Loss: 0.200753
2025-09-02 16:52:38,223 - INFO - Epoch 712/5000 - Train Loss: 0.210860, Val Loss: 0.206226
2025-09-02 16:53:14,830 - INFO - Epoch 713/5000 - Train Loss: 0.212779, Val Loss: 0.201033
2025-09-02 16:53:51,504 - INFO - Epoch 714/5000 - Train Loss: 0.209562, Val Loss: 0.201407
2025-09-02 16:54:28,512 - INFO - Epoch 715/5000 - Train Loss: 0.211306, Val Loss: 0.204226
2025-09-02 16:55:05,675 - INFO - Epoch 716/5000 - Train Loss: 0.211995, Val Loss: 0.217313
2025-09-02 16:55:43,061 - INFO - Epoch 717/5000 - Train Loss: 0.212441, Val Loss: 0.198837
2025-09-02 16:55:43,110 - INFO - New best model saved with Val Loss: 0.198837
2025-09-02 16:56:20,963 - INFO - Epoch 718/5000 - Train Loss: 0.209209, Val Loss: 0.204583
2025-09-02 16:56:58,798 - INFO - Epoch 719/5000 - Train Loss: 0.209900, Val Loss: 0.200902
2025-09-02 16:57:36,912 - INFO - Epoch 720/5000 - Train Loss: 0.210439, Val Loss: 0.205460
2025-09-02 16:58:15,030 - INFO - Epoch 721/5000 - Train Loss: 0.211057, Val Loss: 0.205995
2025-09-02 16:58:52,534 - INFO - Epoch 722/5000 - Train Loss: 0.211541, Val Loss: 0.205419
2025-09-02 16:59:29,855 - INFO - Epoch 723/5000 - Train Loss: 0.211221, Val Loss: 0.196595
2025-09-02 16:59:29,888 - INFO - New best model saved with Val Loss: 0.196595
2025-09-02 17:00:06,057 - INFO - Epoch 724/5000 - Train Loss: 0.209908, Val Loss: 0.197662
2025-09-02 17:00:42,938 - INFO - Epoch 725/5000 - Train Loss: 0.213958, Val Loss: 0.202682
2025-09-02 17:01:19,486 - INFO - Epoch 726/5000 - Train Loss: 0.214232, Val Loss: 0.207751
2025-09-02 17:01:57,391 - INFO - Epoch 727/5000 - Train Loss: 0.209237, Val Loss: 0.210461
2025-09-02 17:02:34,403 - INFO - Epoch 728/5000 - Train Loss: 0.211726, Val Loss: 0.199768
2025-09-02 17:03:10,656 - INFO - Epoch 729/5000 - Train Loss: 0.207218, Val Loss: 0.201544
2025-09-02 17:03:48,035 - INFO - Epoch 730/5000 - Train Loss: 0.208195, Val Loss: 0.199442
2025-09-02 17:04:24,932 - INFO - Epoch 731/5000 - Train Loss: 0.209115, Val Loss: 0.200607
2025-09-02 17:05:01,651 - INFO - Epoch 732/5000 - Train Loss: 0.212416, Val Loss: 0.202261
2025-09-02 17:05:38,591 - INFO - Epoch 733/5000 - Train Loss: 0.210219, Val Loss: 0.202576
2025-09-02 17:06:15,995 - INFO - Epoch 734/5000 - Train Loss: 0.210351, Val Loss: 0.198316
2025-09-02 17:06:53,430 - INFO - Epoch 735/5000 - Train Loss: 0.210103, Val Loss: 0.198719
2025-09-02 17:07:32,513 - INFO - Epoch 736/5000 - Train Loss: 0.210128, Val Loss: 0.196797
2025-09-02 17:08:09,379 - INFO - Epoch 737/5000 - Train Loss: 0.206183, Val Loss: 0.197797
2025-09-02 17:08:46,322 - INFO - Epoch 738/5000 - Train Loss: 0.208079, Val Loss: 0.200670
2025-09-02 17:09:22,917 - INFO - Epoch 739/5000 - Train Loss: 0.209794, Val Loss: 0.198297
2025-09-02 17:09:59,759 - INFO - Epoch 740/5000 - Train Loss: 0.207875, Val Loss: 0.194618
2025-09-02 17:09:59,806 - INFO - New best model saved with Val Loss: 0.194618
2025-09-02 17:10:36,802 - INFO - Epoch 741/5000 - Train Loss: 0.207298, Val Loss: 0.199270
2025-09-02 17:11:13,044 - INFO - Epoch 742/5000 - Train Loss: 0.211210, Val Loss: 0.200371
2025-09-02 17:11:49,974 - INFO - Epoch 743/5000 - Train Loss: 0.208114, Val Loss: 0.195189
2025-09-02 17:12:26,928 - INFO - Epoch 744/5000 - Train Loss: 0.205806, Val Loss: 0.202604
2025-09-02 17:13:03,931 - INFO - Epoch 745/5000 - Train Loss: 0.207545, Val Loss: 0.200522
2025-09-02 17:13:41,583 - INFO - Epoch 746/5000 - Train Loss: 0.207481, Val Loss: 0.193888
2025-09-02 17:13:41,616 - INFO - New best model saved with Val Loss: 0.193888
2025-09-02 17:14:19,720 - INFO - Epoch 747/5000 - Train Loss: 0.209327, Val Loss: 0.197635
2025-09-02 17:14:57,422 - INFO - Epoch 748/5000 - Train Loss: 0.207872, Val Loss: 0.196044
2025-09-02 17:15:34,206 - INFO - Epoch 749/5000 - Train Loss: 0.210745, Val Loss: 0.195817
2025-09-02 17:16:10,965 - INFO - Epoch 750/5000 - Train Loss: 0.208227, Val Loss: 0.199406
2025-09-02 17:16:48,810 - INFO - Epoch 751/5000 - Train Loss: 0.206813, Val Loss: 0.194074
2025-09-02 17:17:26,948 - INFO - Epoch 752/5000 - Train Loss: 0.205910, Val Loss: 0.194646
2025-09-02 17:18:04,798 - INFO - Epoch 753/5000 - Train Loss: 0.206557, Val Loss: 0.199619
2025-09-02 17:18:41,743 - INFO - Epoch 754/5000 - Train Loss: 0.204810, Val Loss: 0.196655
2025-09-02 17:19:18,654 - INFO - Epoch 755/5000 - Train Loss: 0.206244, Val Loss: 0.192210
2025-09-02 17:19:18,687 - INFO - New best model saved with Val Loss: 0.192210
2025-09-02 17:19:55,364 - INFO - Epoch 756/5000 - Train Loss: 0.205724, Val Loss: 0.196451
2025-09-02 17:20:33,670 - INFO - Epoch 757/5000 - Train Loss: 0.207840, Val Loss: 0.201708
2025-09-02 17:21:11,690 - INFO - Epoch 758/5000 - Train Loss: 0.206987, Val Loss: 0.194378
2025-09-02 17:21:48,471 - INFO - Epoch 759/5000 - Train Loss: 0.204887, Val Loss: 0.197238
2025-09-02 17:22:25,597 - INFO - Epoch 760/5000 - Train Loss: 0.204924, Val Loss: 0.194626
2025-09-02 17:23:02,915 - INFO - Epoch 761/5000 - Train Loss: 0.209131, Val Loss: 0.204405
2025-09-02 17:23:39,349 - INFO - Epoch 762/5000 - Train Loss: 0.206988, Val Loss: 0.194488
2025-09-02 17:24:16,229 - INFO - Epoch 763/5000 - Train Loss: 0.204711, Val Loss: 0.194030
2025-09-02 17:24:52,683 - INFO - Epoch 764/5000 - Train Loss: 0.204573, Val Loss: 0.196114
2025-09-02 17:25:29,743 - INFO - Epoch 765/5000 - Train Loss: 0.209475, Val Loss: 0.203141
2025-09-02 17:26:06,637 - INFO - Epoch 766/5000 - Train Loss: 0.206789, Val Loss: 0.197853
2025-09-02 17:26:43,938 - INFO - Epoch 767/5000 - Train Loss: 0.206182, Val Loss: 0.200451
2025-09-02 17:27:20,471 - INFO - Epoch 768/5000 - Train Loss: 0.206931, Val Loss: 0.199384
2025-09-02 17:27:57,223 - INFO - Epoch 769/5000 - Train Loss: 0.204544, Val Loss: 0.191288
2025-09-02 17:27:57,256 - INFO - New best model saved with Val Loss: 0.191288
2025-09-02 17:28:34,056 - INFO - Epoch 770/5000 - Train Loss: 0.204996, Val Loss: 0.190678
2025-09-02 17:28:34,090 - INFO - New best model saved with Val Loss: 0.190678
2025-09-02 17:29:11,697 - INFO - Epoch 771/5000 - Train Loss: 0.202602, Val Loss: 0.195423
2025-09-02 17:29:48,786 - INFO - Epoch 772/5000 - Train Loss: 0.204662, Val Loss: 0.190072
2025-09-02 17:29:48,820 - INFO - New best model saved with Val Loss: 0.190072
2025-09-02 17:30:26,445 - INFO - Epoch 773/5000 - Train Loss: 0.203775, Val Loss: 0.193761
2025-09-02 17:31:03,322 - INFO - Epoch 774/5000 - Train Loss: 0.205264, Val Loss: 0.194529
2025-09-02 17:31:40,411 - INFO - Epoch 775/5000 - Train Loss: 0.204429, Val Loss: 0.196262
2025-09-02 17:32:18,314 - INFO - Epoch 776/5000 - Train Loss: 0.203735, Val Loss: 0.195073
2025-09-02 17:32:55,233 - INFO - Epoch 777/5000 - Train Loss: 0.204699, Val Loss: 0.192504
2025-09-02 17:33:32,298 - INFO - Epoch 778/5000 - Train Loss: 0.206754, Val Loss: 0.202992
2025-09-02 17:34:09,579 - INFO - Epoch 779/5000 - Train Loss: 0.204967, Val Loss: 0.196373
2025-09-02 17:34:47,362 - INFO - Epoch 780/5000 - Train Loss: 0.203981, Val Loss: 0.198395
2025-09-02 17:35:24,106 - INFO - Epoch 781/5000 - Train Loss: 0.203698, Val Loss: 0.194835
2025-09-02 17:36:01,446 - INFO - Epoch 782/5000 - Train Loss: 0.202818, Val Loss: 0.189110
2025-09-02 17:36:01,480 - INFO - New best model saved with Val Loss: 0.189110
2025-09-02 17:36:39,251 - INFO - Epoch 783/5000 - Train Loss: 0.203181, Val Loss: 0.190333
2025-09-02 17:37:16,252 - INFO - Epoch 784/5000 - Train Loss: 0.204406, Val Loss: 0.193417
2025-09-02 17:37:54,165 - INFO - Epoch 785/5000 - Train Loss: 0.205483, Val Loss: 0.194249
2025-09-02 17:38:31,728 - INFO - Epoch 786/5000 - Train Loss: 0.205494, Val Loss: 0.192267
2025-09-02 17:39:08,722 - INFO - Epoch 787/5000 - Train Loss: 0.201245, Val Loss: 0.189806
2025-09-02 17:39:46,327 - INFO - Epoch 788/5000 - Train Loss: 0.204817, Val Loss: 0.197372
2025-09-02 17:40:24,336 - INFO - Epoch 789/5000 - Train Loss: 0.207179, Val Loss: 0.193094
2025-09-02 17:41:01,592 - INFO - Epoch 790/5000 - Train Loss: 0.200700, Val Loss: 0.186822
2025-09-02 17:41:01,626 - INFO - New best model saved with Val Loss: 0.186822
2025-09-02 17:41:38,311 - INFO - Epoch 791/5000 - Train Loss: 0.202732, Val Loss: 0.197016
2025-09-02 17:42:16,156 - INFO - Epoch 792/5000 - Train Loss: 0.205527, Val Loss: 0.191714
2025-09-02 17:42:54,349 - INFO - Epoch 793/5000 - Train Loss: 0.200639, Val Loss: 0.188537
2025-09-02 17:43:31,657 - INFO - Epoch 794/5000 - Train Loss: 0.200639, Val Loss: 0.190002
2025-09-02 17:44:09,901 - INFO - Epoch 795/5000 - Train Loss: 0.202604, Val Loss: 0.196581
2025-09-02 17:44:48,183 - INFO - Epoch 796/5000 - Train Loss: 0.199745, Val Loss: 0.186806
2025-09-02 17:44:48,217 - INFO - New best model saved with Val Loss: 0.186806
2025-09-02 17:45:25,964 - INFO - Epoch 797/5000 - Train Loss: 0.200789, Val Loss: 0.196006
2025-09-02 17:46:02,320 - INFO - Epoch 798/5000 - Train Loss: 0.202118, Val Loss: 0.190618
2025-09-02 17:46:39,420 - INFO - Epoch 799/5000 - Train Loss: 0.201226, Val Loss: 0.187338
2025-09-02 17:47:15,914 - INFO - Epoch 800/5000 - Train Loss: 0.201918, Val Loss: 0.196633
2025-09-02 17:47:52,314 - INFO - Epoch 801/5000 - Train Loss: 0.202674, Val Loss: 0.187785
2025-09-02 17:48:28,667 - INFO - Epoch 802/5000 - Train Loss: 0.201682, Val Loss: 0.196042
2025-09-02 17:49:05,324 - INFO - Epoch 803/5000 - Train Loss: 0.201714, Val Loss: 0.191652
2025-09-02 17:49:41,027 - INFO - Epoch 804/5000 - Train Loss: 0.203983, Val Loss: 0.189939
2025-09-02 17:50:16,816 - INFO - Epoch 805/5000 - Train Loss: 0.200958, Val Loss: 0.197015
2025-09-02 17:50:53,324 - INFO - Epoch 806/5000 - Train Loss: 0.206798, Val Loss: 0.191534
2025-09-02 17:51:29,638 - INFO - Epoch 807/5000 - Train Loss: 0.201315, Val Loss: 0.191413
2025-09-02 17:52:06,391 - INFO - Epoch 808/5000 - Train Loss: 0.200514, Val Loss: 0.191746
2025-09-02 17:52:43,513 - INFO - Epoch 809/5000 - Train Loss: 0.199314, Val Loss: 0.191874
2025-09-02 17:53:19,919 - INFO - Epoch 810/5000 - Train Loss: 0.200486, Val Loss: 0.188515
2025-09-02 17:53:56,090 - INFO - Epoch 811/5000 - Train Loss: 0.201731, Val Loss: 0.187623
2025-09-02 17:54:33,481 - INFO - Epoch 812/5000 - Train Loss: 0.202224, Val Loss: 0.190230
2025-09-02 17:55:10,250 - INFO - Epoch 813/5000 - Train Loss: 0.200105, Val Loss: 0.184855
2025-09-02 17:55:10,317 - INFO - New best model saved with Val Loss: 0.184855
2025-09-02 17:55:47,273 - INFO - Epoch 814/5000 - Train Loss: 0.198482, Val Loss: 0.190476
2025-09-02 17:56:24,149 - INFO - Epoch 815/5000 - Train Loss: 0.202227, Val Loss: 0.193794
2025-09-02 17:57:00,716 - INFO - Epoch 816/5000 - Train Loss: 0.199546, Val Loss: 0.189738
2025-09-02 17:57:37,728 - INFO - Epoch 817/5000 - Train Loss: 0.199354, Val Loss: 0.198476
2025-09-02 17:58:14,850 - INFO - Epoch 818/5000 - Train Loss: 0.200634, Val Loss: 0.190336
2025-09-02 17:58:53,735 - INFO - Epoch 819/5000 - Train Loss: 0.199026, Val Loss: 0.193734
2025-09-02 17:59:30,741 - INFO - Epoch 820/5000 - Train Loss: 0.200746, Val Loss: 0.185873
2025-09-02 18:00:06,694 - INFO - Epoch 821/5000 - Train Loss: 0.199988, Val Loss: 0.190303
2025-09-02 18:00:44,341 - INFO - Epoch 822/5000 - Train Loss: 0.198816, Val Loss: 0.189248
2025-09-02 18:01:22,141 - INFO - Epoch 823/5000 - Train Loss: 0.203594, Val Loss: 0.191417
2025-09-02 18:01:58,801 - INFO - Epoch 824/5000 - Train Loss: 0.200517, Val Loss: 0.191089
2025-09-02 18:02:35,539 - INFO - Epoch 825/5000 - Train Loss: 0.199701, Val Loss: 0.192282
2025-09-02 18:03:13,023 - INFO - Epoch 826/5000 - Train Loss: 0.200773, Val Loss: 0.189489
2025-09-02 18:03:50,358 - INFO - Epoch 827/5000 - Train Loss: 0.198700, Val Loss: 0.185811
2025-09-02 18:04:27,748 - INFO - Epoch 828/5000 - Train Loss: 0.200610, Val Loss: 0.186382
2025-09-02 18:05:04,827 - INFO - Epoch 829/5000 - Train Loss: 0.199354, Val Loss: 0.185518
2025-09-02 18:05:41,545 - INFO - Epoch 830/5000 - Train Loss: 0.198511, Val Loss: 0.186099
2025-09-02 18:06:19,243 - INFO - Epoch 831/5000 - Train Loss: 0.196094, Val Loss: 0.188494
2025-09-02 18:06:56,182 - INFO - Epoch 832/5000 - Train Loss: 0.198132, Val Loss: 0.188383
2025-09-02 18:07:32,385 - INFO - Epoch 833/5000 - Train Loss: 0.198586, Val Loss: 0.189287
2025-09-02 18:08:08,361 - INFO - Epoch 834/5000 - Train Loss: 0.199980, Val Loss: 0.183107
2025-09-02 18:08:08,409 - INFO - New best model saved with Val Loss: 0.183107
2025-09-02 18:08:45,259 - INFO - Epoch 835/5000 - Train Loss: 0.197914, Val Loss: 0.194702
2025-09-02 18:09:21,681 - INFO - Epoch 836/5000 - Train Loss: 0.198942, Val Loss: 0.188597
2025-09-02 18:09:58,958 - INFO - Epoch 837/5000 - Train Loss: 0.197776, Val Loss: 0.190153
2025-09-02 18:10:35,473 - INFO - Epoch 838/5000 - Train Loss: 0.198096, Val Loss: 0.182291
2025-09-02 18:10:35,506 - INFO - New best model saved with Val Loss: 0.182291
2025-09-02 18:11:12,149 - INFO - Epoch 839/5000 - Train Loss: 0.197090, Val Loss: 0.186631
2025-09-02 18:11:49,060 - INFO - Epoch 840/5000 - Train Loss: 0.197279, Val Loss: 0.182023
2025-09-02 18:11:49,095 - INFO - New best model saved with Val Loss: 0.182023
2025-09-02 18:12:25,703 - INFO - Epoch 841/5000 - Train Loss: 0.197533, Val Loss: 0.183038
2025-09-02 18:13:03,233 - INFO - Epoch 842/5000 - Train Loss: 0.196445, Val Loss: 0.183837
2025-09-02 18:13:40,329 - INFO - Epoch 843/5000 - Train Loss: 0.196166, Val Loss: 0.187347
2025-09-02 18:14:17,854 - INFO - Epoch 844/5000 - Train Loss: 0.198923, Val Loss: 0.185333
2025-09-02 18:14:55,015 - INFO - Epoch 845/5000 - Train Loss: 0.197127, Val Loss: 0.193421
2025-09-02 18:15:32,347 - INFO - Epoch 846/5000 - Train Loss: 0.197023, Val Loss: 0.185559
2025-09-02 18:16:09,182 - INFO - Epoch 847/5000 - Train Loss: 0.195187, Val Loss: 0.184611
2025-09-02 18:16:44,948 - INFO - Epoch 848/5000 - Train Loss: 0.196028, Val Loss: 0.183140
2025-09-02 18:17:21,699 - INFO - Epoch 849/5000 - Train Loss: 0.197678, Val Loss: 0.191950
2025-09-02 18:17:57,558 - INFO - Epoch 850/5000 - Train Loss: 0.195687, Val Loss: 0.189479
2025-09-02 18:18:33,851 - INFO - Epoch 851/5000 - Train Loss: 0.199157, Val Loss: 0.194367
2025-09-02 18:19:10,067 - INFO - Epoch 852/5000 - Train Loss: 0.199398, Val Loss: 0.184091
2025-09-02 18:19:47,393 - INFO - Epoch 853/5000 - Train Loss: 0.194333, Val Loss: 0.185631
2025-09-02 18:20:24,117 - INFO - Epoch 854/5000 - Train Loss: 0.195077, Val Loss: 0.182900
2025-09-02 18:21:00,428 - INFO - Epoch 855/5000 - Train Loss: 0.197117, Val Loss: 0.184581
2025-09-02 18:21:37,305 - INFO - Epoch 856/5000 - Train Loss: 0.196318, Val Loss: 0.185035
2025-09-02 18:22:13,803 - INFO - Epoch 857/5000 - Train Loss: 0.194883, Val Loss: 0.186074
2025-09-02 18:22:51,257 - INFO - Epoch 858/5000 - Train Loss: 0.195440, Val Loss: 0.183302
2025-09-02 18:23:27,827 - INFO - Epoch 859/5000 - Train Loss: 0.194924, Val Loss: 0.185137
2025-09-02 18:24:04,235 - INFO - Epoch 860/5000 - Train Loss: 0.196083, Val Loss: 0.181874
2025-09-02 18:24:04,284 - INFO - New best model saved with Val Loss: 0.181874
2025-09-02 18:24:40,701 - INFO - Epoch 861/5000 - Train Loss: 0.197479, Val Loss: 0.185683
2025-09-02 18:25:17,493 - INFO - Epoch 862/5000 - Train Loss: 0.196675, Val Loss: 0.181680
2025-09-02 18:25:17,527 - INFO - New best model saved with Val Loss: 0.181680
2025-09-02 18:25:54,338 - INFO - Epoch 863/5000 - Train Loss: 0.195090, Val Loss: 0.182355
2025-09-02 18:26:33,252 - INFO - Epoch 864/5000 - Train Loss: 0.194138, Val Loss: 0.182937
2025-09-02 18:27:09,760 - INFO - Epoch 865/5000 - Train Loss: 0.195215, Val Loss: 0.183907
2025-09-02 18:27:46,297 - INFO - Epoch 866/5000 - Train Loss: 0.195434, Val Loss: 0.187062
2025-09-02 18:28:22,667 - INFO - Epoch 867/5000 - Train Loss: 0.195343, Val Loss: 0.186084
2025-09-02 18:28:59,574 - INFO - Epoch 868/5000 - Train Loss: 0.195046, Val Loss: 0.183993
2025-09-02 18:29:35,966 - INFO - Epoch 869/5000 - Train Loss: 0.193737, Val Loss: 0.182305
2025-09-02 18:30:12,763 - INFO - Epoch 870/5000 - Train Loss: 0.196603, Val Loss: 0.182030
2025-09-02 18:30:49,685 - INFO - Epoch 871/5000 - Train Loss: 0.194993, Val Loss: 0.180489
2025-09-02 18:30:49,716 - INFO - New best model saved with Val Loss: 0.180489
2025-09-02 18:31:27,168 - INFO - Epoch 872/5000 - Train Loss: 0.193305, Val Loss: 0.180932
2025-09-02 18:32:03,553 - INFO - Epoch 873/5000 - Train Loss: 0.192874, Val Loss: 0.180202
2025-09-02 18:32:03,583 - INFO - New best model saved with Val Loss: 0.180202
2025-09-02 18:32:39,502 - INFO - Epoch 874/5000 - Train Loss: 0.196798, Val Loss: 0.185422
2025-09-02 18:33:16,288 - INFO - Epoch 875/5000 - Train Loss: 0.195225, Val Loss: 0.185715
2025-09-02 18:33:52,803 - INFO - Epoch 876/5000 - Train Loss: 0.193635, Val Loss: 0.184400
2025-09-02 18:34:29,542 - INFO - Epoch 877/5000 - Train Loss: 0.193530, Val Loss: 0.181753
2025-09-02 18:35:05,032 - INFO - Epoch 878/5000 - Train Loss: 0.193030, Val Loss: 0.180620
2025-09-02 18:35:40,497 - INFO - Epoch 879/5000 - Train Loss: 0.192127, Val Loss: 0.184290
2025-09-02 18:36:16,754 - INFO - Epoch 880/5000 - Train Loss: 0.197888, Val Loss: 0.184379
2025-09-02 18:36:52,952 - INFO - Epoch 881/5000 - Train Loss: 0.192873, Val Loss: 0.179356
2025-09-02 18:36:53,002 - INFO - New best model saved with Val Loss: 0.179356
2025-09-02 18:37:28,143 - INFO - Epoch 882/5000 - Train Loss: 0.194003, Val Loss: 0.190088
2025-09-02 18:38:03,784 - INFO - Epoch 883/5000 - Train Loss: 0.193702, Val Loss: 0.179859
2025-09-02 18:38:39,162 - INFO - Epoch 884/5000 - Train Loss: 0.193669, Val Loss: 0.177400
2025-09-02 18:38:39,216 - INFO - New best model saved with Val Loss: 0.177400
2025-09-02 18:39:14,831 - INFO - Epoch 885/5000 - Train Loss: 0.191708, Val Loss: 0.183796
2025-09-02 18:39:50,470 - INFO - Epoch 886/5000 - Train Loss: 0.192900, Val Loss: 0.190806
2025-09-02 18:40:26,092 - INFO - Epoch 887/5000 - Train Loss: 0.197651, Val Loss: 0.184016
2025-09-02 18:41:01,454 - INFO - Epoch 888/5000 - Train Loss: 0.193714, Val Loss: 0.182759
2025-09-02 18:41:37,311 - INFO - Epoch 889/5000 - Train Loss: 0.191786, Val Loss: 0.186502
2025-09-02 18:42:13,337 - INFO - Epoch 890/5000 - Train Loss: 0.192963, Val Loss: 0.180959
2025-09-02 18:42:49,291 - INFO - Epoch 891/5000 - Train Loss: 0.191666, Val Loss: 0.184500
2025-09-02 18:43:26,345 - INFO - Epoch 892/5000 - Train Loss: 0.192200, Val Loss: 0.180650
2025-09-02 18:44:03,158 - INFO - Epoch 893/5000 - Train Loss: 0.191386, Val Loss: 0.177226
2025-09-02 18:44:03,204 - INFO - New best model saved with Val Loss: 0.177226
2025-09-02 18:44:39,668 - INFO - Epoch 894/5000 - Train Loss: 0.190944, Val Loss: 0.178780
2025-09-02 18:45:15,809 - INFO - Epoch 895/5000 - Train Loss: 0.191486, Val Loss: 0.176720
2025-09-02 18:45:15,848 - INFO - New best model saved with Val Loss: 0.176720
2025-09-02 18:45:52,416 - INFO - Epoch 896/5000 - Train Loss: 0.190295, Val Loss: 0.181115
2025-09-02 18:46:28,648 - INFO - Epoch 897/5000 - Train Loss: 0.191370, Val Loss: 0.180334
2025-09-02 18:47:05,180 - INFO - Epoch 898/5000 - Train Loss: 0.190470, Val Loss: 0.177218
2025-09-02 18:47:41,822 - INFO - Epoch 899/5000 - Train Loss: 0.192585, Val Loss: 0.186165
2025-09-02 18:48:17,832 - INFO - Epoch 900/5000 - Train Loss: 0.191992, Val Loss: 0.183958
2025-09-02 18:48:53,737 - INFO - Epoch 901/5000 - Train Loss: 0.190212, Val Loss: 0.177434
2025-09-02 18:49:29,720 - INFO - Epoch 902/5000 - Train Loss: 0.192081, Val Loss: 0.181037
2025-09-02 18:50:06,078 - INFO - Epoch 903/5000 - Train Loss: 0.192963, Val Loss: 0.180518
2025-09-02 18:50:42,339 - INFO - Epoch 904/5000 - Train Loss: 0.191719, Val Loss: 0.183319
2025-09-02 18:51:18,760 - INFO - Epoch 905/5000 - Train Loss: 0.191532, Val Loss: 0.176916
2025-09-02 18:51:55,295 - INFO - Epoch 906/5000 - Train Loss: 0.191571, Val Loss: 0.180824
2025-09-02 18:52:30,520 - INFO - Epoch 907/5000 - Train Loss: 0.190451, Val Loss: 0.184179
2025-09-02 18:53:06,277 - INFO - Epoch 908/5000 - Train Loss: 0.191482, Val Loss: 0.175868
2025-09-02 18:53:06,363 - INFO - New best model saved with Val Loss: 0.175868
2025-09-02 18:53:42,737 - INFO - Epoch 909/5000 - Train Loss: 0.190857, Val Loss: 0.175334
2025-09-02 18:53:42,769 - INFO - New best model saved with Val Loss: 0.175334
2025-09-02 18:54:17,825 - INFO - Epoch 910/5000 - Train Loss: 0.189909, Val Loss: 0.178706
2025-09-02 18:54:53,404 - INFO - Epoch 911/5000 - Train Loss: 0.189738, Val Loss: 0.177006
2025-09-02 18:55:28,818 - INFO - Epoch 912/5000 - Train Loss: 0.190262, Val Loss: 0.180213
2025-09-02 18:56:05,092 - INFO - Epoch 913/5000 - Train Loss: 0.189256, Val Loss: 0.175176
2025-09-02 18:56:05,127 - INFO - New best model saved with Val Loss: 0.175176
2025-09-02 18:56:41,556 - INFO - Epoch 914/5000 - Train Loss: 0.188480, Val Loss: 0.178983
2025-09-02 18:57:16,738 - INFO - Epoch 915/5000 - Train Loss: 0.189762, Val Loss: 0.176307
2025-09-02 18:57:53,278 - INFO - Epoch 916/5000 - Train Loss: 0.191511, Val Loss: 0.179280
2025-09-02 18:58:29,553 - INFO - Epoch 917/5000 - Train Loss: 0.189535, Val Loss: 0.179274
2025-09-02 18:59:06,226 - INFO - Epoch 918/5000 - Train Loss: 0.192793, Val Loss: 0.180258
2025-09-02 18:59:42,355 - INFO - Epoch 919/5000 - Train Loss: 0.188904, Val Loss: 0.181311
2025-09-02 19:00:19,995 - INFO - Epoch 920/5000 - Train Loss: 0.190690, Val Loss: 0.178338
2025-09-02 19:00:57,070 - INFO - Epoch 921/5000 - Train Loss: 0.190338, Val Loss: 0.177427
2025-09-02 19:01:36,780 - INFO - Epoch 922/5000 - Train Loss: 0.188684, Val Loss: 0.176668
2025-09-02 19:02:13,772 - INFO - Epoch 923/5000 - Train Loss: 0.190548, Val Loss: 0.181444
2025-09-02 19:02:52,613 - INFO - Epoch 924/5000 - Train Loss: 0.190733, Val Loss: 0.175984
2025-09-02 19:03:32,664 - INFO - Epoch 925/5000 - Train Loss: 0.190352, Val Loss: 0.184570
2025-09-02 19:04:10,530 - INFO - Epoch 926/5000 - Train Loss: 0.191490, Val Loss: 0.180852
2025-09-02 19:04:49,700 - INFO - Epoch 927/5000 - Train Loss: 0.188102, Val Loss: 0.177204
2025-09-02 19:05:28,792 - INFO - Epoch 928/5000 - Train Loss: 0.187908, Val Loss: 0.174757
2025-09-02 19:05:28,861 - INFO - New best model saved with Val Loss: 0.174757
2025-09-02 19:06:05,570 - INFO - Epoch 929/5000 - Train Loss: 0.189551, Val Loss: 0.176404
2025-09-02 19:06:41,349 - INFO - Epoch 930/5000 - Train Loss: 0.188932, Val Loss: 0.180088
2025-09-02 19:07:25,660 - INFO - Epoch 931/5000 - Train Loss: 0.188154, Val Loss: 0.175457
2025-09-02 19:08:08,456 - INFO - Epoch 932/5000 - Train Loss: 0.188538, Val Loss: 0.180056
2025-09-02 19:08:45,387 - INFO - Epoch 933/5000 - Train Loss: 0.188982, Val Loss: 0.174414
2025-09-02 19:08:45,464 - INFO - New best model saved with Val Loss: 0.174414
2025-09-02 19:09:22,437 - INFO - Epoch 934/5000 - Train Loss: 0.188953, Val Loss: 0.176446
2025-09-02 19:10:00,782 - INFO - Epoch 935/5000 - Train Loss: 0.186837, Val Loss: 0.177068
2025-09-02 19:10:37,441 - INFO - Epoch 936/5000 - Train Loss: 0.187663, Val Loss: 0.173217
2025-09-02 19:10:37,489 - INFO - New best model saved with Val Loss: 0.173217
2025-09-02 19:11:12,522 - INFO - Epoch 937/5000 - Train Loss: 0.188350, Val Loss: 0.177652
2025-09-02 19:11:48,332 - INFO - Epoch 938/5000 - Train Loss: 0.188680, Val Loss: 0.175961
2025-09-02 19:12:26,647 - INFO - Epoch 939/5000 - Train Loss: 0.191096, Val Loss: 0.178202
2025-09-02 19:13:05,858 - INFO - Epoch 940/5000 - Train Loss: 0.187578, Val Loss: 0.178945
2025-09-02 19:13:43,302 - INFO - Epoch 941/5000 - Train Loss: 0.188829, Val Loss: 0.174987
2025-09-02 19:14:21,458 - INFO - Epoch 942/5000 - Train Loss: 0.186384, Val Loss: 0.174773
2025-09-02 19:14:59,441 - INFO - Epoch 943/5000 - Train Loss: 0.188227, Val Loss: 0.176255
2025-09-02 19:15:36,495 - INFO - Epoch 944/5000 - Train Loss: 0.187010, Val Loss: 0.175955
2025-09-02 19:16:15,289 - INFO - Epoch 945/5000 - Train Loss: 0.190322, Val Loss: 0.176688
2025-09-02 19:16:52,151 - INFO - Epoch 946/5000 - Train Loss: 0.187033, Val Loss: 0.173284
2025-09-02 19:17:28,653 - INFO - Epoch 947/5000 - Train Loss: 0.188043, Val Loss: 0.174625
2025-09-02 19:18:05,652 - INFO - Epoch 948/5000 - Train Loss: 0.187483, Val Loss: 0.173259
2025-09-02 19:18:43,847 - INFO - Epoch 949/5000 - Train Loss: 0.185762, Val Loss: 0.171190
2025-09-02 19:18:43,913 - INFO - New best model saved with Val Loss: 0.171190
2025-09-02 19:19:21,146 - INFO - Epoch 950/5000 - Train Loss: 0.186314, Val Loss: 0.174032
2025-09-02 19:19:58,804 - INFO - Epoch 951/5000 - Train Loss: 0.186573, Val Loss: 0.173313
2025-09-02 19:20:34,979 - INFO - Epoch 952/5000 - Train Loss: 0.187568, Val Loss: 0.172986
2025-09-02 19:21:10,793 - INFO - Epoch 953/5000 - Train Loss: 0.184754, Val Loss: 0.171851
2025-09-02 19:21:47,737 - INFO - Epoch 954/5000 - Train Loss: 0.189687, Val Loss: 0.177557
2025-09-02 19:22:24,757 - INFO - Epoch 955/5000 - Train Loss: 0.186191, Val Loss: 0.173366
2025-09-02 19:23:00,842 - INFO - Epoch 956/5000 - Train Loss: 0.185454, Val Loss: 0.174070
2025-09-02 19:23:37,313 - INFO - Epoch 957/5000 - Train Loss: 0.188445, Val Loss: 0.172557
2025-09-02 19:24:14,718 - INFO - Epoch 958/5000 - Train Loss: 0.184647, Val Loss: 0.172947
2025-09-02 19:24:51,993 - INFO - Epoch 959/5000 - Train Loss: 0.185543, Val Loss: 0.178518
2025-09-02 19:25:28,355 - INFO - Epoch 960/5000 - Train Loss: 0.184868, Val Loss: 0.170287
2025-09-02 19:25:28,415 - INFO - New best model saved with Val Loss: 0.170287
2025-09-02 19:26:04,616 - INFO - Epoch 961/5000 - Train Loss: 0.187004, Val Loss: 0.173849
2025-09-02 19:26:40,302 - INFO - Epoch 962/5000 - Train Loss: 0.185164, Val Loss: 0.173135
2025-09-02 19:27:16,627 - INFO - Epoch 963/5000 - Train Loss: 0.187290, Val Loss: 0.181177
2025-09-02 19:27:53,770 - INFO - Epoch 964/5000 - Train Loss: 0.187790, Val Loss: 0.171286
2025-09-02 19:28:31,437 - INFO - Epoch 965/5000 - Train Loss: 0.184837, Val Loss: 0.178035
2025-09-02 19:29:11,750 - INFO - Epoch 966/5000 - Train Loss: 0.185857, Val Loss: 0.173403
2025-09-02 19:29:48,772 - INFO - Epoch 967/5000 - Train Loss: 0.185451, Val Loss: 0.171721
2025-09-02 19:30:25,698 - INFO - Epoch 968/5000 - Train Loss: 0.185007, Val Loss: 0.174136
2025-09-02 19:31:02,169 - INFO - Epoch 969/5000 - Train Loss: 0.183489, Val Loss: 0.170381
2025-09-02 19:31:39,300 - INFO - Epoch 970/5000 - Train Loss: 0.185500, Val Loss: 0.173657
2025-09-02 19:32:15,686 - INFO - Epoch 971/5000 - Train Loss: 0.184863, Val Loss: 0.172047
2025-09-02 19:32:52,290 - INFO - Epoch 972/5000 - Train Loss: 0.186817, Val Loss: 0.176586
2025-09-02 19:33:32,175 - INFO - Epoch 973/5000 - Train Loss: 0.184097, Val Loss: 0.171185
2025-09-02 19:34:58,033 - INFO - Epoch 974/5000 - Train Loss: 0.184571, Val Loss: 0.173329
2025-09-02 19:37:55,660 - INFO - Epoch 975/5000 - Train Loss: 0.188824, Val Loss: 0.177833
2025-09-02 19:39:36,267 - INFO - Epoch 976/5000 - Train Loss: 0.184886, Val Loss: 0.170506
2025-09-02 19:40:20,731 - INFO - Epoch 977/5000 - Train Loss: 0.182978, Val Loss: 0.173839
2025-09-02 19:41:23,888 - INFO - Epoch 978/5000 - Train Loss: 0.183659, Val Loss: 0.170306
2025-09-02 19:44:25,756 - INFO - Epoch 979/5000 - Train Loss: 0.185014, Val Loss: 0.170864
2025-09-02 19:47:05,712 - INFO - Epoch 980/5000 - Train Loss: 0.183532, Val Loss: 0.168237
2025-09-02 19:47:05,807 - INFO - New best model saved with Val Loss: 0.168237
2025-09-02 19:48:19,653 - INFO - Epoch 981/5000 - Train Loss: 0.183347, Val Loss: 0.171128
2025-09-02 19:49:04,350 - INFO - Epoch 982/5000 - Train Loss: 0.184001, Val Loss: 0.171531
2025-09-02 19:49:45,785 - INFO - Epoch 983/5000 - Train Loss: 0.183276, Val Loss: 0.168805
2025-09-02 19:50:26,687 - INFO - Epoch 984/5000 - Train Loss: 0.185397, Val Loss: 0.170146
2025-09-02 19:51:05,675 - INFO - Epoch 985/5000 - Train Loss: 0.184437, Val Loss: 0.178882
2025-09-02 19:51:46,583 - INFO - Epoch 986/5000 - Train Loss: 0.186302, Val Loss: 0.174090
2025-09-02 19:52:22,758 - INFO - Epoch 987/5000 - Train Loss: 0.183541, Val Loss: 0.171995
2025-09-02 19:53:00,142 - INFO - Epoch 988/5000 - Train Loss: 0.182232, Val Loss: 0.175320
2025-09-02 19:53:37,560 - INFO - Epoch 989/5000 - Train Loss: 0.184997, Val Loss: 0.177205
2025-09-02 19:54:13,220 - INFO - Epoch 990/5000 - Train Loss: 0.185220, Val Loss: 0.174885
2025-09-02 19:54:49,411 - INFO - Epoch 991/5000 - Train Loss: 0.184422, Val Loss: 0.171883
2025-09-02 19:55:25,685 - INFO - Epoch 992/5000 - Train Loss: 0.183550, Val Loss: 0.170802
2025-09-02 19:56:01,770 - INFO - Epoch 993/5000 - Train Loss: 0.181437, Val Loss: 0.173777
2025-09-02 19:56:37,843 - INFO - Epoch 994/5000 - Train Loss: 0.185233, Val Loss: 0.174461
2025-09-02 19:57:15,294 - INFO - Epoch 995/5000 - Train Loss: 0.184127, Val Loss: 0.177121
2025-09-02 19:57:51,716 - INFO - Epoch 996/5000 - Train Loss: 0.184204, Val Loss: 0.168121
2025-09-02 19:57:51,760 - INFO - New best model saved with Val Loss: 0.168121
2025-09-02 19:58:28,250 - INFO - Epoch 997/5000 - Train Loss: 0.180565, Val Loss: 0.165615
2025-09-02 19:58:28,281 - INFO - New best model saved with Val Loss: 0.165615
2025-09-02 19:59:05,834 - INFO - Epoch 998/5000 - Train Loss: 0.181893, Val Loss: 0.168056
2025-09-02 19:59:42,295 - INFO - Epoch 999/5000 - Train Loss: 0.180778, Val Loss: 0.171813
2025-09-02 20:00:19,973 - INFO - Epoch 1000/5000 - Train Loss: 0.180993, Val Loss: 0.167287
2025-09-02 20:00:57,397 - INFO - Epoch 1001/5000 - Train Loss: 0.180443, Val Loss: 0.169307
2025-09-02 20:01:33,286 - INFO - Epoch 1002/5000 - Train Loss: 0.183459, Val Loss: 0.168052
2025-09-02 20:02:09,190 - INFO - Epoch 1003/5000 - Train Loss: 0.182347, Val Loss: 0.168754
2025-09-02 20:02:45,212 - INFO - Epoch 1004/5000 - Train Loss: 0.181315, Val Loss: 0.167418
2025-09-02 20:03:22,198 - INFO - Epoch 1005/5000 - Train Loss: 0.181529, Val Loss: 0.168550
2025-09-02 20:03:58,878 - INFO - Epoch 1006/5000 - Train Loss: 0.181144, Val Loss: 0.167252
2025-09-02 20:04:34,884 - INFO - Epoch 1007/5000 - Train Loss: 0.181866, Val Loss: 0.169374
2025-09-02 20:05:10,660 - INFO - Epoch 1008/5000 - Train Loss: 0.179166, Val Loss: 0.165181
2025-09-02 20:05:10,699 - INFO - New best model saved with Val Loss: 0.165181
2025-09-02 20:05:46,275 - INFO - Epoch 1009/5000 - Train Loss: 0.180676, Val Loss: 0.168486
2025-09-02 20:06:21,589 - INFO - Epoch 1010/5000 - Train Loss: 0.181094, Val Loss: 0.167623
2025-09-02 20:06:57,622 - INFO - Epoch 1011/5000 - Train Loss: 0.178516, Val Loss: 0.168278
2025-09-02 20:07:33,245 - INFO - Epoch 1012/5000 - Train Loss: 0.180081, Val Loss: 0.168400
2025-09-02 20:08:09,169 - INFO - Epoch 1013/5000 - Train Loss: 0.179719, Val Loss: 0.165665
2025-09-02 20:08:45,163 - INFO - Epoch 1014/5000 - Train Loss: 0.182232, Val Loss: 0.181179
2025-09-02 20:09:21,671 - INFO - Epoch 1015/5000 - Train Loss: 0.183587, Val Loss: 0.169441
2025-09-02 20:09:57,625 - INFO - Epoch 1016/5000 - Train Loss: 0.179664, Val Loss: 0.168970
2025-09-02 20:10:32,338 - INFO - Epoch 1017/5000 - Train Loss: 0.179602, Val Loss: 0.167097
2025-09-02 20:11:07,803 - INFO - Epoch 1018/5000 - Train Loss: 0.181133, Val Loss: 0.168021
2025-09-02 20:11:44,222 - INFO - Epoch 1019/5000 - Train Loss: 0.180276, Val Loss: 0.163673
2025-09-02 20:11:44,254 - INFO - New best model saved with Val Loss: 0.163673
2025-09-02 20:12:20,295 - INFO - Epoch 1020/5000 - Train Loss: 0.179591, Val Loss: 0.167670
2025-09-02 20:12:56,040 - INFO - Epoch 1021/5000 - Train Loss: 0.179460, Val Loss: 0.164228
2025-09-02 20:13:31,499 - INFO - Epoch 1022/5000 - Train Loss: 0.179833, Val Loss: 0.165096
2025-09-02 20:14:07,235 - INFO - Epoch 1023/5000 - Train Loss: 0.180462, Val Loss: 0.171686
2025-09-02 20:14:43,535 - INFO - Epoch 1024/5000 - Train Loss: 0.179389, Val Loss: 0.166533
2025-09-02 20:15:19,393 - INFO - Epoch 1025/5000 - Train Loss: 0.179228, Val Loss: 0.163264
2025-09-02 20:15:19,423 - INFO - New best model saved with Val Loss: 0.163264
2025-09-02 20:15:55,561 - INFO - Epoch 1026/5000 - Train Loss: 0.180730, Val Loss: 0.174347
2025-09-02 20:16:32,823 - INFO - Epoch 1027/5000 - Train Loss: 0.179017, Val Loss: 0.168065
2025-09-02 20:17:09,056 - INFO - Epoch 1028/5000 - Train Loss: 0.179216, Val Loss: 0.166535
2025-09-02 20:17:45,677 - INFO - Epoch 1029/5000 - Train Loss: 0.177720, Val Loss: 0.164905
2025-09-02 20:18:22,272 - INFO - Epoch 1030/5000 - Train Loss: 0.179050, Val Loss: 0.165593
2025-09-02 20:18:59,160 - INFO - Epoch 1031/5000 - Train Loss: 0.176631, Val Loss: 0.164045
2025-09-02 20:19:36,187 - INFO - Epoch 1032/5000 - Train Loss: 0.177641, Val Loss: 0.163356
2025-09-02 20:20:13,143 - INFO - Epoch 1033/5000 - Train Loss: 0.177167, Val Loss: 0.163881
2025-09-02 20:20:50,396 - INFO - Epoch 1034/5000 - Train Loss: 0.179279, Val Loss: 0.161242
2025-09-02 20:20:50,427 - INFO - New best model saved with Val Loss: 0.161242
2025-09-02 20:21:28,311 - INFO - Epoch 1035/5000 - Train Loss: 0.180329, Val Loss: 0.168201
2025-09-02 20:22:05,115 - INFO - Epoch 1036/5000 - Train Loss: 0.177224, Val Loss: 0.161814
2025-09-02 20:22:42,334 - INFO - Epoch 1037/5000 - Train Loss: 0.177807, Val Loss: 0.165475
2025-09-02 20:23:19,130 - INFO - Epoch 1038/5000 - Train Loss: 0.177411, Val Loss: 0.165832
2025-09-02 20:23:55,743 - INFO - Epoch 1039/5000 - Train Loss: 0.177397, Val Loss: 0.166957
2025-09-02 20:24:32,914 - INFO - Epoch 1040/5000 - Train Loss: 0.179378, Val Loss: 0.166149
2025-09-02 20:25:10,764 - INFO - Epoch 1041/5000 - Train Loss: 0.178706, Val Loss: 0.162516
2025-09-02 20:25:47,993 - INFO - Epoch 1042/5000 - Train Loss: 0.178949, Val Loss: 0.169025
2025-09-02 20:26:25,551 - INFO - Epoch 1043/5000 - Train Loss: 0.176782, Val Loss: 0.161502
2025-09-02 20:27:02,459 - INFO - Epoch 1044/5000 - Train Loss: 0.176846, Val Loss: 0.166422
2025-09-02 20:27:40,006 - INFO - Epoch 1045/5000 - Train Loss: 0.178335, Val Loss: 0.162261
2025-09-02 20:28:16,280 - INFO - Epoch 1046/5000 - Train Loss: 0.177824, Val Loss: 0.163586
2025-09-02 20:28:53,354 - INFO - Epoch 1047/5000 - Train Loss: 0.176209, Val Loss: 0.163644
2025-09-02 20:29:30,891 - INFO - Epoch 1048/5000 - Train Loss: 0.176029, Val Loss: 0.164128
2025-09-02 20:30:07,659 - INFO - Epoch 1049/5000 - Train Loss: 0.174966, Val Loss: 0.162608
2025-09-02 20:30:44,328 - INFO - Epoch 1050/5000 - Train Loss: 0.175931, Val Loss: 0.163474
2025-09-02 20:31:21,311 - INFO - Epoch 1051/5000 - Train Loss: 0.176214, Val Loss: 0.165624
2025-09-02 20:31:58,784 - INFO - Epoch 1052/5000 - Train Loss: 0.175068, Val Loss: 0.166576
2025-09-02 20:32:36,249 - INFO - Epoch 1053/5000 - Train Loss: 0.177359, Val Loss: 0.164514
2025-09-02 20:33:12,736 - INFO - Epoch 1054/5000 - Train Loss: 0.175323, Val Loss: 0.162329
2025-09-02 20:33:49,517 - INFO - Epoch 1055/5000 - Train Loss: 0.176511, Val Loss: 0.160353
2025-09-02 20:33:49,562 - INFO - New best model saved with Val Loss: 0.160353
2025-09-02 20:34:26,156 - INFO - Epoch 1056/5000 - Train Loss: 0.174930, Val Loss: 0.162850
2025-09-02 20:35:02,681 - INFO - Epoch 1057/5000 - Train Loss: 0.175160, Val Loss: 0.165224
2025-09-02 20:35:39,336 - INFO - Epoch 1058/5000 - Train Loss: 0.176160, Val Loss: 0.160409
2025-09-02 20:36:15,684 - INFO - Epoch 1059/5000 - Train Loss: 0.175559, Val Loss: 0.163990
2025-09-02 20:36:52,271 - INFO - Epoch 1060/5000 - Train Loss: 0.175536, Val Loss: 0.162550
2025-09-02 20:37:29,889 - INFO - Epoch 1061/5000 - Train Loss: 0.175195, Val Loss: 0.164764
2025-09-02 20:38:07,227 - INFO - Epoch 1062/5000 - Train Loss: 0.175955, Val Loss: 0.166140
2025-09-02 20:38:44,340 - INFO - Epoch 1063/5000 - Train Loss: 0.173953, Val Loss: 0.158873
2025-09-02 20:38:44,384 - INFO - New best model saved with Val Loss: 0.158873
2025-09-02 20:39:22,426 - INFO - Epoch 1064/5000 - Train Loss: 0.174723, Val Loss: 0.167267
2025-09-02 20:39:59,634 - INFO - Epoch 1065/5000 - Train Loss: 0.177455, Val Loss: 0.158940
2025-09-02 20:40:36,361 - INFO - Epoch 1066/5000 - Train Loss: 0.173402, Val Loss: 0.159553
2025-09-02 20:41:13,318 - INFO - Epoch 1067/5000 - Train Loss: 0.173144, Val Loss: 0.164012
2025-09-02 20:41:50,113 - INFO - Epoch 1068/5000 - Train Loss: 0.174415, Val Loss: 0.164854
2025-09-02 20:42:26,856 - INFO - Epoch 1069/5000 - Train Loss: 0.172550, Val Loss: 0.161477
2025-09-02 20:43:03,574 - INFO - Epoch 1070/5000 - Train Loss: 0.172623, Val Loss: 0.164519
2025-09-02 20:43:40,756 - INFO - Epoch 1071/5000 - Train Loss: 0.176052, Val Loss: 0.161117
2025-09-02 20:44:17,922 - INFO - Epoch 1072/5000 - Train Loss: 0.173933, Val Loss: 0.162048
2025-09-02 20:44:54,371 - INFO - Epoch 1073/5000 - Train Loss: 0.173181, Val Loss: 0.159805
2025-09-02 20:45:31,363 - INFO - Epoch 1074/5000 - Train Loss: 0.171927, Val Loss: 0.160122
2025-09-02 20:46:07,957 - INFO - Epoch 1075/5000 - Train Loss: 0.174098, Val Loss: 0.160230
2025-09-02 20:46:46,656 - INFO - Epoch 1076/5000 - Train Loss: 0.174821, Val Loss: 0.159814
2025-09-02 20:47:23,741 - INFO - Epoch 1077/5000 - Train Loss: 0.173112, Val Loss: 0.158357
2025-09-02 20:47:23,773 - INFO - New best model saved with Val Loss: 0.158357
2025-09-02 20:48:00,782 - INFO - Epoch 1078/5000 - Train Loss: 0.172998, Val Loss: 0.159939
2025-09-02 20:48:37,486 - INFO - Epoch 1079/5000 - Train Loss: 0.172958, Val Loss: 0.157622
2025-09-02 20:48:37,517 - INFO - New best model saved with Val Loss: 0.157622
2025-09-02 20:49:14,770 - INFO - Epoch 1080/5000 - Train Loss: 0.171978, Val Loss: 0.157458
2025-09-02 20:49:14,822 - INFO - New best model saved with Val Loss: 0.157458
2025-09-02 20:49:52,152 - INFO - Epoch 1081/5000 - Train Loss: 0.173189, Val Loss: 0.157518
2025-09-02 20:50:29,285 - INFO - Epoch 1082/5000 - Train Loss: 0.169908, Val Loss: 0.158488
2025-09-02 20:51:05,883 - INFO - Epoch 1083/5000 - Train Loss: 0.174515, Val Loss: 0.158051
2025-09-02 20:51:42,800 - INFO - Epoch 1084/5000 - Train Loss: 0.172512, Val Loss: 0.158553
2025-09-02 20:52:19,458 - INFO - Epoch 1085/5000 - Train Loss: 0.172656, Val Loss: 0.157829
2025-09-02 20:52:56,639 - INFO - Epoch 1086/5000 - Train Loss: 0.171891, Val Loss: 0.159540
2025-09-02 20:53:33,658 - INFO - Epoch 1087/5000 - Train Loss: 0.172178, Val Loss: 0.158218
2025-09-02 20:54:10,780 - INFO - Epoch 1088/5000 - Train Loss: 0.172411, Val Loss: 0.159622
2025-09-02 20:54:47,196 - INFO - Epoch 1089/5000 - Train Loss: 0.171096, Val Loss: 0.159505
2025-09-02 20:55:24,348 - INFO - Epoch 1090/5000 - Train Loss: 0.171240, Val Loss: 0.158961
2025-09-02 20:56:01,536 - INFO - Epoch 1091/5000 - Train Loss: 0.172913, Val Loss: 0.156756
2025-09-02 20:56:01,580 - INFO - New best model saved with Val Loss: 0.156756
2025-09-02 20:56:39,193 - INFO - Epoch 1092/5000 - Train Loss: 0.170109, Val Loss: 0.165770
2025-09-02 20:57:16,082 - INFO - Epoch 1093/5000 - Train Loss: 0.174711, Val Loss: 0.161259
2025-09-02 20:57:53,626 - INFO - Epoch 1094/5000 - Train Loss: 0.171380, Val Loss: 0.161975
2025-09-02 20:58:30,797 - INFO - Epoch 1095/5000 - Train Loss: 0.170092, Val Loss: 0.158959
2025-09-02 20:59:07,677 - INFO - Epoch 1096/5000 - Train Loss: 0.170837, Val Loss: 0.160060
2025-09-02 20:59:44,473 - INFO - Epoch 1097/5000 - Train Loss: 0.168981, Val Loss: 0.158861
2025-09-02 21:00:21,632 - INFO - Epoch 1098/5000 - Train Loss: 0.170116, Val Loss: 0.160982
2025-09-02 21:00:58,044 - INFO - Epoch 1099/5000 - Train Loss: 0.171167, Val Loss: 0.158477
2025-09-02 21:01:35,237 - INFO - Epoch 1100/5000 - Train Loss: 0.171222, Val Loss: 0.158103
2025-09-02 21:02:12,225 - INFO - Epoch 1101/5000 - Train Loss: 0.172585, Val Loss: 0.158889
2025-09-02 21:02:48,707 - INFO - Epoch 1102/5000 - Train Loss: 0.168794, Val Loss: 0.156416
2025-09-02 21:02:48,756 - INFO - New best model saved with Val Loss: 0.156416
2025-09-02 21:03:25,084 - INFO - Epoch 1103/5000 - Train Loss: 0.168442, Val Loss: 0.155727
2025-09-02 21:03:25,127 - INFO - New best model saved with Val Loss: 0.155727
2025-09-02 21:04:02,416 - INFO - Epoch 1104/5000 - Train Loss: 0.169543, Val Loss: 0.154294
2025-09-02 21:04:02,447 - INFO - New best model saved with Val Loss: 0.154294
2025-09-02 21:04:39,850 - INFO - Epoch 1105/5000 - Train Loss: 0.169857, Val Loss: 0.159833
2025-09-02 21:05:16,649 - INFO - Epoch 1106/5000 - Train Loss: 0.169888, Val Loss: 0.153787
2025-09-02 21:05:16,697 - INFO - New best model saved with Val Loss: 0.153787
2025-09-02 21:05:53,573 - INFO - Epoch 1107/5000 - Train Loss: 0.168738, Val Loss: 0.164938
2025-09-02 21:06:29,776 - INFO - Epoch 1108/5000 - Train Loss: 0.170922, Val Loss: 0.154503
2025-09-02 21:07:06,725 - INFO - Epoch 1109/5000 - Train Loss: 0.169096, Val Loss: 0.153824
2025-09-02 21:07:43,815 - INFO - Epoch 1110/5000 - Train Loss: 0.172285, Val Loss: 0.156707
2025-09-02 21:08:20,232 - INFO - Epoch 1111/5000 - Train Loss: 0.169854, Val Loss: 0.159583
2025-09-02 21:08:56,708 - INFO - Epoch 1112/5000 - Train Loss: 0.170116, Val Loss: 0.159619
2025-09-02 21:09:33,313 - INFO - Epoch 1113/5000 - Train Loss: 0.168743, Val Loss: 0.154103
2025-09-02 21:10:10,037 - INFO - Epoch 1114/5000 - Train Loss: 0.168725, Val Loss: 0.162785
2025-09-02 21:10:46,856 - INFO - Epoch 1115/5000 - Train Loss: 0.168055, Val Loss: 0.156088
2025-09-02 21:11:23,463 - INFO - Epoch 1116/5000 - Train Loss: 0.167516, Val Loss: 0.152899
2025-09-02 21:11:23,507 - INFO - New best model saved with Val Loss: 0.152899
2025-09-02 21:12:00,834 - INFO - Epoch 1117/5000 - Train Loss: 0.168004, Val Loss: 0.158276
2025-09-02 21:12:36,981 - INFO - Epoch 1118/5000 - Train Loss: 0.168207, Val Loss: 0.154448
2025-09-02 21:13:13,555 - INFO - Epoch 1119/5000 - Train Loss: 0.169428, Val Loss: 0.156812
2025-09-02 21:13:50,429 - INFO - Epoch 1120/5000 - Train Loss: 0.170497, Val Loss: 0.153261
2025-09-02 21:14:27,112 - INFO - Epoch 1121/5000 - Train Loss: 0.169998, Val Loss: 0.153246
2025-09-02 21:15:03,658 - INFO - Epoch 1122/5000 - Train Loss: 0.167995, Val Loss: 0.156179
2025-09-02 21:15:39,538 - INFO - Epoch 1123/5000 - Train Loss: 0.167469, Val Loss: 0.155276
2025-09-02 21:16:16,558 - INFO - Epoch 1124/5000 - Train Loss: 0.166546, Val Loss: 0.154568
2025-09-02 21:16:53,143 - INFO - Epoch 1125/5000 - Train Loss: 0.168204, Val Loss: 0.159135
2025-09-02 21:17:30,364 - INFO - Epoch 1126/5000 - Train Loss: 0.168749, Val Loss: 0.156174
2025-09-02 21:18:06,891 - INFO - Epoch 1127/5000 - Train Loss: 0.168421, Val Loss: 0.152538
2025-09-02 21:18:06,933 - INFO - New best model saved with Val Loss: 0.152538
2025-09-02 21:18:43,773 - INFO - Epoch 1128/5000 - Train Loss: 0.166210, Val Loss: 0.157118
2025-09-02 21:19:20,403 - INFO - Epoch 1129/5000 - Train Loss: 0.167751, Val Loss: 0.152348
2025-09-02 21:19:20,436 - INFO - New best model saved with Val Loss: 0.152348
2025-09-02 21:19:57,197 - INFO - Epoch 1130/5000 - Train Loss: 0.165844, Val Loss: 0.152404
2025-09-02 21:20:34,564 - INFO - Epoch 1131/5000 - Train Loss: 0.166177, Val Loss: 0.150927
2025-09-02 21:20:34,615 - INFO - New best model saved with Val Loss: 0.150927
2025-09-02 21:21:10,716 - INFO - Epoch 1132/5000 - Train Loss: 0.166287, Val Loss: 0.154962
2025-09-02 21:21:47,115 - INFO - Epoch 1133/5000 - Train Loss: 0.166321, Val Loss: 0.153264
2025-09-02 21:22:23,493 - INFO - Epoch 1134/5000 - Train Loss: 0.167866, Val Loss: 0.154900
2025-09-02 21:23:00,638 - INFO - Epoch 1135/5000 - Train Loss: 0.168099, Val Loss: 0.154860
2025-09-02 21:23:36,491 - INFO - Epoch 1136/5000 - Train Loss: 0.164273, Val Loss: 0.149678
2025-09-02 21:23:36,539 - INFO - New best model saved with Val Loss: 0.149678
2025-09-02 21:24:13,840 - INFO - Epoch 1137/5000 - Train Loss: 0.164721, Val Loss: 0.150081
2025-09-02 21:24:50,343 - INFO - Epoch 1138/5000 - Train Loss: 0.164567, Val Loss: 0.151824
2025-09-02 21:25:26,148 - INFO - Epoch 1139/5000 - Train Loss: 0.168372, Val Loss: 0.155720
2025-09-02 21:26:02,194 - INFO - Epoch 1140/5000 - Train Loss: 0.167398, Val Loss: 0.151983
2025-09-02 21:26:38,784 - INFO - Epoch 1141/5000 - Train Loss: 0.163947, Val Loss: 0.154678
2025-09-02 21:27:15,708 - INFO - Epoch 1142/5000 - Train Loss: 0.165956, Val Loss: 0.152993
2025-09-02 21:27:52,612 - INFO - Epoch 1143/5000 - Train Loss: 0.166536, Val Loss: 0.150988
2025-09-02 21:28:28,779 - INFO - Epoch 1144/5000 - Train Loss: 0.164944, Val Loss: 0.152117
2025-09-02 21:29:06,278 - INFO - Epoch 1145/5000 - Train Loss: 0.164691, Val Loss: 0.154324
2025-09-02 21:29:42,480 - INFO - Epoch 1146/5000 - Train Loss: 0.165278, Val Loss: 0.153748
2025-09-02 21:30:18,689 - INFO - Epoch 1147/5000 - Train Loss: 0.165929, Val Loss: 0.152461
2025-09-02 21:30:54,965 - INFO - Epoch 1148/5000 - Train Loss: 0.165910, Val Loss: 0.150514
2025-09-02 21:31:30,978 - INFO - Epoch 1149/5000 - Train Loss: 0.165600, Val Loss: 0.157262
2025-09-02 21:32:07,141 - INFO - Epoch 1150/5000 - Train Loss: 0.165392, Val Loss: 0.155290
2025-09-02 21:32:43,503 - INFO - Epoch 1151/5000 - Train Loss: 0.165773, Val Loss: 0.148452
2025-09-02 21:32:43,598 - INFO - New best model saved with Val Loss: 0.148452
2025-09-02 21:33:19,300 - INFO - Epoch 1152/5000 - Train Loss: 0.163453, Val Loss: 0.149941
2025-09-02 21:33:56,471 - INFO - Epoch 1153/5000 - Train Loss: 0.165786, Val Loss: 0.153167
2025-09-02 21:34:32,842 - INFO - Epoch 1154/5000 - Train Loss: 0.165815, Val Loss: 0.151141
2025-09-02 21:35:09,853 - INFO - Epoch 1155/5000 - Train Loss: 0.164650, Val Loss: 0.153351
2025-09-02 21:35:45,874 - INFO - Epoch 1156/5000 - Train Loss: 0.163775, Val Loss: 0.148785
2025-09-02 21:36:22,506 - INFO - Epoch 1157/5000 - Train Loss: 0.164510, Val Loss: 0.151801
2025-09-02 21:36:59,710 - INFO - Epoch 1158/5000 - Train Loss: 0.164746, Val Loss: 0.150249
2025-09-02 21:37:36,640 - INFO - Epoch 1159/5000 - Train Loss: 0.164708, Val Loss: 0.154305
2025-09-02 21:38:12,916 - INFO - Epoch 1160/5000 - Train Loss: 0.165537, Val Loss: 0.145941
2025-09-02 21:38:12,966 - INFO - New best model saved with Val Loss: 0.145941
2025-09-02 21:38:49,704 - INFO - Epoch 1161/5000 - Train Loss: 0.164852, Val Loss: 0.157183
2025-09-02 21:39:25,895 - INFO - Epoch 1162/5000 - Train Loss: 0.164891, Val Loss: 0.149094
2025-09-02 21:40:02,756 - INFO - Epoch 1163/5000 - Train Loss: 0.163244, Val Loss: 0.150777
2025-09-02 21:40:38,871 - INFO - Epoch 1164/5000 - Train Loss: 0.162993, Val Loss: 0.149727
2025-09-02 21:41:15,536 - INFO - Epoch 1165/5000 - Train Loss: 0.163194, Val Loss: 0.148803
2025-09-02 21:41:52,217 - INFO - Epoch 1166/5000 - Train Loss: 0.163832, Val Loss: 0.149858
2025-09-02 21:42:29,914 - INFO - Epoch 1167/5000 - Train Loss: 0.163044, Val Loss: 0.149396
2025-09-02 21:43:07,420 - INFO - Epoch 1168/5000 - Train Loss: 0.165891, Val Loss: 0.153554
2025-09-02 21:43:44,662 - INFO - Epoch 1169/5000 - Train Loss: 0.162621, Val Loss: 0.149842
2025-09-02 21:44:21,247 - INFO - Epoch 1170/5000 - Train Loss: 0.162012, Val Loss: 0.150251
2025-09-02 21:44:58,274 - INFO - Epoch 1171/5000 - Train Loss: 0.162496, Val Loss: 0.149999
2025-09-02 21:45:35,746 - INFO - Epoch 1172/5000 - Train Loss: 0.161996, Val Loss: 0.147337
2025-09-02 21:46:12,708 - INFO - Epoch 1173/5000 - Train Loss: 0.162729, Val Loss: 0.151885
2025-09-02 21:46:49,714 - INFO - Epoch 1174/5000 - Train Loss: 0.164588, Val Loss: 0.152804
2025-09-02 21:47:26,683 - INFO - Epoch 1175/5000 - Train Loss: 0.162333, Val Loss: 0.148761
2025-09-02 21:48:02,976 - INFO - Epoch 1176/5000 - Train Loss: 0.162922, Val Loss: 0.150823
2025-09-02 21:48:39,745 - INFO - Epoch 1177/5000 - Train Loss: 0.162199, Val Loss: 0.148591
2025-09-02 21:49:17,180 - INFO - Epoch 1178/5000 - Train Loss: 0.161005, Val Loss: 0.146627
2025-09-02 21:49:54,218 - INFO - Epoch 1179/5000 - Train Loss: 0.164044, Val Loss: 0.149858
2025-09-02 21:50:31,080 - INFO - Epoch 1180/5000 - Train Loss: 0.162420, Val Loss: 0.150626
2025-09-02 21:51:08,275 - INFO - Epoch 1181/5000 - Train Loss: 0.161783, Val Loss: 0.152987
2025-09-02 21:51:45,628 - INFO - Epoch 1182/5000 - Train Loss: 0.161315, Val Loss: 0.150077
2025-09-02 21:52:22,572 - INFO - Epoch 1183/5000 - Train Loss: 0.161925, Val Loss: 0.145729
2025-09-02 21:52:22,639 - INFO - New best model saved with Val Loss: 0.145729
2025-09-02 21:52:59,467 - INFO - Epoch 1184/5000 - Train Loss: 0.162000, Val Loss: 0.152529
2025-09-02 21:53:36,581 - INFO - Epoch 1185/5000 - Train Loss: 0.162478, Val Loss: 0.148868
2025-09-02 21:54:13,608 - INFO - Epoch 1186/5000 - Train Loss: 0.162263, Val Loss: 0.147308
2025-09-02 21:54:50,311 - INFO - Epoch 1187/5000 - Train Loss: 0.162707, Val Loss: 0.148367
2025-09-02 21:55:26,922 - INFO - Epoch 1188/5000 - Train Loss: 0.161633, Val Loss: 0.148708
2025-09-02 21:56:03,813 - INFO - Epoch 1189/5000 - Train Loss: 0.160918, Val Loss: 0.148713
2025-09-02 21:56:40,221 - INFO - Epoch 1190/5000 - Train Loss: 0.161993, Val Loss: 0.148204
2025-09-02 21:57:17,145 - INFO - Epoch 1191/5000 - Train Loss: 0.161832, Val Loss: 0.154291
2025-09-02 21:57:54,150 - INFO - Epoch 1192/5000 - Train Loss: 0.162612, Val Loss: 0.146984
2025-09-02 21:58:31,422 - INFO - Epoch 1193/5000 - Train Loss: 0.162514, Val Loss: 0.150308
2025-09-02 21:59:08,820 - INFO - Epoch 1194/5000 - Train Loss: 0.161911, Val Loss: 0.147419
2025-09-02 21:59:45,732 - INFO - Epoch 1195/5000 - Train Loss: 0.160241, Val Loss: 0.149174
2025-09-02 22:00:22,366 - INFO - Epoch 1196/5000 - Train Loss: 0.160878, Val Loss: 0.145559
2025-09-02 22:00:22,411 - INFO - New best model saved with Val Loss: 0.145559
2025-09-02 22:00:59,221 - INFO - Epoch 1197/5000 - Train Loss: 0.161709, Val Loss: 0.152974
2025-09-02 22:01:36,151 - INFO - Epoch 1198/5000 - Train Loss: 0.163781, Val Loss: 0.154000
2025-09-02 22:02:13,449 - INFO - Epoch 1199/5000 - Train Loss: 0.162728, Val Loss: 0.148271
2025-09-02 22:02:49,590 - INFO - Epoch 1200/5000 - Train Loss: 0.160565, Val Loss: 0.149362
2025-09-02 22:03:26,075 - INFO - Epoch 1201/5000 - Train Loss: 0.159881, Val Loss: 0.148879
2025-09-02 22:04:02,528 - INFO - Epoch 1202/5000 - Train Loss: 0.159513, Val Loss: 0.147404
2025-09-02 22:04:38,646 - INFO - Epoch 1203/5000 - Train Loss: 0.161394, Val Loss: 0.151031
2025-09-02 22:05:14,784 - INFO - Epoch 1204/5000 - Train Loss: 0.159953, Val Loss: 0.144409
2025-09-02 22:05:14,828 - INFO - New best model saved with Val Loss: 0.144409
2025-09-02 22:05:52,016 - INFO - Epoch 1205/5000 - Train Loss: 0.160823, Val Loss: 0.145594
2025-09-02 22:06:31,337 - INFO - Epoch 1206/5000 - Train Loss: 0.162058, Val Loss: 0.147783
2025-09-02 22:07:08,437 - INFO - Epoch 1207/5000 - Train Loss: 0.162580, Val Loss: 0.148602
2025-09-02 22:07:45,253 - INFO - Epoch 1208/5000 - Train Loss: 0.161315, Val Loss: 0.150405
2025-09-02 22:08:28,899 - INFO - Epoch 1209/5000 - Train Loss: 0.159957, Val Loss: 0.147123
2025-09-02 22:09:11,927 - INFO - Epoch 1210/5000 - Train Loss: 0.161303, Val Loss: 0.146595
2025-09-02 22:09:55,172 - INFO - Epoch 1211/5000 - Train Loss: 0.158682, Val Loss: 0.146167
2025-09-02 22:10:43,792 - INFO - Epoch 1212/5000 - Train Loss: 0.159074, Val Loss: 0.145158
2025-09-02 22:11:32,857 - INFO - Epoch 1213/5000 - Train Loss: 0.159179, Val Loss: 0.145226
2025-09-02 22:12:15,706 - INFO - Epoch 1214/5000 - Train Loss: 0.158315, Val Loss: 0.145683
2025-09-02 22:12:58,255 - INFO - Epoch 1215/5000 - Train Loss: 0.159639, Val Loss: 0.144646
2025-09-02 22:13:44,324 - INFO - Epoch 1216/5000 - Train Loss: 0.157921, Val Loss: 0.143942
2025-09-02 22:13:44,373 - INFO - New best model saved with Val Loss: 0.143942
2025-09-02 22:14:24,605 - INFO - Epoch 1217/5000 - Train Loss: 0.162702, Val Loss: 0.152043
2025-09-02 22:15:01,814 - INFO - Epoch 1218/5000 - Train Loss: 0.159698, Val Loss: 0.150647
2025-09-02 22:15:38,142 - INFO - Epoch 1219/5000 - Train Loss: 0.158897, Val Loss: 0.149064
2025-09-02 22:16:14,214 - INFO - Epoch 1220/5000 - Train Loss: 0.158019, Val Loss: 0.143470
2025-09-02 22:16:14,256 - INFO - New best model saved with Val Loss: 0.143470
2025-09-02 22:16:50,177 - INFO - Epoch 1221/5000 - Train Loss: 0.158742, Val Loss: 0.145608
2025-09-02 22:17:26,984 - INFO - Epoch 1222/5000 - Train Loss: 0.157371, Val Loss: 0.144761
2025-09-02 22:18:03,661 - INFO - Epoch 1223/5000 - Train Loss: 0.156909, Val Loss: 0.142999
2025-09-02 22:18:03,707 - INFO - New best model saved with Val Loss: 0.142999
2025-09-02 22:18:40,688 - INFO - Epoch 1224/5000 - Train Loss: 0.158505, Val Loss: 0.146593
2025-09-02 22:19:16,941 - INFO - Epoch 1225/5000 - Train Loss: 0.158517, Val Loss: 0.151014
2025-09-02 22:19:52,896 - INFO - Epoch 1226/5000 - Train Loss: 0.158968, Val Loss: 0.145730
2025-09-02 22:20:28,701 - INFO - Epoch 1227/5000 - Train Loss: 0.161590, Val Loss: 0.147304
2025-09-02 22:21:04,718 - INFO - Epoch 1228/5000 - Train Loss: 0.159412, Val Loss: 0.148746
2025-09-02 22:21:40,974 - INFO - Epoch 1229/5000 - Train Loss: 0.161499, Val Loss: 0.145569
2025-09-02 22:22:17,670 - INFO - Epoch 1230/5000 - Train Loss: 0.159000, Val Loss: 0.146111
2025-09-02 22:22:55,313 - INFO - Epoch 1231/5000 - Train Loss: 0.158164, Val Loss: 0.143003
2025-09-02 22:23:31,646 - INFO - Epoch 1232/5000 - Train Loss: 0.155448, Val Loss: 0.144118
2025-09-02 22:24:08,534 - INFO - Epoch 1233/5000 - Train Loss: 0.156671, Val Loss: 0.142223
2025-09-02 22:24:08,571 - INFO - New best model saved with Val Loss: 0.142223
2025-09-02 22:24:45,107 - INFO - Epoch 1234/5000 - Train Loss: 0.157738, Val Loss: 0.141992
2025-09-02 22:24:45,137 - INFO - New best model saved with Val Loss: 0.141992
2025-09-02 22:25:21,781 - INFO - Epoch 1235/5000 - Train Loss: 0.157437, Val Loss: 0.147287
2025-09-02 22:25:58,516 - INFO - Epoch 1236/5000 - Train Loss: 0.161550, Val Loss: 0.144021
2025-09-02 22:26:35,076 - INFO - Epoch 1237/5000 - Train Loss: 0.157375, Val Loss: 0.143969
2025-09-02 22:27:12,206 - INFO - Epoch 1238/5000 - Train Loss: 0.159573, Val Loss: 0.148777
2025-09-02 22:27:48,892 - INFO - Epoch 1239/5000 - Train Loss: 0.159796, Val Loss: 0.143039
2025-09-02 22:28:25,485 - INFO - Epoch 1240/5000 - Train Loss: 0.158969, Val Loss: 0.145116
2025-09-02 22:29:02,745 - INFO - Epoch 1241/5000 - Train Loss: 0.157548, Val Loss: 0.142716
2025-09-02 22:29:39,870 - INFO - Epoch 1242/5000 - Train Loss: 0.156117, Val Loss: 0.142621
2025-09-02 22:30:16,719 - INFO - Epoch 1243/5000 - Train Loss: 0.156163, Val Loss: 0.144447
2025-09-02 22:30:55,639 - INFO - Epoch 1244/5000 - Train Loss: 0.156069, Val Loss: 0.141542
2025-09-02 22:30:55,685 - INFO - New best model saved with Val Loss: 0.141542
2025-09-02 22:31:32,839 - INFO - Epoch 1245/5000 - Train Loss: 0.156343, Val Loss: 0.142704
2025-09-02 22:32:09,597 - INFO - Epoch 1246/5000 - Train Loss: 0.156896, Val Loss: 0.144711
2025-09-02 22:32:45,715 - INFO - Epoch 1247/5000 - Train Loss: 0.161734, Val Loss: 0.147894
2025-09-02 22:33:22,234 - INFO - Epoch 1248/5000 - Train Loss: 0.158187, Val Loss: 0.144858
2025-09-02 22:33:59,112 - INFO - Epoch 1249/5000 - Train Loss: 0.156507, Val Loss: 0.143119
2025-09-02 22:34:35,749 - INFO - Epoch 1250/5000 - Train Loss: 0.157682, Val Loss: 0.141966
2025-09-02 22:35:12,408 - INFO - Epoch 1251/5000 - Train Loss: 0.158448, Val Loss: 0.145623
2025-09-02 22:35:48,633 - INFO - Epoch 1252/5000 - Train Loss: 0.159576, Val Loss: 0.141578
2025-09-02 22:36:24,738 - INFO - Epoch 1253/5000 - Train Loss: 0.156965, Val Loss: 0.141120
2025-09-02 22:36:24,769 - INFO - New best model saved with Val Loss: 0.141120
2025-09-02 22:37:01,225 - INFO - Epoch 1254/5000 - Train Loss: 0.155903, Val Loss: 0.141672
2025-09-02 22:37:38,110 - INFO - Epoch 1255/5000 - Train Loss: 0.156584, Val Loss: 0.140139
2025-09-02 22:37:38,155 - INFO - New best model saved with Val Loss: 0.140139
2025-09-02 22:38:14,984 - INFO - Epoch 1256/5000 - Train Loss: 0.155768, Val Loss: 0.141260
2025-09-02 22:38:51,461 - INFO - Epoch 1257/5000 - Train Loss: 0.156010, Val Loss: 0.145418
2025-09-02 22:39:27,714 - INFO - Epoch 1258/5000 - Train Loss: 0.159930, Val Loss: 0.147586
2025-09-02 22:40:04,305 - INFO - Epoch 1259/5000 - Train Loss: 0.155756, Val Loss: 0.143815
2025-09-02 22:40:40,726 - INFO - Epoch 1260/5000 - Train Loss: 0.155298, Val Loss: 0.143421
2025-09-02 22:41:18,449 - INFO - Epoch 1261/5000 - Train Loss: 0.154980, Val Loss: 0.144088
2025-09-02 22:41:55,747 - INFO - Epoch 1262/5000 - Train Loss: 0.154050, Val Loss: 0.143157
2025-09-02 22:42:32,148 - INFO - Epoch 1263/5000 - Train Loss: 0.156999, Val Loss: 0.146478
2025-09-02 22:43:08,798 - INFO - Epoch 1264/5000 - Train Loss: 0.155724, Val Loss: 0.142484
2025-09-02 22:43:45,667 - INFO - Epoch 1265/5000 - Train Loss: 0.154895, Val Loss: 0.144931
2025-09-02 22:44:21,560 - INFO - Epoch 1266/5000 - Train Loss: 0.156805, Val Loss: 0.142314
2025-09-02 22:44:57,676 - INFO - Epoch 1267/5000 - Train Loss: 0.155040, Val Loss: 0.145995
2025-09-02 22:45:33,721 - INFO - Epoch 1268/5000 - Train Loss: 0.155967, Val Loss: 0.146459
2025-09-02 22:46:10,730 - INFO - Epoch 1269/5000 - Train Loss: 0.156538, Val Loss: 0.143592
2025-09-02 22:46:47,678 - INFO - Epoch 1270/5000 - Train Loss: 0.154590, Val Loss: 0.141664
2025-09-02 22:47:24,491 - INFO - Epoch 1271/5000 - Train Loss: 0.154592, Val Loss: 0.142414
2025-09-02 22:48:00,469 - INFO - Epoch 1272/5000 - Train Loss: 0.158417, Val Loss: 0.152972
2025-09-02 22:48:36,669 - INFO - Epoch 1273/5000 - Train Loss: 0.160286, Val Loss: 0.145757
2025-09-02 22:49:12,743 - INFO - Epoch 1274/5000 - Train Loss: 0.155286, Val Loss: 0.142601
2025-09-02 22:49:48,649 - INFO - Epoch 1275/5000 - Train Loss: 0.155593, Val Loss: 0.143012
2025-09-02 22:50:24,626 - INFO - Epoch 1276/5000 - Train Loss: 0.154235, Val Loss: 0.141633
2025-09-02 22:51:00,692 - INFO - Epoch 1277/5000 - Train Loss: 0.155326, Val Loss: 0.139749
2025-09-02 22:51:00,739 - INFO - New best model saved with Val Loss: 0.139749
2025-09-02 22:51:37,213 - INFO - Epoch 1278/5000 - Train Loss: 0.155302, Val Loss: 0.141083
2025-09-02 22:52:13,688 - INFO - Epoch 1279/5000 - Train Loss: 0.152943, Val Loss: 0.139460
2025-09-02 22:52:13,718 - INFO - New best model saved with Val Loss: 0.139460
2025-09-02 22:52:50,475 - INFO - Epoch 1280/5000 - Train Loss: 0.153760, Val Loss: 0.140677
2025-09-02 22:53:26,654 - INFO - Epoch 1281/5000 - Train Loss: 0.153922, Val Loss: 0.140817
2025-09-02 22:54:03,903 - INFO - Epoch 1282/5000 - Train Loss: 0.154852, Val Loss: 0.140435
2025-09-02 22:54:40,301 - INFO - Epoch 1283/5000 - Train Loss: 0.155509, Val Loss: 0.144236
2025-09-02 22:55:16,311 - INFO - Epoch 1284/5000 - Train Loss: 0.153046, Val Loss: 0.141098
2025-09-02 22:55:53,056 - INFO - Epoch 1285/5000 - Train Loss: 0.154398, Val Loss: 0.141349
2025-09-02 22:56:30,132 - INFO - Epoch 1286/5000 - Train Loss: 0.153458, Val Loss: 0.145158
2025-09-02 22:57:08,041 - INFO - Epoch 1287/5000 - Train Loss: 0.153797, Val Loss: 0.140313
2025-09-02 22:57:44,476 - INFO - Epoch 1288/5000 - Train Loss: 0.158125, Val Loss: 0.140418
2025-09-02 22:58:21,024 - INFO - Epoch 1289/5000 - Train Loss: 0.153409, Val Loss: 0.143320
2025-09-02 22:58:57,852 - INFO - Epoch 1290/5000 - Train Loss: 0.157677, Val Loss: 0.144120
2025-09-02 22:59:34,100 - INFO - Epoch 1291/5000 - Train Loss: 0.155124, Val Loss: 0.142628
2025-09-02 23:00:09,885 - INFO - Epoch 1292/5000 - Train Loss: 0.154440, Val Loss: 0.143433
2025-09-02 23:00:46,476 - INFO - Epoch 1293/5000 - Train Loss: 0.153141, Val Loss: 0.139396
2025-09-02 23:00:46,530 - INFO - New best model saved with Val Loss: 0.139396
2025-09-02 23:01:22,570 - INFO - Epoch 1294/5000 - Train Loss: 0.153772, Val Loss: 0.140691
2025-09-02 23:01:58,893 - INFO - Epoch 1295/5000 - Train Loss: 0.153985, Val Loss: 0.139411
2025-09-02 23:02:35,190 - INFO - Epoch 1296/5000 - Train Loss: 0.153394, Val Loss: 0.136438
2025-09-02 23:02:35,221 - INFO - New best model saved with Val Loss: 0.136438
2025-09-02 23:03:12,040 - INFO - Epoch 1297/5000 - Train Loss: 0.151809, Val Loss: 0.138495
2025-09-02 23:03:48,451 - INFO - Epoch 1298/5000 - Train Loss: 0.154030, Val Loss: 0.139640
2025-09-02 23:04:25,544 - INFO - Epoch 1299/5000 - Train Loss: 0.153059, Val Loss: 0.143744
2025-09-02 23:05:01,874 - INFO - Epoch 1300/5000 - Train Loss: 0.153060, Val Loss: 0.141659
2025-09-02 23:05:37,502 - INFO - Epoch 1301/5000 - Train Loss: 0.155030, Val Loss: 0.146100
2025-09-02 23:06:13,861 - INFO - Epoch 1302/5000 - Train Loss: 0.153593, Val Loss: 0.140929
2025-09-02 23:06:50,465 - INFO - Epoch 1303/5000 - Train Loss: 0.153975, Val Loss: 0.143481
2025-09-02 23:07:26,995 - INFO - Epoch 1304/5000 - Train Loss: 0.153452, Val Loss: 0.141039
2025-09-02 23:08:04,346 - INFO - Epoch 1305/5000 - Train Loss: 0.153041, Val Loss: 0.136877
2025-09-02 23:08:40,816 - INFO - Epoch 1306/5000 - Train Loss: 0.154667, Val Loss: 0.142066
2025-09-02 23:09:18,338 - INFO - Epoch 1307/5000 - Train Loss: 0.153555, Val Loss: 0.143065
2025-09-02 23:09:55,369 - INFO - Epoch 1308/5000 - Train Loss: 0.153076, Val Loss: 0.138460
2025-09-02 23:10:31,351 - INFO - Epoch 1309/5000 - Train Loss: 0.152352, Val Loss: 0.136837
2025-09-02 23:11:07,624 - INFO - Epoch 1310/5000 - Train Loss: 0.152373, Val Loss: 0.139312
2025-09-02 23:11:45,127 - INFO - Epoch 1311/5000 - Train Loss: 0.152585, Val Loss: 0.139709
2025-09-02 23:12:21,161 - INFO - Epoch 1312/5000 - Train Loss: 0.152005, Val Loss: 0.138948
2025-09-02 23:12:57,541 - INFO - Epoch 1313/5000 - Train Loss: 0.152199, Val Loss: 0.140862
2025-09-02 23:13:34,250 - INFO - Epoch 1314/5000 - Train Loss: 0.154411, Val Loss: 0.144327
2025-09-02 23:14:11,132 - INFO - Epoch 1315/5000 - Train Loss: 0.153236, Val Loss: 0.138276
2025-09-02 23:14:47,755 - INFO - Epoch 1316/5000 - Train Loss: 0.152728, Val Loss: 0.142672
2025-09-02 23:15:25,246 - INFO - Epoch 1317/5000 - Train Loss: 0.151298, Val Loss: 0.137186
2025-09-02 23:16:01,734 - INFO - Epoch 1318/5000 - Train Loss: 0.151432, Val Loss: 0.136025
2025-09-02 23:16:01,774 - INFO - New best model saved with Val Loss: 0.136025
2025-09-02 23:16:38,485 - INFO - Epoch 1319/5000 - Train Loss: 0.152858, Val Loss: 0.140171
2025-09-02 23:17:14,977 - INFO - Epoch 1320/5000 - Train Loss: 0.153752, Val Loss: 0.145115
2025-09-02 23:17:51,634 - INFO - Epoch 1321/5000 - Train Loss: 0.152172, Val Loss: 0.136944
2025-09-02 23:18:28,746 - INFO - Epoch 1322/5000 - Train Loss: 0.150981, Val Loss: 0.138062
2025-09-02 23:19:05,099 - INFO - Epoch 1323/5000 - Train Loss: 0.149992, Val Loss: 0.138435
2025-09-02 23:19:41,127 - INFO - Epoch 1324/5000 - Train Loss: 0.151076, Val Loss: 0.139143
2025-09-02 23:20:17,843 - INFO - Epoch 1325/5000 - Train Loss: 0.154142, Val Loss: 0.139833
2025-09-02 23:20:54,920 - INFO - Epoch 1326/5000 - Train Loss: 0.152286, Val Loss: 0.139292
2025-09-02 23:21:30,737 - INFO - Epoch 1327/5000 - Train Loss: 0.150823, Val Loss: 0.139162
2025-09-02 23:22:07,071 - INFO - Epoch 1328/5000 - Train Loss: 0.153066, Val Loss: 0.145270
2025-09-02 23:22:44,308 - INFO - Epoch 1329/5000 - Train Loss: 0.152587, Val Loss: 0.138699
2025-09-02 23:23:21,362 - INFO - Epoch 1330/5000 - Train Loss: 0.149099, Val Loss: 0.135151
2025-09-02 23:23:21,393 - INFO - New best model saved with Val Loss: 0.135151
2025-09-02 23:23:59,158 - INFO - Epoch 1331/5000 - Train Loss: 0.150972, Val Loss: 0.144631
2025-09-02 23:24:36,655 - INFO - Epoch 1332/5000 - Train Loss: 0.152502, Val Loss: 0.139713
2025-09-02 23:25:13,305 - INFO - Epoch 1333/5000 - Train Loss: 0.149784, Val Loss: 0.137742
2025-09-02 23:25:50,221 - INFO - Epoch 1334/5000 - Train Loss: 0.149662, Val Loss: 0.136317
2025-09-02 23:26:26,626 - INFO - Epoch 1335/5000 - Train Loss: 0.152441, Val Loss: 0.147243
2025-09-02 23:27:03,581 - INFO - Epoch 1336/5000 - Train Loss: 0.154110, Val Loss: 0.141646
2025-09-02 23:27:41,264 - INFO - Epoch 1337/5000 - Train Loss: 0.151053, Val Loss: 0.135726
2025-09-02 23:28:18,590 - INFO - Epoch 1338/5000 - Train Loss: 0.152388, Val Loss: 0.140153
2025-09-02 23:28:55,630 - INFO - Epoch 1339/5000 - Train Loss: 0.151494, Val Loss: 0.137099
2025-09-02 23:29:32,029 - INFO - Epoch 1340/5000 - Train Loss: 0.148948, Val Loss: 0.133349
2025-09-02 23:29:32,069 - INFO - New best model saved with Val Loss: 0.133349
2025-09-02 23:30:09,340 - INFO - Epoch 1341/5000 - Train Loss: 0.150542, Val Loss: 0.139141
2025-09-02 23:30:46,041 - INFO - Epoch 1342/5000 - Train Loss: 0.151067, Val Loss: 0.138028
2025-09-02 23:31:22,259 - INFO - Epoch 1343/5000 - Train Loss: 0.150339, Val Loss: 0.136806
2025-09-02 23:31:57,679 - INFO - Epoch 1344/5000 - Train Loss: 0.148961, Val Loss: 0.136166
2025-09-02 23:32:33,348 - INFO - Epoch 1345/5000 - Train Loss: 0.149482, Val Loss: 0.136768
2025-09-02 23:33:08,572 - INFO - Epoch 1346/5000 - Train Loss: 0.151247, Val Loss: 0.138490
2025-09-02 23:33:43,869 - INFO - Epoch 1347/5000 - Train Loss: 0.150057, Val Loss: 0.138599
2025-09-02 23:34:20,106 - INFO - Epoch 1348/5000 - Train Loss: 0.148965, Val Loss: 0.134152
2025-09-02 23:34:56,889 - INFO - Epoch 1349/5000 - Train Loss: 0.150153, Val Loss: 0.136889
2025-09-02 23:35:33,167 - INFO - Epoch 1350/5000 - Train Loss: 0.151546, Val Loss: 0.134800
2025-09-02 23:36:09,414 - INFO - Epoch 1351/5000 - Train Loss: 0.149632, Val Loss: 0.136040
2025-09-02 23:36:46,349 - INFO - Epoch 1352/5000 - Train Loss: 0.150600, Val Loss: 0.138984
2025-09-02 23:37:23,294 - INFO - Epoch 1353/5000 - Train Loss: 0.150088, Val Loss: 0.136335
2025-09-02 23:37:59,599 - INFO - Epoch 1354/5000 - Train Loss: 0.148887, Val Loss: 0.136466
2025-09-02 23:38:37,724 - INFO - Epoch 1355/5000 - Train Loss: 0.149769, Val Loss: 0.137151
2025-09-02 23:39:15,988 - INFO - Epoch 1356/5000 - Train Loss: 0.148667, Val Loss: 0.136319
2025-09-02 23:39:52,782 - INFO - Epoch 1357/5000 - Train Loss: 0.149282, Val Loss: 0.140146
2025-09-02 23:40:29,400 - INFO - Epoch 1358/5000 - Train Loss: 0.149026, Val Loss: 0.136240
2025-09-02 23:41:05,461 - INFO - Epoch 1359/5000 - Train Loss: 0.149886, Val Loss: 0.136560
2025-09-02 23:41:42,936 - INFO - Epoch 1360/5000 - Train Loss: 0.147251, Val Loss: 0.136838
2025-09-02 23:42:20,787 - INFO - Epoch 1361/5000 - Train Loss: 0.151232, Val Loss: 0.133874
2025-09-02 23:42:58,174 - INFO - Epoch 1362/5000 - Train Loss: 0.148605, Val Loss: 0.138827
2025-09-02 23:43:34,610 - INFO - Epoch 1363/5000 - Train Loss: 0.150379, Val Loss: 0.133608
2025-09-02 23:44:11,899 - INFO - Epoch 1364/5000 - Train Loss: 0.148169, Val Loss: 0.132767
2025-09-02 23:44:11,951 - INFO - New best model saved with Val Loss: 0.132767
2025-09-02 23:44:49,218 - INFO - Epoch 1365/5000 - Train Loss: 0.149862, Val Loss: 0.135358
2025-09-02 23:45:26,062 - INFO - Epoch 1366/5000 - Train Loss: 0.151503, Val Loss: 0.139300
2025-09-02 23:46:01,973 - INFO - Epoch 1367/5000 - Train Loss: 0.150100, Val Loss: 0.136623
2025-09-02 23:46:38,800 - INFO - Epoch 1368/5000 - Train Loss: 0.146806, Val Loss: 0.137010
2025-09-02 23:47:16,340 - INFO - Epoch 1369/5000 - Train Loss: 0.146978, Val Loss: 0.134718
2025-09-02 23:47:53,217 - INFO - Epoch 1370/5000 - Train Loss: 0.147481, Val Loss: 0.134885
2025-09-02 23:48:31,277 - INFO - Epoch 1371/5000 - Train Loss: 0.149531, Val Loss: 0.136540
2025-09-02 23:49:09,399 - INFO - Epoch 1372/5000 - Train Loss: 0.147797, Val Loss: 0.134416
2025-09-02 23:49:46,878 - INFO - Epoch 1373/5000 - Train Loss: 0.147336, Val Loss: 0.142426
2025-09-02 23:50:24,427 - INFO - Epoch 1374/5000 - Train Loss: 0.148875, Val Loss: 0.133445
2025-09-02 23:51:02,193 - INFO - Epoch 1375/5000 - Train Loss: 0.147523, Val Loss: 0.132508
2025-09-02 23:51:02,275 - INFO - New best model saved with Val Loss: 0.132508
2025-09-02 23:51:39,138 - INFO - Epoch 1376/5000 - Train Loss: 0.149080, Val Loss: 0.132659
2025-09-02 23:52:15,719 - INFO - Epoch 1377/5000 - Train Loss: 0.146451, Val Loss: 0.133839
2025-09-02 23:52:53,088 - INFO - Epoch 1378/5000 - Train Loss: 0.146978, Val Loss: 0.135501
2025-09-02 23:53:29,658 - INFO - Epoch 1379/5000 - Train Loss: 0.148928, Val Loss: 0.132536
2025-09-02 23:54:06,610 - INFO - Epoch 1380/5000 - Train Loss: 0.147292, Val Loss: 0.135054
2025-09-02 23:54:43,732 - INFO - Epoch 1381/5000 - Train Loss: 0.146249, Val Loss: 0.132490
2025-09-02 23:54:43,780 - INFO - New best model saved with Val Loss: 0.132490
2025-09-02 23:55:21,250 - INFO - Epoch 1382/5000 - Train Loss: 0.149578, Val Loss: 0.133178
2025-09-02 23:55:57,974 - INFO - Epoch 1383/5000 - Train Loss: 0.146385, Val Loss: 0.134971
2025-09-02 23:56:34,615 - INFO - Epoch 1384/5000 - Train Loss: 0.146243, Val Loss: 0.135767
2025-09-02 23:57:10,908 - INFO - Epoch 1385/5000 - Train Loss: 0.147351, Val Loss: 0.131823
2025-09-02 23:57:10,939 - INFO - New best model saved with Val Loss: 0.131823
2025-09-02 23:57:48,333 - INFO - Epoch 1386/5000 - Train Loss: 0.146493, Val Loss: 0.134262
2025-09-02 23:58:24,969 - INFO - Epoch 1387/5000 - Train Loss: 0.146750, Val Loss: 0.133367
2025-09-02 23:59:02,065 - INFO - Epoch 1388/5000 - Train Loss: 0.146880, Val Loss: 0.134708
2025-09-02 23:59:39,045 - INFO - Epoch 1389/5000 - Train Loss: 0.147109, Val Loss: 0.135721
2025-09-03 00:00:15,667 - INFO - Epoch 1390/5000 - Train Loss: 0.146742, Val Loss: 0.133832
2025-09-03 00:00:52,910 - INFO - Epoch 1391/5000 - Train Loss: 0.147656, Val Loss: 0.131468
2025-09-03 00:00:52,941 - INFO - New best model saved with Val Loss: 0.131468
2025-09-03 00:01:30,660 - INFO - Epoch 1392/5000 - Train Loss: 0.145148, Val Loss: 0.132240
2025-09-03 00:02:06,624 - INFO - Epoch 1393/5000 - Train Loss: 0.144925, Val Loss: 0.130774
2025-09-03 00:02:06,655 - INFO - New best model saved with Val Loss: 0.130774
2025-09-03 00:02:43,991 - INFO - Epoch 1394/5000 - Train Loss: 0.145506, Val Loss: 0.130414
2025-09-03 00:02:44,033 - INFO - New best model saved with Val Loss: 0.130414
2025-09-03 00:03:21,071 - INFO - Epoch 1395/5000 - Train Loss: 0.145885, Val Loss: 0.132062
2025-09-03 00:03:57,827 - INFO - Epoch 1396/5000 - Train Loss: 0.146152, Val Loss: 0.131917
2025-09-03 00:04:34,682 - INFO - Epoch 1397/5000 - Train Loss: 0.146776, Val Loss: 0.133699
2025-09-03 00:05:10,770 - INFO - Epoch 1398/5000 - Train Loss: 0.145599, Val Loss: 0.129255
2025-09-03 00:05:10,801 - INFO - New best model saved with Val Loss: 0.129255
2025-09-03 00:05:47,326 - INFO - Epoch 1399/5000 - Train Loss: 0.147312, Val Loss: 0.133472
2025-09-03 00:06:24,764 - INFO - Epoch 1400/5000 - Train Loss: 0.148819, Val Loss: 0.134700
2025-09-03 00:07:01,671 - INFO - Epoch 1401/5000 - Train Loss: 0.148300, Val Loss: 0.135931
2025-09-03 00:07:38,325 - INFO - Epoch 1402/5000 - Train Loss: 0.145696, Val Loss: 0.130426
2025-09-03 00:08:15,518 - INFO - Epoch 1403/5000 - Train Loss: 0.147181, Val Loss: 0.129574
2025-09-03 00:08:51,904 - INFO - Epoch 1404/5000 - Train Loss: 0.144534, Val Loss: 0.130223
2025-09-03 00:09:29,348 - INFO - Epoch 1405/5000 - Train Loss: 0.145499, Val Loss: 0.131902
2025-09-03 00:10:06,058 - INFO - Epoch 1406/5000 - Train Loss: 0.146986, Val Loss: 0.132876
2025-09-03 00:10:42,202 - INFO - Epoch 1407/5000 - Train Loss: 0.147054, Val Loss: 0.132314
2025-09-03 00:11:18,309 - INFO - Epoch 1408/5000 - Train Loss: 0.147357, Val Loss: 0.138338
2025-09-03 00:11:54,992 - INFO - Epoch 1409/5000 - Train Loss: 0.145988, Val Loss: 0.132040
2025-09-03 00:12:31,626 - INFO - Epoch 1410/5000 - Train Loss: 0.143170, Val Loss: 0.130506
2025-09-03 00:13:08,476 - INFO - Epoch 1411/5000 - Train Loss: 0.144057, Val Loss: 0.135771
2025-09-03 00:13:45,475 - INFO - Epoch 1412/5000 - Train Loss: 0.148318, Val Loss: 0.132588
2025-09-03 00:14:21,535 - INFO - Epoch 1413/5000 - Train Loss: 0.145414, Val Loss: 0.130548
2025-09-03 00:14:57,906 - INFO - Epoch 1414/5000 - Train Loss: 0.142413, Val Loss: 0.130157
2025-09-03 00:15:34,730 - INFO - Epoch 1415/5000 - Train Loss: 0.145017, Val Loss: 0.133699
2025-09-03 00:16:12,066 - INFO - Epoch 1416/5000 - Train Loss: 0.145864, Val Loss: 0.132651
2025-09-03 00:16:48,633 - INFO - Epoch 1417/5000 - Train Loss: 0.143362, Val Loss: 0.131008
2025-09-03 00:17:24,895 - INFO - Epoch 1418/5000 - Train Loss: 0.144506, Val Loss: 0.128463
2025-09-03 00:17:24,940 - INFO - New best model saved with Val Loss: 0.128463
2025-09-03 00:18:01,690 - INFO - Epoch 1419/5000 - Train Loss: 0.144164, Val Loss: 0.130769
2025-09-03 00:18:39,275 - INFO - Epoch 1420/5000 - Train Loss: 0.143690, Val Loss: 0.129336
2025-09-03 00:19:16,938 - INFO - Epoch 1421/5000 - Train Loss: 0.143495, Val Loss: 0.133126
2025-09-03 00:19:53,432 - INFO - Epoch 1422/5000 - Train Loss: 0.143300, Val Loss: 0.131225
2025-09-03 00:20:30,077 - INFO - Epoch 1423/5000 - Train Loss: 0.144134, Val Loss: 0.131137
2025-09-03 00:21:07,265 - INFO - Epoch 1424/5000 - Train Loss: 0.144480, Val Loss: 0.127868
2025-09-03 00:21:07,318 - INFO - New best model saved with Val Loss: 0.127868
2025-09-03 00:21:43,596 - INFO - Epoch 1425/5000 - Train Loss: 0.143293, Val Loss: 0.137181
2025-09-03 00:22:20,366 - INFO - Epoch 1426/5000 - Train Loss: 0.145863, Val Loss: 0.127992
2025-09-03 00:22:57,703 - INFO - Epoch 1427/5000 - Train Loss: 0.142803, Val Loss: 0.127846
2025-09-03 00:22:57,734 - INFO - New best model saved with Val Loss: 0.127846
2025-09-03 00:23:35,138 - INFO - Epoch 1428/5000 - Train Loss: 0.142489, Val Loss: 0.128062
2025-09-03 00:24:12,370 - INFO - Epoch 1429/5000 - Train Loss: 0.141237, Val Loss: 0.126928
2025-09-03 00:24:12,399 - INFO - New best model saved with Val Loss: 0.126928
2025-09-03 00:24:49,109 - INFO - Epoch 1430/5000 - Train Loss: 0.141960, Val Loss: 0.127707
2025-09-03 00:25:27,116 - INFO - Epoch 1431/5000 - Train Loss: 0.141722, Val Loss: 0.128464
2025-09-03 00:26:04,130 - INFO - Epoch 1432/5000 - Train Loss: 0.143217, Val Loss: 0.133714
2025-09-03 00:26:40,145 - INFO - Epoch 1433/5000 - Train Loss: 0.144499, Val Loss: 0.126538
2025-09-03 00:26:40,176 - INFO - New best model saved with Val Loss: 0.126538
2025-09-03 00:27:17,283 - INFO - Epoch 1434/5000 - Train Loss: 0.140627, Val Loss: 0.127595
2025-09-03 00:27:54,165 - INFO - Epoch 1435/5000 - Train Loss: 0.142321, Val Loss: 0.127311
2025-09-03 00:28:30,888 - INFO - Epoch 1436/5000 - Train Loss: 0.141521, Val Loss: 0.129337
2025-09-03 00:29:07,176 - INFO - Epoch 1437/5000 - Train Loss: 0.139806, Val Loss: 0.127575
2025-09-03 00:29:44,072 - INFO - Epoch 1438/5000 - Train Loss: 0.140098, Val Loss: 0.126759
2025-09-03 00:30:20,747 - INFO - Epoch 1439/5000 - Train Loss: 0.141407, Val Loss: 0.130550
2025-09-03 00:30:57,615 - INFO - Epoch 1440/5000 - Train Loss: 0.141089, Val Loss: 0.124866
2025-09-03 00:30:57,646 - INFO - New best model saved with Val Loss: 0.124866
2025-09-03 00:31:34,571 - INFO - Epoch 1441/5000 - Train Loss: 0.140317, Val Loss: 0.125761
2025-09-03 00:32:11,439 - INFO - Epoch 1442/5000 - Train Loss: 0.143709, Val Loss: 0.126182
2025-09-03 00:32:49,125 - INFO - Epoch 1443/5000 - Train Loss: 0.139510, Val Loss: 0.126730
2025-09-03 00:33:26,791 - INFO - Epoch 1444/5000 - Train Loss: 0.138329, Val Loss: 0.127067
2025-09-03 00:34:03,936 - INFO - Epoch 1445/5000 - Train Loss: 0.139295, Val Loss: 0.125165
2025-09-03 00:34:41,103 - INFO - Epoch 1446/5000 - Train Loss: 0.140234, Val Loss: 0.130035
2025-09-03 00:35:18,219 - INFO - Epoch 1447/5000 - Train Loss: 0.140855, Val Loss: 0.127488
2025-09-03 00:35:54,272 - INFO - Epoch 1448/5000 - Train Loss: 0.140860, Val Loss: 0.131006
2025-09-03 00:36:31,038 - INFO - Epoch 1449/5000 - Train Loss: 0.140654, Val Loss: 0.123849
2025-09-03 00:36:31,069 - INFO - New best model saved with Val Loss: 0.123849
2025-09-03 00:37:08,126 - INFO - Epoch 1450/5000 - Train Loss: 0.138127, Val Loss: 0.121537
2025-09-03 00:37:08,157 - INFO - New best model saved with Val Loss: 0.121537
2025-09-03 00:37:45,689 - INFO - Epoch 1451/5000 - Train Loss: 0.138260, Val Loss: 0.123203
2025-09-03 00:38:22,286 - INFO - Epoch 1452/5000 - Train Loss: 0.138792, Val Loss: 0.126699
2025-09-03 00:38:58,879 - INFO - Epoch 1453/5000 - Train Loss: 0.139670, Val Loss: 0.125918
2025-09-03 00:39:36,630 - INFO - Epoch 1454/5000 - Train Loss: 0.139374, Val Loss: 0.128819
2025-09-03 00:40:13,720 - INFO - Epoch 1455/5000 - Train Loss: 0.140546, Val Loss: 0.122969
2025-09-03 00:40:51,098 - INFO - Epoch 1456/5000 - Train Loss: 0.138828, Val Loss: 0.125487
2025-09-03 00:41:28,551 - INFO - Epoch 1457/5000 - Train Loss: 0.137740, Val Loss: 0.122552
2025-09-03 00:42:04,472 - INFO - Epoch 1458/5000 - Train Loss: 0.138161, Val Loss: 0.125678
2025-09-03 00:42:41,002 - INFO - Epoch 1459/5000 - Train Loss: 0.139242, Val Loss: 0.124659
2025-09-03 00:43:18,394 - INFO - Epoch 1460/5000 - Train Loss: 0.139727, Val Loss: 0.125018
2025-09-03 00:43:56,235 - INFO - Epoch 1461/5000 - Train Loss: 0.138842, Val Loss: 0.123837
2025-09-03 00:44:33,511 - INFO - Epoch 1462/5000 - Train Loss: 0.138616, Val Loss: 0.124407
2025-09-03 00:45:10,331 - INFO - Epoch 1463/5000 - Train Loss: 0.137884, Val Loss: 0.124191
2025-09-03 00:45:47,236 - INFO - Epoch 1464/5000 - Train Loss: 0.137207, Val Loss: 0.123481
2025-09-03 00:46:24,157 - INFO - Epoch 1465/5000 - Train Loss: 0.138745, Val Loss: 0.125791
2025-09-03 00:47:00,762 - INFO - Epoch 1466/5000 - Train Loss: 0.138563, Val Loss: 0.124761
2025-09-03 00:47:37,917 - INFO - Epoch 1467/5000 - Train Loss: 0.138164, Val Loss: 0.122883
2025-09-03 00:48:15,511 - INFO - Epoch 1468/5000 - Train Loss: 0.135664, Val Loss: 0.120881
2025-09-03 00:48:15,556 - INFO - New best model saved with Val Loss: 0.120881
2025-09-03 00:48:52,253 - INFO - Epoch 1469/5000 - Train Loss: 0.137353, Val Loss: 0.128960
2025-09-03 00:49:29,795 - INFO - Epoch 1470/5000 - Train Loss: 0.139053, Val Loss: 0.129876
2025-09-03 00:50:06,456 - INFO - Epoch 1471/5000 - Train Loss: 0.138561, Val Loss: 0.125438
2025-09-03 00:50:43,311 - INFO - Epoch 1472/5000 - Train Loss: 0.137693, Val Loss: 0.124298
2025-09-03 00:51:20,343 - INFO - Epoch 1473/5000 - Train Loss: 0.135784, Val Loss: 0.119903
2025-09-03 00:51:20,383 - INFO - New best model saved with Val Loss: 0.119903
2025-09-03 00:51:57,054 - INFO - Epoch 1474/5000 - Train Loss: 0.135967, Val Loss: 0.120012
2025-09-03 00:52:34,415 - INFO - Epoch 1475/5000 - Train Loss: 0.137762, Val Loss: 0.125715
2025-09-03 00:53:11,419 - INFO - Epoch 1476/5000 - Train Loss: 0.136885, Val Loss: 0.124046
2025-09-03 00:53:47,532 - INFO - Epoch 1477/5000 - Train Loss: 0.134658, Val Loss: 0.119511
2025-09-03 00:53:47,562 - INFO - New best model saved with Val Loss: 0.119511
2025-09-03 00:54:24,216 - INFO - Epoch 1478/5000 - Train Loss: 0.135717, Val Loss: 0.125270
2025-09-03 00:55:01,089 - INFO - Epoch 1479/5000 - Train Loss: 0.137399, Val Loss: 0.122481
2025-09-03 00:55:38,399 - INFO - Epoch 1480/5000 - Train Loss: 0.136732, Val Loss: 0.120928
2025-09-03 00:56:15,208 - INFO - Epoch 1481/5000 - Train Loss: 0.134821, Val Loss: 0.124843
2025-09-03 00:56:51,418 - INFO - Epoch 1482/5000 - Train Loss: 0.134847, Val Loss: 0.119889
2025-09-03 00:57:28,387 - INFO - Epoch 1483/5000 - Train Loss: 0.135926, Val Loss: 0.122504
2025-09-03 00:58:05,071 - INFO - Epoch 1484/5000 - Train Loss: 0.137449, Val Loss: 0.124121
2025-09-03 00:58:41,874 - INFO - Epoch 1485/5000 - Train Loss: 0.135805, Val Loss: 0.123291
2025-09-03 00:59:18,648 - INFO - Epoch 1486/5000 - Train Loss: 0.136513, Val Loss: 0.124054
2025-09-03 00:59:55,324 - INFO - Epoch 1487/5000 - Train Loss: 0.136200, Val Loss: 0.121701
2025-09-03 01:00:32,499 - INFO - Epoch 1488/5000 - Train Loss: 0.134493, Val Loss: 0.123120
2025-09-03 01:01:09,509 - INFO - Epoch 1489/5000 - Train Loss: 0.135040, Val Loss: 0.119154
2025-09-03 01:01:09,586 - INFO - New best model saved with Val Loss: 0.119154
2025-09-03 01:01:47,255 - INFO - Epoch 1490/5000 - Train Loss: 0.136805, Val Loss: 0.128185
2025-09-03 01:02:24,419 - INFO - Epoch 1491/5000 - Train Loss: 0.135360, Val Loss: 0.121725
2025-09-03 01:03:01,228 - INFO - Epoch 1492/5000 - Train Loss: 0.135274, Val Loss: 0.123946
2025-09-03 01:03:38,228 - INFO - Epoch 1493/5000 - Train Loss: 0.133152, Val Loss: 0.119313
2025-09-03 01:04:14,271 - INFO - Epoch 1494/5000 - Train Loss: 0.135280, Val Loss: 0.119431
2025-09-03 01:04:50,762 - INFO - Epoch 1495/5000 - Train Loss: 0.133219, Val Loss: 0.123034
2025-09-03 01:05:28,371 - INFO - Epoch 1496/5000 - Train Loss: 0.134898, Val Loss: 0.119443
2025-09-03 01:06:05,295 - INFO - Epoch 1497/5000 - Train Loss: 0.131712, Val Loss: 0.118319
2025-09-03 01:06:05,327 - INFO - New best model saved with Val Loss: 0.118319
2025-09-03 01:06:41,784 - INFO - Epoch 1498/5000 - Train Loss: 0.133756, Val Loss: 0.123793
2025-09-03 01:07:18,679 - INFO - Epoch 1499/5000 - Train Loss: 0.134327, Val Loss: 0.122972
2025-09-03 01:07:55,210 - INFO - Epoch 1500/5000 - Train Loss: 0.134776, Val Loss: 0.119206
2025-09-03 01:08:32,709 - INFO - Epoch 1501/5000 - Train Loss: 0.133044, Val Loss: 0.119260
2025-09-03 01:09:08,852 - INFO - Epoch 1502/5000 - Train Loss: 0.134806, Val Loss: 0.119885
2025-09-03 01:09:45,175 - INFO - Epoch 1503/5000 - Train Loss: 0.134695, Val Loss: 0.122156
2025-09-03 01:10:21,834 - INFO - Epoch 1504/5000 - Train Loss: 0.134930, Val Loss: 0.122201
2025-09-03 01:11:00,110 - INFO - Epoch 1505/5000 - Train Loss: 0.133138, Val Loss: 0.122026
2025-09-03 01:11:37,706 - INFO - Epoch 1506/5000 - Train Loss: 0.134349, Val Loss: 0.121061
2025-09-03 01:12:14,467 - INFO - Epoch 1507/5000 - Train Loss: 0.133010, Val Loss: 0.126058
2025-09-03 01:12:50,506 - INFO - Epoch 1508/5000 - Train Loss: 0.134700, Val Loss: 0.118325
2025-09-03 01:13:27,209 - INFO - Epoch 1509/5000 - Train Loss: 0.132390, Val Loss: 0.119494
2025-09-03 01:14:03,856 - INFO - Epoch 1510/5000 - Train Loss: 0.133221, Val Loss: 0.115549
2025-09-03 01:14:03,902 - INFO - New best model saved with Val Loss: 0.115549
2025-09-03 01:14:41,391 - INFO - Epoch 1511/5000 - Train Loss: 0.136247, Val Loss: 0.122529
2025-09-03 01:15:18,172 - INFO - Epoch 1512/5000 - Train Loss: 0.133309, Val Loss: 0.119127
2025-09-03 01:15:54,587 - INFO - Epoch 1513/5000 - Train Loss: 0.132527, Val Loss: 0.118776
2025-09-03 01:16:30,657 - INFO - Epoch 1514/5000 - Train Loss: 0.134071, Val Loss: 0.120595
2025-09-03 01:17:08,208 - INFO - Epoch 1515/5000 - Train Loss: 0.134386, Val Loss: 0.120422
2025-09-03 01:17:45,158 - INFO - Epoch 1516/5000 - Train Loss: 0.131905, Val Loss: 0.120520
2025-09-03 01:18:21,842 - INFO - Epoch 1517/5000 - Train Loss: 0.133475, Val Loss: 0.119364
2025-09-03 01:18:58,384 - INFO - Epoch 1518/5000 - Train Loss: 0.132280, Val Loss: 0.115199
2025-09-03 01:18:58,415 - INFO - New best model saved with Val Loss: 0.115199
2025-09-03 01:19:35,050 - INFO - Epoch 1519/5000 - Train Loss: 0.131484, Val Loss: 0.120008
2025-09-03 01:20:11,659 - INFO - Epoch 1520/5000 - Train Loss: 0.132804, Val Loss: 0.119003
2025-09-03 01:20:48,032 - INFO - Epoch 1521/5000 - Train Loss: 0.134690, Val Loss: 0.119530
2025-09-03 01:21:25,309 - INFO - Epoch 1522/5000 - Train Loss: 0.133440, Val Loss: 0.120621
2025-09-03 01:22:02,296 - INFO - Epoch 1523/5000 - Train Loss: 0.133028, Val Loss: 0.120812
2025-09-03 01:22:38,840 - INFO - Epoch 1524/5000 - Train Loss: 0.133600, Val Loss: 0.118562
2025-09-03 01:23:15,185 - INFO - Epoch 1525/5000 - Train Loss: 0.133289, Val Loss: 0.117304
2025-09-03 01:23:52,148 - INFO - Epoch 1526/5000 - Train Loss: 0.132135, Val Loss: 0.123872
2025-09-03 01:24:29,337 - INFO - Epoch 1527/5000 - Train Loss: 0.134023, Val Loss: 0.116437
2025-09-03 01:25:06,751 - INFO - Epoch 1528/5000 - Train Loss: 0.131143, Val Loss: 0.117288
2025-09-03 01:25:43,544 - INFO - Epoch 1529/5000 - Train Loss: 0.132070, Val Loss: 0.119846
2025-09-03 01:26:20,257 - INFO - Epoch 1530/5000 - Train Loss: 0.132544, Val Loss: 0.123253
2025-09-03 01:26:56,890 - INFO - Epoch 1531/5000 - Train Loss: 0.133535, Val Loss: 0.116641
2025-09-03 01:27:33,566 - INFO - Epoch 1532/5000 - Train Loss: 0.131354, Val Loss: 0.116854
2025-09-03 01:28:11,111 - INFO - Epoch 1533/5000 - Train Loss: 0.131636, Val Loss: 0.119106
2025-09-03 01:28:48,897 - INFO - Epoch 1534/5000 - Train Loss: 0.133656, Val Loss: 0.119832
2025-09-03 01:29:25,471 - INFO - Epoch 1535/5000 - Train Loss: 0.132786, Val Loss: 0.119997
2025-09-03 01:30:03,411 - INFO - Epoch 1536/5000 - Train Loss: 0.131630, Val Loss: 0.115923
2025-09-03 01:30:40,643 - INFO - Epoch 1537/5000 - Train Loss: 0.130367, Val Loss: 0.117587
2025-09-03 01:31:17,650 - INFO - Epoch 1538/5000 - Train Loss: 0.131846, Val Loss: 0.121617
2025-09-03 01:31:54,164 - INFO - Epoch 1539/5000 - Train Loss: 0.131066, Val Loss: 0.117973
2025-09-03 01:32:31,176 - INFO - Epoch 1540/5000 - Train Loss: 0.131489, Val Loss: 0.119216
2025-09-03 01:33:08,710 - INFO - Epoch 1541/5000 - Train Loss: 0.131819, Val Loss: 0.115372
2025-09-03 01:33:46,738 - INFO - Epoch 1542/5000 - Train Loss: 0.131663, Val Loss: 0.118094
2025-09-03 01:34:24,147 - INFO - Epoch 1543/5000 - Train Loss: 0.130971, Val Loss: 0.116567
2025-09-03 01:35:01,333 - INFO - Epoch 1544/5000 - Train Loss: 0.130751, Val Loss: 0.115072
2025-09-03 01:35:01,383 - INFO - New best model saved with Val Loss: 0.115072
2025-09-03 01:35:38,428 - INFO - Epoch 1545/5000 - Train Loss: 0.130953, Val Loss: 0.116326
2025-09-03 01:36:15,255 - INFO - Epoch 1546/5000 - Train Loss: 0.130746, Val Loss: 0.117624
2025-09-03 01:36:52,053 - INFO - Epoch 1547/5000 - Train Loss: 0.131583, Val Loss: 0.117193
2025-09-03 01:37:28,630 - INFO - Epoch 1548/5000 - Train Loss: 0.130251, Val Loss: 0.115298
2025-09-03 01:38:04,697 - INFO - Epoch 1549/5000 - Train Loss: 0.129872, Val Loss: 0.116351
2025-09-03 01:38:40,151 - INFO - Epoch 1550/5000 - Train Loss: 0.129642, Val Loss: 0.119332
2025-09-03 01:39:16,423 - INFO - Epoch 1551/5000 - Train Loss: 0.130412, Val Loss: 0.116525
2025-09-03 01:39:52,156 - INFO - Epoch 1552/5000 - Train Loss: 0.130523, Val Loss: 0.117434
2025-09-03 01:40:28,335 - INFO - Epoch 1553/5000 - Train Loss: 0.132084, Val Loss: 0.119237
2025-09-03 01:41:04,866 - INFO - Epoch 1554/5000 - Train Loss: 0.129531, Val Loss: 0.116102
2025-09-03 01:41:40,430 - INFO - Epoch 1555/5000 - Train Loss: 0.129447, Val Loss: 0.115995
2025-09-03 01:42:16,714 - INFO - Epoch 1556/5000 - Train Loss: 0.130385, Val Loss: 0.115872
2025-09-03 01:42:53,860 - INFO - Epoch 1557/5000 - Train Loss: 0.130217, Val Loss: 0.116039
2025-09-03 01:43:31,167 - INFO - Epoch 1558/5000 - Train Loss: 0.128770, Val Loss: 0.114415
2025-09-03 01:43:31,232 - INFO - New best model saved with Val Loss: 0.114415
2025-09-03 01:44:07,728 - INFO - Epoch 1559/5000 - Train Loss: 0.130818, Val Loss: 0.117780
2025-09-03 01:44:44,111 - INFO - Epoch 1560/5000 - Train Loss: 0.131304, Val Loss: 0.117052
2025-09-03 01:45:21,533 - INFO - Epoch 1561/5000 - Train Loss: 0.128551, Val Loss: 0.113618
2025-09-03 01:45:21,564 - INFO - New best model saved with Val Loss: 0.113618
2025-09-03 01:45:57,691 - INFO - Epoch 1562/5000 - Train Loss: 0.128089, Val Loss: 0.116966
2025-09-03 01:46:34,205 - INFO - Epoch 1563/5000 - Train Loss: 0.129641, Val Loss: 0.114278
2025-09-03 01:47:09,868 - INFO - Epoch 1564/5000 - Train Loss: 0.128706, Val Loss: 0.115182
2025-09-03 01:47:47,195 - INFO - Epoch 1565/5000 - Train Loss: 0.129933, Val Loss: 0.114517
2025-09-03 01:48:24,878 - INFO - Epoch 1566/5000 - Train Loss: 0.129223, Val Loss: 0.115470
2025-09-03 01:49:01,902 - INFO - Epoch 1567/5000 - Train Loss: 0.129292, Val Loss: 0.118955
2025-09-03 01:49:38,987 - INFO - Epoch 1568/5000 - Train Loss: 0.128639, Val Loss: 0.114848
2025-09-03 01:50:15,992 - INFO - Epoch 1569/5000 - Train Loss: 0.128643, Val Loss: 0.118528
2025-09-03 01:50:52,815 - INFO - Epoch 1570/5000 - Train Loss: 0.129783, Val Loss: 0.113138
2025-09-03 01:50:52,859 - INFO - New best model saved with Val Loss: 0.113138
2025-09-03 01:51:28,998 - INFO - Epoch 1571/5000 - Train Loss: 0.128724, Val Loss: 0.116496
2025-09-03 01:52:05,704 - INFO - Epoch 1572/5000 - Train Loss: 0.129092, Val Loss: 0.113457
2025-09-03 01:52:43,051 - INFO - Epoch 1573/5000 - Train Loss: 0.127367, Val Loss: 0.115202
2025-09-03 01:53:19,050 - INFO - Epoch 1574/5000 - Train Loss: 0.129651, Val Loss: 0.114882
2025-09-03 01:53:55,187 - INFO - Epoch 1575/5000 - Train Loss: 0.127317, Val Loss: 0.114945
2025-09-03 01:54:32,200 - INFO - Epoch 1576/5000 - Train Loss: 0.129337, Val Loss: 0.114124
2025-09-03 01:55:09,479 - INFO - Epoch 1577/5000 - Train Loss: 0.128714, Val Loss: 0.115466
2025-09-03 01:55:46,212 - INFO - Epoch 1578/5000 - Train Loss: 0.128673, Val Loss: 0.114587
2025-09-03 01:56:22,541 - INFO - Epoch 1579/5000 - Train Loss: 0.128381, Val Loss: 0.113955
2025-09-03 01:56:59,028 - INFO - Epoch 1580/5000 - Train Loss: 0.129119, Val Loss: 0.112817
2025-09-03 01:56:59,059 - INFO - New best model saved with Val Loss: 0.112817
2025-09-03 01:57:35,679 - INFO - Epoch 1581/5000 - Train Loss: 0.129513, Val Loss: 0.113824
2025-09-03 01:58:12,758 - INFO - Epoch 1582/5000 - Train Loss: 0.128041, Val Loss: 0.112558
2025-09-03 01:58:12,788 - INFO - New best model saved with Val Loss: 0.112558
2025-09-03 01:58:49,605 - INFO - Epoch 1583/5000 - Train Loss: 0.126807, Val Loss: 0.115293
2025-09-03 01:59:26,126 - INFO - Epoch 1584/5000 - Train Loss: 0.126495, Val Loss: 0.112673
2025-09-03 02:00:02,661 - INFO - Epoch 1585/5000 - Train Loss: 0.128644, Val Loss: 0.118556
2025-09-03 02:00:39,380 - INFO - Epoch 1586/5000 - Train Loss: 0.129462, Val Loss: 0.115992
2025-09-03 02:01:16,890 - INFO - Epoch 1587/5000 - Train Loss: 0.129152, Val Loss: 0.115746
2025-09-03 02:01:54,289 - INFO - Epoch 1588/5000 - Train Loss: 0.128237, Val Loss: 0.113873
2025-09-03 02:02:31,778 - INFO - Epoch 1589/5000 - Train Loss: 0.127368, Val Loss: 0.116450
2025-09-03 02:03:08,631 - INFO - Epoch 1590/5000 - Train Loss: 0.127595, Val Loss: 0.112343
2025-09-03 02:03:08,662 - INFO - New best model saved with Val Loss: 0.112343
2025-09-03 02:03:45,842 - INFO - Epoch 1591/5000 - Train Loss: 0.127527, Val Loss: 0.116265
2025-09-03 02:04:22,787 - INFO - Epoch 1592/5000 - Train Loss: 0.126768, Val Loss: 0.116012
2025-09-03 02:04:58,856 - INFO - Epoch 1593/5000 - Train Loss: 0.127742, Val Loss: 0.111706
2025-09-03 02:04:58,887 - INFO - New best model saved with Val Loss: 0.111706
2025-09-03 02:05:35,514 - INFO - Epoch 1594/5000 - Train Loss: 0.126589, Val Loss: 0.112502
2025-09-03 02:06:12,063 - INFO - Epoch 1595/5000 - Train Loss: 0.126403, Val Loss: 0.110711
2025-09-03 02:06:12,093 - INFO - New best model saved with Val Loss: 0.110711
2025-09-03 02:06:48,460 - INFO - Epoch 1596/5000 - Train Loss: 0.126235, Val Loss: 0.113422
2025-09-03 02:07:24,811 - INFO - Epoch 1597/5000 - Train Loss: 0.125179, Val Loss: 0.116469
2025-09-03 02:08:01,234 - INFO - Epoch 1598/5000 - Train Loss: 0.127774, Val Loss: 0.116333
2025-09-03 02:08:38,802 - INFO - Epoch 1599/5000 - Train Loss: 0.128585, Val Loss: 0.112838
2025-09-03 02:09:16,037 - INFO - Epoch 1600/5000 - Train Loss: 0.127152, Val Loss: 0.112125
2025-09-03 02:09:52,793 - INFO - Epoch 1601/5000 - Train Loss: 0.127246, Val Loss: 0.112379
2025-09-03 02:10:28,638 - INFO - Epoch 1602/5000 - Train Loss: 0.125532, Val Loss: 0.112843
2025-09-03 02:11:04,388 - INFO - Epoch 1603/5000 - Train Loss: 0.125921, Val Loss: 0.112146
2025-09-03 02:11:41,020 - INFO - Epoch 1604/5000 - Train Loss: 0.127423, Val Loss: 0.114048
2025-09-03 02:12:17,666 - INFO - Epoch 1605/5000 - Train Loss: 0.125481, Val Loss: 0.112765
2025-09-03 02:12:54,234 - INFO - Epoch 1606/5000 - Train Loss: 0.126242, Val Loss: 0.112032
2025-09-03 02:13:31,754 - INFO - Epoch 1607/5000 - Train Loss: 0.125433, Val Loss: 0.110859
2025-09-03 02:14:08,635 - INFO - Epoch 1608/5000 - Train Loss: 0.125788, Val Loss: 0.111999
2025-09-03 02:14:44,817 - INFO - Epoch 1609/5000 - Train Loss: 0.126159, Val Loss: 0.108729
2025-09-03 02:14:44,864 - INFO - New best model saved with Val Loss: 0.108729
2025-09-03 02:15:21,169 - INFO - Epoch 1610/5000 - Train Loss: 0.125981, Val Loss: 0.110870
2025-09-03 02:15:57,547 - INFO - Epoch 1611/5000 - Train Loss: 0.126513, Val Loss: 0.111318
2025-09-03 02:16:33,512 - INFO - Epoch 1612/5000 - Train Loss: 0.128905, Val Loss: 0.120751
2025-09-03 02:17:09,280 - INFO - Epoch 1613/5000 - Train Loss: 0.127685, Val Loss: 0.110930
2025-09-03 02:17:46,203 - INFO - Epoch 1614/5000 - Train Loss: 0.125721, Val Loss: 0.111455
2025-09-03 02:18:23,006 - INFO - Epoch 1615/5000 - Train Loss: 0.126599, Val Loss: 0.111701
2025-09-03 02:19:00,188 - INFO - Epoch 1616/5000 - Train Loss: 0.125314, Val Loss: 0.112683
2025-09-03 02:19:37,393 - INFO - Epoch 1617/5000 - Train Loss: 0.128435, Val Loss: 0.115513
2025-09-03 02:20:14,132 - INFO - Epoch 1618/5000 - Train Loss: 0.125944, Val Loss: 0.115259
2025-09-03 02:20:51,898 - INFO - Epoch 1619/5000 - Train Loss: 0.124682, Val Loss: 0.110064
2025-09-03 02:21:28,813 - INFO - Epoch 1620/5000 - Train Loss: 0.124310, Val Loss: 0.109588
2025-09-03 02:22:06,759 - INFO - Epoch 1621/5000 - Train Loss: 0.125160, Val Loss: 0.113177
2025-09-03 02:22:44,009 - INFO - Epoch 1622/5000 - Train Loss: 0.126390, Val Loss: 0.113852
2025-09-03 02:23:21,268 - INFO - Epoch 1623/5000 - Train Loss: 0.125328, Val Loss: 0.115040
2025-09-03 02:23:57,604 - INFO - Epoch 1624/5000 - Train Loss: 0.125756, Val Loss: 0.111730
2025-09-03 02:24:33,970 - INFO - Epoch 1625/5000 - Train Loss: 0.125399, Val Loss: 0.109007
2025-09-03 02:25:10,632 - INFO - Epoch 1626/5000 - Train Loss: 0.125462, Val Loss: 0.109967
2025-09-03 02:25:46,678 - INFO - Epoch 1627/5000 - Train Loss: 0.125492, Val Loss: 0.110513
2025-09-03 02:26:23,657 - INFO - Epoch 1628/5000 - Train Loss: 0.125119, Val Loss: 0.111406
2025-09-03 02:27:00,823 - INFO - Epoch 1629/5000 - Train Loss: 0.124953, Val Loss: 0.110723
2025-09-03 02:27:37,616 - INFO - Epoch 1630/5000 - Train Loss: 0.126214, Val Loss: 0.115857
2025-09-03 02:28:14,751 - INFO - Epoch 1631/5000 - Train Loss: 0.125678, Val Loss: 0.110846
2025-09-03 02:28:51,926 - INFO - Epoch 1632/5000 - Train Loss: 0.123769, Val Loss: 0.111867
2025-09-03 02:29:28,348 - INFO - Epoch 1633/5000 - Train Loss: 0.124298, Val Loss: 0.108428
2025-09-03 02:29:28,399 - INFO - New best model saved with Val Loss: 0.108428
2025-09-03 02:30:04,821 - INFO - Epoch 1634/5000 - Train Loss: 0.124062, Val Loss: 0.111628
2025-09-03 02:30:41,411 - INFO - Epoch 1635/5000 - Train Loss: 0.124633, Val Loss: 0.112555
2025-09-03 02:31:17,708 - INFO - Epoch 1636/5000 - Train Loss: 0.124324, Val Loss: 0.111966
2025-09-03 02:31:54,203 - INFO - Epoch 1637/5000 - Train Loss: 0.125695, Val Loss: 0.113116
2025-09-03 02:32:30,744 - INFO - Epoch 1638/5000 - Train Loss: 0.124428, Val Loss: 0.116757
2025-09-03 02:33:07,055 - INFO - Epoch 1639/5000 - Train Loss: 0.127668, Val Loss: 0.115709
2025-09-03 02:33:43,149 - INFO - Epoch 1640/5000 - Train Loss: 0.124608, Val Loss: 0.110232
2025-09-03 02:34:19,666 - INFO - Epoch 1641/5000 - Train Loss: 0.129495, Val Loss: 0.112520
2025-09-03 02:34:55,980 - INFO - Epoch 1642/5000 - Train Loss: 0.125937, Val Loss: 0.110988
2025-09-03 02:35:32,609 - INFO - Epoch 1643/5000 - Train Loss: 0.124237, Val Loss: 0.109194
2025-09-03 02:36:09,258 - INFO - Epoch 1644/5000 - Train Loss: 0.124102, Val Loss: 0.110800
2025-09-03 02:36:46,492 - INFO - Epoch 1645/5000 - Train Loss: 0.124301, Val Loss: 0.109050
2025-09-03 02:37:23,275 - INFO - Epoch 1646/5000 - Train Loss: 0.124399, Val Loss: 0.108805
2025-09-03 02:37:59,600 - INFO - Epoch 1647/5000 - Train Loss: 0.122624, Val Loss: 0.110554
2025-09-03 02:38:36,155 - INFO - Epoch 1648/5000 - Train Loss: 0.122716, Val Loss: 0.111544
2025-09-03 02:39:13,240 - INFO - Epoch 1649/5000 - Train Loss: 0.123943, Val Loss: 0.108677
2025-09-03 02:39:50,681 - INFO - Epoch 1650/5000 - Train Loss: 0.125094, Val Loss: 0.110590
2025-09-03 02:40:28,610 - INFO - Epoch 1651/5000 - Train Loss: 0.124835, Val Loss: 0.110595
2025-09-03 02:41:06,170 - INFO - Epoch 1652/5000 - Train Loss: 0.122911, Val Loss: 0.114311
2025-09-03 02:41:44,278 - INFO - Epoch 1653/5000 - Train Loss: 0.123894, Val Loss: 0.110766
2025-09-03 02:42:20,943 - INFO - Epoch 1654/5000 - Train Loss: 0.124614, Val Loss: 0.114428
2025-09-03 02:42:58,406 - INFO - Epoch 1655/5000 - Train Loss: 0.125267, Val Loss: 0.108070
2025-09-03 02:42:58,453 - INFO - New best model saved with Val Loss: 0.108070
2025-09-03 02:43:36,246 - INFO - Epoch 1656/5000 - Train Loss: 0.122640, Val Loss: 0.110519
2025-09-03 02:44:13,296 - INFO - Epoch 1657/5000 - Train Loss: 0.122384, Val Loss: 0.110318
2025-09-03 02:44:50,250 - INFO - Epoch 1658/5000 - Train Loss: 0.123717, Val Loss: 0.111297
2025-09-03 02:45:26,442 - INFO - Epoch 1659/5000 - Train Loss: 0.123652, Val Loss: 0.110238
2025-09-03 02:46:03,238 - INFO - Epoch 1660/5000 - Train Loss: 0.120365, Val Loss: 0.107105
2025-09-03 02:46:03,268 - INFO - New best model saved with Val Loss: 0.107105
2025-09-03 02:46:39,830 - INFO - Epoch 1661/5000 - Train Loss: 0.122903, Val Loss: 0.109805
2025-09-03 02:47:17,183 - INFO - Epoch 1662/5000 - Train Loss: 0.123872, Val Loss: 0.108616
2025-09-03 02:47:53,659 - INFO - Epoch 1663/5000 - Train Loss: 0.122760, Val Loss: 0.108201
2025-09-03 02:48:30,370 - INFO - Epoch 1664/5000 - Train Loss: 0.122504, Val Loss: 0.106387
2025-09-03 02:48:30,402 - INFO - New best model saved with Val Loss: 0.106387
2025-09-03 02:49:08,026 - INFO - Epoch 1665/5000 - Train Loss: 0.124216, Val Loss: 0.112053
2025-09-03 02:49:44,712 - INFO - Epoch 1666/5000 - Train Loss: 0.122687, Val Loss: 0.108184
2025-09-03 02:50:21,679 - INFO - Epoch 1667/5000 - Train Loss: 0.122729, Val Loss: 0.107671
2025-09-03 02:50:58,614 - INFO - Epoch 1668/5000 - Train Loss: 0.123078, Val Loss: 0.107533
2025-09-03 02:51:34,251 - INFO - Epoch 1669/5000 - Train Loss: 0.122786, Val Loss: 0.110674
2025-09-03 02:52:10,804 - INFO - Epoch 1670/5000 - Train Loss: 0.122845, Val Loss: 0.109482
2025-09-03 02:52:47,782 - INFO - Epoch 1671/5000 - Train Loss: 0.122109, Val Loss: 0.107685
2025-09-03 02:53:24,235 - INFO - Epoch 1672/5000 - Train Loss: 0.121033, Val Loss: 0.109154
2025-09-03 02:54:01,140 - INFO - Epoch 1673/5000 - Train Loss: 0.122471, Val Loss: 0.107065
2025-09-03 02:54:36,922 - INFO - Epoch 1674/5000 - Train Loss: 0.122171, Val Loss: 0.108840
2025-09-03 02:55:13,167 - INFO - Epoch 1675/5000 - Train Loss: 0.122027, Val Loss: 0.108524
2025-09-03 02:55:49,999 - INFO - Epoch 1676/5000 - Train Loss: 0.123305, Val Loss: 0.109433
2025-09-03 02:56:27,169 - INFO - Epoch 1677/5000 - Train Loss: 0.121372, Val Loss: 0.110941
2025-09-03 02:57:03,874 - INFO - Epoch 1678/5000 - Train Loss: 0.122847, Val Loss: 0.109587
2025-09-03 02:57:40,856 - INFO - Epoch 1679/5000 - Train Loss: 0.122036, Val Loss: 0.106218
2025-09-03 02:57:40,909 - INFO - New best model saved with Val Loss: 0.106218
2025-09-03 02:58:17,108 - INFO - Epoch 1680/5000 - Train Loss: 0.120364, Val Loss: 0.107067
2025-09-03 02:58:52,796 - INFO - Epoch 1681/5000 - Train Loss: 0.120977, Val Loss: 0.107258
2025-09-03 02:59:29,070 - INFO - Epoch 1682/5000 - Train Loss: 0.121639, Val Loss: 0.108537
2025-09-03 03:00:04,257 - INFO - Epoch 1683/5000 - Train Loss: 0.123239, Val Loss: 0.109068
2025-09-03 03:00:39,780 - INFO - Epoch 1684/5000 - Train Loss: 0.121826, Val Loss: 0.108801
2025-09-03 03:01:16,049 - INFO - Epoch 1685/5000 - Train Loss: 0.121731, Val Loss: 0.107192
2025-09-03 03:01:52,183 - INFO - Epoch 1686/5000 - Train Loss: 0.121404, Val Loss: 0.113261
2025-09-03 03:02:28,113 - INFO - Epoch 1687/5000 - Train Loss: 0.121367, Val Loss: 0.105987
2025-09-03 03:02:28,145 - INFO - New best model saved with Val Loss: 0.105987
2025-09-03 03:03:05,220 - INFO - Epoch 1688/5000 - Train Loss: 0.121097, Val Loss: 0.107343
2025-09-03 03:03:42,505 - INFO - Epoch 1689/5000 - Train Loss: 0.123258, Val Loss: 0.112846
2025-09-03 03:04:18,783 - INFO - Epoch 1690/5000 - Train Loss: 0.122518, Val Loss: 0.110235
2025-09-03 03:04:56,012 - INFO - Epoch 1691/5000 - Train Loss: 0.121545, Val Loss: 0.106257
2025-09-03 03:05:32,953 - INFO - Epoch 1692/5000 - Train Loss: 0.120611, Val Loss: 0.105856
2025-09-03 03:05:32,983 - INFO - New best model saved with Val Loss: 0.105856
2025-09-03 03:06:09,668 - INFO - Epoch 1693/5000 - Train Loss: 0.121678, Val Loss: 0.108883
2025-09-03 03:06:45,775 - INFO - Epoch 1694/5000 - Train Loss: 0.120849, Val Loss: 0.105283
2025-09-03 03:06:45,808 - INFO - New best model saved with Val Loss: 0.105283
2025-09-03 03:07:22,512 - INFO - Epoch 1695/5000 - Train Loss: 0.122185, Val Loss: 0.108369
2025-09-03 03:07:58,448 - INFO - Epoch 1696/5000 - Train Loss: 0.120738, Val Loss: 0.109481
2025-09-03 03:08:35,010 - INFO - Epoch 1697/5000 - Train Loss: 0.119970, Val Loss: 0.106349
2025-09-03 03:09:11,477 - INFO - Epoch 1698/5000 - Train Loss: 0.122166, Val Loss: 0.108178
2025-09-03 03:09:48,047 - INFO - Epoch 1699/5000 - Train Loss: 0.120009, Val Loss: 0.105355
2025-09-03 03:10:24,769 - INFO - Epoch 1700/5000 - Train Loss: 0.120551, Val Loss: 0.106684
2025-09-03 03:11:01,526 - INFO - Epoch 1701/5000 - Train Loss: 0.120708, Val Loss: 0.106471
2025-09-03 03:11:37,502 - INFO - Epoch 1702/5000 - Train Loss: 0.121277, Val Loss: 0.109191
2025-09-03 03:12:13,898 - INFO - Epoch 1703/5000 - Train Loss: 0.121116, Val Loss: 0.105066
2025-09-03 03:12:13,930 - INFO - New best model saved with Val Loss: 0.105066
2025-09-03 03:12:50,097 - INFO - Epoch 1704/5000 - Train Loss: 0.120102, Val Loss: 0.108915
2025-09-03 03:13:26,008 - INFO - Epoch 1705/5000 - Train Loss: 0.120661, Val Loss: 0.104850
2025-09-03 03:13:26,060 - INFO - New best model saved with Val Loss: 0.104850
2025-09-03 03:14:03,184 - INFO - Epoch 1706/5000 - Train Loss: 0.120027, Val Loss: 0.104778
2025-09-03 03:14:03,215 - INFO - New best model saved with Val Loss: 0.104778
2025-09-03 03:14:39,274 - INFO - Epoch 1707/5000 - Train Loss: 0.121833, Val Loss: 0.108050
2025-09-03 03:15:16,719 - INFO - Epoch 1708/5000 - Train Loss: 0.121108, Val Loss: 0.106737
2025-09-03 03:15:53,631 - INFO - Epoch 1709/5000 - Train Loss: 0.120731, Val Loss: 0.104660
2025-09-03 03:15:53,679 - INFO - New best model saved with Val Loss: 0.104660
2025-09-03 03:16:30,635 - INFO - Epoch 1710/5000 - Train Loss: 0.120676, Val Loss: 0.105501
2025-09-03 03:17:08,011 - INFO - Epoch 1711/5000 - Train Loss: 0.120007, Val Loss: 0.105325
2025-09-03 03:17:45,631 - INFO - Epoch 1712/5000 - Train Loss: 0.119009, Val Loss: 0.107703
2025-09-03 03:18:23,336 - INFO - Epoch 1713/5000 - Train Loss: 0.119687, Val Loss: 0.104435
2025-09-03 03:18:23,366 - INFO - New best model saved with Val Loss: 0.104435
2025-09-03 03:19:00,624 - INFO - Epoch 1714/5000 - Train Loss: 0.119543, Val Loss: 0.107642
2025-09-03 03:19:37,462 - INFO - Epoch 1715/5000 - Train Loss: 0.120326, Val Loss: 0.103335
2025-09-03 03:19:37,493 - INFO - New best model saved with Val Loss: 0.103335
2025-09-03 03:20:14,787 - INFO - Epoch 1716/5000 - Train Loss: 0.119161, Val Loss: 0.104717
2025-09-03 03:20:51,323 - INFO - Epoch 1717/5000 - Train Loss: 0.118644, Val Loss: 0.104852
2025-09-03 03:21:27,332 - INFO - Epoch 1718/5000 - Train Loss: 0.119798, Val Loss: 0.107041
2025-09-03 03:22:04,736 - INFO - Epoch 1719/5000 - Train Loss: 0.121900, Val Loss: 0.107316
2025-09-03 03:22:42,270 - INFO - Epoch 1720/5000 - Train Loss: 0.118228, Val Loss: 0.105266
2025-09-03 03:23:19,970 - INFO - Epoch 1721/5000 - Train Loss: 0.119056, Val Loss: 0.108309
2025-09-03 03:23:57,431 - INFO - Epoch 1722/5000 - Train Loss: 0.120311, Val Loss: 0.107605
2025-09-03 03:24:34,615 - INFO - Epoch 1723/5000 - Train Loss: 0.120824, Val Loss: 0.105224
2025-09-03 03:25:11,728 - INFO - Epoch 1724/5000 - Train Loss: 0.119066, Val Loss: 0.105993
2025-09-03 03:25:48,970 - INFO - Epoch 1725/5000 - Train Loss: 0.118926, Val Loss: 0.103832
2025-09-03 03:26:26,409 - INFO - Epoch 1726/5000 - Train Loss: 0.119996, Val Loss: 0.111282
2025-09-03 03:27:03,429 - INFO - Epoch 1727/5000 - Train Loss: 0.122180, Val Loss: 0.105002
2025-09-03 03:27:40,382 - INFO - Epoch 1728/5000 - Train Loss: 0.120055, Val Loss: 0.105807
2025-09-03 03:28:17,010 - INFO - Epoch 1729/5000 - Train Loss: 0.119230, Val Loss: 0.105411
2025-09-03 03:28:54,316 - INFO - Epoch 1730/5000 - Train Loss: 0.119509, Val Loss: 0.109937
2025-09-03 03:29:30,995 - INFO - Epoch 1731/5000 - Train Loss: 0.119824, Val Loss: 0.105676
2025-09-03 03:30:07,580 - INFO - Epoch 1732/5000 - Train Loss: 0.118961, Val Loss: 0.110035
2025-09-03 03:30:44,112 - INFO - Epoch 1733/5000 - Train Loss: 0.119607, Val Loss: 0.102871
2025-09-03 03:30:44,153 - INFO - New best model saved with Val Loss: 0.102871
2025-09-03 03:31:21,026 - INFO - Epoch 1734/5000 - Train Loss: 0.118297, Val Loss: 0.105610
2025-09-03 03:31:58,148 - INFO - Epoch 1735/5000 - Train Loss: 0.118093, Val Loss: 0.103337
2025-09-03 03:32:34,247 - INFO - Epoch 1736/5000 - Train Loss: 0.118626, Val Loss: 0.104175
2025-09-03 03:33:12,265 - INFO - Epoch 1737/5000 - Train Loss: 0.118634, Val Loss: 0.102046
2025-09-03 03:33:12,296 - INFO - New best model saved with Val Loss: 0.102046
2025-09-03 03:33:49,165 - INFO - Epoch 1738/5000 - Train Loss: 0.119432, Val Loss: 0.104156
2025-09-03 03:34:26,346 - INFO - Epoch 1739/5000 - Train Loss: 0.119607, Val Loss: 0.105524
2025-09-03 03:35:03,096 - INFO - Epoch 1740/5000 - Train Loss: 0.117296, Val Loss: 0.104506
2025-09-03 03:35:40,601 - INFO - Epoch 1741/5000 - Train Loss: 0.117941, Val Loss: 0.106240
2025-09-03 03:36:17,170 - INFO - Epoch 1742/5000 - Train Loss: 0.118441, Val Loss: 0.104630
2025-09-03 03:36:53,390 - INFO - Epoch 1743/5000 - Train Loss: 0.119538, Val Loss: 0.102708
2025-09-03 03:37:30,409 - INFO - Epoch 1744/5000 - Train Loss: 0.118596, Val Loss: 0.104952
2025-09-03 03:38:07,216 - INFO - Epoch 1745/5000 - Train Loss: 0.117589, Val Loss: 0.108448
2025-09-03 03:38:44,024 - INFO - Epoch 1746/5000 - Train Loss: 0.118345, Val Loss: 0.103631
2025-09-03 03:39:20,394 - INFO - Epoch 1747/5000 - Train Loss: 0.118149, Val Loss: 0.110210
2025-09-03 03:39:57,184 - INFO - Epoch 1748/5000 - Train Loss: 0.118089, Val Loss: 0.102927
2025-09-03 03:40:33,393 - INFO - Epoch 1749/5000 - Train Loss: 0.117936, Val Loss: 0.103714
2025-09-03 03:41:10,223 - INFO - Epoch 1750/5000 - Train Loss: 0.119235, Val Loss: 0.110766
2025-09-03 03:41:46,986 - INFO - Epoch 1751/5000 - Train Loss: 0.119585, Val Loss: 0.104219
2025-09-03 03:42:23,296 - INFO - Epoch 1752/5000 - Train Loss: 0.117841, Val Loss: 0.105744
2025-09-03 03:43:00,928 - INFO - Epoch 1753/5000 - Train Loss: 0.116920, Val Loss: 0.102702
2025-09-03 03:43:38,340 - INFO - Epoch 1754/5000 - Train Loss: 0.118779, Val Loss: 0.103928
2025-09-03 03:44:15,152 - INFO - Epoch 1755/5000 - Train Loss: 0.116364, Val Loss: 0.106015
2025-09-03 03:44:51,669 - INFO - Epoch 1756/5000 - Train Loss: 0.118318, Val Loss: 0.105333
2025-09-03 03:45:28,149 - INFO - Epoch 1757/5000 - Train Loss: 0.118221, Val Loss: 0.103287
2025-09-03 03:46:04,807 - INFO - Epoch 1758/5000 - Train Loss: 0.118054, Val Loss: 0.104476
2025-09-03 03:46:40,828 - INFO - Epoch 1759/5000 - Train Loss: 0.118161, Val Loss: 0.103967
2025-09-03 03:47:18,684 - INFO - Epoch 1760/5000 - Train Loss: 0.116376, Val Loss: 0.102555
2025-09-03 03:47:55,053 - INFO - Epoch 1761/5000 - Train Loss: 0.117281, Val Loss: 0.104088
2025-09-03 03:48:30,654 - INFO - Epoch 1762/5000 - Train Loss: 0.116758, Val Loss: 0.104366
2025-09-03 03:49:07,534 - INFO - Epoch 1763/5000 - Train Loss: 0.116878, Val Loss: 0.103499
2025-09-03 03:49:43,713 - INFO - Epoch 1764/5000 - Train Loss: 0.116579, Val Loss: 0.102070
2025-09-03 03:50:20,062 - INFO - Epoch 1765/5000 - Train Loss: 0.116917, Val Loss: 0.101869
2025-09-03 03:50:20,107 - INFO - New best model saved with Val Loss: 0.101869
2025-09-03 03:50:56,213 - INFO - Epoch 1766/5000 - Train Loss: 0.118358, Val Loss: 0.108459
2025-09-03 03:51:33,160 - INFO - Epoch 1767/5000 - Train Loss: 0.117912, Val Loss: 0.104009
2025-09-03 03:52:09,215 - INFO - Epoch 1768/5000 - Train Loss: 0.116866, Val Loss: 0.100017
2025-09-03 03:52:09,249 - INFO - New best model saved with Val Loss: 0.100017
2025-09-03 03:52:45,074 - INFO - Epoch 1769/5000 - Train Loss: 0.116517, Val Loss: 0.101881
2025-09-03 03:53:21,137 - INFO - Epoch 1770/5000 - Train Loss: 0.115288, Val Loss: 0.104411
2025-09-03 03:53:58,324 - INFO - Epoch 1771/5000 - Train Loss: 0.116049, Val Loss: 0.102041
2025-09-03 03:54:34,813 - INFO - Epoch 1772/5000 - Train Loss: 0.117644, Val Loss: 0.103216
2025-09-03 03:55:11,469 - INFO - Epoch 1773/5000 - Train Loss: 0.116502, Val Loss: 0.103975
2025-09-03 03:55:48,084 - INFO - Epoch 1774/5000 - Train Loss: 0.117396, Val Loss: 0.103489
2025-09-03 03:56:24,436 - INFO - Epoch 1775/5000 - Train Loss: 0.117521, Val Loss: 0.102835
2025-09-03 03:57:00,168 - INFO - Epoch 1776/5000 - Train Loss: 0.116268, Val Loss: 0.101228
2025-09-03 03:57:36,776 - INFO - Epoch 1777/5000 - Train Loss: 0.116242, Val Loss: 0.102038
2025-09-03 03:58:12,952 - INFO - Epoch 1778/5000 - Train Loss: 0.116460, Val Loss: 0.103850
2025-09-03 03:58:49,162 - INFO - Epoch 1779/5000 - Train Loss: 0.115649, Val Loss: 0.102107
2025-09-03 03:59:25,362 - INFO - Epoch 1780/5000 - Train Loss: 0.117042, Val Loss: 0.107888
2025-09-03 04:00:01,416 - INFO - Epoch 1781/5000 - Train Loss: 0.117299, Val Loss: 0.101360
2025-09-03 04:00:37,530 - INFO - Epoch 1782/5000 - Train Loss: 0.115394, Val Loss: 0.102153
2025-09-03 04:01:13,218 - INFO - Epoch 1783/5000 - Train Loss: 0.115596, Val Loss: 0.104062
2025-09-03 04:01:49,280 - INFO - Epoch 1784/5000 - Train Loss: 0.117039, Val Loss: 0.101917
2025-09-03 04:02:25,842 - INFO - Epoch 1785/5000 - Train Loss: 0.116456, Val Loss: 0.102041
2025-09-03 04:03:01,570 - INFO - Epoch 1786/5000 - Train Loss: 0.116481, Val Loss: 0.101363
2025-09-03 04:03:38,042 - INFO - Epoch 1787/5000 - Train Loss: 0.114587, Val Loss: 0.101136
2025-09-03 04:04:14,560 - INFO - Epoch 1788/5000 - Train Loss: 0.114697, Val Loss: 0.100964
2025-09-03 04:04:51,540 - INFO - Epoch 1789/5000 - Train Loss: 0.115587, Val Loss: 0.098471
2025-09-03 04:04:51,598 - INFO - New best model saved with Val Loss: 0.098471
2025-09-03 04:05:27,799 - INFO - Epoch 1790/5000 - Train Loss: 0.115201, Val Loss: 0.103311
2025-09-03 04:06:04,074 - INFO - Epoch 1791/5000 - Train Loss: 0.115483, Val Loss: 0.101190
2025-09-03 04:06:40,658 - INFO - Epoch 1792/5000 - Train Loss: 0.116669, Val Loss: 0.102032
2025-09-03 04:07:17,911 - INFO - Epoch 1793/5000 - Train Loss: 0.115970, Val Loss: 0.104201
2025-09-03 04:07:54,643 - INFO - Epoch 1794/5000 - Train Loss: 0.115130, Val Loss: 0.102771
2025-09-03 04:08:31,326 - INFO - Epoch 1795/5000 - Train Loss: 0.115528, Val Loss: 0.102299
2025-09-03 04:09:07,862 - INFO - Epoch 1796/5000 - Train Loss: 0.117546, Val Loss: 0.106265
2025-09-03 04:09:44,809 - INFO - Epoch 1797/5000 - Train Loss: 0.116390, Val Loss: 0.099119
2025-09-03 04:10:21,715 - INFO - Epoch 1798/5000 - Train Loss: 0.116480, Val Loss: 0.101655
2025-09-03 04:10:58,807 - INFO - Epoch 1799/5000 - Train Loss: 0.115560, Val Loss: 0.102383
2025-09-03 04:11:35,208 - INFO - Epoch 1800/5000 - Train Loss: 0.115423, Val Loss: 0.102627
2025-09-03 04:12:11,618 - INFO - Epoch 1801/5000 - Train Loss: 0.114975, Val Loss: 0.101198
2025-09-03 04:12:48,367 - INFO - Epoch 1802/5000 - Train Loss: 0.115207, Val Loss: 0.100373
2025-09-03 04:13:25,695 - INFO - Epoch 1803/5000 - Train Loss: 0.115515, Val Loss: 0.100578
2025-09-03 04:14:03,044 - INFO - Epoch 1804/5000 - Train Loss: 0.115230, Val Loss: 0.101789
2025-09-03 04:14:39,397 - INFO - Epoch 1805/5000 - Train Loss: 0.115461, Val Loss: 0.101658
2025-09-03 04:15:15,982 - INFO - Epoch 1806/5000 - Train Loss: 0.115211, Val Loss: 0.102136
2025-09-03 04:15:52,922 - INFO - Epoch 1807/5000 - Train Loss: 0.113692, Val Loss: 0.101071
2025-09-03 04:16:30,189 - INFO - Epoch 1808/5000 - Train Loss: 0.115103, Val Loss: 0.098757
2025-09-03 04:17:06,362 - INFO - Epoch 1809/5000 - Train Loss: 0.116920, Val Loss: 0.104855
2025-09-03 04:17:43,147 - INFO - Epoch 1810/5000 - Train Loss: 0.114528, Val Loss: 0.099277
2025-09-03 04:18:19,992 - INFO - Epoch 1811/5000 - Train Loss: 0.114927, Val Loss: 0.099500
2025-09-03 04:18:55,530 - INFO - Epoch 1812/5000 - Train Loss: 0.113778, Val Loss: 0.100752
2025-09-03 04:19:32,035 - INFO - Epoch 1813/5000 - Train Loss: 0.114904, Val Loss: 0.101521
2025-09-03 04:20:08,088 - INFO - Epoch 1814/5000 - Train Loss: 0.115355, Val Loss: 0.101740
2025-09-03 04:20:44,256 - INFO - Epoch 1815/5000 - Train Loss: 0.113698, Val Loss: 0.099886
2025-09-03 04:21:20,337 - INFO - Epoch 1816/5000 - Train Loss: 0.116667, Val Loss: 0.102336
2025-09-03 04:21:56,344 - INFO - Epoch 1817/5000 - Train Loss: 0.115558, Val Loss: 0.097766
2025-09-03 04:21:56,399 - INFO - New best model saved with Val Loss: 0.097766
2025-09-03 04:22:32,699 - INFO - Epoch 1818/5000 - Train Loss: 0.113807, Val Loss: 0.100959
2025-09-03 04:23:09,005 - INFO - Epoch 1819/5000 - Train Loss: 0.113593, Val Loss: 0.100703
2025-09-03 04:23:46,601 - INFO - Epoch 1820/5000 - Train Loss: 0.113602, Val Loss: 0.099332
2025-09-03 04:24:23,946 - INFO - Epoch 1821/5000 - Train Loss: 0.115009, Val Loss: 0.101590
2025-09-03 04:24:59,398 - INFO - Epoch 1822/5000 - Train Loss: 0.115725, Val Loss: 0.099641
2025-09-03 04:25:36,125 - INFO - Epoch 1823/5000 - Train Loss: 0.114221, Val Loss: 0.098393
2025-09-03 04:26:12,737 - INFO - Epoch 1824/5000 - Train Loss: 0.114049, Val Loss: 0.099905
2025-09-03 04:26:48,899 - INFO - Epoch 1825/5000 - Train Loss: 0.113749, Val Loss: 0.100808
2025-09-03 04:27:25,213 - INFO - Epoch 1826/5000 - Train Loss: 0.114580, Val Loss: 0.103793
2025-09-03 04:28:01,675 - INFO - Epoch 1827/5000 - Train Loss: 0.115294, Val Loss: 0.103537
2025-09-03 04:28:38,135 - INFO - Epoch 1828/5000 - Train Loss: 0.114928, Val Loss: 0.097916
2025-09-03 04:29:14,278 - INFO - Epoch 1829/5000 - Train Loss: 0.113415, Val Loss: 0.102916
2025-09-03 04:29:50,728 - INFO - Epoch 1830/5000 - Train Loss: 0.114467, Val Loss: 0.099002
2025-09-03 04:30:27,468 - INFO - Epoch 1831/5000 - Train Loss: 0.114081, Val Loss: 0.102872
2025-09-03 04:31:03,785 - INFO - Epoch 1832/5000 - Train Loss: 0.114279, Val Loss: 0.099169
2025-09-03 04:31:39,730 - INFO - Epoch 1833/5000 - Train Loss: 0.112388, Val Loss: 0.100075
2025-09-03 04:32:16,740 - INFO - Epoch 1834/5000 - Train Loss: 0.113558, Val Loss: 0.098636
2025-09-03 04:32:53,978 - INFO - Epoch 1835/5000 - Train Loss: 0.112930, Val Loss: 0.099423
2025-09-03 04:33:30,335 - INFO - Epoch 1836/5000 - Train Loss: 0.112549, Val Loss: 0.096955
2025-09-03 04:33:30,381 - INFO - New best model saved with Val Loss: 0.096955
2025-09-03 04:34:05,934 - INFO - Epoch 1837/5000 - Train Loss: 0.112817, Val Loss: 0.098866
2025-09-03 04:34:42,429 - INFO - Epoch 1838/5000 - Train Loss: 0.112848, Val Loss: 0.096193
2025-09-03 04:34:42,460 - INFO - New best model saved with Val Loss: 0.096193
2025-09-03 04:35:19,275 - INFO - Epoch 1839/5000 - Train Loss: 0.112821, Val Loss: 0.101215
2025-09-03 04:35:55,751 - INFO - Epoch 1840/5000 - Train Loss: 0.114110, Val Loss: 0.099145
2025-09-03 04:36:32,576 - INFO - Epoch 1841/5000 - Train Loss: 0.112479, Val Loss: 0.097243
2025-09-03 04:37:07,958 - INFO - Epoch 1842/5000 - Train Loss: 0.114768, Val Loss: 0.102606
2025-09-03 04:37:44,619 - INFO - Epoch 1843/5000 - Train Loss: 0.113422, Val Loss: 0.097337
2025-09-03 04:38:21,212 - INFO - Epoch 1844/5000 - Train Loss: 0.112431, Val Loss: 0.099547
2025-09-03 04:38:58,880 - INFO - Epoch 1845/5000 - Train Loss: 0.113231, Val Loss: 0.100322
2025-09-03 04:39:35,503 - INFO - Epoch 1846/5000 - Train Loss: 0.112436, Val Loss: 0.102094
2025-09-03 04:40:12,271 - INFO - Epoch 1847/5000 - Train Loss: 0.113923, Val Loss: 0.101011
2025-09-03 04:40:49,144 - INFO - Epoch 1848/5000 - Train Loss: 0.112173, Val Loss: 0.098883
2025-09-03 04:41:26,340 - INFO - Epoch 1849/5000 - Train Loss: 0.117963, Val Loss: 0.105055
2025-09-03 04:42:03,317 - INFO - Epoch 1850/5000 - Train Loss: 0.115119, Val Loss: 0.100138
2025-09-03 04:42:40,276 - INFO - Epoch 1851/5000 - Train Loss: 0.112743, Val Loss: 0.098004
2025-09-03 04:43:18,278 - INFO - Epoch 1852/5000 - Train Loss: 0.112546, Val Loss: 0.097554
2025-09-03 04:43:54,918 - INFO - Epoch 1853/5000 - Train Loss: 0.112328, Val Loss: 0.098439
2025-09-03 04:44:32,268 - INFO - Epoch 1854/5000 - Train Loss: 0.113125, Val Loss: 0.105052
2025-09-03 04:45:08,456 - INFO - Epoch 1855/5000 - Train Loss: 0.112993, Val Loss: 0.098888
2025-09-03 04:45:44,295 - INFO - Epoch 1856/5000 - Train Loss: 0.112573, Val Loss: 0.102237
2025-09-03 04:46:20,424 - INFO - Epoch 1857/5000 - Train Loss: 0.112830, Val Loss: 0.099119
2025-09-03 04:46:56,582 - INFO - Epoch 1858/5000 - Train Loss: 0.112213, Val Loss: 0.099191
2025-09-03 04:47:31,841 - INFO - Epoch 1859/5000 - Train Loss: 0.112481, Val Loss: 0.096777
2025-09-03 04:48:08,677 - INFO - Epoch 1860/5000 - Train Loss: 0.111873, Val Loss: 0.100130
2025-09-03 04:48:44,830 - INFO - Epoch 1861/5000 - Train Loss: 0.112205, Val Loss: 0.098736
2025-09-03 04:49:20,597 - INFO - Epoch 1862/5000 - Train Loss: 0.112430, Val Loss: 0.099162
2025-09-03 04:49:56,298 - INFO - Epoch 1863/5000 - Train Loss: 0.111419, Val Loss: 0.096850
2025-09-03 04:50:31,791 - INFO - Epoch 1864/5000 - Train Loss: 0.113228, Val Loss: 0.099465
2025-09-03 04:51:07,407 - INFO - Epoch 1865/5000 - Train Loss: 0.113481, Val Loss: 0.099695
2025-09-03 04:51:44,260 - INFO - Epoch 1866/5000 - Train Loss: 0.112159, Val Loss: 0.098125
2025-09-03 04:52:21,348 - INFO - Epoch 1867/5000 - Train Loss: 0.111173, Val Loss: 0.099091
2025-09-03 04:52:58,177 - INFO - Epoch 1868/5000 - Train Loss: 0.112040, Val Loss: 0.096913
2025-09-03 04:53:35,143 - INFO - Epoch 1869/5000 - Train Loss: 0.111925, Val Loss: 0.098048
2025-09-03 04:54:12,218 - INFO - Epoch 1870/5000 - Train Loss: 0.112411, Val Loss: 0.098160
2025-09-03 04:54:49,133 - INFO - Epoch 1871/5000 - Train Loss: 0.111869, Val Loss: 0.097777
2025-09-03 04:55:25,594 - INFO - Epoch 1872/5000 - Train Loss: 0.111741, Val Loss: 0.099761
2025-09-03 04:56:02,969 - INFO - Epoch 1873/5000 - Train Loss: 0.111887, Val Loss: 0.100021
2025-09-03 04:56:39,937 - INFO - Epoch 1874/5000 - Train Loss: 0.111248, Val Loss: 0.099531
2025-09-03 04:57:17,389 - INFO - Epoch 1875/5000 - Train Loss: 0.110902, Val Loss: 0.095724
2025-09-03 04:57:17,442 - INFO - New best model saved with Val Loss: 0.095724
2025-09-03 04:57:56,085 - INFO - Epoch 1876/5000 - Train Loss: 0.111529, Val Loss: 0.098110
2025-09-03 04:58:33,832 - INFO - Epoch 1877/5000 - Train Loss: 0.112587, Val Loss: 0.097400
2025-09-03 04:59:10,448 - INFO - Epoch 1878/5000 - Train Loss: 0.112640, Val Loss: 0.098660
2025-09-03 04:59:46,340 - INFO - Epoch 1879/5000 - Train Loss: 0.112988, Val Loss: 0.098009
2025-09-03 05:00:22,714 - INFO - Epoch 1880/5000 - Train Loss: 0.109614, Val Loss: 0.095433
2025-09-03 05:00:22,746 - INFO - New best model saved with Val Loss: 0.095433
2025-09-03 05:00:58,865 - INFO - Epoch 1881/5000 - Train Loss: 0.111318, Val Loss: 0.098198
2025-09-03 05:01:34,774 - INFO - Epoch 1882/5000 - Train Loss: 0.110838, Val Loss: 0.098540
2025-09-03 05:02:10,477 - INFO - Epoch 1883/5000 - Train Loss: 0.112081, Val Loss: 0.099646
2025-09-03 05:02:46,553 - INFO - Epoch 1884/5000 - Train Loss: 0.112232, Val Loss: 0.097975
2025-09-03 05:03:23,859 - INFO - Epoch 1885/5000 - Train Loss: 0.110682, Val Loss: 0.098633
2025-09-03 05:03:59,921 - INFO - Epoch 1886/5000 - Train Loss: 0.113311, Val Loss: 0.098936
2025-09-03 05:04:36,114 - INFO - Epoch 1887/5000 - Train Loss: 0.113404, Val Loss: 0.103702
2025-09-03 05:05:13,178 - INFO - Epoch 1888/5000 - Train Loss: 0.112198, Val Loss: 0.095890
2025-09-03 05:05:48,262 - INFO - Epoch 1889/5000 - Train Loss: 0.109965, Val Loss: 0.096512
2025-09-03 05:06:24,322 - INFO - Epoch 1890/5000 - Train Loss: 0.110712, Val Loss: 0.098483
2025-09-03 05:07:00,143 - INFO - Epoch 1891/5000 - Train Loss: 0.110313, Val Loss: 0.095887
2025-09-03 05:07:36,882 - INFO - Epoch 1892/5000 - Train Loss: 0.110183, Val Loss: 0.095849
2025-09-03 05:08:13,002 - INFO - Epoch 1893/5000 - Train Loss: 0.111584, Val Loss: 0.096463
2025-09-03 05:08:49,118 - INFO - Epoch 1894/5000 - Train Loss: 0.111061, Val Loss: 0.097269
2025-09-03 05:09:25,218 - INFO - Epoch 1895/5000 - Train Loss: 0.109160, Val Loss: 0.098953
2025-09-03 05:10:01,305 - INFO - Epoch 1896/5000 - Train Loss: 0.111274, Val Loss: 0.094482
2025-09-03 05:10:01,364 - INFO - New best model saved with Val Loss: 0.094482
2025-09-03 05:10:36,893 - INFO - Epoch 1897/5000 - Train Loss: 0.110991, Val Loss: 0.095727
2025-09-03 05:11:12,386 - INFO - Epoch 1898/5000 - Train Loss: 0.111200, Val Loss: 0.097178
2025-09-03 05:11:48,536 - INFO - Epoch 1899/5000 - Train Loss: 0.110610, Val Loss: 0.095132
2025-09-03 05:12:24,134 - INFO - Epoch 1900/5000 - Train Loss: 0.109583, Val Loss: 0.097004
2025-09-03 05:13:01,142 - INFO - Epoch 1901/5000 - Train Loss: 0.109896, Val Loss: 0.097213
2025-09-03 05:13:37,073 - INFO - Epoch 1902/5000 - Train Loss: 0.110820, Val Loss: 0.098587
2025-09-03 05:14:12,979 - INFO - Epoch 1903/5000 - Train Loss: 0.110450, Val Loss: 0.097215
2025-09-03 05:14:49,484 - INFO - Epoch 1904/5000 - Train Loss: 0.112430, Val Loss: 0.098877
2025-09-03 05:15:25,069 - INFO - Epoch 1905/5000 - Train Loss: 0.110869, Val Loss: 0.097887
2025-09-03 05:16:01,442 - INFO - Epoch 1906/5000 - Train Loss: 0.110630, Val Loss: 0.095306
2025-09-03 05:16:37,605 - INFO - Epoch 1907/5000 - Train Loss: 0.109539, Val Loss: 0.093325
2025-09-03 05:16:37,672 - INFO - New best model saved with Val Loss: 0.093325
2025-09-03 05:17:13,426 - INFO - Epoch 1908/5000 - Train Loss: 0.110108, Val Loss: 0.097775
2025-09-03 05:17:49,668 - INFO - Epoch 1909/5000 - Train Loss: 0.110718, Val Loss: 0.094573
2025-09-03 05:18:25,686 - INFO - Epoch 1910/5000 - Train Loss: 0.110206, Val Loss: 0.097599
2025-09-03 05:19:02,212 - INFO - Epoch 1911/5000 - Train Loss: 0.112466, Val Loss: 0.099291
2025-09-03 05:19:37,776 - INFO - Epoch 1912/5000 - Train Loss: 0.110010, Val Loss: 0.095631
2025-09-03 05:20:13,136 - INFO - Epoch 1913/5000 - Train Loss: 0.109536, Val Loss: 0.097908
2025-09-03 05:20:49,631 - INFO - Epoch 1914/5000 - Train Loss: 0.111003, Val Loss: 0.094243
2025-09-03 05:21:24,626 - INFO - Epoch 1915/5000 - Train Loss: 0.108532, Val Loss: 0.095892
2025-09-03 05:22:00,095 - INFO - Epoch 1916/5000 - Train Loss: 0.110280, Val Loss: 0.096402
2025-09-03 05:22:35,170 - INFO - Epoch 1917/5000 - Train Loss: 0.109771, Val Loss: 0.095313
2025-09-03 05:23:10,547 - INFO - Epoch 1918/5000 - Train Loss: 0.109535, Val Loss: 0.093906
2025-09-03 05:23:46,610 - INFO - Epoch 1919/5000 - Train Loss: 0.109700, Val Loss: 0.097142
2025-09-03 05:24:22,353 - INFO - Epoch 1920/5000 - Train Loss: 0.110497, Val Loss: 0.099554
2025-09-03 05:24:57,479 - INFO - Epoch 1921/5000 - Train Loss: 0.109451, Val Loss: 0.097084
2025-09-03 05:25:33,186 - INFO - Epoch 1922/5000 - Train Loss: 0.109285, Val Loss: 0.095045
2025-09-03 05:26:08,656 - INFO - Epoch 1923/5000 - Train Loss: 0.109639, Val Loss: 0.095852
2025-09-03 05:26:43,782 - INFO - Epoch 1924/5000 - Train Loss: 0.109783, Val Loss: 0.097653
2025-09-03 05:27:19,730 - INFO - Epoch 1925/5000 - Train Loss: 0.111189, Val Loss: 0.105017
2025-09-03 05:27:54,871 - INFO - Epoch 1926/5000 - Train Loss: 0.110872, Val Loss: 0.099687
2025-09-03 05:28:30,064 - INFO - Epoch 1927/5000 - Train Loss: 0.110400, Val Loss: 0.094485
2025-09-03 05:29:05,310 - INFO - Epoch 1928/5000 - Train Loss: 0.108656, Val Loss: 0.094188
2025-09-03 05:29:41,904 - INFO - Epoch 1929/5000 - Train Loss: 0.107911, Val Loss: 0.092144
2025-09-03 05:29:41,966 - INFO - New best model saved with Val Loss: 0.092144
2025-09-03 05:30:17,946 - INFO - Epoch 1930/5000 - Train Loss: 0.109040, Val Loss: 0.095398
2025-09-03 05:30:52,656 - INFO - Epoch 1931/5000 - Train Loss: 0.109898, Val Loss: 0.095938
2025-09-03 05:31:28,056 - INFO - Epoch 1932/5000 - Train Loss: 0.109467, Val Loss: 0.093599
2025-09-03 05:32:03,476 - INFO - Epoch 1933/5000 - Train Loss: 0.109600, Val Loss: 0.094497
2025-09-03 05:32:39,554 - INFO - Epoch 1934/5000 - Train Loss: 0.109229, Val Loss: 0.096543
2025-09-03 05:33:14,697 - INFO - Epoch 1935/5000 - Train Loss: 0.110022, Val Loss: 0.095921
2025-09-03 05:33:50,175 - INFO - Epoch 1936/5000 - Train Loss: 0.110378, Val Loss: 0.094725
2025-09-03 05:34:26,051 - INFO - Epoch 1937/5000 - Train Loss: 0.109256, Val Loss: 0.093067
2025-09-03 05:35:02,284 - INFO - Epoch 1938/5000 - Train Loss: 0.108997, Val Loss: 0.096022
2025-09-03 05:35:38,242 - INFO - Epoch 1939/5000 - Train Loss: 0.110086, Val Loss: 0.094471
2025-09-03 05:36:14,304 - INFO - Epoch 1940/5000 - Train Loss: 0.108275, Val Loss: 0.096273
2025-09-03 05:36:50,624 - INFO - Epoch 1941/5000 - Train Loss: 0.108698, Val Loss: 0.094792
2025-09-03 05:37:25,415 - INFO - Epoch 1942/5000 - Train Loss: 0.108432, Val Loss: 0.096933
2025-09-03 05:38:00,536 - INFO - Epoch 1943/5000 - Train Loss: 0.108454, Val Loss: 0.093021
2025-09-03 05:38:36,562 - INFO - Epoch 1944/5000 - Train Loss: 0.108455, Val Loss: 0.096017
2025-09-03 05:39:12,524 - INFO - Epoch 1945/5000 - Train Loss: 0.110534, Val Loss: 0.094815
2025-09-03 05:39:48,200 - INFO - Epoch 1946/5000 - Train Loss: 0.107974, Val Loss: 0.096564
2025-09-03 05:40:23,668 - INFO - Epoch 1947/5000 - Train Loss: 0.109826, Val Loss: 0.094496
2025-09-03 05:40:59,000 - INFO - Epoch 1948/5000 - Train Loss: 0.107838, Val Loss: 0.094763
2025-09-03 05:41:34,380 - INFO - Epoch 1949/5000 - Train Loss: 0.108520, Val Loss: 0.096327
2025-09-03 05:42:10,654 - INFO - Epoch 1950/5000 - Train Loss: 0.110772, Val Loss: 0.093708
2025-09-03 05:42:47,019 - INFO - Epoch 1951/5000 - Train Loss: 0.109320, Val Loss: 0.097974
2025-09-03 05:43:23,703 - INFO - Epoch 1952/5000 - Train Loss: 0.108543, Val Loss: 0.098651
2025-09-03 05:43:59,521 - INFO - Epoch 1953/5000 - Train Loss: 0.110005, Val Loss: 0.096153
2025-09-03 05:44:34,831 - INFO - Epoch 1954/5000 - Train Loss: 0.109373, Val Loss: 0.093315
2025-09-03 05:45:10,602 - INFO - Epoch 1955/5000 - Train Loss: 0.108791, Val Loss: 0.095426
2025-09-03 05:45:45,721 - INFO - Epoch 1956/5000 - Train Loss: 0.108261, Val Loss: 0.093115
2025-09-03 05:46:21,290 - INFO - Epoch 1957/5000 - Train Loss: 0.108421, Val Loss: 0.093726
2025-09-03 05:46:56,681 - INFO - Epoch 1958/5000 - Train Loss: 0.108937, Val Loss: 0.094094
2025-09-03 05:47:32,487 - INFO - Epoch 1959/5000 - Train Loss: 0.108763, Val Loss: 0.095195
2025-09-03 05:48:07,518 - INFO - Epoch 1960/5000 - Train Loss: 0.108984, Val Loss: 0.095670
2025-09-03 05:48:43,542 - INFO - Epoch 1961/5000 - Train Loss: 0.107731, Val Loss: 0.091231
2025-09-03 05:48:43,587 - INFO - New best model saved with Val Loss: 0.091231
2025-09-03 05:49:19,656 - INFO - Epoch 1962/5000 - Train Loss: 0.107687, Val Loss: 0.094670
2025-09-03 05:49:55,884 - INFO - Epoch 1963/5000 - Train Loss: 0.107317, Val Loss: 0.094119
2025-09-03 05:50:31,889 - INFO - Epoch 1964/5000 - Train Loss: 0.107749, Val Loss: 0.092200
2025-09-03 05:51:07,534 - INFO - Epoch 1965/5000 - Train Loss: 0.106846, Val Loss: 0.096446
2025-09-03 05:51:42,671 - INFO - Epoch 1966/5000 - Train Loss: 0.110372, Val Loss: 0.094645
2025-09-03 05:52:18,466 - INFO - Epoch 1967/5000 - Train Loss: 0.108460, Val Loss: 0.096770
2025-09-03 05:52:53,434 - INFO - Epoch 1968/5000 - Train Loss: 0.108638, Val Loss: 0.096723
2025-09-03 05:53:29,022 - INFO - Epoch 1969/5000 - Train Loss: 0.107925, Val Loss: 0.093587
2025-09-03 05:54:04,265 - INFO - Epoch 1970/5000 - Train Loss: 0.107293, Val Loss: 0.094679
2025-09-03 05:54:39,310 - INFO - Epoch 1971/5000 - Train Loss: 0.108274, Val Loss: 0.096624
2025-09-03 05:55:14,441 - INFO - Epoch 1972/5000 - Train Loss: 0.108794, Val Loss: 0.095040
2025-09-03 05:55:50,830 - INFO - Epoch 1973/5000 - Train Loss: 0.107704, Val Loss: 0.092789
2025-09-03 05:56:26,949 - INFO - Epoch 1974/5000 - Train Loss: 0.109308, Val Loss: 0.097572
2025-09-03 05:57:02,377 - INFO - Epoch 1975/5000 - Train Loss: 0.108056, Val Loss: 0.093152
2025-09-03 05:57:38,477 - INFO - Epoch 1976/5000 - Train Loss: 0.108684, Val Loss: 0.093215
2025-09-03 05:58:13,997 - INFO - Epoch 1977/5000 - Train Loss: 0.106404, Val Loss: 0.091305
2025-09-03 05:58:49,472 - INFO - Epoch 1978/5000 - Train Loss: 0.106140, Val Loss: 0.092294
2025-09-03 05:59:26,133 - INFO - Epoch 1979/5000 - Train Loss: 0.107369, Val Loss: 0.096729
2025-09-03 06:00:02,805 - INFO - Epoch 1980/5000 - Train Loss: 0.108485, Val Loss: 0.094421
2025-09-03 06:00:39,592 - INFO - Epoch 1981/5000 - Train Loss: 0.106791, Val Loss: 0.092238
2025-09-03 06:01:15,532 - INFO - Epoch 1982/5000 - Train Loss: 0.107143, Val Loss: 0.092806
2025-09-03 06:01:52,275 - INFO - Epoch 1983/5000 - Train Loss: 0.106401, Val Loss: 0.094882
2025-09-03 06:02:28,420 - INFO - Epoch 1984/5000 - Train Loss: 0.106846, Val Loss: 0.095392
2025-09-03 06:03:04,563 - INFO - Epoch 1985/5000 - Train Loss: 0.108103, Val Loss: 0.092697
2025-09-03 06:03:41,101 - INFO - Epoch 1986/5000 - Train Loss: 0.106132, Val Loss: 0.092739
2025-09-03 06:04:18,059 - INFO - Epoch 1987/5000 - Train Loss: 0.108428, Val Loss: 0.098335
2025-09-03 06:04:54,635 - INFO - Epoch 1988/5000 - Train Loss: 0.107398, Val Loss: 0.095239
2025-09-03 06:05:31,091 - INFO - Epoch 1989/5000 - Train Loss: 0.108701, Val Loss: 0.095415
2025-09-03 06:06:07,527 - INFO - Epoch 1990/5000 - Train Loss: 0.108678, Val Loss: 0.096251
2025-09-03 06:06:43,977 - INFO - Epoch 1991/5000 - Train Loss: 0.106400, Val Loss: 0.094292
2025-09-03 06:07:19,829 - INFO - Epoch 1992/5000 - Train Loss: 0.108293, Val Loss: 0.094437
2025-09-03 06:07:55,823 - INFO - Epoch 1993/5000 - Train Loss: 0.109557, Val Loss: 0.092864
2025-09-03 06:08:32,098 - INFO - Epoch 1994/5000 - Train Loss: 0.108396, Val Loss: 0.095612
2025-09-03 06:09:07,900 - INFO - Epoch 1995/5000 - Train Loss: 0.106948, Val Loss: 0.096450
2025-09-03 06:09:43,595 - INFO - Epoch 1996/5000 - Train Loss: 0.106225, Val Loss: 0.092709
2025-09-03 06:10:19,524 - INFO - Epoch 1997/5000 - Train Loss: 0.107011, Val Loss: 0.093531
2025-09-03 06:10:55,203 - INFO - Epoch 1998/5000 - Train Loss: 0.106825, Val Loss: 0.092176
2025-09-03 06:11:32,233 - INFO - Epoch 1999/5000 - Train Loss: 0.109057, Val Loss: 0.094731
2025-09-03 06:12:09,228 - INFO - Epoch 2000/5000 - Train Loss: 0.108161, Val Loss: 0.094907
2025-09-03 06:12:46,043 - INFO - Epoch 2001/5000 - Train Loss: 0.106217, Val Loss: 0.091405
2025-09-03 06:13:22,264 - INFO - Epoch 2002/5000 - Train Loss: 0.106007, Val Loss: 0.092523
2025-09-03 06:13:57,969 - INFO - Epoch 2003/5000 - Train Loss: 0.105925, Val Loss: 0.093146
2025-09-03 06:14:34,053 - INFO - Epoch 2004/5000 - Train Loss: 0.108307, Val Loss: 0.092436
2025-09-03 06:15:09,615 - INFO - Epoch 2005/5000 - Train Loss: 0.105514, Val Loss: 0.090605
2025-09-03 06:15:09,665 - INFO - New best model saved with Val Loss: 0.090605
2025-09-03 06:15:45,655 - INFO - Epoch 2006/5000 - Train Loss: 0.106402, Val Loss: 0.093782
2025-09-03 06:16:22,213 - INFO - Epoch 2007/5000 - Train Loss: 0.107017, Val Loss: 0.095240
2025-09-03 06:16:58,180 - INFO - Epoch 2008/5000 - Train Loss: 0.106869, Val Loss: 0.091513
2025-09-03 06:17:35,480 - INFO - Epoch 2009/5000 - Train Loss: 0.105931, Val Loss: 0.091928
2025-09-03 06:18:12,556 - INFO - Epoch 2010/5000 - Train Loss: 0.106575, Val Loss: 0.095152
2025-09-03 06:18:48,154 - INFO - Epoch 2011/5000 - Train Loss: 0.105570, Val Loss: 0.091056
2025-09-03 06:19:24,517 - INFO - Epoch 2012/5000 - Train Loss: 0.108767, Val Loss: 0.092041
2025-09-03 06:20:00,983 - INFO - Epoch 2013/5000 - Train Loss: 0.106192, Val Loss: 0.095364
2025-09-03 06:20:36,608 - INFO - Epoch 2014/5000 - Train Loss: 0.105320, Val Loss: 0.095970
2025-09-03 06:21:13,278 - INFO - Epoch 2015/5000 - Train Loss: 0.105270, Val Loss: 0.093544
2025-09-03 06:21:49,716 - INFO - Epoch 2016/5000 - Train Loss: 0.105632, Val Loss: 0.091392
2025-09-03 06:22:26,300 - INFO - Epoch 2017/5000 - Train Loss: 0.105154, Val Loss: 0.091124
2025-09-03 06:23:02,677 - INFO - Epoch 2018/5000 - Train Loss: 0.105318, Val Loss: 0.091688
2025-09-03 06:23:38,681 - INFO - Epoch 2019/5000 - Train Loss: 0.105530, Val Loss: 0.093508
2025-09-03 06:24:14,243 - INFO - Epoch 2020/5000 - Train Loss: 0.106136, Val Loss: 0.093752
2025-09-03 06:24:51,051 - INFO - Epoch 2021/5000 - Train Loss: 0.105721, Val Loss: 0.091756
2025-09-03 06:25:26,633 - INFO - Epoch 2022/5000 - Train Loss: 0.104983, Val Loss: 0.091671
2025-09-03 06:26:03,108 - INFO - Epoch 2023/5000 - Train Loss: 0.105942, Val Loss: 0.092269
2025-09-03 06:26:39,990 - INFO - Epoch 2024/5000 - Train Loss: 0.105355, Val Loss: 0.091619
2025-09-03 06:27:16,607 - INFO - Epoch 2025/5000 - Train Loss: 0.106226, Val Loss: 0.093418
2025-09-03 06:27:52,770 - INFO - Epoch 2026/5000 - Train Loss: 0.107159, Val Loss: 0.098014
2025-09-03 06:28:28,102 - INFO - Epoch 2027/5000 - Train Loss: 0.107657, Val Loss: 0.092466
2025-09-03 06:29:03,950 - INFO - Epoch 2028/5000 - Train Loss: 0.105516, Val Loss: 0.091116
2025-09-03 06:29:39,502 - INFO - Epoch 2029/5000 - Train Loss: 0.106066, Val Loss: 0.092531
2025-09-03 06:30:16,625 - INFO - Epoch 2030/5000 - Train Loss: 0.104866, Val Loss: 0.090536
2025-09-03 06:30:16,671 - INFO - New best model saved with Val Loss: 0.090536
2025-09-03 06:30:53,778 - INFO - Epoch 2031/5000 - Train Loss: 0.104939, Val Loss: 0.094397
2025-09-03 06:31:30,281 - INFO - Epoch 2032/5000 - Train Loss: 0.104989, Val Loss: 0.093358
2025-09-03 06:32:06,867 - INFO - Epoch 2033/5000 - Train Loss: 0.105857, Val Loss: 0.092634
2025-09-03 06:32:43,133 - INFO - Epoch 2034/5000 - Train Loss: 0.104552, Val Loss: 0.093424
2025-09-03 06:33:20,124 - INFO - Epoch 2035/5000 - Train Loss: 0.106281, Val Loss: 0.093571
2025-09-03 06:33:57,651 - INFO - Epoch 2036/5000 - Train Loss: 0.105630, Val Loss: 0.091396
2025-09-03 06:34:33,894 - INFO - Epoch 2037/5000 - Train Loss: 0.105773, Val Loss: 0.091979
2025-09-03 06:35:09,968 - INFO - Epoch 2038/5000 - Train Loss: 0.106675, Val Loss: 0.095342
2025-09-03 06:35:45,066 - INFO - Epoch 2039/5000 - Train Loss: 0.104540, Val Loss: 0.093306
2025-09-03 06:36:20,235 - INFO - Epoch 2040/5000 - Train Loss: 0.105944, Val Loss: 0.094706
2025-09-03 06:36:57,058 - INFO - Epoch 2041/5000 - Train Loss: 0.106760, Val Loss: 0.091549
2025-09-03 06:37:33,225 - INFO - Epoch 2042/5000 - Train Loss: 0.106655, Val Loss: 0.096043
2025-09-03 06:38:09,926 - INFO - Epoch 2043/5000 - Train Loss: 0.106258, Val Loss: 0.090736
2025-09-03 06:38:46,016 - INFO - Epoch 2044/5000 - Train Loss: 0.104647, Val Loss: 0.095167
2025-09-03 06:39:22,206 - INFO - Epoch 2045/5000 - Train Loss: 0.106117, Val Loss: 0.092234
2025-09-03 06:39:57,957 - INFO - Epoch 2046/5000 - Train Loss: 0.104589, Val Loss: 0.090048
2025-09-03 06:39:58,011 - INFO - New best model saved with Val Loss: 0.090048
2025-09-03 06:40:33,679 - INFO - Epoch 2047/5000 - Train Loss: 0.106334, Val Loss: 0.093347
2025-09-03 06:41:09,333 - INFO - Epoch 2048/5000 - Train Loss: 0.105670, Val Loss: 0.093382
2025-09-03 06:41:45,953 - INFO - Epoch 2049/5000 - Train Loss: 0.106752, Val Loss: 0.091258
2025-09-03 06:42:22,159 - INFO - Epoch 2050/5000 - Train Loss: 0.104596, Val Loss: 0.091382
2025-09-03 06:42:58,129 - INFO - Epoch 2051/5000 - Train Loss: 0.106203, Val Loss: 0.093761
2025-09-03 06:43:33,559 - INFO - Epoch 2052/5000 - Train Loss: 0.105590, Val Loss: 0.090466
2025-09-03 06:44:08,629 - INFO - Epoch 2053/5000 - Train Loss: 0.104245, Val Loss: 0.091414
2025-09-03 06:44:44,981 - INFO - Epoch 2054/5000 - Train Loss: 0.106180, Val Loss: 0.094601
2025-09-03 06:45:20,436 - INFO - Epoch 2055/5000 - Train Loss: 0.105848, Val Loss: 0.093116
2025-09-03 06:45:56,268 - INFO - Epoch 2056/5000 - Train Loss: 0.104008, Val Loss: 0.090080
2025-09-03 06:46:31,799 - INFO - Epoch 2057/5000 - Train Loss: 0.103662, Val Loss: 0.090467
2025-09-03 06:47:07,019 - INFO - Epoch 2058/5000 - Train Loss: 0.103573, Val Loss: 0.090907
2025-09-03 06:47:42,700 - INFO - Epoch 2059/5000 - Train Loss: 0.103773, Val Loss: 0.090451
2025-09-03 06:48:17,742 - INFO - Epoch 2060/5000 - Train Loss: 0.104521, Val Loss: 0.092203
2025-09-03 06:48:52,735 - INFO - Epoch 2061/5000 - Train Loss: 0.103750, Val Loss: 0.093298
2025-09-03 06:49:27,641 - INFO - Epoch 2062/5000 - Train Loss: 0.105307, Val Loss: 0.091603
2025-09-03 06:50:03,554 - INFO - Epoch 2063/5000 - Train Loss: 0.105249, Val Loss: 0.090844
2025-09-03 06:50:38,822 - INFO - Epoch 2064/5000 - Train Loss: 0.105124, Val Loss: 0.090439
2025-09-03 06:51:13,656 - INFO - Epoch 2065/5000 - Train Loss: 0.104788, Val Loss: 0.093107
2025-09-03 06:51:49,698 - INFO - Epoch 2066/5000 - Train Loss: 0.106575, Val Loss: 0.092953
2025-09-03 06:52:26,027 - INFO - Epoch 2067/5000 - Train Loss: 0.105061, Val Loss: 0.089652
2025-09-03 06:52:26,072 - INFO - New best model saved with Val Loss: 0.089652
2025-09-03 06:53:01,284 - INFO - Epoch 2068/5000 - Train Loss: 0.104665, Val Loss: 0.089960
2025-09-03 06:53:36,796 - INFO - Epoch 2069/5000 - Train Loss: 0.104168, Val Loss: 0.090184
2025-09-03 06:54:12,888 - INFO - Epoch 2070/5000 - Train Loss: 0.104245, Val Loss: 0.092292
2025-09-03 06:54:48,962 - INFO - Epoch 2071/5000 - Train Loss: 0.104021, Val Loss: 0.089797
2025-09-03 06:55:25,063 - INFO - Epoch 2072/5000 - Train Loss: 0.105384, Val Loss: 0.091454
2025-09-03 06:56:00,638 - INFO - Epoch 2073/5000 - Train Loss: 0.102794, Val Loss: 0.090767
2025-09-03 06:56:36,383 - INFO - Epoch 2074/5000 - Train Loss: 0.104368, Val Loss: 0.093040
2025-09-03 06:57:11,639 - INFO - Epoch 2075/5000 - Train Loss: 0.106332, Val Loss: 0.098207
2025-09-03 06:57:47,771 - INFO - Epoch 2076/5000 - Train Loss: 0.105495, Val Loss: 0.091684
2025-09-03 06:58:23,913 - INFO - Epoch 2077/5000 - Train Loss: 0.104531, Val Loss: 0.091872
2025-09-03 06:58:59,910 - INFO - Epoch 2078/5000 - Train Loss: 0.103881, Val Loss: 0.089779
2025-09-03 06:59:36,349 - INFO - Epoch 2079/5000 - Train Loss: 0.103986, Val Loss: 0.092900
2025-09-03 07:00:13,011 - INFO - Epoch 2080/5000 - Train Loss: 0.106452, Val Loss: 0.092022
2025-09-03 07:00:48,235 - INFO - Epoch 2081/5000 - Train Loss: 0.103367, Val Loss: 0.089576
2025-09-03 07:00:48,276 - INFO - New best model saved with Val Loss: 0.089576
2025-09-03 07:01:24,108 - INFO - Epoch 2082/5000 - Train Loss: 0.103367, Val Loss: 0.090591
2025-09-03 07:01:59,138 - INFO - Epoch 2083/5000 - Train Loss: 0.103695, Val Loss: 0.088130
2025-09-03 07:01:59,188 - INFO - New best model saved with Val Loss: 0.088130
2025-09-03 07:02:35,151 - INFO - Epoch 2084/5000 - Train Loss: 0.103818, Val Loss: 0.094876
2025-09-03 07:03:11,301 - INFO - Epoch 2085/5000 - Train Loss: 0.103784, Val Loss: 0.091899
2025-09-03 07:03:47,400 - INFO - Epoch 2086/5000 - Train Loss: 0.104715, Val Loss: 0.093331
2025-09-03 07:04:23,918 - INFO - Epoch 2087/5000 - Train Loss: 0.104166, Val Loss: 0.090384
2025-09-03 07:04:59,922 - INFO - Epoch 2088/5000 - Train Loss: 0.103143, Val Loss: 0.091597
2025-09-03 07:05:35,786 - INFO - Epoch 2089/5000 - Train Loss: 0.104448, Val Loss: 0.091420
2025-09-03 07:06:12,524 - INFO - Epoch 2090/5000 - Train Loss: 0.103081, Val Loss: 0.090896
2025-09-03 07:06:49,001 - INFO - Epoch 2091/5000 - Train Loss: 0.101434, Val Loss: 0.090516
2025-09-03 07:07:24,332 - INFO - Epoch 2092/5000 - Train Loss: 0.103930, Val Loss: 0.089905
2025-09-03 07:08:00,915 - INFO - Epoch 2093/5000 - Train Loss: 0.104869, Val Loss: 0.092215
2025-09-03 07:08:36,535 - INFO - Epoch 2094/5000 - Train Loss: 0.104155, Val Loss: 0.090055
2025-09-03 07:09:12,386 - INFO - Epoch 2095/5000 - Train Loss: 0.104284, Val Loss: 0.092481
2025-09-03 07:09:48,262 - INFO - Epoch 2096/5000 - Train Loss: 0.102635, Val Loss: 0.088445
2025-09-03 07:10:23,453 - INFO - Epoch 2097/5000 - Train Loss: 0.102561, Val Loss: 0.089830
2025-09-03 07:10:59,904 - INFO - Epoch 2098/5000 - Train Loss: 0.103281, Val Loss: 0.087514
2025-09-03 07:10:59,935 - INFO - New best model saved with Val Loss: 0.087514
2025-09-03 07:11:35,700 - INFO - Epoch 2099/5000 - Train Loss: 0.103579, Val Loss: 0.091094
2025-09-03 07:12:11,902 - INFO - Epoch 2100/5000 - Train Loss: 0.103770, Val Loss: 0.091725
2025-09-03 07:12:48,103 - INFO - Epoch 2101/5000 - Train Loss: 0.102531, Val Loss: 0.089409
2025-09-03 07:13:23,956 - INFO - Epoch 2102/5000 - Train Loss: 0.102100, Val Loss: 0.091843
2025-09-03 07:13:59,192 - INFO - Epoch 2103/5000 - Train Loss: 0.102783, Val Loss: 0.088707
2025-09-03 07:14:35,590 - INFO - Epoch 2104/5000 - Train Loss: 0.102964, Val Loss: 0.089610
2025-09-03 07:15:10,395 - INFO - Epoch 2105/5000 - Train Loss: 0.102926, Val Loss: 0.090599
2025-09-03 07:15:45,730 - INFO - Epoch 2106/5000 - Train Loss: 0.104103, Val Loss: 0.090921
2025-09-03 07:16:21,571 - INFO - Epoch 2107/5000 - Train Loss: 0.102581, Val Loss: 0.095853
2025-09-03 07:16:57,587 - INFO - Epoch 2108/5000 - Train Loss: 0.103664, Val Loss: 0.093143
2025-09-03 07:17:32,980 - INFO - Epoch 2109/5000 - Train Loss: 0.103495, Val Loss: 0.090370
2025-09-03 07:18:08,425 - INFO - Epoch 2110/5000 - Train Loss: 0.102661, Val Loss: 0.089685
2025-09-03 07:18:44,394 - INFO - Epoch 2111/5000 - Train Loss: 0.102797, Val Loss: 0.089370
2025-09-03 07:19:20,074 - INFO - Epoch 2112/5000 - Train Loss: 0.102687, Val Loss: 0.090612
2025-09-03 07:19:55,919 - INFO - Epoch 2113/5000 - Train Loss: 0.102724, Val Loss: 0.090711
2025-09-03 07:20:31,350 - INFO - Epoch 2114/5000 - Train Loss: 0.102936, Val Loss: 0.088095
2025-09-03 07:21:07,219 - INFO - Epoch 2115/5000 - Train Loss: 0.102151, Val Loss: 0.088371
2025-09-03 07:21:43,589 - INFO - Epoch 2116/5000 - Train Loss: 0.103441, Val Loss: 0.091245
2025-09-03 07:22:18,953 - INFO - Epoch 2117/5000 - Train Loss: 0.103324, Val Loss: 0.092500
2025-09-03 07:22:55,101 - INFO - Epoch 2118/5000 - Train Loss: 0.103682, Val Loss: 0.090449
2025-09-03 07:23:30,337 - INFO - Epoch 2119/5000 - Train Loss: 0.102774, Val Loss: 0.093214
2025-09-03 07:24:06,671 - INFO - Epoch 2120/5000 - Train Loss: 0.103255, Val Loss: 0.088343
2025-09-03 07:24:42,125 - INFO - Epoch 2121/5000 - Train Loss: 0.102538, Val Loss: 0.090924
2025-09-03 07:25:17,282 - INFO - Epoch 2122/5000 - Train Loss: 0.103483, Val Loss: 0.089886
2025-09-03 07:25:52,993 - INFO - Epoch 2123/5000 - Train Loss: 0.103049, Val Loss: 0.087732
2025-09-03 07:26:28,622 - INFO - Epoch 2124/5000 - Train Loss: 0.102261, Val Loss: 0.091510
2025-09-03 07:27:04,583 - INFO - Epoch 2125/5000 - Train Loss: 0.102140, Val Loss: 0.089349
2025-09-03 07:27:39,390 - INFO - Epoch 2126/5000 - Train Loss: 0.102571, Val Loss: 0.091958
2025-09-03 07:28:14,967 - INFO - Epoch 2127/5000 - Train Loss: 0.102342, Val Loss: 0.093812
2025-09-03 07:28:50,435 - INFO - Epoch 2128/5000 - Train Loss: 0.102960, Val Loss: 0.087923
2025-09-03 07:29:25,693 - INFO - Epoch 2129/5000 - Train Loss: 0.102804, Val Loss: 0.090327
2025-09-03 07:30:00,882 - INFO - Epoch 2130/5000 - Train Loss: 0.102365, Val Loss: 0.090937
2025-09-03 07:30:36,242 - INFO - Epoch 2131/5000 - Train Loss: 0.102425, Val Loss: 0.090084
2025-09-03 07:31:11,919 - INFO - Epoch 2132/5000 - Train Loss: 0.102919, Val Loss: 0.090550
2025-09-03 07:31:46,873 - INFO - Epoch 2133/5000 - Train Loss: 0.102659, Val Loss: 0.090334
2025-09-03 07:32:22,694 - INFO - Epoch 2134/5000 - Train Loss: 0.102487, Val Loss: 0.091957
2025-09-03 07:32:58,682 - INFO - Epoch 2135/5000 - Train Loss: 0.102461, Val Loss: 0.088140
2025-09-03 07:33:33,653 - INFO - Epoch 2136/5000 - Train Loss: 0.102247, Val Loss: 0.092538
2025-09-03 07:34:09,326 - INFO - Epoch 2137/5000 - Train Loss: 0.102435, Val Loss: 0.088920
2025-09-03 07:34:44,406 - INFO - Epoch 2138/5000 - Train Loss: 0.101537, Val Loss: 0.090885
2025-09-03 07:35:20,435 - INFO - Epoch 2139/5000 - Train Loss: 0.102844, Val Loss: 0.088893
2025-09-03 07:35:56,471 - INFO - Epoch 2140/5000 - Train Loss: 0.102035, Val Loss: 0.090225
2025-09-03 07:36:32,204 - INFO - Epoch 2141/5000 - Train Loss: 0.102191, Val Loss: 0.089977
2025-09-03 07:37:06,967 - INFO - Epoch 2142/5000 - Train Loss: 0.102476, Val Loss: 0.093083
2025-09-03 07:37:42,465 - INFO - Epoch 2143/5000 - Train Loss: 0.102744, Val Loss: 0.090599
2025-09-03 07:38:18,850 - INFO - Epoch 2144/5000 - Train Loss: 0.103330, Val Loss: 0.089078
2025-09-03 07:38:54,126 - INFO - Epoch 2145/5000 - Train Loss: 0.102709, Val Loss: 0.086803
2025-09-03 07:38:54,181 - INFO - New best model saved with Val Loss: 0.086803
2025-09-03 07:39:30,119 - INFO - Epoch 2146/5000 - Train Loss: 0.101748, Val Loss: 0.087736
2025-09-03 07:40:06,481 - INFO - Epoch 2147/5000 - Train Loss: 0.102895, Val Loss: 0.092897
2025-09-03 07:40:41,822 - INFO - Epoch 2148/5000 - Train Loss: 0.104201, Val Loss: 0.092823
2025-09-03 07:41:17,246 - INFO - Epoch 2149/5000 - Train Loss: 0.102920, Val Loss: 0.089814
2025-09-03 07:41:53,285 - INFO - Epoch 2150/5000 - Train Loss: 0.101883, Val Loss: 0.088214
2025-09-03 07:42:29,330 - INFO - Epoch 2151/5000 - Train Loss: 0.103533, Val Loss: 0.089753
2025-09-03 07:43:05,419 - INFO - Epoch 2152/5000 - Train Loss: 0.102292, Val Loss: 0.088554
2025-09-03 07:43:41,064 - INFO - Epoch 2153/5000 - Train Loss: 0.101184, Val Loss: 0.090923
2025-09-03 07:44:16,968 - INFO - Epoch 2154/5000 - Train Loss: 0.101922, Val Loss: 0.090306
2025-09-03 07:44:51,941 - INFO - Epoch 2155/5000 - Train Loss: 0.101262, Val Loss: 0.087888
2025-09-03 07:45:27,651 - INFO - Epoch 2156/5000 - Train Loss: 0.101657, Val Loss: 0.090107
2025-09-03 07:46:04,399 - INFO - Epoch 2157/5000 - Train Loss: 0.101132, Val Loss: 0.088953
2025-09-03 07:46:41,217 - INFO - Epoch 2158/5000 - Train Loss: 0.101985, Val Loss: 0.091447
2025-09-03 07:47:17,552 - INFO - Epoch 2159/5000 - Train Loss: 0.102526, Val Loss: 0.088370
2025-09-03 07:47:55,221 - INFO - Epoch 2160/5000 - Train Loss: 0.101849, Val Loss: 0.089555
2025-09-03 07:48:33,156 - INFO - Epoch 2161/5000 - Train Loss: 0.101401, Val Loss: 0.088831
2025-09-03 07:49:10,338 - INFO - Epoch 2162/5000 - Train Loss: 0.101828, Val Loss: 0.093857
2025-09-03 07:49:47,399 - INFO - Epoch 2163/5000 - Train Loss: 0.102289, Val Loss: 0.089886
2025-09-03 07:50:25,749 - INFO - Epoch 2164/5000 - Train Loss: 0.102626, Val Loss: 0.089246
2025-09-03 07:51:02,764 - INFO - Epoch 2165/5000 - Train Loss: 0.101382, Val Loss: 0.089526
2025-09-03 07:51:40,259 - INFO - Epoch 2166/5000 - Train Loss: 0.101406, Val Loss: 0.088059
2025-09-03 07:52:17,413 - INFO - Epoch 2167/5000 - Train Loss: 0.101484, Val Loss: 0.090383
2025-09-03 07:52:54,846 - INFO - Epoch 2168/5000 - Train Loss: 0.101035, Val Loss: 0.089153
2025-09-03 07:53:32,524 - INFO - Epoch 2169/5000 - Train Loss: 0.100709, Val Loss: 0.088802
2025-09-03 07:54:09,771 - INFO - Epoch 2170/5000 - Train Loss: 0.101181, Val Loss: 0.086227
2025-09-03 07:54:09,825 - INFO - New best model saved with Val Loss: 0.086227
2025-09-03 07:54:47,289 - INFO - Epoch 2171/5000 - Train Loss: 0.100376, Val Loss: 0.090951
2025-09-03 07:55:24,011 - INFO - Epoch 2172/5000 - Train Loss: 0.101700, Val Loss: 0.087529
2025-09-03 07:56:02,838 - INFO - Epoch 2173/5000 - Train Loss: 0.102570, Val Loss: 0.092074
2025-09-03 07:56:41,055 - INFO - Epoch 2174/5000 - Train Loss: 0.104272, Val Loss: 0.088469
2025-09-03 07:57:19,028 - INFO - Epoch 2175/5000 - Train Loss: 0.100482, Val Loss: 0.088929
2025-09-03 07:57:58,160 - INFO - Epoch 2176/5000 - Train Loss: 0.100454, Val Loss: 0.086465
2025-09-03 07:58:35,879 - INFO - Epoch 2177/5000 - Train Loss: 0.100564, Val Loss: 0.087607
2025-09-03 07:59:13,610 - INFO - Epoch 2178/5000 - Train Loss: 0.100552, Val Loss: 0.088397
2025-09-03 07:59:50,844 - INFO - Epoch 2179/5000 - Train Loss: 0.101483, Val Loss: 0.086719
2025-09-03 08:00:28,750 - INFO - Epoch 2180/5000 - Train Loss: 0.101554, Val Loss: 0.093520
2025-09-03 08:01:06,408 - INFO - Epoch 2181/5000 - Train Loss: 0.100827, Val Loss: 0.090297
2025-09-03 08:01:43,906 - INFO - Epoch 2182/5000 - Train Loss: 0.104581, Val Loss: 0.090610
2025-09-03 08:02:21,192 - INFO - Epoch 2183/5000 - Train Loss: 0.102577, Val Loss: 0.088505
2025-09-03 08:02:57,922 - INFO - Epoch 2184/5000 - Train Loss: 0.100526, Val Loss: 0.090878
2025-09-03 08:03:36,213 - INFO - Epoch 2185/5000 - Train Loss: 0.100276, Val Loss: 0.086675
2025-09-03 08:04:13,452 - INFO - Epoch 2186/5000 - Train Loss: 0.100295, Val Loss: 0.088441
2025-09-03 08:04:50,715 - INFO - Epoch 2187/5000 - Train Loss: 0.098981, Val Loss: 0.086047
2025-09-03 08:04:50,749 - INFO - New best model saved with Val Loss: 0.086047
2025-09-03 08:05:28,693 - INFO - Epoch 2188/5000 - Train Loss: 0.100352, Val Loss: 0.087727
2025-09-03 08:06:05,961 - INFO - Epoch 2189/5000 - Train Loss: 0.101875, Val Loss: 0.088693
2025-09-03 08:06:43,486 - INFO - Epoch 2190/5000 - Train Loss: 0.102377, Val Loss: 0.089091
2025-09-03 08:07:22,724 - INFO - Epoch 2191/5000 - Train Loss: 0.100988, Val Loss: 0.088354
2025-09-03 08:08:01,356 - INFO - Epoch 2192/5000 - Train Loss: 0.100914, Val Loss: 0.089123
2025-09-03 08:08:38,816 - INFO - Epoch 2193/5000 - Train Loss: 0.100317, Val Loss: 0.087714
2025-09-03 08:09:16,520 - INFO - Epoch 2194/5000 - Train Loss: 0.101319, Val Loss: 0.091304
2025-09-03 08:09:53,249 - INFO - Epoch 2195/5000 - Train Loss: 0.102646, Val Loss: 0.088024
2025-09-03 08:10:31,093 - INFO - Epoch 2196/5000 - Train Loss: 0.100574, Val Loss: 0.087109
2025-09-03 08:11:09,002 - INFO - Epoch 2197/5000 - Train Loss: 0.099695, Val Loss: 0.089329
2025-09-03 08:11:46,299 - INFO - Epoch 2198/5000 - Train Loss: 0.100728, Val Loss: 0.085988
2025-09-03 08:11:46,354 - INFO - New best model saved with Val Loss: 0.085988
2025-09-03 08:12:24,243 - INFO - Epoch 2199/5000 - Train Loss: 0.099716, Val Loss: 0.085343
2025-09-03 08:12:24,276 - INFO - New best model saved with Val Loss: 0.085343
2025-09-03 08:13:01,776 - INFO - Epoch 2200/5000 - Train Loss: 0.099390, Val Loss: 0.087003
2025-09-03 08:13:39,669 - INFO - Epoch 2201/5000 - Train Loss: 0.100244, Val Loss: 0.088320
2025-09-03 08:14:16,926 - INFO - Epoch 2202/5000 - Train Loss: 0.100641, Val Loss: 0.087332
2025-09-03 08:14:53,718 - INFO - Epoch 2203/5000 - Train Loss: 0.101234, Val Loss: 0.089412
2025-09-03 08:15:31,569 - INFO - Epoch 2204/5000 - Train Loss: 0.100471, Val Loss: 0.089280
2025-09-03 08:16:10,225 - INFO - Epoch 2205/5000 - Train Loss: 0.099720, Val Loss: 0.088305
2025-09-03 08:16:47,671 - INFO - Epoch 2206/5000 - Train Loss: 0.100551, Val Loss: 0.086849
2025-09-03 08:17:24,779 - INFO - Epoch 2207/5000 - Train Loss: 0.100434, Val Loss: 0.088659
2025-09-03 08:18:02,871 - INFO - Epoch 2208/5000 - Train Loss: 0.100892, Val Loss: 0.088234
2025-09-03 08:18:41,590 - INFO - Epoch 2209/5000 - Train Loss: 0.100070, Val Loss: 0.090422
2025-09-03 08:19:19,423 - INFO - Epoch 2210/5000 - Train Loss: 0.101058, Val Loss: 0.087509
2025-09-03 08:19:57,955 - INFO - Epoch 2211/5000 - Train Loss: 0.100363, Val Loss: 0.088817
2025-09-03 08:20:35,121 - INFO - Epoch 2212/5000 - Train Loss: 0.100960, Val Loss: 0.088532
2025-09-03 08:21:12,905 - INFO - Epoch 2213/5000 - Train Loss: 0.100777, Val Loss: 0.090327
2025-09-03 08:21:51,310 - INFO - Epoch 2214/5000 - Train Loss: 0.100738, Val Loss: 0.086585
2025-09-03 08:22:29,428 - INFO - Epoch 2215/5000 - Train Loss: 0.100216, Val Loss: 0.090864
2025-09-03 08:23:07,652 - INFO - Epoch 2216/5000 - Train Loss: 0.100480, Val Loss: 0.085960
2025-09-03 08:23:45,780 - INFO - Epoch 2217/5000 - Train Loss: 0.099757, Val Loss: 0.089967
2025-09-03 08:24:24,352 - INFO - Epoch 2218/5000 - Train Loss: 0.099807, Val Loss: 0.087721
2025-09-03 08:25:02,329 - INFO - Epoch 2219/5000 - Train Loss: 0.100731, Val Loss: 0.086423
2025-09-03 08:25:40,718 - INFO - Epoch 2220/5000 - Train Loss: 0.099233, Val Loss: 0.088985
2025-09-03 08:26:18,480 - INFO - Epoch 2221/5000 - Train Loss: 0.100107, Val Loss: 0.090123
2025-09-03 08:26:55,861 - INFO - Epoch 2222/5000 - Train Loss: 0.100114, Val Loss: 0.085561
2025-09-03 08:27:33,108 - INFO - Epoch 2223/5000 - Train Loss: 0.100904, Val Loss: 0.087830
2025-09-03 08:28:10,776 - INFO - Epoch 2224/5000 - Train Loss: 0.098785, Val Loss: 0.086744
2025-09-03 08:28:48,465 - INFO - Epoch 2225/5000 - Train Loss: 0.099025, Val Loss: 0.088071
2025-09-03 08:29:26,649 - INFO - Epoch 2226/5000 - Train Loss: 0.101184, Val Loss: 0.087494
2025-09-03 08:30:04,179 - INFO - Epoch 2227/5000 - Train Loss: 0.100052, Val Loss: 0.086746
2025-09-03 08:30:41,940 - INFO - Epoch 2228/5000 - Train Loss: 0.097866, Val Loss: 0.088243
2025-09-03 08:31:20,710 - INFO - Epoch 2229/5000 - Train Loss: 0.101713, Val Loss: 0.090964
2025-09-03 08:31:59,560 - INFO - Epoch 2230/5000 - Train Loss: 0.099279, Val Loss: 0.085667
2025-09-03 08:32:38,435 - INFO - Epoch 2231/5000 - Train Loss: 0.099199, Val Loss: 0.087104
2025-09-03 08:33:15,765 - INFO - Epoch 2232/5000 - Train Loss: 0.099139, Val Loss: 0.087495
2025-09-03 08:33:55,007 - INFO - Epoch 2233/5000 - Train Loss: 0.098889, Val Loss: 0.088088
2025-09-03 08:34:33,175 - INFO - Epoch 2234/5000 - Train Loss: 0.099575, Val Loss: 0.086846
2025-09-03 08:35:11,511 - INFO - Epoch 2235/5000 - Train Loss: 0.100160, Val Loss: 0.088943
2025-09-03 08:35:49,801 - INFO - Epoch 2236/5000 - Train Loss: 0.099681, Val Loss: 0.088829
2025-09-03 08:36:27,025 - INFO - Epoch 2237/5000 - Train Loss: 0.099527, Val Loss: 0.090514
2025-09-03 08:37:03,731 - INFO - Epoch 2238/5000 - Train Loss: 0.099735, Val Loss: 0.088059
2025-09-03 08:37:40,705 - INFO - Epoch 2239/5000 - Train Loss: 0.100023, Val Loss: 0.088442
2025-09-03 08:38:19,231 - INFO - Epoch 2240/5000 - Train Loss: 0.099831, Val Loss: 0.087952
2025-09-03 08:38:57,285 - INFO - Epoch 2241/5000 - Train Loss: 0.099469, Val Loss: 0.091927
2025-09-03 08:39:34,806 - INFO - Epoch 2242/5000 - Train Loss: 0.100932, Val Loss: 0.091764
2025-09-03 08:40:12,128 - INFO - Epoch 2243/5000 - Train Loss: 0.101934, Val Loss: 0.088775
2025-09-03 08:40:49,718 - INFO - Epoch 2244/5000 - Train Loss: 0.100278, Val Loss: 0.086517
2025-09-03 08:41:27,958 - INFO - Epoch 2245/5000 - Train Loss: 0.098793, Val Loss: 0.088926
2025-09-03 08:42:05,349 - INFO - Epoch 2246/5000 - Train Loss: 0.098660, Val Loss: 0.085279
2025-09-03 08:42:05,405 - INFO - New best model saved with Val Loss: 0.085279
2025-09-03 08:42:43,617 - INFO - Epoch 2247/5000 - Train Loss: 0.098778, Val Loss: 0.085032
2025-09-03 08:42:43,670 - INFO - New best model saved with Val Loss: 0.085032
2025-09-03 08:43:21,509 - INFO - Epoch 2248/5000 - Train Loss: 0.098705, Val Loss: 0.086149
2025-09-03 08:44:00,214 - INFO - Epoch 2249/5000 - Train Loss: 0.099228, Val Loss: 0.086062
2025-09-03 08:44:37,726 - INFO - Epoch 2250/5000 - Train Loss: 0.099486, Val Loss: 0.086227
2025-09-03 08:45:14,097 - INFO - Epoch 2251/5000 - Train Loss: 0.099293, Val Loss: 0.087823
2025-09-03 08:45:52,506 - INFO - Epoch 2252/5000 - Train Loss: 0.099817, Val Loss: 0.088190
2025-09-03 08:46:30,361 - INFO - Epoch 2253/5000 - Train Loss: 0.100033, Val Loss: 0.089275
2025-09-03 08:47:07,465 - INFO - Epoch 2254/5000 - Train Loss: 0.099734, Val Loss: 0.085892
2025-09-03 08:47:46,323 - INFO - Epoch 2255/5000 - Train Loss: 0.098939, Val Loss: 0.089556
2025-09-03 08:48:22,320 - INFO - Epoch 2256/5000 - Train Loss: 0.099804, Val Loss: 0.086633
2025-09-03 08:49:00,596 - INFO - Epoch 2257/5000 - Train Loss: 0.100176, Val Loss: 0.085493
2025-09-03 08:49:39,160 - INFO - Epoch 2258/5000 - Train Loss: 0.096046, Val Loss: 0.087659
2025-09-03 08:50:17,928 - INFO - Epoch 2259/5000 - Train Loss: 0.098703, Val Loss: 0.085450
2025-09-03 08:50:55,848 - INFO - Epoch 2260/5000 - Train Loss: 0.099950, Val Loss: 0.085079
2025-09-03 08:51:33,319 - INFO - Epoch 2261/5000 - Train Loss: 0.098667, Val Loss: 0.089820
2025-09-03 08:52:10,412 - INFO - Epoch 2262/5000 - Train Loss: 0.099329, Val Loss: 0.087887
2025-09-03 08:52:47,239 - INFO - Epoch 2263/5000 - Train Loss: 0.098770, Val Loss: 0.084696
2025-09-03 08:52:47,294 - INFO - New best model saved with Val Loss: 0.084696
2025-09-03 08:53:25,637 - INFO - Epoch 2264/5000 - Train Loss: 0.098910, Val Loss: 0.084151
2025-09-03 08:53:25,670 - INFO - New best model saved with Val Loss: 0.084151
2025-09-03 08:54:03,191 - INFO - Epoch 2265/5000 - Train Loss: 0.096910, Val Loss: 0.084538
2025-09-03 08:54:42,693 - INFO - Epoch 2266/5000 - Train Loss: 0.098064, Val Loss: 0.087154
2025-09-03 08:55:20,733 - INFO - Epoch 2267/5000 - Train Loss: 0.098274, Val Loss: 0.086032
2025-09-03 08:55:57,357 - INFO - Epoch 2268/5000 - Train Loss: 0.098048, Val Loss: 0.086299
2025-09-03 08:56:34,862 - INFO - Epoch 2269/5000 - Train Loss: 0.098296, Val Loss: 0.088416
2025-09-03 08:57:13,366 - INFO - Epoch 2270/5000 - Train Loss: 0.098018, Val Loss: 0.086428
2025-09-03 08:57:50,651 - INFO - Epoch 2271/5000 - Train Loss: 0.098796, Val Loss: 0.086252
2025-09-03 08:58:29,367 - INFO - Epoch 2272/5000 - Train Loss: 0.099147, Val Loss: 0.088512
2025-09-03 08:59:06,179 - INFO - Epoch 2273/5000 - Train Loss: 0.100084, Val Loss: 0.088378
2025-09-03 08:59:43,880 - INFO - Epoch 2274/5000 - Train Loss: 0.098617, Val Loss: 0.085443
2025-09-03 09:00:21,124 - INFO - Epoch 2275/5000 - Train Loss: 0.098292, Val Loss: 0.091409
2025-09-03 09:00:57,481 - INFO - Epoch 2276/5000 - Train Loss: 0.100478, Val Loss: 0.087896
2025-09-03 09:01:35,901 - INFO - Epoch 2277/5000 - Train Loss: 0.098729, Val Loss: 0.086778
2025-09-03 09:02:14,150 - INFO - Epoch 2278/5000 - Train Loss: 0.098350, Val Loss: 0.089599
2025-09-03 09:02:52,615 - INFO - Epoch 2279/5000 - Train Loss: 0.098728, Val Loss: 0.086194
2025-09-03 09:03:30,587 - INFO - Epoch 2280/5000 - Train Loss: 0.098058, Val Loss: 0.088526
2025-09-03 09:04:08,483 - INFO - Epoch 2281/5000 - Train Loss: 0.099295, Val Loss: 0.085417
2025-09-03 09:04:45,905 - INFO - Epoch 2282/5000 - Train Loss: 0.098203, Val Loss: 0.085593
2025-09-03 09:05:23,076 - INFO - Epoch 2283/5000 - Train Loss: 0.098584, Val Loss: 0.085212
2025-09-03 09:06:00,817 - INFO - Epoch 2284/5000 - Train Loss: 0.098089, Val Loss: 0.085474
2025-09-03 09:06:38,708 - INFO - Epoch 2285/5000 - Train Loss: 0.098844, Val Loss: 0.085061
2025-09-03 09:07:16,916 - INFO - Epoch 2286/5000 - Train Loss: 0.097685, Val Loss: 0.085099
2025-09-03 09:07:55,438 - INFO - Epoch 2287/5000 - Train Loss: 0.097326, Val Loss: 0.085398
2025-09-03 09:08:32,953 - INFO - Epoch 2288/5000 - Train Loss: 0.096563, Val Loss: 0.084930
2025-09-03 09:09:10,261 - INFO - Epoch 2289/5000 - Train Loss: 0.096422, Val Loss: 0.086362
2025-09-03 09:09:46,263 - INFO - Epoch 2290/5000 - Train Loss: 0.100062, Val Loss: 0.086501
2025-09-03 09:10:23,354 - INFO - Epoch 2291/5000 - Train Loss: 0.098210, Val Loss: 0.087131
2025-09-03 09:11:01,489 - INFO - Epoch 2292/5000 - Train Loss: 0.097725, Val Loss: 0.086149
2025-09-03 09:11:38,791 - INFO - Epoch 2293/5000 - Train Loss: 0.097945, Val Loss: 0.084474
2025-09-03 09:12:16,438 - INFO - Epoch 2294/5000 - Train Loss: 0.098941, Val Loss: 0.086917
2025-09-03 09:12:54,681 - INFO - Epoch 2295/5000 - Train Loss: 0.098593, Val Loss: 0.088271
2025-09-03 09:13:32,826 - INFO - Epoch 2296/5000 - Train Loss: 0.099298, Val Loss: 0.087767
2025-09-03 09:14:10,350 - INFO - Epoch 2297/5000 - Train Loss: 0.098186, Val Loss: 0.085431
2025-09-03 09:14:48,225 - INFO - Epoch 2298/5000 - Train Loss: 0.098633, Val Loss: 0.086468
2025-09-03 09:15:25,985 - INFO - Epoch 2299/5000 - Train Loss: 0.097058, Val Loss: 0.084386
2025-09-03 09:16:03,346 - INFO - Epoch 2300/5000 - Train Loss: 0.097465, Val Loss: 0.087908
2025-09-03 09:16:43,063 - INFO - Epoch 2301/5000 - Train Loss: 0.098395, Val Loss: 0.083859
2025-09-03 09:16:43,115 - INFO - New best model saved with Val Loss: 0.083859
2025-09-03 09:17:22,877 - INFO - Epoch 2302/5000 - Train Loss: 0.098196, Val Loss: 0.084370
2025-09-03 09:18:01,668 - INFO - Epoch 2303/5000 - Train Loss: 0.098401, Val Loss: 0.086444
2025-09-03 09:18:38,961 - INFO - Epoch 2304/5000 - Train Loss: 0.097789, Val Loss: 0.085752
2025-09-03 09:19:17,768 - INFO - Epoch 2305/5000 - Train Loss: 0.097814, Val Loss: 0.086458
2025-09-03 09:19:55,451 - INFO - Epoch 2306/5000 - Train Loss: 0.097954, Val Loss: 0.086008
2025-09-03 09:20:34,034 - INFO - Epoch 2307/5000 - Train Loss: 0.098549, Val Loss: 0.088241
2025-09-03 09:21:12,142 - INFO - Epoch 2308/5000 - Train Loss: 0.097539, Val Loss: 0.084031
2025-09-03 09:21:49,962 - INFO - Epoch 2309/5000 - Train Loss: 0.098496, Val Loss: 0.085782
2025-09-03 09:22:28,451 - INFO - Epoch 2310/5000 - Train Loss: 0.098637, Val Loss: 0.083962
2025-09-03 09:23:05,278 - INFO - Epoch 2311/5000 - Train Loss: 0.097539, Val Loss: 0.084459
2025-09-03 09:23:42,962 - INFO - Epoch 2312/5000 - Train Loss: 0.097456, Val Loss: 0.084839
2025-09-03 09:24:19,569 - INFO - Epoch 2313/5000 - Train Loss: 0.096571, Val Loss: 0.083244
2025-09-03 09:24:19,677 - INFO - New best model saved with Val Loss: 0.083244
2025-09-03 09:24:58,200 - INFO - Epoch 2314/5000 - Train Loss: 0.097302, Val Loss: 0.085578
2025-09-03 09:25:37,510 - INFO - Epoch 2315/5000 - Train Loss: 0.097620, Val Loss: 0.085771
2025-09-03 09:26:15,004 - INFO - Epoch 2316/5000 - Train Loss: 0.099184, Val Loss: 0.084374
2025-09-03 09:26:53,544 - INFO - Epoch 2317/5000 - Train Loss: 0.097122, Val Loss: 0.083852
2025-09-03 09:27:31,445 - INFO - Epoch 2318/5000 - Train Loss: 0.098482, Val Loss: 0.083458
2025-09-03 09:28:09,270 - INFO - Epoch 2319/5000 - Train Loss: 0.097486, Val Loss: 0.086430
2025-09-03 09:28:46,750 - INFO - Epoch 2320/5000 - Train Loss: 0.097120, Val Loss: 0.086246
2025-09-03 09:29:24,464 - INFO - Epoch 2321/5000 - Train Loss: 0.097093, Val Loss: 0.083030
2025-09-03 09:29:24,514 - INFO - New best model saved with Val Loss: 0.083030
2025-09-03 09:30:01,075 - INFO - Epoch 2322/5000 - Train Loss: 0.096681, Val Loss: 0.084250
2025-09-03 09:30:38,888 - INFO - Epoch 2323/5000 - Train Loss: 0.096270, Val Loss: 0.084550
2025-09-03 09:31:16,727 - INFO - Epoch 2324/5000 - Train Loss: 0.098208, Val Loss: 0.085319
2025-09-03 09:31:54,223 - INFO - Epoch 2325/5000 - Train Loss: 0.097270, Val Loss: 0.082535
2025-09-03 09:31:54,311 - INFO - New best model saved with Val Loss: 0.082535
2025-09-03 09:32:31,184 - INFO - Epoch 2326/5000 - Train Loss: 0.096189, Val Loss: 0.084394
2025-09-03 09:33:08,107 - INFO - Epoch 2327/5000 - Train Loss: 0.096976, Val Loss: 0.084752
2025-09-03 09:33:44,818 - INFO - Epoch 2328/5000 - Train Loss: 0.098460, Val Loss: 0.086830
2025-09-03 09:34:22,405 - INFO - Epoch 2329/5000 - Train Loss: 0.096901, Val Loss: 0.083279
2025-09-03 09:34:59,920 - INFO - Epoch 2330/5000 - Train Loss: 0.097086, Val Loss: 0.085664
2025-09-03 09:35:38,734 - INFO - Epoch 2331/5000 - Train Loss: 0.096683, Val Loss: 0.085839
2025-09-03 09:36:15,239 - INFO - Epoch 2332/5000 - Train Loss: 0.097753, Val Loss: 0.084848
2025-09-03 09:36:53,318 - INFO - Epoch 2333/5000 - Train Loss: 0.098225, Val Loss: 0.088394
2025-09-03 09:37:31,083 - INFO - Epoch 2334/5000 - Train Loss: 0.098059, Val Loss: 0.084506
2025-09-03 09:38:09,407 - INFO - Epoch 2335/5000 - Train Loss: 0.097893, Val Loss: 0.084344
2025-09-03 09:38:46,325 - INFO - Epoch 2336/5000 - Train Loss: 0.097202, Val Loss: 0.085022
2025-09-03 09:39:25,483 - INFO - Epoch 2337/5000 - Train Loss: 0.097129, Val Loss: 0.082768
2025-09-03 09:40:03,127 - INFO - Epoch 2338/5000 - Train Loss: 0.096887, Val Loss: 0.084225
2025-09-03 09:40:41,019 - INFO - Epoch 2339/5000 - Train Loss: 0.097068, Val Loss: 0.085687
2025-09-03 09:41:19,392 - INFO - Epoch 2340/5000 - Train Loss: 0.096792, Val Loss: 0.084439
2025-09-03 09:41:58,475 - INFO - Epoch 2341/5000 - Train Loss: 0.096960, Val Loss: 0.084347
2025-09-03 09:42:37,156 - INFO - Epoch 2342/5000 - Train Loss: 0.096662, Val Loss: 0.085555
2025-09-03 09:43:16,149 - INFO - Epoch 2343/5000 - Train Loss: 0.097031, Val Loss: 0.083603
2025-09-03 09:43:55,492 - INFO - Epoch 2344/5000 - Train Loss: 0.095725, Val Loss: 0.086040
2025-09-03 09:44:35,435 - INFO - Epoch 2345/5000 - Train Loss: 0.096039, Val Loss: 0.083335
2025-09-03 09:45:14,285 - INFO - Epoch 2346/5000 - Train Loss: 0.097082, Val Loss: 0.084230
2025-09-03 09:45:52,237 - INFO - Epoch 2347/5000 - Train Loss: 0.096763, Val Loss: 0.083278
2025-09-03 09:46:31,097 - INFO - Epoch 2348/5000 - Train Loss: 0.096801, Val Loss: 0.084733
2025-09-03 09:47:10,064 - INFO - Epoch 2349/5000 - Train Loss: 0.096381, Val Loss: 0.084805
2025-09-03 09:47:48,395 - INFO - Epoch 2350/5000 - Train Loss: 0.096301, Val Loss: 0.086391
2025-09-03 09:48:26,977 - INFO - Epoch 2351/5000 - Train Loss: 0.097760, Val Loss: 0.084852
2025-09-03 09:49:05,927 - INFO - Epoch 2352/5000 - Train Loss: 0.096595, Val Loss: 0.083667
2025-09-03 09:49:43,547 - INFO - Epoch 2353/5000 - Train Loss: 0.097307, Val Loss: 0.083617
2025-09-03 09:50:21,494 - INFO - Epoch 2354/5000 - Train Loss: 0.097441, Val Loss: 0.090882
2025-09-03 09:51:01,314 - INFO - Epoch 2355/5000 - Train Loss: 0.097244, Val Loss: 0.086039
2025-09-03 09:51:39,447 - INFO - Epoch 2356/5000 - Train Loss: 0.096306, Val Loss: 0.086537
2025-09-03 09:52:17,595 - INFO - Epoch 2357/5000 - Train Loss: 0.096274, Val Loss: 0.084550
2025-09-03 09:52:55,703 - INFO - Epoch 2358/5000 - Train Loss: 0.095688, Val Loss: 0.084421
2025-09-03 09:53:33,882 - INFO - Epoch 2359/5000 - Train Loss: 0.096403, Val Loss: 0.088013
2025-09-03 09:54:12,214 - INFO - Epoch 2360/5000 - Train Loss: 0.097079, Val Loss: 0.084459
2025-09-03 09:54:50,913 - INFO - Epoch 2361/5000 - Train Loss: 0.095970, Val Loss: 0.085400
2025-09-03 09:55:28,844 - INFO - Epoch 2362/5000 - Train Loss: 0.097034, Val Loss: 0.085535
2025-09-03 09:56:06,419 - INFO - Epoch 2363/5000 - Train Loss: 0.095599, Val Loss: 0.082638
2025-09-03 09:56:43,780 - INFO - Epoch 2364/5000 - Train Loss: 0.095769, Val Loss: 0.083718
2025-09-03 09:57:22,307 - INFO - Epoch 2365/5000 - Train Loss: 0.097143, Val Loss: 0.083896
2025-09-03 09:57:59,796 - INFO - Epoch 2366/5000 - Train Loss: 0.096689, Val Loss: 0.084281
2025-09-03 09:58:38,067 - INFO - Epoch 2367/5000 - Train Loss: 0.096336, Val Loss: 0.085868
2025-09-03 09:59:16,860 - INFO - Epoch 2368/5000 - Train Loss: 0.098150, Val Loss: 0.086829
2025-09-03 09:59:55,329 - INFO - Epoch 2369/5000 - Train Loss: 0.098138, Val Loss: 0.084846
2025-09-03 10:00:33,311 - INFO - Epoch 2370/5000 - Train Loss: 0.094888, Val Loss: 0.083564
2025-09-03 10:01:11,735 - INFO - Epoch 2371/5000 - Train Loss: 0.095279, Val Loss: 0.083256
2025-09-03 10:01:49,703 - INFO - Epoch 2372/5000 - Train Loss: 0.095126, Val Loss: 0.082594
2025-09-03 10:02:27,322 - INFO - Epoch 2373/5000 - Train Loss: 0.095421, Val Loss: 0.086821
2025-09-03 10:03:06,100 - INFO - Epoch 2374/5000 - Train Loss: 0.096958, Val Loss: 0.085043
2025-09-03 10:03:45,395 - INFO - Epoch 2375/5000 - Train Loss: 0.098616, Val Loss: 0.086718
2025-09-03 10:04:22,701 - INFO - Epoch 2376/5000 - Train Loss: 0.097409, Val Loss: 0.084592
2025-09-03 10:05:01,948 - INFO - Epoch 2377/5000 - Train Loss: 0.096264, Val Loss: 0.084190
2025-09-03 10:05:40,366 - INFO - Epoch 2378/5000 - Train Loss: 0.096397, Val Loss: 0.082564
2025-09-03 10:06:18,566 - INFO - Epoch 2379/5000 - Train Loss: 0.096102, Val Loss: 0.083352
2025-09-03 10:06:56,269 - INFO - Epoch 2380/5000 - Train Loss: 0.096010, Val Loss: 0.085823
2025-09-03 10:07:34,104 - INFO - Epoch 2381/5000 - Train Loss: 0.096871, Val Loss: 0.084442
2025-09-03 10:08:11,133 - INFO - Epoch 2382/5000 - Train Loss: 0.095657, Val Loss: 0.082749
2025-09-03 10:08:49,785 - INFO - Epoch 2383/5000 - Train Loss: 0.094969, Val Loss: 0.081632
2025-09-03 10:08:49,835 - INFO - New best model saved with Val Loss: 0.081632
2025-09-03 10:09:27,539 - INFO - Epoch 2384/5000 - Train Loss: 0.096172, Val Loss: 0.084256
2025-09-03 10:10:04,358 - INFO - Epoch 2385/5000 - Train Loss: 0.096169, Val Loss: 0.084522
2025-09-03 10:10:41,499 - INFO - Epoch 2386/5000 - Train Loss: 0.095118, Val Loss: 0.081683
2025-09-03 10:11:19,259 - INFO - Epoch 2387/5000 - Train Loss: 0.095835, Val Loss: 0.083984
2025-09-03 10:11:57,979 - INFO - Epoch 2388/5000 - Train Loss: 0.095846, Val Loss: 0.084349
2025-09-03 10:12:35,718 - INFO - Epoch 2389/5000 - Train Loss: 0.095888, Val Loss: 0.085905
2025-09-03 10:13:12,606 - INFO - Epoch 2390/5000 - Train Loss: 0.095991, Val Loss: 0.085073
2025-09-03 10:13:50,777 - INFO - Epoch 2391/5000 - Train Loss: 0.095292, Val Loss: 0.083988
2025-09-03 10:14:27,198 - INFO - Epoch 2392/5000 - Train Loss: 0.097374, Val Loss: 0.085234
2025-09-03 10:15:04,652 - INFO - Epoch 2393/5000 - Train Loss: 0.095723, Val Loss: 0.085053
2025-09-03 10:15:42,201 - INFO - Epoch 2394/5000 - Train Loss: 0.095384, Val Loss: 0.084966
2025-09-03 10:16:19,561 - INFO - Epoch 2395/5000 - Train Loss: 0.094705, Val Loss: 0.081704
2025-09-03 10:16:57,351 - INFO - Epoch 2396/5000 - Train Loss: 0.095487, Val Loss: 0.084637
2025-09-03 10:17:35,392 - INFO - Epoch 2397/5000 - Train Loss: 0.096277, Val Loss: 0.082992
2025-09-03 10:18:13,304 - INFO - Epoch 2398/5000 - Train Loss: 0.095553, Val Loss: 0.083408
2025-09-03 10:18:50,755 - INFO - Epoch 2399/5000 - Train Loss: 0.094439, Val Loss: 0.084893
2025-09-03 10:19:29,339 - INFO - Epoch 2400/5000 - Train Loss: 0.095606, Val Loss: 0.087033
2025-09-03 10:20:07,148 - INFO - Epoch 2401/5000 - Train Loss: 0.095672, Val Loss: 0.083298
2025-09-03 10:20:44,986 - INFO - Epoch 2402/5000 - Train Loss: 0.096515, Val Loss: 0.083368
2025-09-03 10:21:22,323 - INFO - Epoch 2403/5000 - Train Loss: 0.095588, Val Loss: 0.084133
2025-09-03 10:22:00,483 - INFO - Epoch 2404/5000 - Train Loss: 0.094469, Val Loss: 0.084012
2025-09-03 10:22:38,240 - INFO - Epoch 2405/5000 - Train Loss: 0.095418, Val Loss: 0.084310
2025-09-03 10:23:16,322 - INFO - Epoch 2406/5000 - Train Loss: 0.094420, Val Loss: 0.082487
2025-09-03 10:23:54,397 - INFO - Epoch 2407/5000 - Train Loss: 0.095890, Val Loss: 0.083329
2025-09-03 10:24:33,020 - INFO - Epoch 2408/5000 - Train Loss: 0.095796, Val Loss: 0.083133
2025-09-03 10:25:10,620 - INFO - Epoch 2409/5000 - Train Loss: 0.095491, Val Loss: 0.085312
2025-09-03 10:25:47,943 - INFO - Epoch 2410/5000 - Train Loss: 0.096214, Val Loss: 0.080986
2025-09-03 10:25:47,992 - INFO - New best model saved with Val Loss: 0.080986
2025-09-03 10:26:26,520 - INFO - Epoch 2411/5000 - Train Loss: 0.095897, Val Loss: 0.082521
2025-09-03 10:27:03,485 - INFO - Epoch 2412/5000 - Train Loss: 0.094601, Val Loss: 0.084272
2025-09-03 10:27:41,417 - INFO - Epoch 2413/5000 - Train Loss: 0.094825, Val Loss: 0.083209
2025-09-03 10:28:17,867 - INFO - Epoch 2414/5000 - Train Loss: 0.096308, Val Loss: 0.084319
2025-09-03 10:28:55,398 - INFO - Epoch 2415/5000 - Train Loss: 0.095474, Val Loss: 0.081735
2025-09-03 10:29:31,995 - INFO - Epoch 2416/5000 - Train Loss: 0.094950, Val Loss: 0.084744
2025-09-03 10:30:09,073 - INFO - Epoch 2417/5000 - Train Loss: 0.095503, Val Loss: 0.083543
2025-09-03 10:30:45,471 - INFO - Epoch 2418/5000 - Train Loss: 0.094234, Val Loss: 0.083354
2025-09-03 10:31:23,027 - INFO - Epoch 2419/5000 - Train Loss: 0.095141, Val Loss: 0.082660
2025-09-03 10:31:59,808 - INFO - Epoch 2420/5000 - Train Loss: 0.095382, Val Loss: 0.083394
2025-09-03 10:32:37,861 - INFO - Epoch 2421/5000 - Train Loss: 0.095085, Val Loss: 0.084986
2025-09-03 10:33:14,905 - INFO - Epoch 2422/5000 - Train Loss: 0.096586, Val Loss: 0.083751
2025-09-03 10:33:50,974 - INFO - Epoch 2423/5000 - Train Loss: 0.095008, Val Loss: 0.082437
2025-09-03 10:34:27,648 - INFO - Epoch 2424/5000 - Train Loss: 0.094720, Val Loss: 0.083334
2025-09-03 10:35:03,860 - INFO - Epoch 2425/5000 - Train Loss: 0.095564, Val Loss: 0.084194
2025-09-03 10:35:41,560 - INFO - Epoch 2426/5000 - Train Loss: 0.095281, Val Loss: 0.090133
2025-09-03 10:36:20,161 - INFO - Epoch 2427/5000 - Train Loss: 0.096635, Val Loss: 0.082233
2025-09-03 10:36:57,675 - INFO - Epoch 2428/5000 - Train Loss: 0.095724, Val Loss: 0.083044
2025-09-03 10:37:39,453 - INFO - Epoch 2429/5000 - Train Loss: 0.095290, Val Loss: 0.085245
2025-09-03 10:38:23,086 - INFO - Epoch 2430/5000 - Train Loss: 0.094306, Val Loss: 0.082891
2025-09-03 10:39:00,457 - INFO - Epoch 2431/5000 - Train Loss: 0.094848, Val Loss: 0.082806
2025-09-03 10:39:39,854 - INFO - Epoch 2432/5000 - Train Loss: 0.094054, Val Loss: 0.084522
2025-09-03 10:40:22,140 - INFO - Epoch 2433/5000 - Train Loss: 0.094955, Val Loss: 0.085104
2025-09-03 10:41:00,354 - INFO - Epoch 2434/5000 - Train Loss: 0.095763, Val Loss: 0.084155
2025-09-03 10:41:38,411 - INFO - Epoch 2435/5000 - Train Loss: 0.094733, Val Loss: 0.083380
2025-09-03 10:42:15,462 - INFO - Epoch 2436/5000 - Train Loss: 0.095783, Val Loss: 0.082242
2025-09-03 10:42:54,253 - INFO - Epoch 2437/5000 - Train Loss: 0.095754, Val Loss: 0.085697
2025-09-03 10:43:32,564 - INFO - Epoch 2438/5000 - Train Loss: 0.095200, Val Loss: 0.083751
2025-09-03 10:44:09,161 - INFO - Epoch 2439/5000 - Train Loss: 0.094344, Val Loss: 0.084166
2025-09-03 10:44:47,696 - INFO - Epoch 2440/5000 - Train Loss: 0.094448, Val Loss: 0.082234
2025-09-03 10:45:26,209 - INFO - Epoch 2441/5000 - Train Loss: 0.095313, Val Loss: 0.081607
2025-09-03 10:46:02,594 - INFO - Epoch 2442/5000 - Train Loss: 0.094280, Val Loss: 0.083618
2025-09-03 10:46:39,220 - INFO - Epoch 2443/5000 - Train Loss: 0.094680, Val Loss: 0.083992
2025-09-03 10:47:15,882 - INFO - Epoch 2444/5000 - Train Loss: 0.095029, Val Loss: 0.082374
2025-09-03 10:47:52,743 - INFO - Epoch 2445/5000 - Train Loss: 0.093808, Val Loss: 0.081959
2025-09-03 10:48:30,735 - INFO - Epoch 2446/5000 - Train Loss: 0.094481, Val Loss: 0.083078
2025-09-03 10:49:09,330 - INFO - Epoch 2447/5000 - Train Loss: 0.093683, Val Loss: 0.082717
2025-09-03 10:49:48,489 - INFO - Epoch 2448/5000 - Train Loss: 0.094324, Val Loss: 0.082198
2025-09-03 10:50:27,301 - INFO - Epoch 2449/5000 - Train Loss: 0.095213, Val Loss: 0.084214
2025-09-03 10:51:04,444 - INFO - Epoch 2450/5000 - Train Loss: 0.095160, Val Loss: 0.084261
2025-09-03 10:51:42,858 - INFO - Epoch 2451/5000 - Train Loss: 0.094076, Val Loss: 0.080995
2025-09-03 10:52:21,553 - INFO - Epoch 2452/5000 - Train Loss: 0.094715, Val Loss: 0.082731
2025-09-03 10:53:00,359 - INFO - Epoch 2453/5000 - Train Loss: 0.093633, Val Loss: 0.081182
2025-09-03 10:53:38,478 - INFO - Epoch 2454/5000 - Train Loss: 0.095517, Val Loss: 0.090127
2025-09-03 10:54:17,671 - INFO - Epoch 2455/5000 - Train Loss: 0.094527, Val Loss: 0.081270
2025-09-03 10:54:55,758 - INFO - Epoch 2456/5000 - Train Loss: 0.094527, Val Loss: 0.084237
2025-09-03 10:55:32,970 - INFO - Epoch 2457/5000 - Train Loss: 0.095646, Val Loss: 0.083730
2025-09-03 10:56:10,193 - INFO - Epoch 2458/5000 - Train Loss: 0.094194, Val Loss: 0.083020
2025-09-03 10:56:47,760 - INFO - Epoch 2459/5000 - Train Loss: 0.093815, Val Loss: 0.081868
2025-09-03 10:57:25,971 - INFO - Epoch 2460/5000 - Train Loss: 0.093808, Val Loss: 0.085620
2025-09-03 10:58:06,359 - INFO - Epoch 2461/5000 - Train Loss: 0.095381, Val Loss: 0.082395
2025-09-03 10:59:14,407 - INFO - Epoch 2462/5000 - Train Loss: 0.093348, Val Loss: 0.081538
2025-09-03 11:02:20,905 - INFO - Epoch 2463/5000 - Train Loss: 0.093292, Val Loss: 0.083533
2025-09-03 11:06:58,903 - INFO - Epoch 2464/5000 - Train Loss: 0.094068, Val Loss: 0.083060
2025-09-03 11:11:08,432 - INFO - Epoch 2465/5000 - Train Loss: 0.092626, Val Loss: 0.082146
2025-09-03 11:13:21,438 - INFO - Epoch 2466/5000 - Train Loss: 0.093659, Val Loss: 0.081598
2025-09-03 11:14:41,629 - INFO - Epoch 2467/5000 - Train Loss: 0.094170, Val Loss: 0.081655
2025-09-03 11:15:30,979 - INFO - Epoch 2468/5000 - Train Loss: 0.094264, Val Loss: 0.081943
2025-09-03 11:16:10,482 - INFO - Epoch 2469/5000 - Train Loss: 0.093456, Val Loss: 0.081781
2025-09-03 11:16:48,848 - INFO - Epoch 2470/5000 - Train Loss: 0.094396, Val Loss: 0.082620
2025-09-03 11:17:26,874 - INFO - Epoch 2471/5000 - Train Loss: 0.093153, Val Loss: 0.081939
2025-09-03 11:18:04,376 - INFO - Epoch 2472/5000 - Train Loss: 0.095854, Val Loss: 0.080589
2025-09-03 11:18:04,429 - INFO - New best model saved with Val Loss: 0.080589
2025-09-03 11:18:42,476 - INFO - Epoch 2473/5000 - Train Loss: 0.096678, Val Loss: 0.083507
2025-09-03 11:19:20,948 - INFO - Epoch 2474/5000 - Train Loss: 0.094724, Val Loss: 0.082690
2025-09-03 11:19:58,621 - INFO - Epoch 2475/5000 - Train Loss: 0.093628, Val Loss: 0.082833
2025-09-03 11:20:37,287 - INFO - Epoch 2476/5000 - Train Loss: 0.093684, Val Loss: 0.083471
2025-09-03 11:21:15,612 - INFO - Epoch 2477/5000 - Train Loss: 0.093800, Val Loss: 0.081077
2025-09-03 11:21:54,523 - INFO - Epoch 2478/5000 - Train Loss: 0.094324, Val Loss: 0.085066
2025-09-03 11:22:32,900 - INFO - Epoch 2479/5000 - Train Loss: 0.095071, Val Loss: 0.082315
2025-09-03 11:23:11,119 - INFO - Epoch 2480/5000 - Train Loss: 0.095349, Val Loss: 0.082636
2025-09-03 11:23:49,440 - INFO - Epoch 2481/5000 - Train Loss: 0.093031, Val Loss: 0.082435
2025-09-03 11:24:27,389 - INFO - Epoch 2482/5000 - Train Loss: 0.093546, Val Loss: 0.080736
2025-09-03 11:25:05,446 - INFO - Epoch 2483/5000 - Train Loss: 0.093130, Val Loss: 0.079834
2025-09-03 11:25:05,493 - INFO - New best model saved with Val Loss: 0.079834
2025-09-03 11:25:44,081 - INFO - Epoch 2484/5000 - Train Loss: 0.095266, Val Loss: 0.082881
2025-09-03 11:26:23,979 - INFO - Epoch 2485/5000 - Train Loss: 0.092134, Val Loss: 0.081562
2025-09-03 11:27:03,644 - INFO - Epoch 2486/5000 - Train Loss: 0.092734, Val Loss: 0.082334
2025-09-03 11:27:41,938 - INFO - Epoch 2487/5000 - Train Loss: 0.093584, Val Loss: 0.081181
2025-09-03 11:28:20,197 - INFO - Epoch 2488/5000 - Train Loss: 0.092914, Val Loss: 0.085414
2025-09-03 11:28:58,207 - INFO - Epoch 2489/5000 - Train Loss: 0.095898, Val Loss: 0.084359
2025-09-03 11:29:36,069 - INFO - Epoch 2490/5000 - Train Loss: 0.094075, Val Loss: 0.083703
2025-09-03 11:30:13,188 - INFO - Epoch 2491/5000 - Train Loss: 0.093413, Val Loss: 0.081090
2025-09-03 11:30:51,225 - INFO - Epoch 2492/5000 - Train Loss: 0.092918, Val Loss: 0.081090
2025-09-03 11:31:27,708 - INFO - Epoch 2493/5000 - Train Loss: 0.093791, Val Loss: 0.083375
2025-09-03 11:32:05,504 - INFO - Epoch 2494/5000 - Train Loss: 0.093855, Val Loss: 0.085638
2025-09-03 11:32:43,844 - INFO - Epoch 2495/5000 - Train Loss: 0.093258, Val Loss: 0.080303
2025-09-03 11:33:22,408 - INFO - Epoch 2496/5000 - Train Loss: 0.093483, Val Loss: 0.080387
2025-09-03 11:33:59,200 - INFO - Epoch 2497/5000 - Train Loss: 0.093712, Val Loss: 0.082901
2025-09-03 11:34:37,538 - INFO - Epoch 2498/5000 - Train Loss: 0.094590, Val Loss: 0.083149
2025-09-03 11:35:14,234 - INFO - Epoch 2499/5000 - Train Loss: 0.093763, Val Loss: 0.082697
2025-09-03 11:35:51,307 - INFO - Epoch 2500/5000 - Train Loss: 0.094097, Val Loss: 0.082324
2025-09-03 11:36:28,912 - INFO - Epoch 2501/5000 - Train Loss: 0.092650, Val Loss: 0.080777
2025-09-03 11:37:06,512 - INFO - Epoch 2502/5000 - Train Loss: 0.092401, Val Loss: 0.081421
2025-09-03 11:37:43,713 - INFO - Epoch 2503/5000 - Train Loss: 0.093163, Val Loss: 0.081899
2025-09-03 11:38:21,773 - INFO - Epoch 2504/5000 - Train Loss: 0.094061, Val Loss: 0.081426
2025-09-03 11:38:59,386 - INFO - Epoch 2505/5000 - Train Loss: 0.093919, Val Loss: 0.082390
2025-09-03 11:39:40,701 - INFO - Epoch 2506/5000 - Train Loss: 0.093163, Val Loss: 0.087895
2025-09-03 11:40:17,753 - INFO - Epoch 2507/5000 - Train Loss: 0.093494, Val Loss: 0.082803
2025-09-03 11:40:55,359 - INFO - Epoch 2508/5000 - Train Loss: 0.093766, Val Loss: 0.081782
2025-09-03 11:41:34,232 - INFO - Epoch 2509/5000 - Train Loss: 0.093354, Val Loss: 0.082082
2025-09-03 11:42:13,403 - INFO - Epoch 2510/5000 - Train Loss: 0.093034, Val Loss: 0.080390
2025-09-03 11:42:52,229 - INFO - Epoch 2511/5000 - Train Loss: 0.092906, Val Loss: 0.083360
2025-09-03 11:43:30,305 - INFO - Epoch 2512/5000 - Train Loss: 0.094050, Val Loss: 0.081450
2025-09-03 11:44:08,265 - INFO - Epoch 2513/5000 - Train Loss: 0.093093, Val Loss: 0.081424
2025-09-03 11:44:45,608 - INFO - Epoch 2514/5000 - Train Loss: 0.093992, Val Loss: 0.081226
2025-09-03 11:45:23,318 - INFO - Epoch 2515/5000 - Train Loss: 0.093397, Val Loss: 0.081380
2025-09-03 11:46:00,869 - INFO - Epoch 2516/5000 - Train Loss: 0.093124, Val Loss: 0.081235
2025-09-03 11:46:37,747 - INFO - Epoch 2517/5000 - Train Loss: 0.093158, Val Loss: 0.080094
2025-09-03 11:47:17,118 - INFO - Epoch 2518/5000 - Train Loss: 0.093593, Val Loss: 0.083285
2025-09-03 11:47:54,439 - INFO - Epoch 2519/5000 - Train Loss: 0.093440, Val Loss: 0.081298
2025-09-03 11:48:31,965 - INFO - Epoch 2520/5000 - Train Loss: 0.093027, Val Loss: 0.082292
2025-09-03 11:49:09,375 - INFO - Epoch 2521/5000 - Train Loss: 0.093413, Val Loss: 0.081264
2025-09-03 11:49:48,178 - INFO - Epoch 2522/5000 - Train Loss: 0.092674, Val Loss: 0.081700
2025-09-03 11:50:25,911 - INFO - Epoch 2523/5000 - Train Loss: 0.091896, Val Loss: 0.079566
2025-09-03 11:50:25,964 - INFO - New best model saved with Val Loss: 0.079566
2025-09-03 11:51:04,188 - INFO - Epoch 2524/5000 - Train Loss: 0.092661, Val Loss: 0.080337
2025-09-03 11:51:42,745 - INFO - Epoch 2525/5000 - Train Loss: 0.092235, Val Loss: 0.079965
2025-09-03 11:52:20,718 - INFO - Epoch 2526/5000 - Train Loss: 0.092766, Val Loss: 0.080665
2025-09-03 11:53:00,167 - INFO - Epoch 2527/5000 - Train Loss: 0.093415, Val Loss: 0.080015
2025-09-03 11:53:40,468 - INFO - Epoch 2528/5000 - Train Loss: 0.092492, Val Loss: 0.081885
2025-09-03 11:54:18,562 - INFO - Epoch 2529/5000 - Train Loss: 0.092558, Val Loss: 0.082995
2025-09-03 11:54:57,052 - INFO - Epoch 2530/5000 - Train Loss: 0.092843, Val Loss: 0.082784
2025-09-03 11:55:35,159 - INFO - Epoch 2531/5000 - Train Loss: 0.092431, Val Loss: 0.080727
2025-09-03 11:56:14,829 - INFO - Epoch 2532/5000 - Train Loss: 0.092974, Val Loss: 0.080652
2025-09-03 11:56:53,714 - INFO - Epoch 2533/5000 - Train Loss: 0.093766, Val Loss: 0.080967
2025-09-03 11:57:32,976 - INFO - Epoch 2534/5000 - Train Loss: 0.091968, Val Loss: 0.080189
2025-09-03 11:58:12,450 - INFO - Epoch 2535/5000 - Train Loss: 0.092530, Val Loss: 0.083702
2025-09-03 11:58:51,167 - INFO - Epoch 2536/5000 - Train Loss: 0.092109, Val Loss: 0.080405
2025-09-03 11:59:31,052 - INFO - Epoch 2537/5000 - Train Loss: 0.091694, Val Loss: 0.082569
2025-09-03 12:00:10,454 - INFO - Epoch 2538/5000 - Train Loss: 0.093468, Val Loss: 0.082838
2025-09-03 12:00:48,481 - INFO - Epoch 2539/5000 - Train Loss: 0.092626, Val Loss: 0.082971
2025-09-03 12:01:27,656 - INFO - Epoch 2540/5000 - Train Loss: 0.092864, Val Loss: 0.081778
2025-09-03 12:02:06,921 - INFO - Epoch 2541/5000 - Train Loss: 0.093021, Val Loss: 0.082152
2025-09-03 12:02:46,522 - INFO - Epoch 2542/5000 - Train Loss: 0.091762, Val Loss: 0.081323
2025-09-03 12:03:24,572 - INFO - Epoch 2543/5000 - Train Loss: 0.092590, Val Loss: 0.079691
2025-09-03 12:04:01,986 - INFO - Epoch 2544/5000 - Train Loss: 0.092659, Val Loss: 0.081918
2025-09-03 12:04:39,708 - INFO - Epoch 2545/5000 - Train Loss: 0.093964, Val Loss: 0.083907
2025-09-03 12:05:17,390 - INFO - Epoch 2546/5000 - Train Loss: 0.093830, Val Loss: 0.079896
2025-09-03 12:05:55,670 - INFO - Epoch 2547/5000 - Train Loss: 0.093285, Val Loss: 0.079340
2025-09-03 12:05:55,722 - INFO - New best model saved with Val Loss: 0.079340
2025-09-03 12:06:33,770 - INFO - Epoch 2548/5000 - Train Loss: 0.092747, Val Loss: 0.082000
2025-09-03 12:07:12,166 - INFO - Epoch 2549/5000 - Train Loss: 0.091903, Val Loss: 0.080522
2025-09-03 12:07:51,248 - INFO - Epoch 2550/5000 - Train Loss: 0.092071, Val Loss: 0.081791
2025-09-03 12:08:30,885 - INFO - Epoch 2551/5000 - Train Loss: 0.092321, Val Loss: 0.083566
2025-09-03 12:09:08,898 - INFO - Epoch 2552/5000 - Train Loss: 0.092541, Val Loss: 0.080797
2025-09-03 12:09:46,384 - INFO - Epoch 2553/5000 - Train Loss: 0.092122, Val Loss: 0.082304
2025-09-03 12:10:23,161 - INFO - Epoch 2554/5000 - Train Loss: 0.093920, Val Loss: 0.081360
2025-09-03 12:11:00,904 - INFO - Epoch 2555/5000 - Train Loss: 0.092186, Val Loss: 0.080831
2025-09-03 12:11:38,812 - INFO - Epoch 2556/5000 - Train Loss: 0.092361, Val Loss: 0.081235
2025-09-03 12:12:17,281 - INFO - Epoch 2557/5000 - Train Loss: 0.092171, Val Loss: 0.078318
2025-09-03 12:12:17,315 - INFO - New best model saved with Val Loss: 0.078318
2025-09-03 12:12:56,365 - INFO - Epoch 2558/5000 - Train Loss: 0.092870, Val Loss: 0.087938
2025-09-03 12:13:33,606 - INFO - Epoch 2559/5000 - Train Loss: 0.093837, Val Loss: 0.080264
2025-09-03 12:14:11,931 - INFO - Epoch 2560/5000 - Train Loss: 0.092154, Val Loss: 0.081078
2025-09-03 12:14:49,741 - INFO - Epoch 2561/5000 - Train Loss: 0.092651, Val Loss: 0.079258
2025-09-03 12:15:27,266 - INFO - Epoch 2562/5000 - Train Loss: 0.091827, Val Loss: 0.081988
2025-09-03 12:16:04,793 - INFO - Epoch 2563/5000 - Train Loss: 0.092036, Val Loss: 0.080354
2025-09-03 12:16:43,797 - INFO - Epoch 2564/5000 - Train Loss: 0.091750, Val Loss: 0.082395
2025-09-03 12:17:21,860 - INFO - Epoch 2565/5000 - Train Loss: 0.091272, Val Loss: 0.079440
2025-09-03 12:17:59,936 - INFO - Epoch 2566/5000 - Train Loss: 0.093094, Val Loss: 0.081388
2025-09-03 12:18:36,916 - INFO - Epoch 2567/5000 - Train Loss: 0.092149, Val Loss: 0.079195
2025-09-03 12:19:14,750 - INFO - Epoch 2568/5000 - Train Loss: 0.090749, Val Loss: 0.081124
2025-09-03 12:19:53,112 - INFO - Epoch 2569/5000 - Train Loss: 0.090901, Val Loss: 0.078577
2025-09-03 12:20:29,919 - INFO - Epoch 2570/5000 - Train Loss: 0.091304, Val Loss: 0.079828
2025-09-03 12:21:08,658 - INFO - Epoch 2571/5000 - Train Loss: 0.091202, Val Loss: 0.080071
2025-09-03 12:21:46,505 - INFO - Epoch 2572/5000 - Train Loss: 0.091977, Val Loss: 0.082489
2025-09-03 12:22:24,642 - INFO - Epoch 2573/5000 - Train Loss: 0.092125, Val Loss: 0.081905
2025-09-03 12:23:02,913 - INFO - Epoch 2574/5000 - Train Loss: 0.093834, Val Loss: 0.081729
2025-09-03 12:23:41,962 - INFO - Epoch 2575/5000 - Train Loss: 0.092190, Val Loss: 0.081428
2025-09-03 12:24:19,950 - INFO - Epoch 2576/5000 - Train Loss: 0.093909, Val Loss: 0.081871
2025-09-03 12:24:57,926 - INFO - Epoch 2577/5000 - Train Loss: 0.094670, Val Loss: 0.080653
2025-09-03 12:25:35,301 - INFO - Epoch 2578/5000 - Train Loss: 0.092339, Val Loss: 0.080789
2025-09-03 12:26:14,787 - INFO - Epoch 2579/5000 - Train Loss: 0.091925, Val Loss: 0.079520
2025-09-03 12:26:52,829 - INFO - Epoch 2580/5000 - Train Loss: 0.091351, Val Loss: 0.081457
2025-09-03 12:27:31,908 - INFO - Epoch 2581/5000 - Train Loss: 0.091815, Val Loss: 0.080996
2025-09-03 12:28:10,464 - INFO - Epoch 2582/5000 - Train Loss: 0.091198, Val Loss: 0.080606
2025-09-03 12:28:49,609 - INFO - Epoch 2583/5000 - Train Loss: 0.091062, Val Loss: 0.079514
2025-09-03 12:29:27,593 - INFO - Epoch 2584/5000 - Train Loss: 0.091328, Val Loss: 0.085205
2025-09-03 12:30:05,288 - INFO - Epoch 2585/5000 - Train Loss: 0.092516, Val Loss: 0.081695
2025-09-03 12:30:43,395 - INFO - Epoch 2586/5000 - Train Loss: 0.092386, Val Loss: 0.079475
2025-09-03 12:31:22,483 - INFO - Epoch 2587/5000 - Train Loss: 0.091483, Val Loss: 0.081282
2025-09-03 12:31:59,617 - INFO - Epoch 2588/5000 - Train Loss: 0.092916, Val Loss: 0.079611
2025-09-03 12:32:36,931 - INFO - Epoch 2589/5000 - Train Loss: 0.091745, Val Loss: 0.080210
2025-09-03 12:33:14,398 - INFO - Epoch 2590/5000 - Train Loss: 0.091396, Val Loss: 0.077935
2025-09-03 12:33:14,442 - INFO - New best model saved with Val Loss: 0.077935
2025-09-03 12:33:52,642 - INFO - Epoch 2591/5000 - Train Loss: 0.091310, Val Loss: 0.080891
2025-09-03 12:34:31,064 - INFO - Epoch 2592/5000 - Train Loss: 0.090986, Val Loss: 0.079958
2025-09-03 12:35:08,573 - INFO - Epoch 2593/5000 - Train Loss: 0.093114, Val Loss: 0.082424
2025-09-03 12:35:46,042 - INFO - Epoch 2594/5000 - Train Loss: 0.092043, Val Loss: 0.080824
2025-09-03 12:36:24,415 - INFO - Epoch 2595/5000 - Train Loss: 0.091893, Val Loss: 0.080493
2025-09-03 12:37:01,285 - INFO - Epoch 2596/5000 - Train Loss: 0.091659, Val Loss: 0.081437
2025-09-03 12:37:38,434 - INFO - Epoch 2597/5000 - Train Loss: 0.092889, Val Loss: 0.080638
2025-09-03 12:38:15,766 - INFO - Epoch 2598/5000 - Train Loss: 0.091692, Val Loss: 0.079769
2025-09-03 12:38:53,275 - INFO - Epoch 2599/5000 - Train Loss: 0.092908, Val Loss: 0.080708
2025-09-03 12:39:32,773 - INFO - Epoch 2600/5000 - Train Loss: 0.092202, Val Loss: 0.080282
2025-09-03 12:40:11,225 - INFO - Epoch 2601/5000 - Train Loss: 0.090193, Val Loss: 0.080297
2025-09-03 12:40:48,533 - INFO - Epoch 2602/5000 - Train Loss: 0.091873, Val Loss: 0.082968
2025-09-03 12:41:26,265 - INFO - Epoch 2603/5000 - Train Loss: 0.091284, Val Loss: 0.078435
2025-09-03 12:42:05,687 - INFO - Epoch 2604/5000 - Train Loss: 0.091342, Val Loss: 0.080433
2025-09-03 12:42:45,387 - INFO - Epoch 2605/5000 - Train Loss: 0.091941, Val Loss: 0.080759
2025-09-03 12:43:24,619 - INFO - Epoch 2606/5000 - Train Loss: 0.092181, Val Loss: 0.080913
2025-09-03 12:44:03,428 - INFO - Epoch 2607/5000 - Train Loss: 0.090905, Val Loss: 0.079739
2025-09-03 12:44:42,424 - INFO - Epoch 2608/5000 - Train Loss: 0.091552, Val Loss: 0.078826
2025-09-03 12:45:20,774 - INFO - Epoch 2609/5000 - Train Loss: 0.091163, Val Loss: 0.084581
2025-09-03 12:45:58,357 - INFO - Epoch 2610/5000 - Train Loss: 0.090520, Val Loss: 0.078563
2025-09-03 12:46:37,365 - INFO - Epoch 2611/5000 - Train Loss: 0.090545, Val Loss: 0.079964
2025-09-03 12:47:15,305 - INFO - Epoch 2612/5000 - Train Loss: 0.091535, Val Loss: 0.081180
2025-09-03 12:47:53,793 - INFO - Epoch 2613/5000 - Train Loss: 0.091200, Val Loss: 0.079985
2025-09-03 12:48:31,075 - INFO - Epoch 2614/5000 - Train Loss: 0.090890, Val Loss: 0.078525
2025-09-03 12:49:08,468 - INFO - Epoch 2615/5000 - Train Loss: 0.090725, Val Loss: 0.080745
2025-09-03 12:49:46,536 - INFO - Epoch 2616/5000 - Train Loss: 0.091663, Val Loss: 0.081138
2025-09-03 12:50:24,827 - INFO - Epoch 2617/5000 - Train Loss: 0.091650, Val Loss: 0.081095
2025-09-03 12:51:01,870 - INFO - Epoch 2618/5000 - Train Loss: 0.092515, Val Loss: 0.078281
2025-09-03 12:51:39,256 - INFO - Epoch 2619/5000 - Train Loss: 0.090186, Val Loss: 0.078457
2025-09-03 12:52:17,433 - INFO - Epoch 2620/5000 - Train Loss: 0.090046, Val Loss: 0.079232
2025-09-03 12:52:54,883 - INFO - Epoch 2621/5000 - Train Loss: 0.092052, Val Loss: 0.082100
2025-09-03 12:53:33,511 - INFO - Epoch 2622/5000 - Train Loss: 0.090723, Val Loss: 0.080330
2025-09-03 12:54:10,653 - INFO - Epoch 2623/5000 - Train Loss: 0.090483, Val Loss: 0.081145
2025-09-03 12:54:48,158 - INFO - Epoch 2624/5000 - Train Loss: 0.089958, Val Loss: 0.079688
2025-09-03 12:55:26,925 - INFO - Epoch 2625/5000 - Train Loss: 0.090470, Val Loss: 0.081529
2025-09-03 12:56:04,712 - INFO - Epoch 2626/5000 - Train Loss: 0.093235, Val Loss: 0.080411
2025-09-03 12:56:42,034 - INFO - Epoch 2627/5000 - Train Loss: 0.091845, Val Loss: 0.082464
2025-09-03 12:57:19,828 - INFO - Epoch 2628/5000 - Train Loss: 0.091341, Val Loss: 0.078374
2025-09-03 12:57:57,406 - INFO - Epoch 2629/5000 - Train Loss: 0.090741, Val Loss: 0.079813
2025-09-03 12:58:35,024 - INFO - Epoch 2630/5000 - Train Loss: 0.091156, Val Loss: 0.079323
2025-09-03 12:59:13,281 - INFO - Epoch 2631/5000 - Train Loss: 0.090498, Val Loss: 0.078461
2025-09-03 12:59:53,852 - INFO - Epoch 2632/5000 - Train Loss: 0.091647, Val Loss: 0.078268
2025-09-03 13:00:31,852 - INFO - Epoch 2633/5000 - Train Loss: 0.091273, Val Loss: 0.083958
2025-09-03 13:01:09,198 - INFO - Epoch 2634/5000 - Train Loss: 0.092802, Val Loss: 0.083694
2025-09-03 13:01:48,197 - INFO - Epoch 2635/5000 - Train Loss: 0.090632, Val Loss: 0.078665
2025-09-03 13:02:26,993 - INFO - Epoch 2636/5000 - Train Loss: 0.090329, Val Loss: 0.079130
2025-09-03 13:03:05,315 - INFO - Epoch 2637/5000 - Train Loss: 0.090771, Val Loss: 0.079405
2025-09-03 13:03:44,238 - INFO - Epoch 2638/5000 - Train Loss: 0.090150, Val Loss: 0.078424
2025-09-03 13:04:22,350 - INFO - Epoch 2639/5000 - Train Loss: 0.089747, Val Loss: 0.078935
2025-09-03 13:05:01,019 - INFO - Epoch 2640/5000 - Train Loss: 0.091080, Val Loss: 0.082201
2025-09-03 13:05:39,305 - INFO - Epoch 2641/5000 - Train Loss: 0.090972, Val Loss: 0.082049
2025-09-03 13:06:17,372 - INFO - Epoch 2642/5000 - Train Loss: 0.090490, Val Loss: 0.079170
2025-09-03 13:06:55,424 - INFO - Epoch 2643/5000 - Train Loss: 0.091083, Val Loss: 0.079002
2025-09-03 13:07:32,596 - INFO - Epoch 2644/5000 - Train Loss: 0.090426, Val Loss: 0.079552
2025-09-03 13:08:10,710 - INFO - Epoch 2645/5000 - Train Loss: 0.090665, Val Loss: 0.080617
2025-09-03 13:08:49,027 - INFO - Epoch 2646/5000 - Train Loss: 0.090160, Val Loss: 0.078241
2025-09-03 13:09:27,427 - INFO - Epoch 2647/5000 - Train Loss: 0.089986, Val Loss: 0.077160
2025-09-03 13:09:27,476 - INFO - New best model saved with Val Loss: 0.077160
2025-09-03 13:10:06,414 - INFO - Epoch 2648/5000 - Train Loss: 0.090530, Val Loss: 0.080535
2025-09-03 13:10:44,235 - INFO - Epoch 2649/5000 - Train Loss: 0.091680, Val Loss: 0.081456
2025-09-03 13:11:22,733 - INFO - Epoch 2650/5000 - Train Loss: 0.090560, Val Loss: 0.079241
2025-09-03 13:12:01,405 - INFO - Epoch 2651/5000 - Train Loss: 0.090544, Val Loss: 0.080778
2025-09-03 13:12:40,653 - INFO - Epoch 2652/5000 - Train Loss: 0.090927, Val Loss: 0.080497
2025-09-03 13:13:18,535 - INFO - Epoch 2653/5000 - Train Loss: 0.090846, Val Loss: 0.081162
2025-09-03 13:13:56,362 - INFO - Epoch 2654/5000 - Train Loss: 0.091200, Val Loss: 0.080536
2025-09-03 13:14:34,290 - INFO - Epoch 2655/5000 - Train Loss: 0.090620, Val Loss: 0.078779
2025-09-03 13:15:11,319 - INFO - Epoch 2656/5000 - Train Loss: 0.090131, Val Loss: 0.081015
2025-09-03 13:15:48,779 - INFO - Epoch 2657/5000 - Train Loss: 0.090066, Val Loss: 0.077627
2025-09-03 13:16:26,716 - INFO - Epoch 2658/5000 - Train Loss: 0.090261, Val Loss: 0.080750
2025-09-03 13:17:04,083 - INFO - Epoch 2659/5000 - Train Loss: 0.092545, Val Loss: 0.084912
2025-09-03 13:17:42,511 - INFO - Epoch 2660/5000 - Train Loss: 0.090822, Val Loss: 0.078782
2025-09-03 13:18:21,358 - INFO - Epoch 2661/5000 - Train Loss: 0.090900, Val Loss: 0.079481
2025-09-03 13:18:59,815 - INFO - Epoch 2662/5000 - Train Loss: 0.089987, Val Loss: 0.078477
2025-09-03 13:19:37,393 - INFO - Epoch 2663/5000 - Train Loss: 0.089530, Val Loss: 0.079011
2025-09-03 13:20:15,284 - INFO - Epoch 2664/5000 - Train Loss: 0.089857, Val Loss: 0.079927
2025-09-03 13:20:53,624 - INFO - Epoch 2665/5000 - Train Loss: 0.089746, Val Loss: 0.078138
2025-09-03 13:21:31,496 - INFO - Epoch 2666/5000 - Train Loss: 0.089620, Val Loss: 0.077418
2025-09-03 13:22:08,645 - INFO - Epoch 2667/5000 - Train Loss: 0.090500, Val Loss: 0.079078
2025-09-03 13:22:46,437 - INFO - Epoch 2668/5000 - Train Loss: 0.090214, Val Loss: 0.078832
2025-09-03 13:23:23,316 - INFO - Epoch 2669/5000 - Train Loss: 0.090334, Val Loss: 0.079433
2025-09-03 13:24:00,756 - INFO - Epoch 2670/5000 - Train Loss: 0.090125, Val Loss: 0.078273
2025-09-03 13:24:38,223 - INFO - Epoch 2671/5000 - Train Loss: 0.088752, Val Loss: 0.078702
2025-09-03 13:25:15,117 - INFO - Epoch 2672/5000 - Train Loss: 0.091322, Val Loss: 0.079382
2025-09-03 13:25:52,883 - INFO - Epoch 2673/5000 - Train Loss: 0.091356, Val Loss: 0.081064
2025-09-03 13:26:29,597 - INFO - Epoch 2674/5000 - Train Loss: 0.089720, Val Loss: 0.077911
2025-09-03 13:27:06,141 - INFO - Epoch 2675/5000 - Train Loss: 0.090457, Val Loss: 0.078786
2025-09-03 13:27:43,223 - INFO - Epoch 2676/5000 - Train Loss: 0.089804, Val Loss: 0.080430
2025-09-03 13:28:21,286 - INFO - Epoch 2677/5000 - Train Loss: 0.089828, Val Loss: 0.079206
2025-09-03 13:28:59,196 - INFO - Epoch 2678/5000 - Train Loss: 0.091514, Val Loss: 0.079542
2025-09-03 13:29:36,633 - INFO - Epoch 2679/5000 - Train Loss: 0.091014, Val Loss: 0.077332
2025-09-03 13:30:13,990 - INFO - Epoch 2680/5000 - Train Loss: 0.089008, Val Loss: 0.078670
2025-09-03 13:30:51,651 - INFO - Epoch 2681/5000 - Train Loss: 0.089814, Val Loss: 0.078533
2025-09-03 13:31:30,210 - INFO - Epoch 2682/5000 - Train Loss: 0.089467, Val Loss: 0.077887
2025-09-03 13:32:08,239 - INFO - Epoch 2683/5000 - Train Loss: 0.089055, Val Loss: 0.077912
2025-09-03 13:32:46,952 - INFO - Epoch 2684/5000 - Train Loss: 0.089697, Val Loss: 0.078032
2025-09-03 13:33:25,112 - INFO - Epoch 2685/5000 - Train Loss: 0.089966, Val Loss: 0.078668
2025-09-03 13:34:04,370 - INFO - Epoch 2686/5000 - Train Loss: 0.090036, Val Loss: 0.081234
2025-09-03 13:34:40,781 - INFO - Epoch 2687/5000 - Train Loss: 0.090106, Val Loss: 0.077869
2025-09-03 13:35:17,589 - INFO - Epoch 2688/5000 - Train Loss: 0.089939, Val Loss: 0.080730
2025-09-03 13:35:54,673 - INFO - Epoch 2689/5000 - Train Loss: 0.090717, Val Loss: 0.079763
2025-09-03 13:36:31,906 - INFO - Epoch 2690/5000 - Train Loss: 0.090884, Val Loss: 0.078618
2025-09-03 13:37:09,660 - INFO - Epoch 2691/5000 - Train Loss: 0.089721, Val Loss: 0.078222
2025-09-03 13:37:48,006 - INFO - Epoch 2692/5000 - Train Loss: 0.089928, Val Loss: 0.078193
2025-09-03 13:38:25,068 - INFO - Epoch 2693/5000 - Train Loss: 0.090257, Val Loss: 0.080614
2025-09-03 13:39:02,414 - INFO - Epoch 2694/5000 - Train Loss: 0.090379, Val Loss: 0.081724
2025-09-03 13:39:39,926 - INFO - Epoch 2695/5000 - Train Loss: 0.089469, Val Loss: 0.078208
2025-09-03 13:40:16,250 - INFO - Epoch 2696/5000 - Train Loss: 0.089294, Val Loss: 0.078872
2025-09-03 13:40:53,082 - INFO - Epoch 2697/5000 - Train Loss: 0.091286, Val Loss: 0.079675
2025-09-03 13:41:31,050 - INFO - Epoch 2698/5000 - Train Loss: 0.089505, Val Loss: 0.077814
2025-09-03 13:42:09,234 - INFO - Epoch 2699/5000 - Train Loss: 0.089886, Val Loss: 0.080180
2025-09-03 13:42:45,706 - INFO - Epoch 2700/5000 - Train Loss: 0.091635, Val Loss: 0.077476
2025-09-03 13:43:22,585 - INFO - Epoch 2701/5000 - Train Loss: 0.090536, Val Loss: 0.078483
2025-09-03 13:44:00,350 - INFO - Epoch 2702/5000 - Train Loss: 0.089494, Val Loss: 0.076692
2025-09-03 13:44:00,405 - INFO - New best model saved with Val Loss: 0.076692
2025-09-03 13:44:38,763 - INFO - Epoch 2703/5000 - Train Loss: 0.090057, Val Loss: 0.077869
2025-09-03 13:45:15,996 - INFO - Epoch 2704/5000 - Train Loss: 0.089829, Val Loss: 0.078462
2025-09-03 13:45:53,572 - INFO - Epoch 2705/5000 - Train Loss: 0.089610, Val Loss: 0.081174
2025-09-03 13:46:31,601 - INFO - Epoch 2706/5000 - Train Loss: 0.089696, Val Loss: 0.078654
2025-09-03 13:47:09,237 - INFO - Epoch 2707/5000 - Train Loss: 0.089090, Val Loss: 0.077766
2025-09-03 13:47:48,319 - INFO - Epoch 2708/5000 - Train Loss: 0.090903, Val Loss: 0.077330
2025-09-03 13:48:25,579 - INFO - Epoch 2709/5000 - Train Loss: 0.089120, Val Loss: 0.078084
2025-09-03 13:49:02,363 - INFO - Epoch 2710/5000 - Train Loss: 0.089518, Val Loss: 0.078073
2025-09-03 13:49:40,302 - INFO - Epoch 2711/5000 - Train Loss: 0.089735, Val Loss: 0.079545
2025-09-03 13:50:17,752 - INFO - Epoch 2712/5000 - Train Loss: 0.089330, Val Loss: 0.078264
2025-09-03 13:50:56,881 - INFO - Epoch 2713/5000 - Train Loss: 0.089256, Val Loss: 0.077455
2025-09-03 13:51:35,766 - INFO - Epoch 2714/5000 - Train Loss: 0.089854, Val Loss: 0.077145
2025-09-03 13:52:13,299 - INFO - Epoch 2715/5000 - Train Loss: 0.088501, Val Loss: 0.080504
2025-09-03 13:52:50,710 - INFO - Epoch 2716/5000 - Train Loss: 0.089159, Val Loss: 0.078931
2025-09-03 13:53:28,837 - INFO - Epoch 2717/5000 - Train Loss: 0.089386, Val Loss: 0.077597
2025-09-03 13:54:07,710 - INFO - Epoch 2718/5000 - Train Loss: 0.090057, Val Loss: 0.076836
2025-09-03 13:54:46,138 - INFO - Epoch 2719/5000 - Train Loss: 0.089792, Val Loss: 0.075597
2025-09-03 13:54:46,188 - INFO - New best model saved with Val Loss: 0.075597
2025-09-03 13:55:25,084 - INFO - Epoch 2720/5000 - Train Loss: 0.089799, Val Loss: 0.080101
2025-09-03 13:56:04,101 - INFO - Epoch 2721/5000 - Train Loss: 0.089820, Val Loss: 0.078246
2025-09-03 13:56:42,979 - INFO - Epoch 2722/5000 - Train Loss: 0.088479, Val Loss: 0.076801
2025-09-03 13:57:21,355 - INFO - Epoch 2723/5000 - Train Loss: 0.089941, Val Loss: 0.077848
2025-09-03 13:57:59,205 - INFO - Epoch 2724/5000 - Train Loss: 0.089321, Val Loss: 0.079645
2025-09-03 13:58:35,946 - INFO - Epoch 2725/5000 - Train Loss: 0.088995, Val Loss: 0.078195
2025-09-03 13:59:13,408 - INFO - Epoch 2726/5000 - Train Loss: 0.087934, Val Loss: 0.078192
2025-09-03 13:59:52,027 - INFO - Epoch 2727/5000 - Train Loss: 0.089835, Val Loss: 0.078426
2025-09-03 14:00:31,010 - INFO - Epoch 2728/5000 - Train Loss: 0.088730, Val Loss: 0.079106
2025-09-03 14:01:08,978 - INFO - Epoch 2729/5000 - Train Loss: 0.089505, Val Loss: 0.077754
2025-09-03 14:01:46,905 - INFO - Epoch 2730/5000 - Train Loss: 0.088932, Val Loss: 0.077083
2025-09-03 14:02:24,010 - INFO - Epoch 2731/5000 - Train Loss: 0.089033, Val Loss: 0.078698
2025-09-03 14:03:01,341 - INFO - Epoch 2732/5000 - Train Loss: 0.088207, Val Loss: 0.079361
2025-09-03 14:03:38,733 - INFO - Epoch 2733/5000 - Train Loss: 0.088780, Val Loss: 0.078190
2025-09-03 14:04:15,539 - INFO - Epoch 2734/5000 - Train Loss: 0.089329, Val Loss: 0.078500
2025-09-03 14:04:53,546 - INFO - Epoch 2735/5000 - Train Loss: 0.088576, Val Loss: 0.077025
2025-09-03 14:05:31,241 - INFO - Epoch 2736/5000 - Train Loss: 0.089626, Val Loss: 0.077402
2025-09-03 14:06:08,269 - INFO - Epoch 2737/5000 - Train Loss: 0.089516, Val Loss: 0.079127
2025-09-03 14:06:45,904 - INFO - Epoch 2738/5000 - Train Loss: 0.089405, Val Loss: 0.077644
2025-09-03 14:07:23,808 - INFO - Epoch 2739/5000 - Train Loss: 0.088647, Val Loss: 0.079267
2025-09-03 14:08:01,343 - INFO - Epoch 2740/5000 - Train Loss: 0.088988, Val Loss: 0.078132
2025-09-03 14:08:39,404 - INFO - Epoch 2741/5000 - Train Loss: 0.090490, Val Loss: 0.078837
2025-09-03 14:09:16,929 - INFO - Epoch 2742/5000 - Train Loss: 0.089368, Val Loss: 0.078152
2025-09-03 14:09:55,766 - INFO - Epoch 2743/5000 - Train Loss: 0.089806, Val Loss: 0.078574
2025-09-03 14:10:34,079 - INFO - Epoch 2744/5000 - Train Loss: 0.089316, Val Loss: 0.077760
2025-09-03 14:11:13,520 - INFO - Epoch 2745/5000 - Train Loss: 0.088744, Val Loss: 0.078436
2025-09-03 14:11:50,320 - INFO - Epoch 2746/5000 - Train Loss: 0.089425, Val Loss: 0.080146
2025-09-03 14:12:29,329 - INFO - Epoch 2747/5000 - Train Loss: 0.089674, Val Loss: 0.078389
2025-09-03 14:13:06,035 - INFO - Epoch 2748/5000 - Train Loss: 0.088833, Val Loss: 0.077013
2025-09-03 14:13:42,862 - INFO - Epoch 2749/5000 - Train Loss: 0.088588, Val Loss: 0.077599
2025-09-03 14:14:20,487 - INFO - Epoch 2750/5000 - Train Loss: 0.089249, Val Loss: 0.079311
2025-09-03 14:14:57,754 - INFO - Epoch 2751/5000 - Train Loss: 0.089554, Val Loss: 0.078238
2025-09-03 14:15:35,701 - INFO - Epoch 2752/5000 - Train Loss: 0.089057, Val Loss: 0.077006
2025-09-03 14:16:12,741 - INFO - Epoch 2753/5000 - Train Loss: 0.089340, Val Loss: 0.080838
2025-09-03 14:16:50,745 - INFO - Epoch 2754/5000 - Train Loss: 0.089676, Val Loss: 0.078746
2025-09-03 14:17:28,621 - INFO - Epoch 2755/5000 - Train Loss: 0.088163, Val Loss: 0.077377
2025-09-03 14:18:05,657 - INFO - Epoch 2756/5000 - Train Loss: 0.088016, Val Loss: 0.076679
2025-09-03 14:18:43,954 - INFO - Epoch 2757/5000 - Train Loss: 0.088208, Val Loss: 0.078413
2025-09-03 14:19:25,044 - INFO - Epoch 2758/5000 - Train Loss: 0.088665, Val Loss: 0.077100
2025-09-03 14:20:02,931 - INFO - Epoch 2759/5000 - Train Loss: 0.088091, Val Loss: 0.076813
2025-09-03 14:20:41,995 - INFO - Epoch 2760/5000 - Train Loss: 0.088196, Val Loss: 0.079463
2025-09-03 14:21:21,262 - INFO - Epoch 2761/5000 - Train Loss: 0.088727, Val Loss: 0.076798
2025-09-03 14:21:59,435 - INFO - Epoch 2762/5000 - Train Loss: 0.089069, Val Loss: 0.078707
2025-09-03 14:22:37,393 - INFO - Epoch 2763/5000 - Train Loss: 0.088777, Val Loss: 0.077268
2025-09-03 14:23:15,748 - INFO - Epoch 2764/5000 - Train Loss: 0.088882, Val Loss: 0.075963
2025-09-03 14:23:55,194 - INFO - Epoch 2765/5000 - Train Loss: 0.088370, Val Loss: 0.080908
2025-09-03 14:24:32,867 - INFO - Epoch 2766/5000 - Train Loss: 0.088886, Val Loss: 0.076670
2025-09-03 14:25:12,099 - INFO - Epoch 2767/5000 - Train Loss: 0.087472, Val Loss: 0.079641
2025-09-03 14:25:49,920 - INFO - Epoch 2768/5000 - Train Loss: 0.088885, Val Loss: 0.077066
2025-09-03 14:26:28,953 - INFO - Epoch 2769/5000 - Train Loss: 0.089135, Val Loss: 0.079318
2025-09-03 14:27:07,326 - INFO - Epoch 2770/5000 - Train Loss: 0.090176, Val Loss: 0.078710
2025-09-03 14:27:47,940 - INFO - Epoch 2771/5000 - Train Loss: 0.090478, Val Loss: 0.077810
2025-09-03 14:28:29,455 - INFO - Epoch 2772/5000 - Train Loss: 0.089780, Val Loss: 0.079086
2025-09-03 14:29:10,840 - INFO - Epoch 2773/5000 - Train Loss: 0.088829, Val Loss: 0.078793
2025-09-03 14:29:53,440 - INFO - Epoch 2774/5000 - Train Loss: 0.089081, Val Loss: 0.077872
2025-09-03 14:30:35,238 - INFO - Epoch 2775/5000 - Train Loss: 0.087948, Val Loss: 0.076582
2025-09-03 14:31:15,548 - INFO - Epoch 2776/5000 - Train Loss: 0.087765, Val Loss: 0.076918
2025-09-03 14:31:57,827 - INFO - Epoch 2777/5000 - Train Loss: 0.088322, Val Loss: 0.077339
2025-09-03 14:32:40,371 - INFO - Epoch 2778/5000 - Train Loss: 0.087904, Val Loss: 0.077215
2025-09-03 14:33:22,412 - INFO - Epoch 2779/5000 - Train Loss: 0.088375, Val Loss: 0.079502
2025-09-03 14:34:03,572 - INFO - Epoch 2780/5000 - Train Loss: 0.089742, Val Loss: 0.079663
2025-09-03 14:34:46,462 - INFO - Epoch 2781/5000 - Train Loss: 0.089233, Val Loss: 0.076159
2025-09-03 14:35:29,687 - INFO - Epoch 2782/5000 - Train Loss: 0.088700, Val Loss: 0.081615
2025-09-03 14:36:10,846 - INFO - Epoch 2783/5000 - Train Loss: 0.088253, Val Loss: 0.077529
2025-09-03 14:36:53,955 - INFO - Epoch 2784/5000 - Train Loss: 0.087756, Val Loss: 0.077028
2025-09-03 14:37:36,762 - INFO - Epoch 2785/5000 - Train Loss: 0.089967, Val Loss: 0.079903
2025-09-03 14:38:19,777 - INFO - Epoch 2786/5000 - Train Loss: 0.089765, Val Loss: 0.078895
2025-09-03 14:39:02,833 - INFO - Epoch 2787/5000 - Train Loss: 0.087765, Val Loss: 0.080132
2025-09-03 14:39:44,633 - INFO - Epoch 2788/5000 - Train Loss: 0.088615, Val Loss: 0.076988
2025-09-03 14:40:25,214 - INFO - Epoch 2789/5000 - Train Loss: 0.088267, Val Loss: 0.076658
2025-09-03 14:41:06,303 - INFO - Epoch 2790/5000 - Train Loss: 0.087505, Val Loss: 0.076892
2025-09-03 14:41:48,207 - INFO - Epoch 2791/5000 - Train Loss: 0.088214, Val Loss: 0.078293
2025-09-03 14:42:29,308 - INFO - Epoch 2792/5000 - Train Loss: 0.088219, Val Loss: 0.076417
2025-09-03 14:43:11,111 - INFO - Epoch 2793/5000 - Train Loss: 0.087134, Val Loss: 0.076471
2025-09-03 14:43:56,582 - INFO - Epoch 2794/5000 - Train Loss: 0.088297, Val Loss: 0.077993
2025-09-03 14:44:39,758 - INFO - Epoch 2795/5000 - Train Loss: 0.089138, Val Loss: 0.077347
2025-09-03 14:45:19,905 - INFO - Epoch 2796/5000 - Train Loss: 0.087288, Val Loss: 0.077425
2025-09-03 14:46:01,725 - INFO - Epoch 2797/5000 - Train Loss: 0.089408, Val Loss: 0.076815
2025-09-03 14:46:41,439 - INFO - Epoch 2798/5000 - Train Loss: 0.087793, Val Loss: 0.075990
2025-09-03 14:47:23,161 - INFO - Epoch 2799/5000 - Train Loss: 0.089420, Val Loss: 0.078769
2025-09-03 14:48:04,702 - INFO - Epoch 2800/5000 - Train Loss: 0.088906, Val Loss: 0.077000
2025-09-03 14:48:47,728 - INFO - Epoch 2801/5000 - Train Loss: 0.088647, Val Loss: 0.078473
2025-09-03 14:49:30,135 - INFO - Epoch 2802/5000 - Train Loss: 0.087692, Val Loss: 0.078172
2025-09-03 14:50:14,327 - INFO - Epoch 2803/5000 - Train Loss: 0.087498, Val Loss: 0.075417
2025-09-03 14:50:14,385 - INFO - New best model saved with Val Loss: 0.075417
2025-09-03 14:50:56,413 - INFO - Epoch 2804/5000 - Train Loss: 0.089121, Val Loss: 0.076730
2025-09-03 14:51:37,516 - INFO - Epoch 2805/5000 - Train Loss: 0.088160, Val Loss: 0.075723
2025-09-03 14:52:19,697 - INFO - Epoch 2806/5000 - Train Loss: 0.088251, Val Loss: 0.077471
2025-09-03 14:53:01,388 - INFO - Epoch 2807/5000 - Train Loss: 0.088414, Val Loss: 0.077898
2025-09-03 14:53:41,501 - INFO - Epoch 2808/5000 - Train Loss: 0.087613, Val Loss: 0.078163
2025-09-03 14:54:21,406 - INFO - Epoch 2809/5000 - Train Loss: 0.087846, Val Loss: 0.076265
2025-09-03 14:55:02,480 - INFO - Epoch 2810/5000 - Train Loss: 0.087345, Val Loss: 0.076662
2025-09-03 14:55:44,936 - INFO - Epoch 2811/5000 - Train Loss: 0.087934, Val Loss: 0.078135
2025-09-03 14:56:27,281 - INFO - Epoch 2812/5000 - Train Loss: 0.087248, Val Loss: 0.075680
2025-09-03 14:57:11,466 - INFO - Epoch 2813/5000 - Train Loss: 0.087926, Val Loss: 0.078037
2025-09-03 14:57:54,625 - INFO - Epoch 2814/5000 - Train Loss: 0.087530, Val Loss: 0.077176
2025-09-03 14:58:36,906 - INFO - Epoch 2815/5000 - Train Loss: 0.088329, Val Loss: 0.078857
2025-09-03 14:59:17,731 - INFO - Epoch 2816/5000 - Train Loss: 0.088623, Val Loss: 0.075644
2025-09-03 14:59:58,728 - INFO - Epoch 2817/5000 - Train Loss: 0.087458, Val Loss: 0.074942
2025-09-03 14:59:58,784 - INFO - New best model saved with Val Loss: 0.074942
2025-09-03 15:00:42,193 - INFO - Epoch 2818/5000 - Train Loss: 0.087246, Val Loss: 0.075725
2025-09-03 15:01:24,656 - INFO - Epoch 2819/5000 - Train Loss: 0.087476, Val Loss: 0.079067
2025-09-03 15:02:04,529 - INFO - Epoch 2820/5000 - Train Loss: 0.086939, Val Loss: 0.076954
2025-09-03 15:02:46,681 - INFO - Epoch 2821/5000 - Train Loss: 0.089130, Val Loss: 0.077507
2025-09-03 15:03:28,422 - INFO - Epoch 2822/5000 - Train Loss: 0.087027, Val Loss: 0.075423
2025-09-03 15:04:07,122 - INFO - Epoch 2823/5000 - Train Loss: 0.087801, Val Loss: 0.079638
2025-09-03 15:04:48,074 - INFO - Epoch 2824/5000 - Train Loss: 0.088050, Val Loss: 0.079757
2025-09-03 15:05:27,070 - INFO - Epoch 2825/5000 - Train Loss: 0.088437, Val Loss: 0.077923
2025-09-03 15:06:06,241 - INFO - Epoch 2826/5000 - Train Loss: 0.087318, Val Loss: 0.074591
2025-09-03 15:06:06,332 - INFO - New best model saved with Val Loss: 0.074591
2025-09-03 15:06:46,537 - INFO - Epoch 2827/5000 - Train Loss: 0.086960, Val Loss: 0.076492
2025-09-03 15:07:25,288 - INFO - Epoch 2828/5000 - Train Loss: 0.087437, Val Loss: 0.077408
2025-09-03 15:08:03,868 - INFO - Epoch 2829/5000 - Train Loss: 0.089065, Val Loss: 0.077997
2025-09-03 15:08:44,725 - INFO - Epoch 2830/5000 - Train Loss: 0.087869, Val Loss: 0.076277
2025-09-03 15:09:25,490 - INFO - Epoch 2831/5000 - Train Loss: 0.087692, Val Loss: 0.076253
2025-09-03 15:10:07,433 - INFO - Epoch 2832/5000 - Train Loss: 0.086772, Val Loss: 0.077938
2025-09-03 15:10:47,431 - INFO - Epoch 2833/5000 - Train Loss: 0.088084, Val Loss: 0.076869
2025-09-03 15:11:29,403 - INFO - Epoch 2834/5000 - Train Loss: 0.087792, Val Loss: 0.076347
2025-09-03 15:12:10,469 - INFO - Epoch 2835/5000 - Train Loss: 0.087767, Val Loss: 0.074877
2025-09-03 15:12:49,903 - INFO - Epoch 2836/5000 - Train Loss: 0.086994, Val Loss: 0.079201
2025-09-03 15:13:29,789 - INFO - Epoch 2837/5000 - Train Loss: 0.087118, Val Loss: 0.077445
2025-09-03 15:14:10,337 - INFO - Epoch 2838/5000 - Train Loss: 0.087477, Val Loss: 0.076813
2025-09-03 15:14:49,164 - INFO - Epoch 2839/5000 - Train Loss: 0.086982, Val Loss: 0.076836
2025-09-03 15:15:28,022 - INFO - Epoch 2840/5000 - Train Loss: 0.088398, Val Loss: 0.076969
2025-09-03 15:16:07,555 - INFO - Epoch 2841/5000 - Train Loss: 0.088689, Val Loss: 0.077875
2025-09-03 15:16:46,971 - INFO - Epoch 2842/5000 - Train Loss: 0.087222, Val Loss: 0.076406
2025-09-03 15:17:28,953 - INFO - Epoch 2843/5000 - Train Loss: 0.085306, Val Loss: 0.076167
2025-09-03 15:18:15,439 - INFO - Epoch 2844/5000 - Train Loss: 0.087508, Val Loss: 0.077001
2025-09-03 15:18:57,028 - INFO - Epoch 2845/5000 - Train Loss: 0.088516, Val Loss: 0.077121
2025-09-03 15:19:39,100 - INFO - Epoch 2846/5000 - Train Loss: 0.087396, Val Loss: 0.076519
2025-09-03 15:20:18,786 - INFO - Epoch 2847/5000 - Train Loss: 0.086576, Val Loss: 0.075275
2025-09-03 15:20:59,387 - INFO - Epoch 2848/5000 - Train Loss: 0.086846, Val Loss: 0.076979
2025-09-03 15:21:39,890 - INFO - Epoch 2849/5000 - Train Loss: 0.088177, Val Loss: 0.076516
2025-09-03 15:22:19,402 - INFO - Epoch 2850/5000 - Train Loss: 0.086573, Val Loss: 0.075311
2025-09-03 15:22:58,091 - INFO - Epoch 2851/5000 - Train Loss: 0.087406, Val Loss: 0.076920
2025-09-03 15:23:37,560 - INFO - Epoch 2852/5000 - Train Loss: 0.087630, Val Loss: 0.077468
2025-09-03 15:24:16,913 - INFO - Epoch 2853/5000 - Train Loss: 0.087279, Val Loss: 0.077073
2025-09-03 15:24:56,215 - INFO - Epoch 2854/5000 - Train Loss: 0.087711, Val Loss: 0.077262
2025-09-03 15:25:36,182 - INFO - Epoch 2855/5000 - Train Loss: 0.086742, Val Loss: 0.078586
2025-09-03 15:26:17,678 - INFO - Epoch 2856/5000 - Train Loss: 0.087602, Val Loss: 0.076661
2025-09-03 15:26:59,928 - INFO - Epoch 2857/5000 - Train Loss: 0.087372, Val Loss: 0.077494
2025-09-03 15:27:41,395 - INFO - Epoch 2858/5000 - Train Loss: 0.087673, Val Loss: 0.076299
2025-09-03 15:28:20,462 - INFO - Epoch 2859/5000 - Train Loss: 0.086695, Val Loss: 0.076077
2025-09-03 15:28:58,823 - INFO - Epoch 2860/5000 - Train Loss: 0.086033, Val Loss: 0.075493
2025-09-03 15:29:37,016 - INFO - Epoch 2861/5000 - Train Loss: 0.087309, Val Loss: 0.076259
2025-09-03 15:30:15,779 - INFO - Epoch 2862/5000 - Train Loss: 0.087052, Val Loss: 0.077774
2025-09-03 15:30:55,577 - INFO - Epoch 2863/5000 - Train Loss: 0.087998, Val Loss: 0.079087
2025-09-03 15:31:34,951 - INFO - Epoch 2864/5000 - Train Loss: 0.086807, Val Loss: 0.074882
2025-09-03 15:32:14,621 - INFO - Epoch 2865/5000 - Train Loss: 0.087032, Val Loss: 0.076476
2025-09-03 15:32:55,267 - INFO - Epoch 2866/5000 - Train Loss: 0.087900, Val Loss: 0.076938
2025-09-03 15:33:34,462 - INFO - Epoch 2867/5000 - Train Loss: 0.088655, Val Loss: 0.075433
2025-09-03 15:34:13,484 - INFO - Epoch 2868/5000 - Train Loss: 0.086226, Val Loss: 0.075773
2025-09-03 15:34:52,358 - INFO - Epoch 2869/5000 - Train Loss: 0.086347, Val Loss: 0.075530
2025-09-03 15:35:32,901 - INFO - Epoch 2870/5000 - Train Loss: 0.086383, Val Loss: 0.076257
2025-09-03 15:36:12,199 - INFO - Epoch 2871/5000 - Train Loss: 0.086484, Val Loss: 0.076792
2025-09-03 15:36:52,162 - INFO - Epoch 2872/5000 - Train Loss: 0.087600, Val Loss: 0.075798
2025-09-03 15:37:31,880 - INFO - Epoch 2873/5000 - Train Loss: 0.085960, Val Loss: 0.074290
2025-09-03 15:37:31,965 - INFO - New best model saved with Val Loss: 0.074290
2025-09-03 15:38:11,444 - INFO - Epoch 2874/5000 - Train Loss: 0.085836, Val Loss: 0.075112
2025-09-03 15:38:50,580 - INFO - Epoch 2875/5000 - Train Loss: 0.087759, Val Loss: 0.075614
2025-09-03 15:39:29,605 - INFO - Epoch 2876/5000 - Train Loss: 0.086566, Val Loss: 0.076977
2025-09-03 15:40:08,601 - INFO - Epoch 2877/5000 - Train Loss: 0.087007, Val Loss: 0.075762
2025-09-03 15:40:48,991 - INFO - Epoch 2878/5000 - Train Loss: 0.087827, Val Loss: 0.075093
2025-09-03 15:41:29,347 - INFO - Epoch 2879/5000 - Train Loss: 0.086651, Val Loss: 0.074013
2025-09-03 15:41:29,423 - INFO - New best model saved with Val Loss: 0.074013
2025-09-03 15:42:08,171 - INFO - Epoch 2880/5000 - Train Loss: 0.087141, Val Loss: 0.076350
2025-09-03 15:42:46,825 - INFO - Epoch 2881/5000 - Train Loss: 0.086761, Val Loss: 0.076321
2025-09-03 15:43:26,875 - INFO - Epoch 2882/5000 - Train Loss: 0.086575, Val Loss: 0.077112
2025-09-03 15:44:05,209 - INFO - Epoch 2883/5000 - Train Loss: 0.087362, Val Loss: 0.075452
2025-09-03 15:44:43,456 - INFO - Epoch 2884/5000 - Train Loss: 0.087694, Val Loss: 0.075067
2025-09-03 15:45:22,428 - INFO - Epoch 2885/5000 - Train Loss: 0.086474, Val Loss: 0.075947
2025-09-03 15:45:59,963 - INFO - Epoch 2886/5000 - Train Loss: 0.086404, Val Loss: 0.074734
2025-09-03 15:46:37,682 - INFO - Epoch 2887/5000 - Train Loss: 0.086735, Val Loss: 0.077206
2025-09-03 15:47:14,585 - INFO - Epoch 2888/5000 - Train Loss: 0.086637, Val Loss: 0.073763
2025-09-03 15:47:14,664 - INFO - New best model saved with Val Loss: 0.073763
2025-09-03 15:47:53,349 - INFO - Epoch 2889/5000 - Train Loss: 0.085848, Val Loss: 0.074256
2025-09-03 15:48:32,188 - INFO - Epoch 2890/5000 - Train Loss: 0.086031, Val Loss: 0.076916
2025-09-03 15:49:11,862 - INFO - Epoch 2891/5000 - Train Loss: 0.087152, Val Loss: 0.076661
2025-09-03 15:49:49,883 - INFO - Epoch 2892/5000 - Train Loss: 0.086952, Val Loss: 0.075674
2025-09-03 15:50:26,792 - INFO - Epoch 2893/5000 - Train Loss: 0.085776, Val Loss: 0.081309
2025-09-03 15:51:05,956 - INFO - Epoch 2894/5000 - Train Loss: 0.087587, Val Loss: 0.078795
2025-09-03 15:51:44,774 - INFO - Epoch 2895/5000 - Train Loss: 0.086750, Val Loss: 0.076671
2025-09-03 15:52:25,912 - INFO - Epoch 2896/5000 - Train Loss: 0.087360, Val Loss: 0.076716
2025-09-03 15:53:06,105 - INFO - Epoch 2897/5000 - Train Loss: 0.086245, Val Loss: 0.074164
2025-09-03 15:53:47,107 - INFO - Epoch 2898/5000 - Train Loss: 0.085993, Val Loss: 0.074846
2025-09-03 15:54:25,368 - INFO - Epoch 2899/5000 - Train Loss: 0.086049, Val Loss: 0.076556
2025-09-03 15:55:02,606 - INFO - Epoch 2900/5000 - Train Loss: 0.086955, Val Loss: 0.074541
2025-09-03 15:55:39,478 - INFO - Epoch 2901/5000 - Train Loss: 0.086051, Val Loss: 0.074071
2025-09-03 15:56:17,669 - INFO - Epoch 2902/5000 - Train Loss: 0.086154, Val Loss: 0.075838
2025-09-03 15:56:55,406 - INFO - Epoch 2903/5000 - Train Loss: 0.085809, Val Loss: 0.077816
2025-09-03 15:57:33,460 - INFO - Epoch 2904/5000 - Train Loss: 0.084739, Val Loss: 0.076325
2025-09-03 15:58:11,605 - INFO - Epoch 2905/5000 - Train Loss: 0.087718, Val Loss: 0.076441
2025-09-03 15:58:50,857 - INFO - Epoch 2906/5000 - Train Loss: 0.086594, Val Loss: 0.076362
2025-09-03 15:59:30,373 - INFO - Epoch 2907/5000 - Train Loss: 0.086233, Val Loss: 0.074825
2025-09-03 16:00:08,801 - INFO - Epoch 2908/5000 - Train Loss: 0.086193, Val Loss: 0.075118
2025-09-03 16:00:46,236 - INFO - Epoch 2909/5000 - Train Loss: 0.086425, Val Loss: 0.078212
2025-09-03 16:01:26,330 - INFO - Epoch 2910/5000 - Train Loss: 0.086026, Val Loss: 0.075218
2025-09-03 16:02:06,040 - INFO - Epoch 2911/5000 - Train Loss: 0.086533, Val Loss: 0.077599
2025-09-03 16:02:44,432 - INFO - Epoch 2912/5000 - Train Loss: 0.085615, Val Loss: 0.073531
2025-09-03 16:02:44,484 - INFO - New best model saved with Val Loss: 0.073531
2025-09-03 16:03:21,916 - INFO - Epoch 2913/5000 - Train Loss: 0.086181, Val Loss: 0.075620
2025-09-03 16:03:58,286 - INFO - Epoch 2914/5000 - Train Loss: 0.086074, Val Loss: 0.074814
2025-09-03 16:04:34,854 - INFO - Epoch 2915/5000 - Train Loss: 0.086156, Val Loss: 0.075946
2025-09-03 16:05:12,503 - INFO - Epoch 2916/5000 - Train Loss: 0.086513, Val Loss: 0.074609
2025-09-03 16:05:50,190 - INFO - Epoch 2917/5000 - Train Loss: 0.087429, Val Loss: 0.076339
2025-09-03 16:06:32,459 - INFO - Epoch 2918/5000 - Train Loss: 0.087345, Val Loss: 0.077324
2025-09-03 16:07:12,650 - INFO - Epoch 2919/5000 - Train Loss: 0.084945, Val Loss: 0.076281
2025-09-03 16:07:50,696 - INFO - Epoch 2920/5000 - Train Loss: 0.087253, Val Loss: 0.078578
2025-09-03 16:08:28,307 - INFO - Epoch 2921/5000 - Train Loss: 0.085524, Val Loss: 0.075866
2025-09-03 16:09:05,465 - INFO - Epoch 2922/5000 - Train Loss: 0.086684, Val Loss: 0.076116
2025-09-03 16:09:42,094 - INFO - Epoch 2923/5000 - Train Loss: 0.087027, Val Loss: 0.077956
2025-09-03 16:10:19,109 - INFO - Epoch 2924/5000 - Train Loss: 0.086446, Val Loss: 0.074965
2025-09-03 16:10:57,589 - INFO - Epoch 2925/5000 - Train Loss: 0.085838, Val Loss: 0.075167
2025-09-03 16:11:35,297 - INFO - Epoch 2926/5000 - Train Loss: 0.086331, Val Loss: 0.076184
2025-09-03 16:12:13,285 - INFO - Epoch 2927/5000 - Train Loss: 0.087071, Val Loss: 0.075742
2025-09-03 16:12:51,406 - INFO - Epoch 2928/5000 - Train Loss: 0.086618, Val Loss: 0.074619
2025-09-03 16:13:29,366 - INFO - Epoch 2929/5000 - Train Loss: 0.086347, Val Loss: 0.079893
2025-09-03 16:14:07,628 - INFO - Epoch 2930/5000 - Train Loss: 0.087466, Val Loss: 0.075620
2025-09-03 16:14:46,755 - INFO - Epoch 2931/5000 - Train Loss: 0.086627, Val Loss: 0.073631
2025-09-03 16:15:24,347 - INFO - Epoch 2932/5000 - Train Loss: 0.085287, Val Loss: 0.074675
2025-09-03 16:16:02,348 - INFO - Epoch 2933/5000 - Train Loss: 0.084489, Val Loss: 0.076739
2025-09-03 16:16:42,115 - INFO - Epoch 2934/5000 - Train Loss: 0.084944, Val Loss: 0.073934
2025-09-03 16:17:21,591 - INFO - Epoch 2935/5000 - Train Loss: 0.085382, Val Loss: 0.078551
2025-09-03 16:17:58,296 - INFO - Epoch 2936/5000 - Train Loss: 0.086936, Val Loss: 0.077525
2025-09-03 16:18:35,776 - INFO - Epoch 2937/5000 - Train Loss: 0.086690, Val Loss: 0.076668
2025-09-03 16:19:13,230 - INFO - Epoch 2938/5000 - Train Loss: 0.085531, Val Loss: 0.075634
2025-09-03 16:19:49,222 - INFO - Epoch 2939/5000 - Train Loss: 0.085434, Val Loss: 0.074980
2025-09-03 16:20:26,166 - INFO - Epoch 2940/5000 - Train Loss: 0.085670, Val Loss: 0.074041
2025-09-03 16:21:02,831 - INFO - Epoch 2941/5000 - Train Loss: 0.086014, Val Loss: 0.075323
2025-09-03 16:21:39,853 - INFO - Epoch 2942/5000 - Train Loss: 0.087380, Val Loss: 0.076902
2025-09-03 16:22:22,212 - INFO - Epoch 2943/5000 - Train Loss: 0.085273, Val Loss: 0.075718
2025-09-03 16:23:02,017 - INFO - Epoch 2944/5000 - Train Loss: 0.085561, Val Loss: 0.075020
2025-09-03 16:23:39,728 - INFO - Epoch 2945/5000 - Train Loss: 0.084967, Val Loss: 0.074423
2025-09-03 16:24:16,462 - INFO - Epoch 2946/5000 - Train Loss: 0.085114, Val Loss: 0.075062
2025-09-03 16:24:52,978 - INFO - Epoch 2947/5000 - Train Loss: 0.084736, Val Loss: 0.073985
2025-09-03 16:25:30,385 - INFO - Epoch 2948/5000 - Train Loss: 0.085671, Val Loss: 0.074613
2025-09-03 16:26:08,064 - INFO - Epoch 2949/5000 - Train Loss: 0.084498, Val Loss: 0.075659
2025-09-03 16:26:45,749 - INFO - Epoch 2950/5000 - Train Loss: 0.087463, Val Loss: 0.076744
2025-09-03 16:27:23,806 - INFO - Epoch 2951/5000 - Train Loss: 0.086456, Val Loss: 0.074429
2025-09-03 16:28:00,316 - INFO - Epoch 2952/5000 - Train Loss: 0.085252, Val Loss: 0.074179
2025-09-03 16:28:37,337 - INFO - Epoch 2953/5000 - Train Loss: 0.085141, Val Loss: 0.074427
2025-09-03 16:29:14,979 - INFO - Epoch 2954/5000 - Train Loss: 0.085023, Val Loss: 0.074590
2025-09-03 16:29:53,092 - INFO - Epoch 2955/5000 - Train Loss: 0.085462, Val Loss: 0.076121
2025-09-03 16:30:30,139 - INFO - Epoch 2956/5000 - Train Loss: 0.087616, Val Loss: 0.076477
2025-09-03 16:31:06,325 - INFO - Epoch 2957/5000 - Train Loss: 0.086289, Val Loss: 0.075723
2025-09-03 16:31:42,791 - INFO - Epoch 2958/5000 - Train Loss: 0.085087, Val Loss: 0.074264
2025-09-03 16:32:19,302 - INFO - Epoch 2959/5000 - Train Loss: 0.085974, Val Loss: 0.075942
2025-09-03 16:32:58,014 - INFO - Epoch 2960/5000 - Train Loss: 0.086540, Val Loss: 0.076090
2025-09-03 16:33:35,148 - INFO - Epoch 2961/5000 - Train Loss: 0.084309, Val Loss: 0.075195
2025-09-03 16:34:10,846 - INFO - Epoch 2962/5000 - Train Loss: 0.086985, Val Loss: 0.077973
2025-09-03 16:34:46,295 - INFO - Epoch 2963/5000 - Train Loss: 0.086856, Val Loss: 0.076943
2025-09-03 16:35:23,983 - INFO - Epoch 2964/5000 - Train Loss: 0.085737, Val Loss: 0.075336
2025-09-03 16:36:01,093 - INFO - Epoch 2965/5000 - Train Loss: 0.085234, Val Loss: 0.074360
2025-09-03 16:36:37,100 - INFO - Epoch 2966/5000 - Train Loss: 0.085265, Val Loss: 0.075889
2025-09-03 16:37:14,034 - INFO - Epoch 2967/5000 - Train Loss: 0.085093, Val Loss: 0.073823
2025-09-03 16:37:51,846 - INFO - Epoch 2968/5000 - Train Loss: 0.085307, Val Loss: 0.076112
2025-09-03 16:38:28,054 - INFO - Epoch 2969/5000 - Train Loss: 0.085032, Val Loss: 0.076886
2025-09-03 16:39:04,151 - INFO - Epoch 2970/5000 - Train Loss: 0.086203, Val Loss: 0.076291
2025-09-03 16:39:40,175 - INFO - Epoch 2971/5000 - Train Loss: 0.085415, Val Loss: 0.078461
2025-09-03 16:40:17,089 - INFO - Epoch 2972/5000 - Train Loss: 0.085087, Val Loss: 0.074983
2025-09-03 16:40:53,004 - INFO - Epoch 2973/5000 - Train Loss: 0.085273, Val Loss: 0.073887
2025-09-03 16:41:29,343 - INFO - Epoch 2974/5000 - Train Loss: 0.085548, Val Loss: 0.076494
2025-09-03 16:42:05,662 - INFO - Epoch 2975/5000 - Train Loss: 0.085543, Val Loss: 0.075978
2025-09-03 16:42:42,375 - INFO - Epoch 2976/5000 - Train Loss: 0.085773, Val Loss: 0.075692
2025-09-03 16:43:19,390 - INFO - Epoch 2977/5000 - Train Loss: 0.085472, Val Loss: 0.074765
2025-09-03 16:43:56,237 - INFO - Epoch 2978/5000 - Train Loss: 0.084930, Val Loss: 0.075644
2025-09-03 16:44:33,394 - INFO - Epoch 2979/5000 - Train Loss: 0.085780, Val Loss: 0.074045
2025-09-03 16:45:35,571 - INFO - Epoch 2980/5000 - Train Loss: 0.084513, Val Loss: 0.073284
2025-09-03 16:45:35,622 - INFO - New best model saved with Val Loss: 0.073284
2025-09-03 16:46:11,805 - INFO - Epoch 2981/5000 - Train Loss: 0.085387, Val Loss: 0.075205
2025-09-03 16:46:47,622 - INFO - Epoch 2982/5000 - Train Loss: 0.085094, Val Loss: 0.074118
2025-09-03 16:47:24,547 - INFO - Epoch 2983/5000 - Train Loss: 0.084999, Val Loss: 0.074164
2025-09-03 16:48:03,026 - INFO - Epoch 2984/5000 - Train Loss: 0.084440, Val Loss: 0.073368
2025-09-03 16:48:40,303 - INFO - Epoch 2985/5000 - Train Loss: 0.084610, Val Loss: 0.075541
2025-09-03 16:49:18,332 - INFO - Epoch 2986/5000 - Train Loss: 0.084427, Val Loss: 0.074414
2025-09-03 16:49:56,055 - INFO - Epoch 2987/5000 - Train Loss: 0.084279, Val Loss: 0.073677
2025-09-03 16:50:34,019 - INFO - Epoch 2988/5000 - Train Loss: 0.085216, Val Loss: 0.074287
2025-09-03 16:51:10,353 - INFO - Epoch 2989/5000 - Train Loss: 0.085459, Val Loss: 0.074016
2025-09-03 16:51:46,707 - INFO - Epoch 2990/5000 - Train Loss: 0.085484, Val Loss: 0.075878
2025-09-03 16:52:25,004 - INFO - Epoch 2991/5000 - Train Loss: 0.084398, Val Loss: 0.074146
2025-09-03 16:53:01,851 - INFO - Epoch 2992/5000 - Train Loss: 0.084521, Val Loss: 0.074782
2025-09-03 16:53:39,128 - INFO - Epoch 2993/5000 - Train Loss: 0.084952, Val Loss: 0.074177
2025-09-03 16:54:16,627 - INFO - Epoch 2994/5000 - Train Loss: 0.084468, Val Loss: 0.074627
2025-09-03 16:54:53,721 - INFO - Epoch 2995/5000 - Train Loss: 0.084762, Val Loss: 0.075660
2025-09-03 16:55:31,398 - INFO - Epoch 2996/5000 - Train Loss: 0.085894, Val Loss: 0.074026
2025-09-03 16:56:09,399 - INFO - Epoch 2997/5000 - Train Loss: 0.086346, Val Loss: 0.073775
2025-09-03 16:56:46,214 - INFO - Epoch 2998/5000 - Train Loss: 0.084903, Val Loss: 0.074669
2025-09-03 16:57:23,049 - INFO - Epoch 2999/5000 - Train Loss: 0.084467, Val Loss: 0.073514
2025-09-03 16:58:00,691 - INFO - Epoch 3000/5000 - Train Loss: 0.084463, Val Loss: 0.074699
2025-09-03 16:58:38,705 - INFO - Epoch 3001/5000 - Train Loss: 0.084339, Val Loss: 0.075459
2025-09-03 16:59:15,988 - INFO - Epoch 3002/5000 - Train Loss: 0.086048, Val Loss: 0.073282
2025-09-03 16:59:16,031 - INFO - New best model saved with Val Loss: 0.073282
2025-09-03 16:59:53,808 - INFO - Epoch 3003/5000 - Train Loss: 0.085217, Val Loss: 0.075448
2025-09-03 17:00:31,356 - INFO - Epoch 3004/5000 - Train Loss: 0.084914, Val Loss: 0.074230
2025-09-03 17:01:08,221 - INFO - Epoch 3005/5000 - Train Loss: 0.083715, Val Loss: 0.073327
2025-09-03 17:01:44,463 - INFO - Epoch 3006/5000 - Train Loss: 0.085090, Val Loss: 0.073998
2025-09-03 17:02:21,356 - INFO - Epoch 3007/5000 - Train Loss: 0.085991, Val Loss: 0.074334
2025-09-03 17:02:58,696 - INFO - Epoch 3008/5000 - Train Loss: 0.086186, Val Loss: 0.075610
2025-09-03 17:03:36,385 - INFO - Epoch 3009/5000 - Train Loss: 0.084558, Val Loss: 0.073574
2025-09-03 17:04:12,671 - INFO - Epoch 3010/5000 - Train Loss: 0.084213, Val Loss: 0.074594
2025-09-03 17:04:49,273 - INFO - Epoch 3011/5000 - Train Loss: 0.086322, Val Loss: 0.077241
2025-09-03 17:05:26,776 - INFO - Epoch 3012/5000 - Train Loss: 0.084517, Val Loss: 0.073822
2025-09-03 17:06:02,802 - INFO - Epoch 3013/5000 - Train Loss: 0.085012, Val Loss: 0.073634
2025-09-03 17:06:39,182 - INFO - Epoch 3014/5000 - Train Loss: 0.084783, Val Loss: 0.074991
2025-09-03 17:07:15,418 - INFO - Epoch 3015/5000 - Train Loss: 0.084770, Val Loss: 0.075212
2025-09-03 17:07:51,987 - INFO - Epoch 3016/5000 - Train Loss: 0.083735, Val Loss: 0.074634
2025-09-03 17:08:29,148 - INFO - Epoch 3017/5000 - Train Loss: 0.084331, Val Loss: 0.074838
2025-09-03 17:09:04,811 - INFO - Epoch 3018/5000 - Train Loss: 0.086779, Val Loss: 0.074179
2025-09-03 17:09:40,336 - INFO - Epoch 3019/5000 - Train Loss: 0.084235, Val Loss: 0.075071
2025-09-03 17:10:16,548 - INFO - Epoch 3020/5000 - Train Loss: 0.084390, Val Loss: 0.075093
2025-09-03 17:10:52,881 - INFO - Epoch 3021/5000 - Train Loss: 0.085218, Val Loss: 0.075319
2025-09-03 17:11:28,682 - INFO - Epoch 3022/5000 - Train Loss: 0.084430, Val Loss: 0.073622
2025-09-03 17:12:03,967 - INFO - Epoch 3023/5000 - Train Loss: 0.084095, Val Loss: 0.072834
2025-09-03 17:12:04,054 - INFO - New best model saved with Val Loss: 0.072834
2025-09-03 17:12:40,057 - INFO - Epoch 3024/5000 - Train Loss: 0.083969, Val Loss: 0.075119
2025-09-03 17:13:15,970 - INFO - Epoch 3025/5000 - Train Loss: 0.084396, Val Loss: 0.072415
2025-09-03 17:13:16,014 - INFO - New best model saved with Val Loss: 0.072415
2025-09-03 17:13:52,224 - INFO - Epoch 3026/5000 - Train Loss: 0.083814, Val Loss: 0.072524
2025-09-03 17:14:28,724 - INFO - Epoch 3027/5000 - Train Loss: 0.083494, Val Loss: 0.073286
2025-09-03 17:15:04,911 - INFO - Epoch 3028/5000 - Train Loss: 0.084092, Val Loss: 0.074688
2025-09-03 17:15:41,127 - INFO - Epoch 3029/5000 - Train Loss: 0.084184, Val Loss: 0.074008
2025-09-03 17:16:16,982 - INFO - Epoch 3030/5000 - Train Loss: 0.084719, Val Loss: 0.073343
2025-09-03 17:16:53,158 - INFO - Epoch 3031/5000 - Train Loss: 0.084951, Val Loss: 0.074658
2025-09-03 17:17:29,254 - INFO - Epoch 3032/5000 - Train Loss: 0.085033, Val Loss: 0.076727
2025-09-03 17:18:05,710 - INFO - Epoch 3033/5000 - Train Loss: 0.085271, Val Loss: 0.075665
2025-09-03 17:18:41,632 - INFO - Epoch 3034/5000 - Train Loss: 0.084069, Val Loss: 0.074110
2025-09-03 17:19:17,856 - INFO - Epoch 3035/5000 - Train Loss: 0.084507, Val Loss: 0.075726
2025-09-03 17:19:53,652 - INFO - Epoch 3036/5000 - Train Loss: 0.085684, Val Loss: 0.075802
2025-09-03 17:20:30,298 - INFO - Epoch 3037/5000 - Train Loss: 0.084528, Val Loss: 0.073690
2025-09-03 17:21:06,371 - INFO - Epoch 3038/5000 - Train Loss: 0.084536, Val Loss: 0.074250
2025-09-03 17:21:43,237 - INFO - Epoch 3039/5000 - Train Loss: 0.084211, Val Loss: 0.074178
2025-09-03 17:22:18,966 - INFO - Epoch 3040/5000 - Train Loss: 0.083546, Val Loss: 0.072444
2025-09-03 17:22:54,978 - INFO - Epoch 3041/5000 - Train Loss: 0.083360, Val Loss: 0.074388
2025-09-03 17:23:31,164 - INFO - Epoch 3042/5000 - Train Loss: 0.084318, Val Loss: 0.073702
2025-09-03 17:24:07,584 - INFO - Epoch 3043/5000 - Train Loss: 0.084903, Val Loss: 0.073821
2025-09-03 17:24:43,638 - INFO - Epoch 3044/5000 - Train Loss: 0.083940, Val Loss: 0.074127
2025-09-03 17:25:18,722 - INFO - Epoch 3045/5000 - Train Loss: 0.086096, Val Loss: 0.075188
2025-09-03 17:25:54,767 - INFO - Epoch 3046/5000 - Train Loss: 0.083744, Val Loss: 0.072929
2025-09-03 17:26:31,013 - INFO - Epoch 3047/5000 - Train Loss: 0.084049, Val Loss: 0.072673
2025-09-03 17:27:07,313 - INFO - Epoch 3048/5000 - Train Loss: 0.083686, Val Loss: 0.072527
2025-09-03 17:27:43,420 - INFO - Epoch 3049/5000 - Train Loss: 0.084882, Val Loss: 0.077580
2025-09-03 17:28:19,111 - INFO - Epoch 3050/5000 - Train Loss: 0.085651, Val Loss: 0.073516
2025-09-03 17:28:54,967 - INFO - Epoch 3051/5000 - Train Loss: 0.084571, Val Loss: 0.073052
2025-09-03 17:29:31,038 - INFO - Epoch 3052/5000 - Train Loss: 0.083423, Val Loss: 0.074187
2025-09-03 17:30:06,902 - INFO - Epoch 3053/5000 - Train Loss: 0.083719, Val Loss: 0.072192
2025-09-03 17:30:06,946 - INFO - New best model saved with Val Loss: 0.072192
2025-09-03 17:30:42,814 - INFO - Epoch 3054/5000 - Train Loss: 0.083097, Val Loss: 0.073533
2025-09-03 17:31:18,575 - INFO - Epoch 3055/5000 - Train Loss: 0.084631, Val Loss: 0.075374
2025-09-03 17:31:54,369 - INFO - Epoch 3056/5000 - Train Loss: 0.084890, Val Loss: 0.072511
2025-09-03 17:32:30,486 - INFO - Epoch 3057/5000 - Train Loss: 0.083168, Val Loss: 0.071624
2025-09-03 17:32:30,537 - INFO - New best model saved with Val Loss: 0.071624
2025-09-03 17:33:05,722 - INFO - Epoch 3058/5000 - Train Loss: 0.083277, Val Loss: 0.073516
2025-09-03 17:33:41,416 - INFO - Epoch 3059/5000 - Train Loss: 0.083318, Val Loss: 0.074113
2025-09-03 17:34:16,537 - INFO - Epoch 3060/5000 - Train Loss: 0.084502, Val Loss: 0.075003
2025-09-03 17:34:52,743 - INFO - Epoch 3061/5000 - Train Loss: 0.083834, Val Loss: 0.073619
2025-09-03 17:35:28,536 - INFO - Epoch 3062/5000 - Train Loss: 0.084724, Val Loss: 0.073871
2025-09-03 17:36:04,042 - INFO - Epoch 3063/5000 - Train Loss: 0.084362, Val Loss: 0.072985
2025-09-03 17:36:39,957 - INFO - Epoch 3064/5000 - Train Loss: 0.084624, Val Loss: 0.074363
2025-09-03 17:37:16,517 - INFO - Epoch 3065/5000 - Train Loss: 0.085169, Val Loss: 0.073518
2025-09-03 17:37:51,864 - INFO - Epoch 3066/5000 - Train Loss: 0.083911, Val Loss: 0.072586
2025-09-03 17:38:27,606 - INFO - Epoch 3067/5000 - Train Loss: 0.083977, Val Loss: 0.073947
2025-09-03 17:39:03,382 - INFO - Epoch 3068/5000 - Train Loss: 0.084500, Val Loss: 0.074377
2025-09-03 17:39:38,845 - INFO - Epoch 3069/5000 - Train Loss: 0.084358, Val Loss: 0.074593
2025-09-03 17:40:14,845 - INFO - Epoch 3070/5000 - Train Loss: 0.083564, Val Loss: 0.073440
2025-09-03 17:40:51,172 - INFO - Epoch 3071/5000 - Train Loss: 0.083507, Val Loss: 0.072852
2025-09-03 17:41:27,517 - INFO - Epoch 3072/5000 - Train Loss: 0.082807, Val Loss: 0.073644
2025-09-03 17:42:02,998 - INFO - Epoch 3073/5000 - Train Loss: 0.082986, Val Loss: 0.073594
2025-09-03 17:42:38,836 - INFO - Epoch 3074/5000 - Train Loss: 0.083402, Val Loss: 0.071502
2025-09-03 17:42:38,885 - INFO - New best model saved with Val Loss: 0.071502
2025-09-03 17:43:15,127 - INFO - Epoch 3075/5000 - Train Loss: 0.083745, Val Loss: 0.073487
2025-09-03 17:43:51,334 - INFO - Epoch 3076/5000 - Train Loss: 0.084805, Val Loss: 0.078596
2025-09-03 17:44:26,992 - INFO - Epoch 3077/5000 - Train Loss: 0.084530, Val Loss: 0.073584
2025-09-03 17:45:02,994 - INFO - Epoch 3078/5000 - Train Loss: 0.085428, Val Loss: 0.073266
2025-09-03 17:45:38,979 - INFO - Epoch 3079/5000 - Train Loss: 0.085453, Val Loss: 0.075867
2025-09-03 17:46:15,618 - INFO - Epoch 3080/5000 - Train Loss: 0.084355, Val Loss: 0.074031
2025-09-03 17:46:53,020 - INFO - Epoch 3081/5000 - Train Loss: 0.084056, Val Loss: 0.072452
2025-09-03 17:47:28,742 - INFO - Epoch 3082/5000 - Train Loss: 0.083633, Val Loss: 0.072710
2025-09-03 17:48:05,026 - INFO - Epoch 3083/5000 - Train Loss: 0.082661, Val Loss: 0.073644
2025-09-03 17:48:41,171 - INFO - Epoch 3084/5000 - Train Loss: 0.083877, Val Loss: 0.071175
2025-09-03 17:48:41,227 - INFO - New best model saved with Val Loss: 0.071175
2025-09-03 17:49:17,037 - INFO - Epoch 3085/5000 - Train Loss: 0.083548, Val Loss: 0.073139
2025-09-03 17:49:52,768 - INFO - Epoch 3086/5000 - Train Loss: 0.083001, Val Loss: 0.073543
2025-09-03 17:50:28,825 - INFO - Epoch 3087/5000 - Train Loss: 0.084059, Val Loss: 0.074743
2025-09-03 17:51:04,928 - INFO - Epoch 3088/5000 - Train Loss: 0.084327, Val Loss: 0.072532
2025-09-03 17:51:45,022 - INFO - Epoch 3089/5000 - Train Loss: 0.082889, Val Loss: 0.073231
2025-09-03 17:52:30,980 - INFO - Epoch 3090/5000 - Train Loss: 0.084195, Val Loss: 0.073511
2025-09-03 17:53:13,658 - INFO - Epoch 3091/5000 - Train Loss: 0.083118, Val Loss: 0.072776
2025-09-03 17:53:55,352 - INFO - Epoch 3092/5000 - Train Loss: 0.083798, Val Loss: 0.072293
2025-09-03 17:54:39,190 - INFO - Epoch 3093/5000 - Train Loss: 0.084105, Val Loss: 0.073214
2025-09-03 17:55:22,314 - INFO - Epoch 3094/5000 - Train Loss: 0.083764, Val Loss: 0.074094
2025-09-03 17:56:03,959 - INFO - Epoch 3095/5000 - Train Loss: 0.083120, Val Loss: 0.073886
2025-09-03 17:56:50,261 - INFO - Epoch 3096/5000 - Train Loss: 0.083585, Val Loss: 0.073790
2025-09-03 17:57:32,688 - INFO - Epoch 3097/5000 - Train Loss: 0.083245, Val Loss: 0.073585
2025-09-03 17:58:08,797 - INFO - Epoch 3098/5000 - Train Loss: 0.083990, Val Loss: 0.074955
2025-09-03 17:58:45,122 - INFO - Epoch 3099/5000 - Train Loss: 0.083769, Val Loss: 0.071962
2025-09-03 17:59:21,533 - INFO - Epoch 3100/5000 - Train Loss: 0.083179, Val Loss: 0.072281
2025-09-03 17:59:58,788 - INFO - Epoch 3101/5000 - Train Loss: 0.084638, Val Loss: 0.074940
2025-09-03 18:00:34,479 - INFO - Epoch 3102/5000 - Train Loss: 0.083546, Val Loss: 0.080077
2025-09-03 18:01:10,609 - INFO - Epoch 3103/5000 - Train Loss: 0.084289, Val Loss: 0.073291
2025-09-03 18:01:46,876 - INFO - Epoch 3104/5000 - Train Loss: 0.083900, Val Loss: 0.074717
2025-09-03 18:02:23,353 - INFO - Epoch 3105/5000 - Train Loss: 0.082900, Val Loss: 0.074552
2025-09-03 18:02:59,251 - INFO - Epoch 3106/5000 - Train Loss: 0.083000, Val Loss: 0.075359
2025-09-03 18:03:37,290 - INFO - Epoch 3107/5000 - Train Loss: 0.083205, Val Loss: 0.072790
2025-09-03 18:04:14,046 - INFO - Epoch 3108/5000 - Train Loss: 0.083334, Val Loss: 0.074633
2025-09-03 18:04:50,881 - INFO - Epoch 3109/5000 - Train Loss: 0.083091, Val Loss: 0.074393
2025-09-03 18:05:27,904 - INFO - Epoch 3110/5000 - Train Loss: 0.084185, Val Loss: 0.073736
2025-09-03 18:06:05,965 - INFO - Epoch 3111/5000 - Train Loss: 0.082159, Val Loss: 0.071868
2025-09-03 18:06:43,162 - INFO - Epoch 3112/5000 - Train Loss: 0.081964, Val Loss: 0.072498
2025-09-03 18:07:20,201 - INFO - Epoch 3113/5000 - Train Loss: 0.082622, Val Loss: 0.074379
2025-09-03 18:07:56,767 - INFO - Epoch 3114/5000 - Train Loss: 0.083361, Val Loss: 0.074170
2025-09-03 18:08:33,514 - INFO - Epoch 3115/5000 - Train Loss: 0.084419, Val Loss: 0.072372
2025-09-03 18:09:09,712 - INFO - Epoch 3116/5000 - Train Loss: 0.082541, Val Loss: 0.072363
2025-09-03 18:09:45,324 - INFO - Epoch 3117/5000 - Train Loss: 0.083224, Val Loss: 0.073335
2025-09-03 18:10:21,225 - INFO - Epoch 3118/5000 - Train Loss: 0.082993, Val Loss: 0.073313
2025-09-03 18:10:57,812 - INFO - Epoch 3119/5000 - Train Loss: 0.084056, Val Loss: 0.071912
2025-09-03 18:11:34,004 - INFO - Epoch 3120/5000 - Train Loss: 0.083210, Val Loss: 0.073437
2025-09-03 18:12:10,952 - INFO - Epoch 3121/5000 - Train Loss: 0.083619, Val Loss: 0.072901
2025-09-03 18:12:47,122 - INFO - Epoch 3122/5000 - Train Loss: 0.082834, Val Loss: 0.073602
2025-09-03 18:13:23,181 - INFO - Epoch 3123/5000 - Train Loss: 0.083868, Val Loss: 0.073501
2025-09-03 18:14:00,472 - INFO - Epoch 3124/5000 - Train Loss: 0.083279, Val Loss: 0.072017
2025-09-03 18:14:36,687 - INFO - Epoch 3125/5000 - Train Loss: 0.082406, Val Loss: 0.072060
2025-09-03 18:15:13,204 - INFO - Epoch 3126/5000 - Train Loss: 0.082561, Val Loss: 0.072621
2025-09-03 18:15:49,204 - INFO - Epoch 3127/5000 - Train Loss: 0.083714, Val Loss: 0.073943
2025-09-03 18:16:26,288 - INFO - Epoch 3128/5000 - Train Loss: 0.083925, Val Loss: 0.074227
2025-09-03 18:17:02,741 - INFO - Epoch 3129/5000 - Train Loss: 0.083653, Val Loss: 0.075596
2025-09-03 18:17:39,072 - INFO - Epoch 3130/5000 - Train Loss: 0.083414, Val Loss: 0.072389
2025-09-03 18:18:15,574 - INFO - Epoch 3131/5000 - Train Loss: 0.082511, Val Loss: 0.072575
2025-09-03 18:18:51,305 - INFO - Epoch 3132/5000 - Train Loss: 0.082973, Val Loss: 0.076227
2025-09-03 18:19:28,360 - INFO - Epoch 3133/5000 - Train Loss: 0.082988, Val Loss: 0.073988
2025-09-03 18:20:05,043 - INFO - Epoch 3134/5000 - Train Loss: 0.082825, Val Loss: 0.073108
2025-09-03 18:20:42,059 - INFO - Epoch 3135/5000 - Train Loss: 0.083499, Val Loss: 0.080839
2025-09-03 18:21:16,931 - INFO - Epoch 3136/5000 - Train Loss: 0.084588, Val Loss: 0.073081
2025-09-03 18:21:53,229 - INFO - Epoch 3137/5000 - Train Loss: 0.082931, Val Loss: 0.073564
2025-09-03 18:22:30,254 - INFO - Epoch 3138/5000 - Train Loss: 0.083573, Val Loss: 0.074865
2025-09-03 18:23:06,470 - INFO - Epoch 3139/5000 - Train Loss: 0.083510, Val Loss: 0.071023
2025-09-03 18:23:06,529 - INFO - New best model saved with Val Loss: 0.071023
2025-09-03 18:23:42,369 - INFO - Epoch 3140/5000 - Train Loss: 0.081313, Val Loss: 0.072769
2025-09-03 18:24:17,877 - INFO - Epoch 3141/5000 - Train Loss: 0.083844, Val Loss: 0.072321
2025-09-03 18:24:55,032 - INFO - Epoch 3142/5000 - Train Loss: 0.083267, Val Loss: 0.073240
2025-09-03 18:25:32,026 - INFO - Epoch 3143/5000 - Train Loss: 0.082014, Val Loss: 0.072891
2025-09-03 18:26:08,543 - INFO - Epoch 3144/5000 - Train Loss: 0.083251, Val Loss: 0.072978
2025-09-03 18:26:44,784 - INFO - Epoch 3145/5000 - Train Loss: 0.082798, Val Loss: 0.073455
2025-09-03 18:27:21,144 - INFO - Epoch 3146/5000 - Train Loss: 0.082063, Val Loss: 0.072054
2025-09-03 18:27:56,477 - INFO - Epoch 3147/5000 - Train Loss: 0.082629, Val Loss: 0.075026
2025-09-03 18:28:32,514 - INFO - Epoch 3148/5000 - Train Loss: 0.082594, Val Loss: 0.073395
2025-09-03 18:29:08,427 - INFO - Epoch 3149/5000 - Train Loss: 0.083677, Val Loss: 0.073871
2025-09-03 18:29:45,281 - INFO - Epoch 3150/5000 - Train Loss: 0.082845, Val Loss: 0.072814
2025-09-03 18:30:21,562 - INFO - Epoch 3151/5000 - Train Loss: 0.082503, Val Loss: 0.071567
2025-09-03 18:30:57,167 - INFO - Epoch 3152/5000 - Train Loss: 0.081865, Val Loss: 0.073192
2025-09-03 18:31:32,934 - INFO - Epoch 3153/5000 - Train Loss: 0.083248, Val Loss: 0.072926
2025-09-03 18:32:09,112 - INFO - Epoch 3154/5000 - Train Loss: 0.082102, Val Loss: 0.071629
2025-09-03 18:32:45,664 - INFO - Epoch 3155/5000 - Train Loss: 0.083087, Val Loss: 0.074354
2025-09-03 18:33:22,018 - INFO - Epoch 3156/5000 - Train Loss: 0.082906, Val Loss: 0.074389
2025-09-03 18:33:57,533 - INFO - Epoch 3157/5000 - Train Loss: 0.082033, Val Loss: 0.072318
2025-09-03 18:34:35,004 - INFO - Epoch 3158/5000 - Train Loss: 0.082164, Val Loss: 0.072063
2025-09-03 18:35:11,406 - INFO - Epoch 3159/5000 - Train Loss: 0.082200, Val Loss: 0.071942
2025-09-03 18:35:47,298 - INFO - Epoch 3160/5000 - Train Loss: 0.081578, Val Loss: 0.074124
2025-09-03 18:36:25,462 - INFO - Epoch 3161/5000 - Train Loss: 0.083170, Val Loss: 0.072701
2025-09-03 18:37:03,602 - INFO - Epoch 3162/5000 - Train Loss: 0.082782, Val Loss: 0.072802
2025-09-03 18:37:39,748 - INFO - Epoch 3163/5000 - Train Loss: 0.082779, Val Loss: 0.074130
2025-09-03 18:38:16,596 - INFO - Epoch 3164/5000 - Train Loss: 0.082845, Val Loss: 0.072904
2025-09-03 18:38:52,699 - INFO - Epoch 3165/5000 - Train Loss: 0.082502, Val Loss: 0.072456
2025-09-03 18:39:29,140 - INFO - Epoch 3166/5000 - Train Loss: 0.083817, Val Loss: 0.075508
2025-09-03 18:40:04,832 - INFO - Epoch 3167/5000 - Train Loss: 0.082689, Val Loss: 0.075003
2025-09-03 18:40:41,408 - INFO - Epoch 3168/5000 - Train Loss: 0.082842, Val Loss: 0.073502
2025-09-03 18:41:17,501 - INFO - Epoch 3169/5000 - Train Loss: 0.081996, Val Loss: 0.072712
2025-09-03 18:41:54,073 - INFO - Epoch 3170/5000 - Train Loss: 0.082736, Val Loss: 0.071554
2025-09-03 18:42:31,155 - INFO - Epoch 3171/5000 - Train Loss: 0.082671, Val Loss: 0.073586
2025-09-03 18:43:08,624 - INFO - Epoch 3172/5000 - Train Loss: 0.082589, Val Loss: 0.074500
2025-09-03 18:43:45,251 - INFO - Epoch 3173/5000 - Train Loss: 0.083436, Val Loss: 0.073321
2025-09-03 18:44:22,229 - INFO - Epoch 3174/5000 - Train Loss: 0.083261, Val Loss: 0.074227
2025-09-03 18:44:59,328 - INFO - Epoch 3175/5000 - Train Loss: 0.083660, Val Loss: 0.076207
2025-09-03 18:45:35,939 - INFO - Epoch 3176/5000 - Train Loss: 0.082250, Val Loss: 0.073099
2025-09-03 18:46:12,205 - INFO - Epoch 3177/5000 - Train Loss: 0.082224, Val Loss: 0.070998
2025-09-03 18:46:12,256 - INFO - New best model saved with Val Loss: 0.070998
2025-09-03 18:46:49,833 - INFO - Epoch 3178/5000 - Train Loss: 0.083302, Val Loss: 0.073222
2025-09-03 18:47:26,922 - INFO - Epoch 3179/5000 - Train Loss: 0.082145, Val Loss: 0.072695
2025-09-03 18:48:06,004 - INFO - Epoch 3180/5000 - Train Loss: 0.081910, Val Loss: 0.077163
2025-09-03 18:48:43,491 - INFO - Epoch 3181/5000 - Train Loss: 0.083779, Val Loss: 0.072983
2025-09-03 18:49:19,876 - INFO - Epoch 3182/5000 - Train Loss: 0.081832, Val Loss: 0.070745
2025-09-03 18:49:19,922 - INFO - New best model saved with Val Loss: 0.070745
2025-09-03 18:49:57,168 - INFO - Epoch 3183/5000 - Train Loss: 0.082196, Val Loss: 0.071216
2025-09-03 18:50:34,429 - INFO - Epoch 3184/5000 - Train Loss: 0.081692, Val Loss: 0.072978
2025-09-03 18:51:11,856 - INFO - Epoch 3185/5000 - Train Loss: 0.082132, Val Loss: 0.073766
2025-09-03 18:51:48,439 - INFO - Epoch 3186/5000 - Train Loss: 0.083678, Val Loss: 0.072088
2025-09-03 18:52:25,499 - INFO - Epoch 3187/5000 - Train Loss: 0.082199, Val Loss: 0.072528
2025-09-03 18:53:02,585 - INFO - Epoch 3188/5000 - Train Loss: 0.081930, Val Loss: 0.072222
2025-09-03 18:53:39,603 - INFO - Epoch 3189/5000 - Train Loss: 0.081461, Val Loss: 0.071768
2025-09-03 18:54:15,805 - INFO - Epoch 3190/5000 - Train Loss: 0.083191, Val Loss: 0.074055
2025-09-03 18:54:53,259 - INFO - Epoch 3191/5000 - Train Loss: 0.082559, Val Loss: 0.074383
2025-09-03 18:55:30,451 - INFO - Epoch 3192/5000 - Train Loss: 0.082692, Val Loss: 0.071932
2025-09-03 18:56:07,794 - INFO - Epoch 3193/5000 - Train Loss: 0.081490, Val Loss: 0.071853
2025-09-03 18:56:46,501 - INFO - Epoch 3194/5000 - Train Loss: 0.082637, Val Loss: 0.073684
2025-09-03 18:57:23,911 - INFO - Epoch 3195/5000 - Train Loss: 0.083147, Val Loss: 0.071042
2025-09-03 18:58:00,922 - INFO - Epoch 3196/5000 - Train Loss: 0.081842, Val Loss: 0.075691
2025-09-03 18:58:38,274 - INFO - Epoch 3197/5000 - Train Loss: 0.082847, Val Loss: 0.072594
2025-09-03 18:59:16,193 - INFO - Epoch 3198/5000 - Train Loss: 0.081955, Val Loss: 0.071610
2025-09-03 18:59:53,738 - INFO - Epoch 3199/5000 - Train Loss: 0.081933, Val Loss: 0.072556
2025-09-03 19:00:29,581 - INFO - Epoch 3200/5000 - Train Loss: 0.081616, Val Loss: 0.070989
2025-09-03 19:01:06,186 - INFO - Epoch 3201/5000 - Train Loss: 0.080891, Val Loss: 0.071565
2025-09-03 19:01:43,556 - INFO - Epoch 3202/5000 - Train Loss: 0.081994, Val Loss: 0.072580
2025-09-03 19:02:20,035 - INFO - Epoch 3203/5000 - Train Loss: 0.082028, Val Loss: 0.073932
2025-09-03 19:02:57,581 - INFO - Epoch 3204/5000 - Train Loss: 0.082269, Val Loss: 0.074276
2025-09-03 19:03:34,048 - INFO - Epoch 3205/5000 - Train Loss: 0.083105, Val Loss: 0.072386
2025-09-03 19:04:11,892 - INFO - Epoch 3206/5000 - Train Loss: 0.082546, Val Loss: 0.071834
2025-09-03 19:04:50,416 - INFO - Epoch 3207/5000 - Train Loss: 0.081389, Val Loss: 0.074343
2025-09-03 19:05:28,522 - INFO - Epoch 3208/5000 - Train Loss: 0.082396, Val Loss: 0.071946
2025-09-03 19:06:05,471 - INFO - Epoch 3209/5000 - Train Loss: 0.082408, Val Loss: 0.072120
2025-09-03 19:06:42,307 - INFO - Epoch 3210/5000 - Train Loss: 0.082556, Val Loss: 0.072372
2025-09-03 19:07:19,033 - INFO - Epoch 3211/5000 - Train Loss: 0.082205, Val Loss: 0.071327
2025-09-03 19:07:56,214 - INFO - Epoch 3212/5000 - Train Loss: 0.082140, Val Loss: 0.073661
2025-09-03 19:08:36,769 - INFO - Epoch 3213/5000 - Train Loss: 0.081731, Val Loss: 0.071151
2025-09-03 19:09:14,683 - INFO - Epoch 3214/5000 - Train Loss: 0.081181, Val Loss: 0.074023
2025-09-03 19:09:52,337 - INFO - Epoch 3215/5000 - Train Loss: 0.082270, Val Loss: 0.074158
2025-09-03 19:10:30,058 - INFO - Epoch 3216/5000 - Train Loss: 0.082254, Val Loss: 0.071429
2025-09-03 19:11:07,333 - INFO - Epoch 3217/5000 - Train Loss: 0.081996, Val Loss: 0.072363
2025-09-03 19:11:43,911 - INFO - Epoch 3218/5000 - Train Loss: 0.081785, Val Loss: 0.073162
2025-09-03 19:12:21,498 - INFO - Epoch 3219/5000 - Train Loss: 0.081548, Val Loss: 0.072025
2025-09-03 19:12:58,579 - INFO - Epoch 3220/5000 - Train Loss: 0.081295, Val Loss: 0.071930
2025-09-03 19:13:35,926 - INFO - Epoch 3221/5000 - Train Loss: 0.082842, Val Loss: 0.072754
2025-09-03 19:14:13,860 - INFO - Epoch 3222/5000 - Train Loss: 0.082463, Val Loss: 0.073331
2025-09-03 19:14:53,743 - INFO - Epoch 3223/5000 - Train Loss: 0.081543, Val Loss: 0.071637
2025-09-03 19:15:32,121 - INFO - Epoch 3224/5000 - Train Loss: 0.081765, Val Loss: 0.070337
2025-09-03 19:15:32,190 - INFO - New best model saved with Val Loss: 0.070337
2025-09-03 19:16:09,906 - INFO - Epoch 3225/5000 - Train Loss: 0.082835, Val Loss: 0.072479
2025-09-03 19:16:47,597 - INFO - Epoch 3226/5000 - Train Loss: 0.082183, Val Loss: 0.073136
2025-09-03 19:17:25,694 - INFO - Epoch 3227/5000 - Train Loss: 0.081734, Val Loss: 0.070953
2025-09-03 19:18:04,620 - INFO - Epoch 3228/5000 - Train Loss: 0.081874, Val Loss: 0.070748
2025-09-03 19:18:41,841 - INFO - Epoch 3229/5000 - Train Loss: 0.081187, Val Loss: 0.071369
2025-09-03 19:19:19,478 - INFO - Epoch 3230/5000 - Train Loss: 0.082147, Val Loss: 0.072939
2025-09-03 19:19:57,098 - INFO - Epoch 3231/5000 - Train Loss: 0.082446, Val Loss: 0.070723
2025-09-03 19:20:34,246 - INFO - Epoch 3232/5000 - Train Loss: 0.081140, Val Loss: 0.072573
2025-09-03 19:21:11,322 - INFO - Epoch 3233/5000 - Train Loss: 0.081268, Val Loss: 0.070911
2025-09-03 19:21:47,797 - INFO - Epoch 3234/5000 - Train Loss: 0.081875, Val Loss: 0.072532
2025-09-03 19:22:25,652 - INFO - Epoch 3235/5000 - Train Loss: 0.081357, Val Loss: 0.071612
2025-09-03 19:23:02,279 - INFO - Epoch 3236/5000 - Train Loss: 0.081093, Val Loss: 0.072198
2025-09-03 19:23:39,474 - INFO - Epoch 3237/5000 - Train Loss: 0.081456, Val Loss: 0.071646
2025-09-03 19:24:16,348 - INFO - Epoch 3238/5000 - Train Loss: 0.081667, Val Loss: 0.072739
2025-09-03 19:24:54,252 - INFO - Epoch 3239/5000 - Train Loss: 0.082148, Val Loss: 0.071160
2025-09-03 19:25:31,697 - INFO - Epoch 3240/5000 - Train Loss: 0.080946, Val Loss: 0.072222
2025-09-03 19:26:08,441 - INFO - Epoch 3241/5000 - Train Loss: 0.082003, Val Loss: 0.077916
2025-09-03 19:26:44,545 - INFO - Epoch 3242/5000 - Train Loss: 0.082257, Val Loss: 0.070872
2025-09-03 19:27:21,736 - INFO - Epoch 3243/5000 - Train Loss: 0.081579, Val Loss: 0.070755
2025-09-03 19:27:58,953 - INFO - Epoch 3244/5000 - Train Loss: 0.081727, Val Loss: 0.071016
2025-09-03 19:28:35,580 - INFO - Epoch 3245/5000 - Train Loss: 0.080849, Val Loss: 0.069755
2025-09-03 19:28:35,646 - INFO - New best model saved with Val Loss: 0.069755
2025-09-03 19:29:12,454 - INFO - Epoch 3246/5000 - Train Loss: 0.081107, Val Loss: 0.073564
2025-09-03 19:29:49,789 - INFO - Epoch 3247/5000 - Train Loss: 0.081473, Val Loss: 0.072458
2025-09-03 19:30:26,158 - INFO - Epoch 3248/5000 - Train Loss: 0.080473, Val Loss: 0.071086
2025-09-03 19:31:03,596 - INFO - Epoch 3249/5000 - Train Loss: 0.081353, Val Loss: 0.072178
2025-09-03 19:31:40,283 - INFO - Epoch 3250/5000 - Train Loss: 0.081664, Val Loss: 0.073788
2025-09-03 19:32:17,694 - INFO - Epoch 3251/5000 - Train Loss: 0.080848, Val Loss: 0.071148
2025-09-03 19:32:54,487 - INFO - Epoch 3252/5000 - Train Loss: 0.082159, Val Loss: 0.072997
2025-09-03 19:33:30,701 - INFO - Epoch 3253/5000 - Train Loss: 0.081035, Val Loss: 0.072731
2025-09-03 19:34:08,055 - INFO - Epoch 3254/5000 - Train Loss: 0.081220, Val Loss: 0.073198
2025-09-03 19:34:45,796 - INFO - Epoch 3255/5000 - Train Loss: 0.081433, Val Loss: 0.071803
2025-09-03 19:35:22,399 - INFO - Epoch 3256/5000 - Train Loss: 0.081244, Val Loss: 0.072642
2025-09-03 19:35:59,352 - INFO - Epoch 3257/5000 - Train Loss: 0.082119, Val Loss: 0.071537
2025-09-03 19:36:36,950 - INFO - Epoch 3258/5000 - Train Loss: 0.081025, Val Loss: 0.070628
2025-09-03 19:37:15,573 - INFO - Epoch 3259/5000 - Train Loss: 0.080887, Val Loss: 0.070812
2025-09-03 19:37:52,417 - INFO - Epoch 3260/5000 - Train Loss: 0.081547, Val Loss: 0.072147
2025-09-03 19:38:30,228 - INFO - Epoch 3261/5000 - Train Loss: 0.080967, Val Loss: 0.074715
2025-09-03 19:39:06,052 - INFO - Epoch 3262/5000 - Train Loss: 0.081588, Val Loss: 0.070499
2025-09-03 19:39:42,673 - INFO - Epoch 3263/5000 - Train Loss: 0.080769, Val Loss: 0.070764
2025-09-03 19:40:19,045 - INFO - Epoch 3264/5000 - Train Loss: 0.081694, Val Loss: 0.070485
2025-09-03 19:40:56,158 - INFO - Epoch 3265/5000 - Train Loss: 0.081461, Val Loss: 0.071895
2025-09-03 19:41:33,112 - INFO - Epoch 3266/5000 - Train Loss: 0.081671, Val Loss: 0.075090
2025-09-03 19:42:10,733 - INFO - Epoch 3267/5000 - Train Loss: 0.082223, Val Loss: 0.070958
2025-09-03 19:42:48,341 - INFO - Epoch 3268/5000 - Train Loss: 0.081888, Val Loss: 0.072712
2025-09-03 19:43:25,736 - INFO - Epoch 3269/5000 - Train Loss: 0.081399, Val Loss: 0.072504
2025-09-03 19:44:02,179 - INFO - Epoch 3270/5000 - Train Loss: 0.080632, Val Loss: 0.070133
2025-09-03 19:44:39,357 - INFO - Epoch 3271/5000 - Train Loss: 0.080768, Val Loss: 0.073096
2025-09-03 19:45:16,716 - INFO - Epoch 3272/5000 - Train Loss: 0.081163, Val Loss: 0.070667
2025-09-03 19:45:53,247 - INFO - Epoch 3273/5000 - Train Loss: 0.080587, Val Loss: 0.072562
2025-09-03 19:46:29,529 - INFO - Epoch 3274/5000 - Train Loss: 0.080713, Val Loss: 0.070595
2025-09-03 19:47:06,186 - INFO - Epoch 3275/5000 - Train Loss: 0.081222, Val Loss: 0.075221
2025-09-03 19:47:42,135 - INFO - Epoch 3276/5000 - Train Loss: 0.081701, Val Loss: 0.072497
2025-09-03 19:48:17,651 - INFO - Epoch 3277/5000 - Train Loss: 0.081084, Val Loss: 0.072443
2025-09-03 19:48:54,433 - INFO - Epoch 3278/5000 - Train Loss: 0.080414, Val Loss: 0.070188
2025-09-03 19:49:31,720 - INFO - Epoch 3279/5000 - Train Loss: 0.081486, Val Loss: 0.070073
2025-09-03 19:50:08,871 - INFO - Epoch 3280/5000 - Train Loss: 0.080465, Val Loss: 0.072179
2025-09-03 19:50:46,935 - INFO - Epoch 3281/5000 - Train Loss: 0.082183, Val Loss: 0.071451
2025-09-03 19:51:23,111 - INFO - Epoch 3282/5000 - Train Loss: 0.081799, Val Loss: 0.072457
2025-09-03 19:52:00,940 - INFO - Epoch 3283/5000 - Train Loss: 0.080924, Val Loss: 0.070621
2025-09-03 19:52:39,323 - INFO - Epoch 3284/5000 - Train Loss: 0.079825, Val Loss: 0.070731
2025-09-03 19:53:16,206 - INFO - Epoch 3285/5000 - Train Loss: 0.080584, Val Loss: 0.071060
2025-09-03 19:53:52,729 - INFO - Epoch 3286/5000 - Train Loss: 0.081294, Val Loss: 0.072581
2025-09-03 19:54:30,356 - INFO - Epoch 3287/5000 - Train Loss: 0.081841, Val Loss: 0.073735
2025-09-03 19:55:07,872 - INFO - Epoch 3288/5000 - Train Loss: 0.080793, Val Loss: 0.071076
2025-09-03 19:55:44,675 - INFO - Epoch 3289/5000 - Train Loss: 0.080840, Val Loss: 0.071219
2025-09-03 19:56:21,573 - INFO - Epoch 3290/5000 - Train Loss: 0.082025, Val Loss: 0.071211
2025-09-03 19:56:59,874 - INFO - Epoch 3291/5000 - Train Loss: 0.081609, Val Loss: 0.071368
2025-09-03 19:57:38,395 - INFO - Epoch 3292/5000 - Train Loss: 0.080774, Val Loss: 0.070415
2025-09-03 19:58:16,040 - INFO - Epoch 3293/5000 - Train Loss: 0.081076, Val Loss: 0.070322
2025-09-03 19:58:54,238 - INFO - Epoch 3294/5000 - Train Loss: 0.081136, Val Loss: 0.071731
2025-09-03 19:59:31,562 - INFO - Epoch 3295/5000 - Train Loss: 0.080508, Val Loss: 0.071192
2025-09-03 20:00:08,463 - INFO - Epoch 3296/5000 - Train Loss: 0.080190, Val Loss: 0.070525
2025-09-03 20:00:46,019 - INFO - Epoch 3297/5000 - Train Loss: 0.080686, Val Loss: 0.073225
2025-09-03 20:01:22,225 - INFO - Epoch 3298/5000 - Train Loss: 0.081753, Val Loss: 0.072804
2025-09-03 20:01:59,180 - INFO - Epoch 3299/5000 - Train Loss: 0.080864, Val Loss: 0.070872
2025-09-03 20:02:37,428 - INFO - Epoch 3300/5000 - Train Loss: 0.081061, Val Loss: 0.071104
2025-09-03 20:03:15,596 - INFO - Epoch 3301/5000 - Train Loss: 0.081156, Val Loss: 0.073260
2025-09-03 20:03:51,819 - INFO - Epoch 3302/5000 - Train Loss: 0.081097, Val Loss: 0.071353
2025-09-03 20:04:28,405 - INFO - Epoch 3303/5000 - Train Loss: 0.081077, Val Loss: 0.070799
2025-09-03 20:05:05,277 - INFO - Epoch 3304/5000 - Train Loss: 0.080607, Val Loss: 0.070673
2025-09-03 20:05:42,881 - INFO - Epoch 3305/5000 - Train Loss: 0.080580, Val Loss: 0.070387
2025-09-03 20:06:19,510 - INFO - Epoch 3306/5000 - Train Loss: 0.080077, Val Loss: 0.069715
2025-09-03 20:06:19,599 - INFO - New best model saved with Val Loss: 0.069715
2025-09-03 20:06:55,828 - INFO - Epoch 3307/5000 - Train Loss: 0.080250, Val Loss: 0.071646
2025-09-03 20:07:31,563 - INFO - Epoch 3308/5000 - Train Loss: 0.080270, Val Loss: 0.071657
2025-09-03 20:08:08,084 - INFO - Epoch 3309/5000 - Train Loss: 0.080650, Val Loss: 0.074386
2025-09-03 20:08:44,999 - INFO - Epoch 3310/5000 - Train Loss: 0.080303, Val Loss: 0.072646
2025-09-03 20:09:22,853 - INFO - Epoch 3311/5000 - Train Loss: 0.081614, Val Loss: 0.071854
2025-09-03 20:09:59,508 - INFO - Epoch 3312/5000 - Train Loss: 0.080591, Val Loss: 0.071824
2025-09-03 20:10:38,153 - INFO - Epoch 3313/5000 - Train Loss: 0.080436, Val Loss: 0.073119
2025-09-03 20:11:15,823 - INFO - Epoch 3314/5000 - Train Loss: 0.080560, Val Loss: 0.072416
2025-09-03 20:11:51,823 - INFO - Epoch 3315/5000 - Train Loss: 0.080353, Val Loss: 0.070091
2025-09-03 20:12:28,147 - INFO - Epoch 3316/5000 - Train Loss: 0.081237, Val Loss: 0.072424
2025-09-03 20:13:05,785 - INFO - Epoch 3317/5000 - Train Loss: 0.080919, Val Loss: 0.069643
2025-09-03 20:13:05,856 - INFO - New best model saved with Val Loss: 0.069643
2025-09-03 20:13:43,387 - INFO - Epoch 3318/5000 - Train Loss: 0.081109, Val Loss: 0.070307
2025-09-03 20:14:19,907 - INFO - Epoch 3319/5000 - Train Loss: 0.080715, Val Loss: 0.072321
2025-09-03 20:14:56,398 - INFO - Epoch 3320/5000 - Train Loss: 0.079933, Val Loss: 0.071770
2025-09-03 20:15:33,344 - INFO - Epoch 3321/5000 - Train Loss: 0.080380, Val Loss: 0.071135
2025-09-03 20:16:09,029 - INFO - Epoch 3322/5000 - Train Loss: 0.080849, Val Loss: 0.071072
2025-09-03 20:16:44,391 - INFO - Epoch 3323/5000 - Train Loss: 0.080766, Val Loss: 0.072125
2025-09-03 20:17:20,738 - INFO - Epoch 3324/5000 - Train Loss: 0.080558, Val Loss: 0.069611
2025-09-03 20:17:20,801 - INFO - New best model saved with Val Loss: 0.069611
2025-09-03 20:17:57,474 - INFO - Epoch 3325/5000 - Train Loss: 0.080015, Val Loss: 0.069514
2025-09-03 20:17:57,554 - INFO - New best model saved with Val Loss: 0.069514
2025-09-03 20:18:33,882 - INFO - Epoch 3326/5000 - Train Loss: 0.080393, Val Loss: 0.070243
2025-09-03 20:19:09,371 - INFO - Epoch 3327/5000 - Train Loss: 0.081454, Val Loss: 0.072572
2025-09-03 20:19:45,636 - INFO - Epoch 3328/5000 - Train Loss: 0.082790, Val Loss: 0.070135
2025-09-03 20:20:22,315 - INFO - Epoch 3329/5000 - Train Loss: 0.080611, Val Loss: 0.074050
2025-09-03 20:20:59,127 - INFO - Epoch 3330/5000 - Train Loss: 0.081968, Val Loss: 0.071700
2025-09-03 20:21:34,900 - INFO - Epoch 3331/5000 - Train Loss: 0.080587, Val Loss: 0.070314
2025-09-03 20:22:11,339 - INFO - Epoch 3332/5000 - Train Loss: 0.081274, Val Loss: 0.073421
2025-09-03 20:22:47,717 - INFO - Epoch 3333/5000 - Train Loss: 0.081101, Val Loss: 0.070351
2025-09-03 20:23:24,276 - INFO - Epoch 3334/5000 - Train Loss: 0.079418, Val Loss: 0.070985
2025-09-03 20:24:00,502 - INFO - Epoch 3335/5000 - Train Loss: 0.080062, Val Loss: 0.072483
2025-09-03 20:24:36,751 - INFO - Epoch 3336/5000 - Train Loss: 0.080297, Val Loss: 0.069778
2025-09-03 20:25:12,452 - INFO - Epoch 3337/5000 - Train Loss: 0.079704, Val Loss: 0.072714
2025-09-03 20:25:49,074 - INFO - Epoch 3338/5000 - Train Loss: 0.080397, Val Loss: 0.070004
2025-09-03 20:26:26,667 - INFO - Epoch 3339/5000 - Train Loss: 0.079156, Val Loss: 0.070290
2025-09-03 20:27:02,431 - INFO - Epoch 3340/5000 - Train Loss: 0.080370, Val Loss: 0.070554
2025-09-03 20:27:39,515 - INFO - Epoch 3341/5000 - Train Loss: 0.078502, Val Loss: 0.072337
2025-09-03 20:28:16,127 - INFO - Epoch 3342/5000 - Train Loss: 0.081113, Val Loss: 0.070265
2025-09-03 20:28:53,064 - INFO - Epoch 3343/5000 - Train Loss: 0.080703, Val Loss: 0.070528
2025-09-03 20:29:29,471 - INFO - Epoch 3344/5000 - Train Loss: 0.080042, Val Loss: 0.071527
2025-09-03 20:30:05,559 - INFO - Epoch 3345/5000 - Train Loss: 0.079845, Val Loss: 0.071371
2025-09-03 20:30:41,910 - INFO - Epoch 3346/5000 - Train Loss: 0.080197, Val Loss: 0.071033
2025-09-03 20:31:18,607 - INFO - Epoch 3347/5000 - Train Loss: 0.078793, Val Loss: 0.068930
2025-09-03 20:31:18,668 - INFO - New best model saved with Val Loss: 0.068930
2025-09-03 20:31:55,806 - INFO - Epoch 3348/5000 - Train Loss: 0.080221, Val Loss: 0.070226
2025-09-03 20:32:32,349 - INFO - Epoch 3349/5000 - Train Loss: 0.079996, Val Loss: 0.072175
2025-09-03 20:33:08,496 - INFO - Epoch 3350/5000 - Train Loss: 0.080504, Val Loss: 0.072048
2025-09-03 20:33:45,282 - INFO - Epoch 3351/5000 - Train Loss: 0.080423, Val Loss: 0.070257
2025-09-03 20:34:21,783 - INFO - Epoch 3352/5000 - Train Loss: 0.080164, Val Loss: 0.069518
2025-09-03 20:34:57,905 - INFO - Epoch 3353/5000 - Train Loss: 0.079912, Val Loss: 0.070863
2025-09-03 20:35:34,020 - INFO - Epoch 3354/5000 - Train Loss: 0.079049, Val Loss: 0.072688
2025-09-03 20:36:09,726 - INFO - Epoch 3355/5000 - Train Loss: 0.080847, Val Loss: 0.070622
2025-09-03 20:36:45,275 - INFO - Epoch 3356/5000 - Train Loss: 0.079890, Val Loss: 0.070410
2025-09-03 20:37:21,189 - INFO - Epoch 3357/5000 - Train Loss: 0.078918, Val Loss: 0.069723
2025-09-03 20:37:57,229 - INFO - Epoch 3358/5000 - Train Loss: 0.080235, Val Loss: 0.070628
2025-09-03 20:38:32,680 - INFO - Epoch 3359/5000 - Train Loss: 0.079752, Val Loss: 0.070308
2025-09-03 20:39:08,841 - INFO - Epoch 3360/5000 - Train Loss: 0.079858, Val Loss: 0.070488
2025-09-03 20:39:44,763 - INFO - Epoch 3361/5000 - Train Loss: 0.079769, Val Loss: 0.071049
2025-09-03 20:40:19,745 - INFO - Epoch 3362/5000 - Train Loss: 0.080707, Val Loss: 0.070675
2025-09-03 20:40:55,415 - INFO - Epoch 3363/5000 - Train Loss: 0.081026, Val Loss: 0.068545
2025-09-03 20:40:55,462 - INFO - New best model saved with Val Loss: 0.068545
2025-09-03 20:41:31,811 - INFO - Epoch 3364/5000 - Train Loss: 0.080690, Val Loss: 0.070954
2025-09-03 20:42:08,676 - INFO - Epoch 3365/5000 - Train Loss: 0.079104, Val Loss: 0.070487
2025-09-03 20:42:44,876 - INFO - Epoch 3366/5000 - Train Loss: 0.079449, Val Loss: 0.071031
2025-09-03 20:43:21,466 - INFO - Epoch 3367/5000 - Train Loss: 0.080954, Val Loss: 0.071119
2025-09-03 20:43:57,705 - INFO - Epoch 3368/5000 - Train Loss: 0.080343, Val Loss: 0.070487
2025-09-03 20:44:33,769 - INFO - Epoch 3369/5000 - Train Loss: 0.080732, Val Loss: 0.076357
2025-09-03 20:45:09,730 - INFO - Epoch 3370/5000 - Train Loss: 0.081255, Val Loss: 0.068884
2025-09-03 20:45:45,692 - INFO - Epoch 3371/5000 - Train Loss: 0.080745, Val Loss: 0.069180
2025-09-03 20:46:21,834 - INFO - Epoch 3372/5000 - Train Loss: 0.079239, Val Loss: 0.068830
2025-09-03 20:46:58,660 - INFO - Epoch 3373/5000 - Train Loss: 0.079374, Val Loss: 0.070362
2025-09-03 20:47:35,626 - INFO - Epoch 3374/5000 - Train Loss: 0.079386, Val Loss: 0.072392
2025-09-03 20:48:12,128 - INFO - Epoch 3375/5000 - Train Loss: 0.079967, Val Loss: 0.071069
2025-09-03 20:48:48,767 - INFO - Epoch 3376/5000 - Train Loss: 0.080132, Val Loss: 0.069256
2025-09-03 20:49:24,358 - INFO - Epoch 3377/5000 - Train Loss: 0.078532, Val Loss: 0.069993
2025-09-03 20:50:00,110 - INFO - Epoch 3378/5000 - Train Loss: 0.079260, Val Loss: 0.069575
2025-09-03 20:50:35,935 - INFO - Epoch 3379/5000 - Train Loss: 0.079203, Val Loss: 0.069532
2025-09-03 20:51:12,104 - INFO - Epoch 3380/5000 - Train Loss: 0.080215, Val Loss: 0.069448
2025-09-03 20:51:48,545 - INFO - Epoch 3381/5000 - Train Loss: 0.079208, Val Loss: 0.070303
2025-09-03 20:52:24,589 - INFO - Epoch 3382/5000 - Train Loss: 0.079820, Val Loss: 0.070312
2025-09-03 20:53:01,140 - INFO - Epoch 3383/5000 - Train Loss: 0.079752, Val Loss: 0.069749
2025-09-03 20:53:38,046 - INFO - Epoch 3384/5000 - Train Loss: 0.080034, Val Loss: 0.070860
2025-09-03 20:54:13,981 - INFO - Epoch 3385/5000 - Train Loss: 0.078781, Val Loss: 0.070543
2025-09-03 20:54:50,341 - INFO - Epoch 3386/5000 - Train Loss: 0.079868, Val Loss: 0.071266
2025-09-03 20:55:26,562 - INFO - Epoch 3387/5000 - Train Loss: 0.079818, Val Loss: 0.072139
2025-09-03 20:56:02,769 - INFO - Epoch 3388/5000 - Train Loss: 0.081015, Val Loss: 0.071375
2025-09-03 20:56:39,477 - INFO - Epoch 3389/5000 - Train Loss: 0.080083, Val Loss: 0.071588
2025-09-03 20:57:15,778 - INFO - Epoch 3390/5000 - Train Loss: 0.079802, Val Loss: 0.070336
2025-09-03 20:57:52,162 - INFO - Epoch 3391/5000 - Train Loss: 0.079890, Val Loss: 0.071454
2025-09-03 20:58:28,163 - INFO - Epoch 3392/5000 - Train Loss: 0.079727, Val Loss: 0.070620
2025-09-03 20:59:04,491 - INFO - Epoch 3393/5000 - Train Loss: 0.079080, Val Loss: 0.069839
2025-09-03 20:59:40,801 - INFO - Epoch 3394/5000 - Train Loss: 0.079192, Val Loss: 0.070036
2025-09-03 21:00:17,134 - INFO - Epoch 3395/5000 - Train Loss: 0.079814, Val Loss: 0.073505
2025-09-03 21:00:53,101 - INFO - Epoch 3396/5000 - Train Loss: 0.079595, Val Loss: 0.070211
2025-09-03 21:01:28,744 - INFO - Epoch 3397/5000 - Train Loss: 0.079412, Val Loss: 0.069974
2025-09-03 21:02:05,588 - INFO - Epoch 3398/5000 - Train Loss: 0.078865, Val Loss: 0.070861
2025-09-03 21:02:41,971 - INFO - Epoch 3399/5000 - Train Loss: 0.079422, Val Loss: 0.070862
2025-09-03 21:03:19,008 - INFO - Epoch 3400/5000 - Train Loss: 0.079876, Val Loss: 0.069232
2025-09-03 21:03:56,125 - INFO - Epoch 3401/5000 - Train Loss: 0.079687, Val Loss: 0.071590
2025-09-03 21:04:31,932 - INFO - Epoch 3402/5000 - Train Loss: 0.080306, Val Loss: 0.070081
2025-09-03 21:05:08,297 - INFO - Epoch 3403/5000 - Train Loss: 0.079316, Val Loss: 0.069324
2025-09-03 21:05:44,697 - INFO - Epoch 3404/5000 - Train Loss: 0.079183, Val Loss: 0.072403
2025-09-03 21:06:21,043 - INFO - Epoch 3405/5000 - Train Loss: 0.080748, Val Loss: 0.072957
2025-09-03 21:06:56,913 - INFO - Epoch 3406/5000 - Train Loss: 0.082107, Val Loss: 0.069656
2025-09-03 21:07:33,018 - INFO - Epoch 3407/5000 - Train Loss: 0.079218, Val Loss: 0.069881
2025-09-03 21:08:09,041 - INFO - Epoch 3408/5000 - Train Loss: 0.079542, Val Loss: 0.069739
2025-09-03 21:08:45,087 - INFO - Epoch 3409/5000 - Train Loss: 0.079765, Val Loss: 0.072471
2025-09-03 21:09:20,730 - INFO - Epoch 3410/5000 - Train Loss: 0.080651, Val Loss: 0.071235
2025-09-03 21:09:57,159 - INFO - Epoch 3411/5000 - Train Loss: 0.079688, Val Loss: 0.069150
2025-09-03 21:10:33,226 - INFO - Epoch 3412/5000 - Train Loss: 0.079229, Val Loss: 0.071553
2025-09-03 21:11:09,889 - INFO - Epoch 3413/5000 - Train Loss: 0.079121, Val Loss: 0.071348
2025-09-03 21:11:46,631 - INFO - Epoch 3414/5000 - Train Loss: 0.078954, Val Loss: 0.070187
2025-09-03 21:12:22,670 - INFO - Epoch 3415/5000 - Train Loss: 0.079209, Val Loss: 0.069219
2025-09-03 21:12:58,782 - INFO - Epoch 3416/5000 - Train Loss: 0.079917, Val Loss: 0.071199
2025-09-03 21:13:34,708 - INFO - Epoch 3417/5000 - Train Loss: 0.079104, Val Loss: 0.069472
2025-09-03 21:14:10,215 - INFO - Epoch 3418/5000 - Train Loss: 0.078711, Val Loss: 0.069247
2025-09-03 21:14:46,111 - INFO - Epoch 3419/5000 - Train Loss: 0.078764, Val Loss: 0.069655
2025-09-03 21:15:22,122 - INFO - Epoch 3420/5000 - Train Loss: 0.079170, Val Loss: 0.072512
2025-09-03 21:15:58,646 - INFO - Epoch 3421/5000 - Train Loss: 0.079540, Val Loss: 0.069196
2025-09-03 21:16:34,950 - INFO - Epoch 3422/5000 - Train Loss: 0.078742, Val Loss: 0.071236
2025-09-03 21:17:10,720 - INFO - Epoch 3423/5000 - Train Loss: 0.080824, Val Loss: 0.071003
2025-09-03 21:17:46,996 - INFO - Epoch 3424/5000 - Train Loss: 0.079009, Val Loss: 0.070533
2025-09-03 21:18:22,557 - INFO - Epoch 3425/5000 - Train Loss: 0.078501, Val Loss: 0.069666
2025-09-03 21:18:58,536 - INFO - Epoch 3426/5000 - Train Loss: 0.078790, Val Loss: 0.069615
2025-09-03 21:19:34,522 - INFO - Epoch 3427/5000 - Train Loss: 0.079976, Val Loss: 0.072127
2025-09-03 21:20:10,609 - INFO - Epoch 3428/5000 - Train Loss: 0.078836, Val Loss: 0.068987
2025-09-03 21:20:46,692 - INFO - Epoch 3429/5000 - Train Loss: 0.078756, Val Loss: 0.069645
2025-09-03 21:21:22,796 - INFO - Epoch 3430/5000 - Train Loss: 0.079191, Val Loss: 0.070544
2025-09-03 21:21:58,307 - INFO - Epoch 3431/5000 - Train Loss: 0.079762, Val Loss: 0.070251
2025-09-03 21:22:34,767 - INFO - Epoch 3432/5000 - Train Loss: 0.078482, Val Loss: 0.069632
2025-09-03 21:23:11,171 - INFO - Epoch 3433/5000 - Train Loss: 0.079272, Val Loss: 0.070136
2025-09-03 21:23:47,669 - INFO - Epoch 3434/5000 - Train Loss: 0.079407, Val Loss: 0.068027
2025-09-03 21:23:47,712 - INFO - New best model saved with Val Loss: 0.068027
2025-09-03 21:24:24,016 - INFO - Epoch 3435/5000 - Train Loss: 0.079453, Val Loss: 0.070195
2025-09-03 21:24:59,885 - INFO - Epoch 3436/5000 - Train Loss: 0.078393, Val Loss: 0.068518
2025-09-03 21:25:35,693 - INFO - Epoch 3437/5000 - Train Loss: 0.078642, Val Loss: 0.069497
2025-09-03 21:26:11,839 - INFO - Epoch 3438/5000 - Train Loss: 0.078800, Val Loss: 0.070409
2025-09-03 21:26:47,503 - INFO - Epoch 3439/5000 - Train Loss: 0.079707, Val Loss: 0.070626
2025-09-03 21:27:23,669 - INFO - Epoch 3440/5000 - Train Loss: 0.079171, Val Loss: 0.069116
2025-09-03 21:27:59,938 - INFO - Epoch 3441/5000 - Train Loss: 0.078917, Val Loss: 0.070219
2025-09-03 21:28:36,631 - INFO - Epoch 3442/5000 - Train Loss: 0.079983, Val Loss: 0.070625
2025-09-03 21:29:13,158 - INFO - Epoch 3443/5000 - Train Loss: 0.079130, Val Loss: 0.069732
2025-09-03 21:29:49,154 - INFO - Epoch 3444/5000 - Train Loss: 0.080373, Val Loss: 0.071720
2025-09-03 21:30:25,151 - INFO - Epoch 3445/5000 - Train Loss: 0.079362, Val Loss: 0.069222
2025-09-03 21:31:01,267 - INFO - Epoch 3446/5000 - Train Loss: 0.078486, Val Loss: 0.072518
2025-09-03 21:31:38,225 - INFO - Epoch 3447/5000 - Train Loss: 0.078419, Val Loss: 0.067974
2025-09-03 21:31:38,263 - INFO - New best model saved with Val Loss: 0.067974
2025-09-03 21:32:14,639 - INFO - Epoch 3448/5000 - Train Loss: 0.078725, Val Loss: 0.068925
2025-09-03 21:32:50,875 - INFO - Epoch 3449/5000 - Train Loss: 0.079690, Val Loss: 0.070693
2025-09-03 21:33:27,232 - INFO - Epoch 3450/5000 - Train Loss: 0.079148, Val Loss: 0.070097
2025-09-03 21:34:04,078 - INFO - Epoch 3451/5000 - Train Loss: 0.079064, Val Loss: 0.069738
2025-09-03 21:34:40,659 - INFO - Epoch 3452/5000 - Train Loss: 0.077712, Val Loss: 0.070161
2025-09-03 21:35:17,221 - INFO - Epoch 3453/5000 - Train Loss: 0.078217, Val Loss: 0.068244
2025-09-03 21:35:53,134 - INFO - Epoch 3454/5000 - Train Loss: 0.078406, Val Loss: 0.071626
2025-09-03 21:36:29,233 - INFO - Epoch 3455/5000 - Train Loss: 0.079633, Val Loss: 0.068614
2025-09-03 21:37:05,390 - INFO - Epoch 3456/5000 - Train Loss: 0.078066, Val Loss: 0.068746
2025-09-03 21:37:42,251 - INFO - Epoch 3457/5000 - Train Loss: 0.078009, Val Loss: 0.069635
2025-09-03 21:38:18,674 - INFO - Epoch 3458/5000 - Train Loss: 0.078918, Val Loss: 0.068705
2025-09-03 21:38:54,601 - INFO - Epoch 3459/5000 - Train Loss: 0.079226, Val Loss: 0.069266
2025-09-03 21:39:30,159 - INFO - Epoch 3460/5000 - Train Loss: 0.079131, Val Loss: 0.074264
2025-09-03 21:40:06,181 - INFO - Epoch 3461/5000 - Train Loss: 0.079753, Val Loss: 0.071664
2025-09-03 21:40:41,733 - INFO - Epoch 3462/5000 - Train Loss: 0.079290, Val Loss: 0.074834
2025-09-03 21:41:17,272 - INFO - Epoch 3463/5000 - Train Loss: 0.079686, Val Loss: 0.069256
2025-09-03 21:41:53,495 - INFO - Epoch 3464/5000 - Train Loss: 0.079986, Val Loss: 0.069966
2025-09-03 21:42:30,725 - INFO - Epoch 3465/5000 - Train Loss: 0.078484, Val Loss: 0.070491
2025-09-03 21:43:07,728 - INFO - Epoch 3466/5000 - Train Loss: 0.078672, Val Loss: 0.071751
2025-09-03 21:43:45,141 - INFO - Epoch 3467/5000 - Train Loss: 0.080205, Val Loss: 0.072866
2025-09-03 21:44:21,489 - INFO - Epoch 3468/5000 - Train Loss: 0.079221, Val Loss: 0.070100
2025-09-03 21:44:58,471 - INFO - Epoch 3469/5000 - Train Loss: 0.078601, Val Loss: 0.074659
2025-09-03 21:45:34,725 - INFO - Epoch 3470/5000 - Train Loss: 0.079969, Val Loss: 0.068293
2025-09-03 21:46:11,276 - INFO - Epoch 3471/5000 - Train Loss: 0.077862, Val Loss: 0.070046
2025-09-03 21:46:47,824 - INFO - Epoch 3472/5000 - Train Loss: 0.079396, Val Loss: 0.069922
2025-09-03 21:47:24,028 - INFO - Epoch 3473/5000 - Train Loss: 0.078165, Val Loss: 0.068146
2025-09-03 21:48:00,094 - INFO - Epoch 3474/5000 - Train Loss: 0.077955, Val Loss: 0.069062
2025-09-03 21:48:36,177 - INFO - Epoch 3475/5000 - Train Loss: 0.078615, Val Loss: 0.069304
2025-09-03 21:49:11,867 - INFO - Epoch 3476/5000 - Train Loss: 0.078550, Val Loss: 0.069314
2025-09-03 21:49:48,599 - INFO - Epoch 3477/5000 - Train Loss: 0.078531, Val Loss: 0.069186
2025-09-03 21:50:25,338 - INFO - Epoch 3478/5000 - Train Loss: 0.078056, Val Loss: 0.071133
2025-09-03 21:51:01,654 - INFO - Epoch 3479/5000 - Train Loss: 0.078169, Val Loss: 0.069768
2025-09-03 21:51:38,913 - INFO - Epoch 3480/5000 - Train Loss: 0.078227, Val Loss: 0.070062
2025-09-03 21:52:16,818 - INFO - Epoch 3481/5000 - Train Loss: 0.078178, Val Loss: 0.069055
2025-09-03 21:52:54,099 - INFO - Epoch 3482/5000 - Train Loss: 0.078147, Val Loss: 0.069863
2025-09-03 21:53:30,412 - INFO - Epoch 3483/5000 - Train Loss: 0.078486, Val Loss: 0.069039
2025-09-03 21:54:06,576 - INFO - Epoch 3484/5000 - Train Loss: 0.078818, Val Loss: 0.071585
2025-09-03 21:54:42,556 - INFO - Epoch 3485/5000 - Train Loss: 0.078647, Val Loss: 0.068471
2025-09-03 21:55:18,421 - INFO - Epoch 3486/5000 - Train Loss: 0.078441, Val Loss: 0.070869
2025-09-03 21:55:55,188 - INFO - Epoch 3487/5000 - Train Loss: 0.078977, Val Loss: 0.069185
2025-09-03 21:56:31,676 - INFO - Epoch 3488/5000 - Train Loss: 0.078769, Val Loss: 0.069045
2025-09-03 21:57:07,534 - INFO - Epoch 3489/5000 - Train Loss: 0.077681, Val Loss: 0.070251
2025-09-03 21:57:43,422 - INFO - Epoch 3490/5000 - Train Loss: 0.077701, Val Loss: 0.069499
2025-09-03 21:58:19,970 - INFO - Epoch 3491/5000 - Train Loss: 0.078098, Val Loss: 0.068964
2025-09-03 21:58:56,462 - INFO - Epoch 3492/5000 - Train Loss: 0.077558, Val Loss: 0.068972
2025-09-03 21:59:32,437 - INFO - Epoch 3493/5000 - Train Loss: 0.077849, Val Loss: 0.070556
2025-09-03 22:00:08,431 - INFO - Epoch 3494/5000 - Train Loss: 0.078746, Val Loss: 0.072041
2025-09-03 22:00:44,761 - INFO - Epoch 3495/5000 - Train Loss: 0.078071, Val Loss: 0.069541
2025-09-03 22:01:20,922 - INFO - Epoch 3496/5000 - Train Loss: 0.077820, Val Loss: 0.068961
2025-09-03 22:01:57,868 - INFO - Epoch 3497/5000 - Train Loss: 0.078908, Val Loss: 0.069725
2025-09-03 22:02:33,701 - INFO - Epoch 3498/5000 - Train Loss: 0.078682, Val Loss: 0.069447
2025-09-03 22:03:10,968 - INFO - Epoch 3499/5000 - Train Loss: 0.077494, Val Loss: 0.068733
2025-09-03 22:03:47,877 - INFO - Epoch 3500/5000 - Train Loss: 0.077696, Val Loss: 0.068739
2025-09-03 22:04:25,003 - INFO - Epoch 3501/5000 - Train Loss: 0.078147, Val Loss: 0.069264
2025-09-03 22:05:01,358 - INFO - Epoch 3502/5000 - Train Loss: 0.078113, Val Loss: 0.068943
2025-09-03 22:05:37,122 - INFO - Epoch 3503/5000 - Train Loss: 0.077942, Val Loss: 0.070232
2025-09-03 22:06:13,770 - INFO - Epoch 3504/5000 - Train Loss: 0.078400, Val Loss: 0.069607
2025-09-03 22:06:50,530 - INFO - Epoch 3505/5000 - Train Loss: 0.078810, Val Loss: 0.070754
2025-09-03 22:07:26,863 - INFO - Epoch 3506/5000 - Train Loss: 0.078582, Val Loss: 0.069546
2025-09-03 22:08:02,487 - INFO - Epoch 3507/5000 - Train Loss: 0.078016, Val Loss: 0.070627
2025-09-03 22:08:39,194 - INFO - Epoch 3508/5000 - Train Loss: 0.078509, Val Loss: 0.069300
2025-09-03 22:09:15,309 - INFO - Epoch 3509/5000 - Train Loss: 0.078393, Val Loss: 0.068716
2025-09-03 22:09:51,470 - INFO - Epoch 3510/5000 - Train Loss: 0.076914, Val Loss: 0.069359
2025-09-03 22:10:28,082 - INFO - Epoch 3511/5000 - Train Loss: 0.077489, Val Loss: 0.068399
2025-09-03 22:11:06,871 - INFO - Epoch 3512/5000 - Train Loss: 0.077953, Val Loss: 0.070081
2025-09-03 22:11:45,341 - INFO - Epoch 3513/5000 - Train Loss: 0.078605, Val Loss: 0.070757
2025-09-03 22:12:21,548 - INFO - Epoch 3514/5000 - Train Loss: 0.078887, Val Loss: 0.070919
2025-09-03 22:12:57,611 - INFO - Epoch 3515/5000 - Train Loss: 0.078053, Val Loss: 0.068428
2025-09-03 22:13:34,155 - INFO - Epoch 3516/5000 - Train Loss: 0.078704, Val Loss: 0.072512
2025-09-03 22:14:09,962 - INFO - Epoch 3517/5000 - Train Loss: 0.078756, Val Loss: 0.068045
2025-09-03 22:14:46,312 - INFO - Epoch 3518/5000 - Train Loss: 0.078306, Val Loss: 0.069085
2025-09-03 22:15:23,103 - INFO - Epoch 3519/5000 - Train Loss: 0.078361, Val Loss: 0.068054
2025-09-03 22:15:58,801 - INFO - Epoch 3520/5000 - Train Loss: 0.077035, Val Loss: 0.068304
2025-09-03 22:16:35,150 - INFO - Epoch 3521/5000 - Train Loss: 0.077689, Val Loss: 0.069568
2025-09-03 22:17:11,751 - INFO - Epoch 3522/5000 - Train Loss: 0.077270, Val Loss: 0.069116
2025-09-03 22:17:48,408 - INFO - Epoch 3523/5000 - Train Loss: 0.077896, Val Loss: 0.069128
2025-09-03 22:18:25,745 - INFO - Epoch 3524/5000 - Train Loss: 0.079266, Val Loss: 0.069137
2025-09-03 22:19:03,097 - INFO - Epoch 3525/5000 - Train Loss: 0.078799, Val Loss: 0.071730
2025-09-03 22:19:39,639 - INFO - Epoch 3526/5000 - Train Loss: 0.078954, Val Loss: 0.068562
2025-09-03 22:20:16,512 - INFO - Epoch 3527/5000 - Train Loss: 0.079048, Val Loss: 0.069366
2025-09-03 22:20:52,675 - INFO - Epoch 3528/5000 - Train Loss: 0.077556, Val Loss: 0.068972
2025-09-03 22:21:28,662 - INFO - Epoch 3529/5000 - Train Loss: 0.077502, Val Loss: 0.068242
2025-09-03 22:22:04,964 - INFO - Epoch 3530/5000 - Train Loss: 0.078573, Val Loss: 0.068891
2025-09-03 22:22:41,964 - INFO - Epoch 3531/5000 - Train Loss: 0.078080, Val Loss: 0.072161
2025-09-03 22:23:18,406 - INFO - Epoch 3532/5000 - Train Loss: 0.078589, Val Loss: 0.070147
2025-09-03 22:23:54,390 - INFO - Epoch 3533/5000 - Train Loss: 0.078590, Val Loss: 0.067780
2025-09-03 22:23:54,432 - INFO - New best model saved with Val Loss: 0.067780
2025-09-03 22:24:31,089 - INFO - Epoch 3534/5000 - Train Loss: 0.077311, Val Loss: 0.069686
2025-09-03 22:25:07,499 - INFO - Epoch 3535/5000 - Train Loss: 0.078446, Val Loss: 0.071303
2025-09-03 22:25:43,023 - INFO - Epoch 3536/5000 - Train Loss: 0.078338, Val Loss: 0.069184
2025-09-03 22:26:19,089 - INFO - Epoch 3537/5000 - Train Loss: 0.076101, Val Loss: 0.068207
2025-09-03 22:26:55,378 - INFO - Epoch 3538/5000 - Train Loss: 0.077675, Val Loss: 0.069020
2025-09-03 22:27:31,506 - INFO - Epoch 3539/5000 - Train Loss: 0.077380, Val Loss: 0.067617
2025-09-03 22:27:31,538 - INFO - New best model saved with Val Loss: 0.067617
2025-09-03 22:28:07,866 - INFO - Epoch 3540/5000 - Train Loss: 0.077746, Val Loss: 0.067654
2025-09-03 22:28:44,294 - INFO - Epoch 3541/5000 - Train Loss: 0.077517, Val Loss: 0.068883
2025-09-03 22:29:20,302 - INFO - Epoch 3542/5000 - Train Loss: 0.078221, Val Loss: 0.069004
2025-09-03 22:29:56,468 - INFO - Epoch 3543/5000 - Train Loss: 0.079155, Val Loss: 0.069725
2025-09-03 22:30:33,371 - INFO - Epoch 3544/5000 - Train Loss: 0.078123, Val Loss: 0.068516
2025-09-03 22:31:09,458 - INFO - Epoch 3545/5000 - Train Loss: 0.077851, Val Loss: 0.068668
2025-09-03 22:31:45,813 - INFO - Epoch 3546/5000 - Train Loss: 0.078543, Val Loss: 0.069039
2025-09-03 22:32:23,210 - INFO - Epoch 3547/5000 - Train Loss: 0.077426, Val Loss: 0.071115
2025-09-03 22:33:00,654 - INFO - Epoch 3548/5000 - Train Loss: 0.077574, Val Loss: 0.068468
2025-09-03 22:33:37,599 - INFO - Epoch 3549/5000 - Train Loss: 0.077139, Val Loss: 0.067202
2025-09-03 22:33:37,631 - INFO - New best model saved with Val Loss: 0.067202
2025-09-03 22:34:14,387 - INFO - Epoch 3550/5000 - Train Loss: 0.078337, Val Loss: 0.070436
2025-09-03 22:34:51,324 - INFO - Epoch 3551/5000 - Train Loss: 0.077561, Val Loss: 0.067469
2025-09-03 22:35:27,672 - INFO - Epoch 3552/5000 - Train Loss: 0.077227, Val Loss: 0.070295
2025-09-03 22:36:04,858 - INFO - Epoch 3553/5000 - Train Loss: 0.077854, Val Loss: 0.071473
2025-09-03 22:36:41,051 - INFO - Epoch 3554/5000 - Train Loss: 0.077155, Val Loss: 0.070216
2025-09-03 22:37:17,813 - INFO - Epoch 3555/5000 - Train Loss: 0.078592, Val Loss: 0.067150
2025-09-03 22:37:17,845 - INFO - New best model saved with Val Loss: 0.067150
2025-09-03 22:37:54,569 - INFO - Epoch 3556/5000 - Train Loss: 0.077260, Val Loss: 0.068628
2025-09-03 22:38:31,464 - INFO - Epoch 3557/5000 - Train Loss: 0.077947, Val Loss: 0.068950
2025-09-03 22:39:08,816 - INFO - Epoch 3558/5000 - Train Loss: 0.077000, Val Loss: 0.068412
2025-09-03 22:39:45,691 - INFO - Epoch 3559/5000 - Train Loss: 0.077127, Val Loss: 0.068497
2025-09-03 22:40:22,269 - INFO - Epoch 3560/5000 - Train Loss: 0.078386, Val Loss: 0.069235
2025-09-03 22:40:59,124 - INFO - Epoch 3561/5000 - Train Loss: 0.078455, Val Loss: 0.070590
2025-09-03 22:41:35,212 - INFO - Epoch 3562/5000 - Train Loss: 0.078274, Val Loss: 0.067923
2025-09-03 22:42:11,245 - INFO - Epoch 3563/5000 - Train Loss: 0.076641, Val Loss: 0.068921
2025-09-03 22:42:47,259 - INFO - Epoch 3564/5000 - Train Loss: 0.077132, Val Loss: 0.067854
2025-09-03 22:43:23,628 - INFO - Epoch 3565/5000 - Train Loss: 0.076694, Val Loss: 0.067689
2025-09-03 22:44:00,275 - INFO - Epoch 3566/5000 - Train Loss: 0.077228, Val Loss: 0.069996
2025-09-03 22:44:37,115 - INFO - Epoch 3567/5000 - Train Loss: 0.078038, Val Loss: 0.069903
2025-09-03 22:45:14,174 - INFO - Epoch 3568/5000 - Train Loss: 0.076937, Val Loss: 0.069190
2025-09-03 22:45:50,444 - INFO - Epoch 3569/5000 - Train Loss: 0.077133, Val Loss: 0.067795
2025-09-03 22:46:27,246 - INFO - Epoch 3570/5000 - Train Loss: 0.077116, Val Loss: 0.068173
2025-09-03 22:47:04,518 - INFO - Epoch 3571/5000 - Train Loss: 0.078449, Val Loss: 0.067427
2025-09-03 22:47:41,671 - INFO - Epoch 3572/5000 - Train Loss: 0.077087, Val Loss: 0.069299
2025-09-03 22:48:18,695 - INFO - Epoch 3573/5000 - Train Loss: 0.077621, Val Loss: 0.069796
2025-09-03 22:48:55,642 - INFO - Epoch 3574/5000 - Train Loss: 0.078058, Val Loss: 0.069046
2025-09-03 22:49:32,229 - INFO - Epoch 3575/5000 - Train Loss: 0.077451, Val Loss: 0.068385
2025-09-03 22:50:08,454 - INFO - Epoch 3576/5000 - Train Loss: 0.077136, Val Loss: 0.071353
2025-09-03 22:50:44,494 - INFO - Epoch 3577/5000 - Train Loss: 0.077766, Val Loss: 0.068009
2025-09-03 22:51:20,352 - INFO - Epoch 3578/5000 - Train Loss: 0.078810, Val Loss: 0.069476
2025-09-03 22:51:56,356 - INFO - Epoch 3579/5000 - Train Loss: 0.076866, Val Loss: 0.069123
2025-09-03 22:52:32,548 - INFO - Epoch 3580/5000 - Train Loss: 0.077199, Val Loss: 0.068054
2025-09-03 22:53:09,418 - INFO - Epoch 3581/5000 - Train Loss: 0.076916, Val Loss: 0.068337
2025-09-03 22:53:45,454 - INFO - Epoch 3582/5000 - Train Loss: 0.076932, Val Loss: 0.069489
2025-09-03 22:54:21,824 - INFO - Epoch 3583/5000 - Train Loss: 0.077127, Val Loss: 0.069563
2025-09-03 22:54:58,667 - INFO - Epoch 3584/5000 - Train Loss: 0.076937, Val Loss: 0.068774
2025-09-03 22:55:35,802 - INFO - Epoch 3585/5000 - Train Loss: 0.078698, Val Loss: 0.069612
2025-09-03 22:56:11,555 - INFO - Epoch 3586/5000 - Train Loss: 0.077458, Val Loss: 0.069356
2025-09-03 22:56:47,632 - INFO - Epoch 3587/5000 - Train Loss: 0.076603, Val Loss: 0.070003
2025-09-03 22:57:24,156 - INFO - Epoch 3588/5000 - Train Loss: 0.076406, Val Loss: 0.069031
2025-09-03 22:58:00,907 - INFO - Epoch 3589/5000 - Train Loss: 0.077059, Val Loss: 0.067116
2025-09-03 22:58:00,948 - INFO - New best model saved with Val Loss: 0.067116
2025-09-03 22:58:37,978 - INFO - Epoch 3590/5000 - Train Loss: 0.076917, Val Loss: 0.068395
2025-09-03 22:59:14,205 - INFO - Epoch 3591/5000 - Train Loss: 0.077759, Val Loss: 0.071030
2025-09-03 22:59:51,295 - INFO - Epoch 3592/5000 - Train Loss: 0.076824, Val Loss: 0.068501
2025-09-03 23:00:28,235 - INFO - Epoch 3593/5000 - Train Loss: 0.076409, Val Loss: 0.068678
2025-09-03 23:01:04,973 - INFO - Epoch 3594/5000 - Train Loss: 0.078157, Val Loss: 0.071091
2025-09-03 23:01:41,849 - INFO - Epoch 3595/5000 - Train Loss: 0.079397, Val Loss: 0.068268
2025-09-03 23:02:19,049 - INFO - Epoch 3596/5000 - Train Loss: 0.077594, Val Loss: 0.067627
2025-09-03 23:02:55,556 - INFO - Epoch 3597/5000 - Train Loss: 0.077217, Val Loss: 0.069088
2025-09-03 23:03:31,626 - INFO - Epoch 3598/5000 - Train Loss: 0.078844, Val Loss: 0.070407
2025-09-03 23:04:08,080 - INFO - Epoch 3599/5000 - Train Loss: 0.077557, Val Loss: 0.067871
2025-09-03 23:04:45,396 - INFO - Epoch 3600/5000 - Train Loss: 0.077566, Val Loss: 0.068630
2025-09-03 23:05:22,347 - INFO - Epoch 3601/5000 - Train Loss: 0.077774, Val Loss: 0.068721
2025-09-03 23:05:59,730 - INFO - Epoch 3602/5000 - Train Loss: 0.076159, Val Loss: 0.068531
2025-09-03 23:06:35,938 - INFO - Epoch 3603/5000 - Train Loss: 0.077021, Val Loss: 0.068942
2025-09-03 23:07:12,334 - INFO - Epoch 3604/5000 - Train Loss: 0.077470, Val Loss: 0.068913
2025-09-03 23:07:48,654 - INFO - Epoch 3605/5000 - Train Loss: 0.078279, Val Loss: 0.070730
2025-09-03 23:08:26,018 - INFO - Epoch 3606/5000 - Train Loss: 0.077712, Val Loss: 0.067577
2025-09-03 23:09:02,061 - INFO - Epoch 3607/5000 - Train Loss: 0.078004, Val Loss: 0.072617
2025-09-03 23:09:38,000 - INFO - Epoch 3608/5000 - Train Loss: 0.077767, Val Loss: 0.066912
2025-09-03 23:09:38,042 - INFO - New best model saved with Val Loss: 0.066912
2025-09-03 23:10:14,196 - INFO - Epoch 3609/5000 - Train Loss: 0.077803, Val Loss: 0.067117
2025-09-03 23:10:50,352 - INFO - Epoch 3610/5000 - Train Loss: 0.075448, Val Loss: 0.067693
2025-09-03 23:11:27,186 - INFO - Epoch 3611/5000 - Train Loss: 0.076005, Val Loss: 0.067333
2025-09-03 23:12:04,103 - INFO - Epoch 3612/5000 - Train Loss: 0.076989, Val Loss: 0.066666
2025-09-03 23:12:04,135 - INFO - New best model saved with Val Loss: 0.066666
2025-09-03 23:12:41,329 - INFO - Epoch 3613/5000 - Train Loss: 0.076925, Val Loss: 0.067751
2025-09-03 23:13:17,369 - INFO - Epoch 3614/5000 - Train Loss: 0.076994, Val Loss: 0.070282
2025-09-03 23:13:53,570 - INFO - Epoch 3615/5000 - Train Loss: 0.077413, Val Loss: 0.069308
2025-09-03 23:14:29,967 - INFO - Epoch 3616/5000 - Train Loss: 0.076794, Val Loss: 0.068442
2025-09-03 23:15:05,938 - INFO - Epoch 3617/5000 - Train Loss: 0.076057, Val Loss: 0.066460
2025-09-03 23:15:05,970 - INFO - New best model saved with Val Loss: 0.066460
2025-09-03 23:15:42,550 - INFO - Epoch 3618/5000 - Train Loss: 0.077400, Val Loss: 0.069690
2025-09-03 23:16:18,938 - INFO - Epoch 3619/5000 - Train Loss: 0.077661, Val Loss: 0.068715
2025-09-03 23:16:55,346 - INFO - Epoch 3620/5000 - Train Loss: 0.076568, Val Loss: 0.068658
2025-09-03 23:17:31,503 - INFO - Epoch 3621/5000 - Train Loss: 0.076824, Val Loss: 0.067672
2025-09-03 23:18:07,416 - INFO - Epoch 3622/5000 - Train Loss: 0.076994, Val Loss: 0.070625
2025-09-03 23:18:44,313 - INFO - Epoch 3623/5000 - Train Loss: 0.076823, Val Loss: 0.068480
2025-09-03 23:19:20,895 - INFO - Epoch 3624/5000 - Train Loss: 0.076959, Val Loss: 0.069693
2025-09-03 23:19:57,814 - INFO - Epoch 3625/5000 - Train Loss: 0.077002, Val Loss: 0.070922
2025-09-03 23:20:34,295 - INFO - Epoch 3626/5000 - Train Loss: 0.077224, Val Loss: 0.069330
2025-09-03 23:21:10,880 - INFO - Epoch 3627/5000 - Train Loss: 0.076697, Val Loss: 0.067604
2025-09-03 23:21:48,472 - INFO - Epoch 3628/5000 - Train Loss: 0.076435, Val Loss: 0.068332
2025-09-03 23:22:25,019 - INFO - Epoch 3629/5000 - Train Loss: 0.077172, Val Loss: 0.068708
2025-09-03 23:23:02,060 - INFO - Epoch 3630/5000 - Train Loss: 0.076682, Val Loss: 0.068715
2025-09-03 23:23:38,828 - INFO - Epoch 3631/5000 - Train Loss: 0.076897, Val Loss: 0.068603
2025-09-03 23:24:16,112 - INFO - Epoch 3632/5000 - Train Loss: 0.076800, Val Loss: 0.068014
2025-09-03 23:24:51,735 - INFO - Epoch 3633/5000 - Train Loss: 0.077353, Val Loss: 0.068093
2025-09-03 23:25:28,428 - INFO - Epoch 3634/5000 - Train Loss: 0.077130, Val Loss: 0.069694
2025-09-03 23:26:04,648 - INFO - Epoch 3635/5000 - Train Loss: 0.077511, Val Loss: 0.067981
2025-09-03 23:26:41,177 - INFO - Epoch 3636/5000 - Train Loss: 0.076073, Val Loss: 0.068638
2025-09-03 23:27:17,619 - INFO - Epoch 3637/5000 - Train Loss: 0.076956, Val Loss: 0.069848
2025-09-03 23:27:53,863 - INFO - Epoch 3638/5000 - Train Loss: 0.076962, Val Loss: 0.068326
2025-09-03 23:28:30,081 - INFO - Epoch 3639/5000 - Train Loss: 0.076982, Val Loss: 0.067905
2025-09-03 23:29:06,649 - INFO - Epoch 3640/5000 - Train Loss: 0.077219, Val Loss: 0.068453
2025-09-03 23:29:43,185 - INFO - Epoch 3641/5000 - Train Loss: 0.077840, Val Loss: 0.069368
2025-09-03 23:30:19,569 - INFO - Epoch 3642/5000 - Train Loss: 0.077176, Val Loss: 0.068701
2025-09-03 23:30:56,322 - INFO - Epoch 3643/5000 - Train Loss: 0.075985, Val Loss: 0.068471
2025-09-03 23:31:33,232 - INFO - Epoch 3644/5000 - Train Loss: 0.076208, Val Loss: 0.066754
2025-09-03 23:32:10,062 - INFO - Epoch 3645/5000 - Train Loss: 0.076431, Val Loss: 0.068752
2025-09-03 23:32:47,313 - INFO - Epoch 3646/5000 - Train Loss: 0.076166, Val Loss: 0.067119
2025-09-03 23:33:24,826 - INFO - Epoch 3647/5000 - Train Loss: 0.076814, Val Loss: 0.068891
2025-09-03 23:34:01,545 - INFO - Epoch 3648/5000 - Train Loss: 0.077090, Val Loss: 0.069434
2025-09-03 23:34:38,098 - INFO - Epoch 3649/5000 - Train Loss: 0.075159, Val Loss: 0.066797
2025-09-03 23:35:13,963 - INFO - Epoch 3650/5000 - Train Loss: 0.076259, Val Loss: 0.068392
2025-09-03 23:35:50,779 - INFO - Epoch 3651/5000 - Train Loss: 0.077392, Val Loss: 0.068461
2025-09-03 23:36:27,431 - INFO - Epoch 3652/5000 - Train Loss: 0.076077, Val Loss: 0.066361
2025-09-03 23:36:27,478 - INFO - New best model saved with Val Loss: 0.066361
2025-09-03 23:37:03,920 - INFO - Epoch 3653/5000 - Train Loss: 0.075792, Val Loss: 0.069062
2025-09-03 23:37:40,631 - INFO - Epoch 3654/5000 - Train Loss: 0.076910, Val Loss: 0.067853
2025-09-03 23:38:17,753 - INFO - Epoch 3655/5000 - Train Loss: 0.076903, Val Loss: 0.068651
2025-09-03 23:38:54,776 - INFO - Epoch 3656/5000 - Train Loss: 0.076707, Val Loss: 0.069276
2025-09-03 23:39:30,734 - INFO - Epoch 3657/5000 - Train Loss: 0.076795, Val Loss: 0.066547
2025-09-03 23:40:06,687 - INFO - Epoch 3658/5000 - Train Loss: 0.076238, Val Loss: 0.068870
2025-09-03 23:40:43,203 - INFO - Epoch 3659/5000 - Train Loss: 0.075956, Val Loss: 0.069036
2025-09-03 23:41:19,717 - INFO - Epoch 3660/5000 - Train Loss: 0.075915, Val Loss: 0.067489
2025-09-03 23:41:56,487 - INFO - Epoch 3661/5000 - Train Loss: 0.075768, Val Loss: 0.066960
2025-09-03 23:42:32,700 - INFO - Epoch 3662/5000 - Train Loss: 0.076014, Val Loss: 0.067398
2025-09-03 23:43:09,591 - INFO - Epoch 3663/5000 - Train Loss: 0.076086, Val Loss: 0.069489
2025-09-03 23:43:45,056 - INFO - Epoch 3664/5000 - Train Loss: 0.077799, Val Loss: 0.068178
2025-09-03 23:44:21,681 - INFO - Epoch 3665/5000 - Train Loss: 0.077326, Val Loss: 0.069762
2025-09-03 23:44:58,485 - INFO - Epoch 3666/5000 - Train Loss: 0.077571, Val Loss: 0.065947
2025-09-03 23:44:58,517 - INFO - New best model saved with Val Loss: 0.065947
2025-09-03 23:45:34,987 - INFO - Epoch 3667/5000 - Train Loss: 0.076094, Val Loss: 0.069525
2025-09-03 23:46:10,863 - INFO - Epoch 3668/5000 - Train Loss: 0.077791, Val Loss: 0.069910
2025-09-03 23:46:46,954 - INFO - Epoch 3669/5000 - Train Loss: 0.075833, Val Loss: 0.067072
2025-09-03 23:47:22,934 - INFO - Epoch 3670/5000 - Train Loss: 0.076300, Val Loss: 0.066521
2025-09-03 23:47:58,951 - INFO - Epoch 3671/5000 - Train Loss: 0.075585, Val Loss: 0.066907
2025-09-03 23:48:34,111 - INFO - Epoch 3672/5000 - Train Loss: 0.077239, Val Loss: 0.068441
2025-09-03 23:49:09,189 - INFO - Epoch 3673/5000 - Train Loss: 0.076814, Val Loss: 0.068922
2025-09-03 23:49:44,769 - INFO - Epoch 3674/5000 - Train Loss: 0.076673, Val Loss: 0.068839
2025-09-03 23:50:20,321 - INFO - Epoch 3675/5000 - Train Loss: 0.076928, Val Loss: 0.070832
2025-09-03 23:50:55,338 - INFO - Epoch 3676/5000 - Train Loss: 0.076368, Val Loss: 0.066353
2025-09-03 23:51:31,062 - INFO - Epoch 3677/5000 - Train Loss: 0.076015, Val Loss: 0.067366
2025-09-03 23:52:07,688 - INFO - Epoch 3678/5000 - Train Loss: 0.077220, Val Loss: 0.067793
2025-09-03 23:52:43,791 - INFO - Epoch 3679/5000 - Train Loss: 0.078679, Val Loss: 0.070792
2025-09-03 23:53:20,089 - INFO - Epoch 3680/5000 - Train Loss: 0.076155, Val Loss: 0.068079
2025-09-03 23:53:57,227 - INFO - Epoch 3681/5000 - Train Loss: 0.076041, Val Loss: 0.067821
2025-09-03 23:54:33,758 - INFO - Epoch 3682/5000 - Train Loss: 0.076209, Val Loss: 0.069606
2025-09-03 23:55:09,340 - INFO - Epoch 3683/5000 - Train Loss: 0.077021, Val Loss: 0.068356
2025-09-03 23:55:45,020 - INFO - Epoch 3684/5000 - Train Loss: 0.076108, Val Loss: 0.067962
2025-09-03 23:56:20,813 - INFO - Epoch 3685/5000 - Train Loss: 0.076144, Val Loss: 0.067208
2025-09-03 23:56:56,662 - INFO - Epoch 3686/5000 - Train Loss: 0.076069, Val Loss: 0.066564
2025-09-03 23:57:32,493 - INFO - Epoch 3687/5000 - Train Loss: 0.076653, Val Loss: 0.067401
2025-09-03 23:58:08,164 - INFO - Epoch 3688/5000 - Train Loss: 0.076177, Val Loss: 0.066015
2025-09-03 23:58:44,370 - INFO - Epoch 3689/5000 - Train Loss: 0.076945, Val Loss: 0.067823
2025-09-03 23:59:20,952 - INFO - Epoch 3690/5000 - Train Loss: 0.077709, Val Loss: 0.068885
2025-09-03 23:59:56,837 - INFO - Epoch 3691/5000 - Train Loss: 0.076587, Val Loss: 0.068416
2025-09-04 00:00:32,669 - INFO - Epoch 3692/5000 - Train Loss: 0.075768, Val Loss: 0.066185
2025-09-04 00:01:08,843 - INFO - Epoch 3693/5000 - Train Loss: 0.075908, Val Loss: 0.067172
2025-09-04 00:01:44,609 - INFO - Epoch 3694/5000 - Train Loss: 0.076964, Val Loss: 0.066823
2025-09-04 00:02:20,748 - INFO - Epoch 3695/5000 - Train Loss: 0.075765, Val Loss: 0.067103
2025-09-04 00:02:57,835 - INFO - Epoch 3696/5000 - Train Loss: 0.076390, Val Loss: 0.066628
2025-09-04 00:03:34,849 - INFO - Epoch 3697/5000 - Train Loss: 0.076708, Val Loss: 0.066476
2025-09-04 00:04:11,206 - INFO - Epoch 3698/5000 - Train Loss: 0.075372, Val Loss: 0.066618
2025-09-04 00:04:47,019 - INFO - Epoch 3699/5000 - Train Loss: 0.075285, Val Loss: 0.066218
2025-09-04 00:05:22,947 - INFO - Epoch 3700/5000 - Train Loss: 0.076454, Val Loss: 0.069497
2025-09-04 00:05:58,664 - INFO - Epoch 3701/5000 - Train Loss: 0.076048, Val Loss: 0.066928
2025-09-04 00:06:34,764 - INFO - Epoch 3702/5000 - Train Loss: 0.075173, Val Loss: 0.066529
2025-09-04 00:07:10,615 - INFO - Epoch 3703/5000 - Train Loss: 0.076045, Val Loss: 0.068850
2025-09-04 00:07:47,627 - INFO - Epoch 3704/5000 - Train Loss: 0.076737, Val Loss: 0.066961
2025-09-04 00:08:23,970 - INFO - Epoch 3705/5000 - Train Loss: 0.076260, Val Loss: 0.067400
2025-09-04 00:09:00,210 - INFO - Epoch 3706/5000 - Train Loss: 0.076103, Val Loss: 0.068052
2025-09-04 00:09:37,025 - INFO - Epoch 3707/5000 - Train Loss: 0.076227, Val Loss: 0.068633
2025-09-04 00:10:13,159 - INFO - Epoch 3708/5000 - Train Loss: 0.076246, Val Loss: 0.067247
2025-09-04 00:10:49,171 - INFO - Epoch 3709/5000 - Train Loss: 0.075687, Val Loss: 0.067316
2025-09-04 00:11:25,170 - INFO - Epoch 3710/5000 - Train Loss: 0.075747, Val Loss: 0.068661
2025-09-04 00:12:01,530 - INFO - Epoch 3711/5000 - Train Loss: 0.077110, Val Loss: 0.067425
2025-09-04 00:12:37,725 - INFO - Epoch 3712/5000 - Train Loss: 0.076689, Val Loss: 0.068708
2025-09-04 00:13:14,067 - INFO - Epoch 3713/5000 - Train Loss: 0.075339, Val Loss: 0.066945
2025-09-04 00:13:50,561 - INFO - Epoch 3714/5000 - Train Loss: 0.075295, Val Loss: 0.067451
2025-09-04 00:14:26,797 - INFO - Epoch 3715/5000 - Train Loss: 0.075889, Val Loss: 0.069603
2025-09-04 00:15:03,693 - INFO - Epoch 3716/5000 - Train Loss: 0.076081, Val Loss: 0.070949
2025-09-04 00:15:40,156 - INFO - Epoch 3717/5000 - Train Loss: 0.076290, Val Loss: 0.066634
2025-09-04 00:16:16,704 - INFO - Epoch 3718/5000 - Train Loss: 0.075894, Val Loss: 0.068560
2025-09-04 00:16:53,302 - INFO - Epoch 3719/5000 - Train Loss: 0.075663, Val Loss: 0.067292
2025-09-04 00:17:29,656 - INFO - Epoch 3720/5000 - Train Loss: 0.076123, Val Loss: 0.067397
2025-09-04 00:18:07,134 - INFO - Epoch 3721/5000 - Train Loss: 0.075635, Val Loss: 0.067954
2025-09-04 00:18:43,601 - INFO - Epoch 3722/5000 - Train Loss: 0.075425, Val Loss: 0.067145
2025-09-04 00:19:19,908 - INFO - Epoch 3723/5000 - Train Loss: 0.076381, Val Loss: 0.068435
2025-09-04 00:19:55,809 - INFO - Epoch 3724/5000 - Train Loss: 0.075204, Val Loss: 0.066578
2025-09-04 00:20:31,645 - INFO - Epoch 3725/5000 - Train Loss: 0.075786, Val Loss: 0.068992
2025-09-04 00:21:07,883 - INFO - Epoch 3726/5000 - Train Loss: 0.075063, Val Loss: 0.067271
2025-09-04 00:21:43,828 - INFO - Epoch 3727/5000 - Train Loss: 0.076117, Val Loss: 0.067254
2025-09-04 00:22:19,578 - INFO - Epoch 3728/5000 - Train Loss: 0.075962, Val Loss: 0.067915
2025-09-04 00:22:55,541 - INFO - Epoch 3729/5000 - Train Loss: 0.075790, Val Loss: 0.067509
2025-09-04 00:23:31,708 - INFO - Epoch 3730/5000 - Train Loss: 0.075406, Val Loss: 0.068931
2025-09-04 00:24:08,181 - INFO - Epoch 3731/5000 - Train Loss: 0.076012, Val Loss: 0.067991
2025-09-04 00:24:44,582 - INFO - Epoch 3732/5000 - Train Loss: 0.075924, Val Loss: 0.068260
2025-09-04 00:25:20,358 - INFO - Epoch 3733/5000 - Train Loss: 0.075267, Val Loss: 0.065715
2025-09-04 00:25:20,399 - INFO - New best model saved with Val Loss: 0.065715
2025-09-04 00:25:55,887 - INFO - Epoch 3734/5000 - Train Loss: 0.075424, Val Loss: 0.067485
2025-09-04 00:26:31,570 - INFO - Epoch 3735/5000 - Train Loss: 0.076998, Val Loss: 0.067793
2025-09-04 00:27:07,092 - INFO - Epoch 3736/5000 - Train Loss: 0.075435, Val Loss: 0.067793
2025-09-04 00:27:42,602 - INFO - Epoch 3737/5000 - Train Loss: 0.075773, Val Loss: 0.067157
2025-09-04 00:28:18,327 - INFO - Epoch 3738/5000 - Train Loss: 0.075765, Val Loss: 0.066182
2025-09-04 00:28:53,583 - INFO - Epoch 3739/5000 - Train Loss: 0.075491, Val Loss: 0.069932
2025-09-04 00:29:29,640 - INFO - Epoch 3740/5000 - Train Loss: 0.076776, Val Loss: 0.068214
2025-09-04 00:30:06,099 - INFO - Epoch 3741/5000 - Train Loss: 0.081321, Val Loss: 0.068317
2025-09-04 00:30:42,354 - INFO - Epoch 3742/5000 - Train Loss: 0.076237, Val Loss: 0.067121
2025-09-04 00:31:18,855 - INFO - Epoch 3743/5000 - Train Loss: 0.076574, Val Loss: 0.066820
2025-09-04 00:31:55,146 - INFO - Epoch 3744/5000 - Train Loss: 0.074592, Val Loss: 0.068142
2025-09-04 00:32:31,749 - INFO - Epoch 3745/5000 - Train Loss: 0.075202, Val Loss: 0.065904
2025-09-04 00:33:08,336 - INFO - Epoch 3746/5000 - Train Loss: 0.075090, Val Loss: 0.065603
2025-09-04 00:33:08,368 - INFO - New best model saved with Val Loss: 0.065603
2025-09-04 00:33:44,918 - INFO - Epoch 3747/5000 - Train Loss: 0.076174, Val Loss: 0.069015
2025-09-04 00:34:21,680 - INFO - Epoch 3748/5000 - Train Loss: 0.075573, Val Loss: 0.066149
2025-09-04 00:34:57,491 - INFO - Epoch 3749/5000 - Train Loss: 0.075654, Val Loss: 0.067364
2025-09-04 00:35:33,575 - INFO - Epoch 3750/5000 - Train Loss: 0.074889, Val Loss: 0.065744
2025-09-04 00:36:09,868 - INFO - Epoch 3751/5000 - Train Loss: 0.075126, Val Loss: 0.066096
2025-09-04 00:36:45,849 - INFO - Epoch 3752/5000 - Train Loss: 0.075345, Val Loss: 0.065692
2025-09-04 00:37:23,039 - INFO - Epoch 3753/5000 - Train Loss: 0.075137, Val Loss: 0.065639
2025-09-04 00:37:58,976 - INFO - Epoch 3754/5000 - Train Loss: 0.075662, Val Loss: 0.067635
2025-09-04 00:38:35,159 - INFO - Epoch 3755/5000 - Train Loss: 0.075628, Val Loss: 0.067642
2025-09-04 00:39:11,531 - INFO - Epoch 3756/5000 - Train Loss: 0.075234, Val Loss: 0.067890
2025-09-04 00:39:47,864 - INFO - Epoch 3757/5000 - Train Loss: 0.075375, Val Loss: 0.067761
2025-09-04 00:40:24,170 - INFO - Epoch 3758/5000 - Train Loss: 0.075389, Val Loss: 0.068171
2025-09-04 00:41:00,349 - INFO - Epoch 3759/5000 - Train Loss: 0.076250, Val Loss: 0.067345
2025-09-04 00:41:37,125 - INFO - Epoch 3760/5000 - Train Loss: 0.074819, Val Loss: 0.066850
2025-09-04 00:42:13,853 - INFO - Epoch 3761/5000 - Train Loss: 0.075471, Val Loss: 0.068588
2025-09-04 00:42:50,225 - INFO - Epoch 3762/5000 - Train Loss: 0.075850, Val Loss: 0.067310
2025-09-04 00:43:26,152 - INFO - Epoch 3763/5000 - Train Loss: 0.075446, Val Loss: 0.066445
2025-09-04 00:44:01,843 - INFO - Epoch 3764/5000 - Train Loss: 0.075614, Val Loss: 0.067272
2025-09-04 00:44:37,921 - INFO - Epoch 3765/5000 - Train Loss: 0.075404, Val Loss: 0.065795
2025-09-04 00:45:13,977 - INFO - Epoch 3766/5000 - Train Loss: 0.075122, Val Loss: 0.068055
2025-09-04 00:45:49,746 - INFO - Epoch 3767/5000 - Train Loss: 0.076140, Val Loss: 0.070694
2025-09-04 00:46:25,722 - INFO - Epoch 3768/5000 - Train Loss: 0.075025, Val Loss: 0.066419
2025-09-04 00:47:02,213 - INFO - Epoch 3769/5000 - Train Loss: 0.075781, Val Loss: 0.068015
2025-09-04 00:47:38,785 - INFO - Epoch 3770/5000 - Train Loss: 0.075670, Val Loss: 0.067518
2025-09-04 00:48:15,042 - INFO - Epoch 3771/5000 - Train Loss: 0.075584, Val Loss: 0.065975
2025-09-04 00:48:51,227 - INFO - Epoch 3772/5000 - Train Loss: 0.075488, Val Loss: 0.067443
2025-09-04 00:49:27,486 - INFO - Epoch 3773/5000 - Train Loss: 0.075315, Val Loss: 0.066039
2025-09-04 00:50:04,046 - INFO - Epoch 3774/5000 - Train Loss: 0.074703, Val Loss: 0.067922
2025-09-04 00:50:40,612 - INFO - Epoch 3775/5000 - Train Loss: 0.075147, Val Loss: 0.067926
2025-09-04 00:51:15,955 - INFO - Epoch 3776/5000 - Train Loss: 0.075966, Val Loss: 0.065952
2025-09-04 00:51:52,134 - INFO - Epoch 3777/5000 - Train Loss: 0.075699, Val Loss: 0.067298
2025-09-04 00:52:28,138 - INFO - Epoch 3778/5000 - Train Loss: 0.075230, Val Loss: 0.069037
2025-09-04 00:53:03,653 - INFO - Epoch 3779/5000 - Train Loss: 0.075638, Val Loss: 0.065951
2025-09-04 00:53:39,795 - INFO - Epoch 3780/5000 - Train Loss: 0.075239, Val Loss: 0.068103
2025-09-04 00:54:15,752 - INFO - Epoch 3781/5000 - Train Loss: 0.074974, Val Loss: 0.065958
2025-09-04 00:54:51,911 - INFO - Epoch 3782/5000 - Train Loss: 0.074760, Val Loss: 0.065757
2025-09-04 00:55:27,572 - INFO - Epoch 3783/5000 - Train Loss: 0.075915, Val Loss: 0.069811
2025-09-04 00:56:03,220 - INFO - Epoch 3784/5000 - Train Loss: 0.075519, Val Loss: 0.067836
2025-09-04 00:56:39,004 - INFO - Epoch 3785/5000 - Train Loss: 0.075184, Val Loss: 0.067362
2025-09-04 00:57:14,648 - INFO - Epoch 3786/5000 - Train Loss: 0.074602, Val Loss: 0.068730
2025-09-04 00:57:50,977 - INFO - Epoch 3787/5000 - Train Loss: 0.074427, Val Loss: 0.068404
2025-09-04 00:58:27,552 - INFO - Epoch 3788/5000 - Train Loss: 0.074862, Val Loss: 0.068200
2025-09-04 00:59:03,813 - INFO - Epoch 3789/5000 - Train Loss: 0.075316, Val Loss: 0.071234
2025-09-04 00:59:39,884 - INFO - Epoch 3790/5000 - Train Loss: 0.076175, Val Loss: 0.066807
2025-09-04 01:00:16,137 - INFO - Epoch 3791/5000 - Train Loss: 0.075464, Val Loss: 0.066326
2025-09-04 01:00:52,565 - INFO - Epoch 3792/5000 - Train Loss: 0.075780, Val Loss: 0.066271
2025-09-04 01:01:27,903 - INFO - Epoch 3793/5000 - Train Loss: 0.075407, Val Loss: 0.067131
2025-09-04 01:02:03,450 - INFO - Epoch 3794/5000 - Train Loss: 0.075045, Val Loss: 0.068297
2025-09-04 01:02:39,267 - INFO - Epoch 3795/5000 - Train Loss: 0.074735, Val Loss: 0.067302
2025-09-04 01:03:15,289 - INFO - Epoch 3796/5000 - Train Loss: 0.076000, Val Loss: 0.067166
2025-09-04 01:03:51,687 - INFO - Epoch 3797/5000 - Train Loss: 0.074602, Val Loss: 0.065215
2025-09-04 01:03:51,743 - INFO - New best model saved with Val Loss: 0.065215
2025-09-04 01:04:27,670 - INFO - Epoch 3798/5000 - Train Loss: 0.075377, Val Loss: 0.067244
2025-09-04 01:05:03,195 - INFO - Epoch 3799/5000 - Train Loss: 0.074727, Val Loss: 0.066417
2025-09-04 01:05:39,693 - INFO - Epoch 3800/5000 - Train Loss: 0.074431, Val Loss: 0.065639
2025-09-04 01:06:16,001 - INFO - Epoch 3801/5000 - Train Loss: 0.074111, Val Loss: 0.065820
2025-09-04 01:06:52,424 - INFO - Epoch 3802/5000 - Train Loss: 0.074718, Val Loss: 0.067088
2025-09-04 01:07:29,549 - INFO - Epoch 3803/5000 - Train Loss: 0.074660, Val Loss: 0.067924
2025-09-04 01:08:06,333 - INFO - Epoch 3804/5000 - Train Loss: 0.075449, Val Loss: 0.067210
2025-09-04 01:08:42,419 - INFO - Epoch 3805/5000 - Train Loss: 0.075715, Val Loss: 0.068677
2025-09-04 01:09:18,140 - INFO - Epoch 3806/5000 - Train Loss: 0.075879, Val Loss: 0.066207
2025-09-04 01:09:55,741 - INFO - Epoch 3807/5000 - Train Loss: 0.075468, Val Loss: 0.065729
2025-09-04 01:10:32,569 - INFO - Epoch 3808/5000 - Train Loss: 0.074701, Val Loss: 0.066616
2025-09-04 01:11:09,848 - INFO - Epoch 3809/5000 - Train Loss: 0.074728, Val Loss: 0.067118
2025-09-04 01:11:46,179 - INFO - Epoch 3810/5000 - Train Loss: 0.075140, Val Loss: 0.067831
2025-09-04 01:12:22,847 - INFO - Epoch 3811/5000 - Train Loss: 0.074657, Val Loss: 0.068719
2025-09-04 01:12:59,147 - INFO - Epoch 3812/5000 - Train Loss: 0.075616, Val Loss: 0.069628
2025-09-04 01:13:35,271 - INFO - Epoch 3813/5000 - Train Loss: 0.076054, Val Loss: 0.069472
2025-09-04 01:14:12,258 - INFO - Epoch 3814/5000 - Train Loss: 0.075933, Val Loss: 0.066510
2025-09-04 01:14:48,996 - INFO - Epoch 3815/5000 - Train Loss: 0.073968, Val Loss: 0.066075
2025-09-04 01:15:25,389 - INFO - Epoch 3816/5000 - Train Loss: 0.075560, Val Loss: 0.065919
2025-09-04 01:16:01,814 - INFO - Epoch 3817/5000 - Train Loss: 0.075344, Val Loss: 0.066679
2025-09-04 01:16:38,993 - INFO - Epoch 3818/5000 - Train Loss: 0.075356, Val Loss: 0.068760
2025-09-04 01:17:14,907 - INFO - Epoch 3819/5000 - Train Loss: 0.074995, Val Loss: 0.068617
2025-09-04 01:17:50,707 - INFO - Epoch 3820/5000 - Train Loss: 0.075500, Val Loss: 0.068070
2025-09-04 01:18:27,176 - INFO - Epoch 3821/5000 - Train Loss: 0.074939, Val Loss: 0.066409
2025-09-04 01:19:03,658 - INFO - Epoch 3822/5000 - Train Loss: 0.075587, Val Loss: 0.068678
2025-09-04 01:19:40,005 - INFO - Epoch 3823/5000 - Train Loss: 0.075702, Val Loss: 0.070202
2025-09-04 01:20:16,359 - INFO - Epoch 3824/5000 - Train Loss: 0.075307, Val Loss: 0.068250
2025-09-04 01:20:52,678 - INFO - Epoch 3825/5000 - Train Loss: 0.075186, Val Loss: 0.066451
2025-09-04 01:21:29,171 - INFO - Epoch 3826/5000 - Train Loss: 0.074091, Val Loss: 0.065681
2025-09-04 01:22:06,128 - INFO - Epoch 3827/5000 - Train Loss: 0.073808, Val Loss: 0.065823
2025-09-04 01:22:42,601 - INFO - Epoch 3828/5000 - Train Loss: 0.074711, Val Loss: 0.065619
2025-09-04 01:23:19,188 - INFO - Epoch 3829/5000 - Train Loss: 0.074205, Val Loss: 0.069425
2025-09-04 01:23:55,579 - INFO - Epoch 3830/5000 - Train Loss: 0.074370, Val Loss: 0.065570
2025-09-04 01:24:32,065 - INFO - Epoch 3831/5000 - Train Loss: 0.074671, Val Loss: 0.065399
2025-09-04 01:25:07,690 - INFO - Epoch 3832/5000 - Train Loss: 0.074501, Val Loss: 0.066598
2025-09-04 01:25:44,203 - INFO - Epoch 3833/5000 - Train Loss: 0.074458, Val Loss: 0.067608
2025-09-04 01:26:20,980 - INFO - Epoch 3834/5000 - Train Loss: 0.075386, Val Loss: 0.068347
2025-09-04 01:26:56,678 - INFO - Epoch 3835/5000 - Train Loss: 0.074700, Val Loss: 0.067608
2025-09-04 01:27:33,253 - INFO - Epoch 3836/5000 - Train Loss: 0.074923, Val Loss: 0.065040
2025-09-04 01:27:33,299 - INFO - New best model saved with Val Loss: 0.065040
2025-09-04 01:28:09,312 - INFO - Epoch 3837/5000 - Train Loss: 0.074451, Val Loss: 0.068634
2025-09-04 01:28:45,606 - INFO - Epoch 3838/5000 - Train Loss: 0.075339, Val Loss: 0.065649
2025-09-04 01:29:21,523 - INFO - Epoch 3839/5000 - Train Loss: 0.073930, Val Loss: 0.065912
2025-09-04 01:29:57,849 - INFO - Epoch 3840/5000 - Train Loss: 0.073773, Val Loss: 0.066627
2025-09-04 01:30:34,497 - INFO - Epoch 3841/5000 - Train Loss: 0.074422, Val Loss: 0.066173
2025-09-04 01:31:10,792 - INFO - Epoch 3842/5000 - Train Loss: 0.074554, Val Loss: 0.066260
2025-09-04 01:31:46,654 - INFO - Epoch 3843/5000 - Train Loss: 0.074251, Val Loss: 0.065636
2025-09-04 01:32:22,658 - INFO - Epoch 3844/5000 - Train Loss: 0.074576, Val Loss: 0.065942
2025-09-04 01:32:58,920 - INFO - Epoch 3845/5000 - Train Loss: 0.074589, Val Loss: 0.067615
2025-09-04 01:33:35,634 - INFO - Epoch 3846/5000 - Train Loss: 0.074185, Val Loss: 0.068054
2025-09-04 01:34:12,270 - INFO - Epoch 3847/5000 - Train Loss: 0.075053, Val Loss: 0.066603
2025-09-04 01:34:48,749 - INFO - Epoch 3848/5000 - Train Loss: 0.073312, Val Loss: 0.066146
2025-09-04 01:35:24,790 - INFO - Epoch 3849/5000 - Train Loss: 0.074624, Val Loss: 0.065416
2025-09-04 01:36:01,114 - INFO - Epoch 3850/5000 - Train Loss: 0.074477, Val Loss: 0.064537
2025-09-04 01:36:01,146 - INFO - New best model saved with Val Loss: 0.064537
2025-09-04 01:36:36,978 - INFO - Epoch 3851/5000 - Train Loss: 0.074476, Val Loss: 0.065923
2025-09-04 01:37:13,037 - INFO - Epoch 3852/5000 - Train Loss: 0.075139, Val Loss: 0.069078
2025-09-04 01:37:48,828 - INFO - Epoch 3853/5000 - Train Loss: 0.074767, Val Loss: 0.066340
2025-09-04 01:38:25,241 - INFO - Epoch 3854/5000 - Train Loss: 0.074583, Val Loss: 0.064854
2025-09-04 01:39:01,949 - INFO - Epoch 3855/5000 - Train Loss: 0.074279, Val Loss: 0.065129
2025-09-04 01:39:38,277 - INFO - Epoch 3856/5000 - Train Loss: 0.074285, Val Loss: 0.065990
2025-09-04 01:40:14,365 - INFO - Epoch 3857/5000 - Train Loss: 0.074920, Val Loss: 0.067635
2025-09-04 01:40:49,546 - INFO - Epoch 3858/5000 - Train Loss: 0.074146, Val Loss: 0.065648
2025-09-04 01:41:25,677 - INFO - Epoch 3859/5000 - Train Loss: 0.075007, Val Loss: 0.065501
2025-09-04 01:42:01,796 - INFO - Epoch 3860/5000 - Train Loss: 0.074365, Val Loss: 0.066503
2025-09-04 01:42:37,914 - INFO - Epoch 3861/5000 - Train Loss: 0.075302, Val Loss: 0.067544
2025-09-04 01:43:14,168 - INFO - Epoch 3862/5000 - Train Loss: 0.075143, Val Loss: 0.065884
2025-09-04 01:43:50,629 - INFO - Epoch 3863/5000 - Train Loss: 0.074417, Val Loss: 0.067390
2025-09-04 01:44:26,627 - INFO - Epoch 3864/5000 - Train Loss: 0.074429, Val Loss: 0.067249
2025-09-04 01:45:02,719 - INFO - Epoch 3865/5000 - Train Loss: 0.075869, Val Loss: 0.068872
2025-09-04 01:45:39,172 - INFO - Epoch 3866/5000 - Train Loss: 0.075163, Val Loss: 0.067771
2025-09-04 01:46:16,045 - INFO - Epoch 3867/5000 - Train Loss: 0.074625, Val Loss: 0.066546
2025-09-04 01:46:52,466 - INFO - Epoch 3868/5000 - Train Loss: 0.076466, Val Loss: 0.066229
2025-09-04 01:47:28,572 - INFO - Epoch 3869/5000 - Train Loss: 0.073010, Val Loss: 0.066914
2025-09-04 01:48:04,498 - INFO - Epoch 3870/5000 - Train Loss: 0.074359, Val Loss: 0.065633
2025-09-04 01:48:40,786 - INFO - Epoch 3871/5000 - Train Loss: 0.074897, Val Loss: 0.068308
2025-09-04 01:49:16,828 - INFO - Epoch 3872/5000 - Train Loss: 0.075580, Val Loss: 0.067214
2025-09-04 01:49:53,009 - INFO - Epoch 3873/5000 - Train Loss: 0.075381, Val Loss: 0.065660
2025-09-04 01:50:29,572 - INFO - Epoch 3874/5000 - Train Loss: 0.073697, Val Loss: 0.066697
2025-09-04 01:51:05,991 - INFO - Epoch 3875/5000 - Train Loss: 0.074516, Val Loss: 0.066087
2025-09-04 01:51:42,208 - INFO - Epoch 3876/5000 - Train Loss: 0.074384, Val Loss: 0.065665
2025-09-04 01:52:17,654 - INFO - Epoch 3877/5000 - Train Loss: 0.074243, Val Loss: 0.066699
2025-09-04 01:52:53,744 - INFO - Epoch 3878/5000 - Train Loss: 0.075046, Val Loss: 0.068326
2025-09-04 01:53:29,179 - INFO - Epoch 3879/5000 - Train Loss: 0.075129, Val Loss: 0.066678
2025-09-04 01:54:04,924 - INFO - Epoch 3880/5000 - Train Loss: 0.073331, Val Loss: 0.069559
2025-09-04 01:54:41,355 - INFO - Epoch 3881/5000 - Train Loss: 0.074211, Val Loss: 0.066177
2025-09-04 01:55:17,420 - INFO - Epoch 3882/5000 - Train Loss: 0.076209, Val Loss: 0.067386
2025-09-04 01:55:53,325 - INFO - Epoch 3883/5000 - Train Loss: 0.074698, Val Loss: 0.067158
2025-09-04 01:56:29,166 - INFO - Epoch 3884/5000 - Train Loss: 0.075113, Val Loss: 0.066664
2025-09-04 01:57:04,797 - INFO - Epoch 3885/5000 - Train Loss: 0.074549, Val Loss: 0.065673
2025-09-04 01:57:40,937 - INFO - Epoch 3886/5000 - Train Loss: 0.074207, Val Loss: 0.065852
2025-09-04 01:58:17,028 - INFO - Epoch 3887/5000 - Train Loss: 0.075339, Val Loss: 0.067015
2025-09-04 01:58:53,206 - INFO - Epoch 3888/5000 - Train Loss: 0.074051, Val Loss: 0.064956
2025-09-04 01:59:30,210 - INFO - Epoch 3889/5000 - Train Loss: 0.073962, Val Loss: 0.066310
2025-09-04 02:00:07,703 - INFO - Epoch 3890/5000 - Train Loss: 0.074905, Val Loss: 0.066130
2025-09-04 02:00:44,347 - INFO - Epoch 3891/5000 - Train Loss: 0.073606, Val Loss: 0.064731
2025-09-04 02:01:20,313 - INFO - Epoch 3892/5000 - Train Loss: 0.074198, Val Loss: 0.065587
2025-09-04 02:01:56,756 - INFO - Epoch 3893/5000 - Train Loss: 0.073907, Val Loss: 0.067104
2025-09-04 02:02:32,925 - INFO - Epoch 3894/5000 - Train Loss: 0.073987, Val Loss: 0.066684
2025-09-04 02:03:09,797 - INFO - Epoch 3895/5000 - Train Loss: 0.075019, Val Loss: 0.066573
2025-09-04 02:03:45,666 - INFO - Epoch 3896/5000 - Train Loss: 0.074205, Val Loss: 0.070104
2025-09-04 02:04:21,304 - INFO - Epoch 3897/5000 - Train Loss: 0.076064, Val Loss: 0.067523
2025-09-04 02:04:57,212 - INFO - Epoch 3898/5000 - Train Loss: 0.074421, Val Loss: 0.065877
2025-09-04 02:05:32,789 - INFO - Epoch 3899/5000 - Train Loss: 0.072597, Val Loss: 0.067491
2025-09-04 02:06:08,506 - INFO - Epoch 3900/5000 - Train Loss: 0.075436, Val Loss: 0.067148
2025-09-04 02:06:44,566 - INFO - Epoch 3901/5000 - Train Loss: 0.073662, Val Loss: 0.066265
2025-09-04 02:07:21,166 - INFO - Epoch 3902/5000 - Train Loss: 0.074119, Val Loss: 0.066402
2025-09-04 02:07:57,412 - INFO - Epoch 3903/5000 - Train Loss: 0.075478, Val Loss: 0.065752
2025-09-04 02:08:33,304 - INFO - Epoch 3904/5000 - Train Loss: 0.074353, Val Loss: 0.065398
2025-09-04 02:09:09,890 - INFO - Epoch 3905/5000 - Train Loss: 0.074237, Val Loss: 0.065219
2025-09-04 02:09:46,175 - INFO - Epoch 3906/5000 - Train Loss: 0.073872, Val Loss: 0.067795
2025-09-04 02:10:22,428 - INFO - Epoch 3907/5000 - Train Loss: 0.073823, Val Loss: 0.068463
2025-09-04 02:10:58,359 - INFO - Epoch 3908/5000 - Train Loss: 0.074802, Val Loss: 0.066388
2025-09-04 02:11:34,427 - INFO - Epoch 3909/5000 - Train Loss: 0.074093, Val Loss: 0.066736
2025-09-04 02:12:11,456 - INFO - Epoch 3910/5000 - Train Loss: 0.074280, Val Loss: 0.066391
2025-09-04 02:12:48,628 - INFO - Epoch 3911/5000 - Train Loss: 0.073674, Val Loss: 0.066594
2025-09-04 02:13:26,290 - INFO - Epoch 3912/5000 - Train Loss: 0.073325, Val Loss: 0.065703
2025-09-04 02:14:02,539 - INFO - Epoch 3913/5000 - Train Loss: 0.073298, Val Loss: 0.065844
2025-09-04 02:14:38,030 - INFO - Epoch 3914/5000 - Train Loss: 0.073569, Val Loss: 0.066256
2025-09-04 02:15:13,347 - INFO - Epoch 3915/5000 - Train Loss: 0.074142, Val Loss: 0.065766
2025-09-04 02:15:49,648 - INFO - Epoch 3916/5000 - Train Loss: 0.073340, Val Loss: 0.065462
2025-09-04 02:16:24,782 - INFO - Epoch 3917/5000 - Train Loss: 0.073009, Val Loss: 0.065334
2025-09-04 02:17:00,508 - INFO - Epoch 3918/5000 - Train Loss: 0.074107, Val Loss: 0.066850
2025-09-04 02:17:36,082 - INFO - Epoch 3919/5000 - Train Loss: 0.073376, Val Loss: 0.064399
2025-09-04 02:17:36,125 - INFO - New best model saved with Val Loss: 0.064399
2025-09-04 02:18:11,970 - INFO - Epoch 3920/5000 - Train Loss: 0.073225, Val Loss: 0.067232
2025-09-04 02:18:48,101 - INFO - Epoch 3921/5000 - Train Loss: 0.073016, Val Loss: 0.065894
2025-09-04 02:19:23,538 - INFO - Epoch 3922/5000 - Train Loss: 0.074398, Val Loss: 0.065786
2025-09-04 02:19:59,622 - INFO - Epoch 3923/5000 - Train Loss: 0.074497, Val Loss: 0.067472
2025-09-04 02:20:35,539 - INFO - Epoch 3924/5000 - Train Loss: 0.073870, Val Loss: 0.071023
2025-09-04 02:21:11,136 - INFO - Epoch 3925/5000 - Train Loss: 0.073640, Val Loss: 0.066188
2025-09-04 02:21:46,693 - INFO - Epoch 3926/5000 - Train Loss: 0.074143, Val Loss: 0.066956
2025-09-04 02:22:22,944 - INFO - Epoch 3927/5000 - Train Loss: 0.073539, Val Loss: 0.065623
2025-09-04 02:22:58,630 - INFO - Epoch 3928/5000 - Train Loss: 0.074771, Val Loss: 0.066228
2025-09-04 02:23:34,628 - INFO - Epoch 3929/5000 - Train Loss: 0.074501, Val Loss: 0.067240
2025-09-04 02:24:10,667 - INFO - Epoch 3930/5000 - Train Loss: 0.073941, Val Loss: 0.066088
2025-09-04 02:24:47,139 - INFO - Epoch 3931/5000 - Train Loss: 0.073584, Val Loss: 0.068655
2025-09-04 02:25:23,252 - INFO - Epoch 3932/5000 - Train Loss: 0.074158, Val Loss: 0.068714
2025-09-04 02:25:59,541 - INFO - Epoch 3933/5000 - Train Loss: 0.074299, Val Loss: 0.065662
2025-09-04 02:26:35,693 - INFO - Epoch 3934/5000 - Train Loss: 0.073185, Val Loss: 0.066248
2025-09-04 02:27:12,800 - INFO - Epoch 3935/5000 - Train Loss: 0.073061, Val Loss: 0.063363
2025-09-04 02:27:12,832 - INFO - New best model saved with Val Loss: 0.063363
2025-09-04 02:27:49,570 - INFO - Epoch 3936/5000 - Train Loss: 0.072702, Val Loss: 0.066176
2025-09-04 02:28:25,336 - INFO - Epoch 3937/5000 - Train Loss: 0.074982, Val Loss: 0.067913
2025-09-04 02:29:01,442 - INFO - Epoch 3938/5000 - Train Loss: 0.074400, Val Loss: 0.065410
2025-09-04 02:29:38,132 - INFO - Epoch 3939/5000 - Train Loss: 0.073682, Val Loss: 0.065965
2025-09-04 02:30:15,028 - INFO - Epoch 3940/5000 - Train Loss: 0.073970, Val Loss: 0.066390
2025-09-04 02:30:51,646 - INFO - Epoch 3941/5000 - Train Loss: 0.074415, Val Loss: 0.066534
2025-09-04 02:31:28,303 - INFO - Epoch 3942/5000 - Train Loss: 0.073946, Val Loss: 0.066297
2025-09-04 02:32:05,045 - INFO - Epoch 3943/5000 - Train Loss: 0.073461, Val Loss: 0.067071
2025-09-04 02:32:41,197 - INFO - Epoch 3944/5000 - Train Loss: 0.073219, Val Loss: 0.064171
2025-09-04 02:33:17,741 - INFO - Epoch 3945/5000 - Train Loss: 0.073339, Val Loss: 0.066893
2025-09-04 02:33:53,927 - INFO - Epoch 3946/5000 - Train Loss: 0.073657, Val Loss: 0.064782
2025-09-04 02:34:29,986 - INFO - Epoch 3947/5000 - Train Loss: 0.073798, Val Loss: 0.065981
2025-09-04 02:35:06,273 - INFO - Epoch 3948/5000 - Train Loss: 0.073951, Val Loss: 0.065268
2025-09-04 02:35:42,967 - INFO - Epoch 3949/5000 - Train Loss: 0.073487, Val Loss: 0.065418
2025-09-04 02:36:19,360 - INFO - Epoch 3950/5000 - Train Loss: 0.073357, Val Loss: 0.065237
2025-09-04 02:36:56,126 - INFO - Epoch 3951/5000 - Train Loss: 0.072336, Val Loss: 0.065269
2025-09-04 02:37:31,587 - INFO - Epoch 3952/5000 - Train Loss: 0.072872, Val Loss: 0.064231
2025-09-04 02:38:08,528 - INFO - Epoch 3953/5000 - Train Loss: 0.073365, Val Loss: 0.067753
2025-09-04 02:38:45,119 - INFO - Epoch 3954/5000 - Train Loss: 0.073471, Val Loss: 0.065432
2025-09-04 02:39:21,225 - INFO - Epoch 3955/5000 - Train Loss: 0.073973, Val Loss: 0.065398
2025-09-04 02:39:58,300 - INFO - Epoch 3956/5000 - Train Loss: 0.074878, Val Loss: 0.067470
2025-09-04 02:40:35,320 - INFO - Epoch 3957/5000 - Train Loss: 0.075255, Val Loss: 0.068567
2025-09-04 02:41:11,702 - INFO - Epoch 3958/5000 - Train Loss: 0.073708, Val Loss: 0.065915
2025-09-04 02:41:48,491 - INFO - Epoch 3959/5000 - Train Loss: 0.074575, Val Loss: 0.066682
2025-09-04 02:42:24,613 - INFO - Epoch 3960/5000 - Train Loss: 0.074399, Val Loss: 0.066719
2025-09-04 02:43:00,872 - INFO - Epoch 3961/5000 - Train Loss: 0.073958, Val Loss: 0.065906
2025-09-04 02:43:37,173 - INFO - Epoch 3962/5000 - Train Loss: 0.073375, Val Loss: 0.067589
2025-09-04 02:44:13,102 - INFO - Epoch 3963/5000 - Train Loss: 0.074461, Val Loss: 0.068864
2025-09-04 02:44:50,212 - INFO - Epoch 3964/5000 - Train Loss: 0.074208, Val Loss: 0.064904
2025-09-04 02:45:26,516 - INFO - Epoch 3965/5000 - Train Loss: 0.073287, Val Loss: 0.064110
2025-09-04 02:46:02,680 - INFO - Epoch 3966/5000 - Train Loss: 0.074166, Val Loss: 0.065913
2025-09-04 02:46:38,961 - INFO - Epoch 3967/5000 - Train Loss: 0.073499, Val Loss: 0.064606
2025-09-04 02:47:15,001 - INFO - Epoch 3968/5000 - Train Loss: 0.073287, Val Loss: 0.064357
2025-09-04 02:47:52,039 - INFO - Epoch 3969/5000 - Train Loss: 0.073428, Val Loss: 0.065338
2025-09-04 02:48:29,064 - INFO - Epoch 3970/5000 - Train Loss: 0.073670, Val Loss: 0.065519
2025-09-04 02:49:05,918 - INFO - Epoch 3971/5000 - Train Loss: 0.073291, Val Loss: 0.064422
2025-09-04 02:49:42,140 - INFO - Epoch 3972/5000 - Train Loss: 0.074052, Val Loss: 0.064381
2025-09-04 02:50:18,644 - INFO - Epoch 3973/5000 - Train Loss: 0.073345, Val Loss: 0.066197
2025-09-04 02:50:55,348 - INFO - Epoch 3974/5000 - Train Loss: 0.073332, Val Loss: 0.066020
2025-09-04 02:51:32,678 - INFO - Epoch 3975/5000 - Train Loss: 0.073840, Val Loss: 0.066406
2025-09-04 02:52:09,061 - INFO - Epoch 3976/5000 - Train Loss: 0.074624, Val Loss: 0.064405
2025-09-04 02:52:45,881 - INFO - Epoch 3977/5000 - Train Loss: 0.073385, Val Loss: 0.066696
2025-09-04 02:53:22,925 - INFO - Epoch 3978/5000 - Train Loss: 0.074261, Val Loss: 0.064868
2025-09-04 02:53:59,920 - INFO - Epoch 3979/5000 - Train Loss: 0.072874, Val Loss: 0.064203
2025-09-04 02:54:36,948 - INFO - Epoch 3980/5000 - Train Loss: 0.072548, Val Loss: 0.066234
2025-09-04 02:55:14,352 - INFO - Epoch 3981/5000 - Train Loss: 0.072477, Val Loss: 0.064275
2025-09-04 02:55:51,411 - INFO - Epoch 3982/5000 - Train Loss: 0.072423, Val Loss: 0.064551
2025-09-04 02:56:28,240 - INFO - Epoch 3983/5000 - Train Loss: 0.073367, Val Loss: 0.065896
2025-09-04 02:57:04,980 - INFO - Epoch 3984/5000 - Train Loss: 0.073865, Val Loss: 0.065283
2025-09-04 02:57:42,743 - INFO - Epoch 3985/5000 - Train Loss: 0.072494, Val Loss: 0.064530
2025-09-04 02:58:19,235 - INFO - Epoch 3986/5000 - Train Loss: 0.073708, Val Loss: 0.065247
2025-09-04 02:58:56,338 - INFO - Epoch 3987/5000 - Train Loss: 0.074125, Val Loss: 0.065219
2025-09-04 02:59:32,739 - INFO - Epoch 3988/5000 - Train Loss: 0.073224, Val Loss: 0.066887
2025-09-04 03:00:09,217 - INFO - Epoch 3989/5000 - Train Loss: 0.073535, Val Loss: 0.065713
2025-09-04 03:00:45,385 - INFO - Epoch 3990/5000 - Train Loss: 0.073678, Val Loss: 0.066410
2025-09-04 03:01:21,569 - INFO - Epoch 3991/5000 - Train Loss: 0.073020, Val Loss: 0.064851
2025-09-04 03:01:57,937 - INFO - Epoch 3992/5000 - Train Loss: 0.072520, Val Loss: 0.066804
2025-09-04 03:02:34,978 - INFO - Epoch 3993/5000 - Train Loss: 0.073660, Val Loss: 0.065284
2025-09-04 03:03:11,325 - INFO - Epoch 3994/5000 - Train Loss: 0.074047, Val Loss: 0.066566
2025-09-04 03:03:47,803 - INFO - Epoch 3995/5000 - Train Loss: 0.073913, Val Loss: 0.068034
2025-09-04 03:04:24,187 - INFO - Epoch 3996/5000 - Train Loss: 0.073883, Val Loss: 0.065059
2025-09-04 03:05:01,256 - INFO - Epoch 3997/5000 - Train Loss: 0.073545, Val Loss: 0.065554
2025-09-04 03:05:38,136 - INFO - Epoch 3998/5000 - Train Loss: 0.072660, Val Loss: 0.065903
2025-09-04 03:06:14,306 - INFO - Epoch 3999/5000 - Train Loss: 0.073570, Val Loss: 0.065191
2025-09-04 03:06:51,204 - INFO - Epoch 4000/5000 - Train Loss: 0.073708, Val Loss: 0.069499
2025-09-04 03:07:27,829 - INFO - Epoch 4001/5000 - Train Loss: 0.074964, Val Loss: 0.066883
2025-09-04 03:08:04,344 - INFO - Epoch 4002/5000 - Train Loss: 0.073558, Val Loss: 0.063965
2025-09-04 03:08:41,075 - INFO - Epoch 4003/5000 - Train Loss: 0.072822, Val Loss: 0.066039
2025-09-04 03:09:18,110 - INFO - Epoch 4004/5000 - Train Loss: 0.072757, Val Loss: 0.064742
2025-09-04 03:09:54,164 - INFO - Epoch 4005/5000 - Train Loss: 0.073744, Val Loss: 0.067778
2025-09-04 03:10:30,509 - INFO - Epoch 4006/5000 - Train Loss: 0.073966, Val Loss: 0.064389
2025-09-04 03:11:07,102 - INFO - Epoch 4007/5000 - Train Loss: 0.074510, Val Loss: 0.065854
2025-09-04 03:11:43,729 - INFO - Epoch 4008/5000 - Train Loss: 0.073468, Val Loss: 0.065595
2025-09-04 03:12:20,286 - INFO - Epoch 4009/5000 - Train Loss: 0.073135, Val Loss: 0.065874
2025-09-04 03:12:57,182 - INFO - Epoch 4010/5000 - Train Loss: 0.072205, Val Loss: 0.067078
2025-09-04 03:13:33,929 - INFO - Epoch 4011/5000 - Train Loss: 0.073298, Val Loss: 0.066356
2025-09-04 03:14:09,791 - INFO - Epoch 4012/5000 - Train Loss: 0.075650, Val Loss: 0.065998
2025-09-04 03:14:45,929 - INFO - Epoch 4013/5000 - Train Loss: 0.073952, Val Loss: 0.065199
2025-09-04 03:15:21,883 - INFO - Epoch 4014/5000 - Train Loss: 0.072667, Val Loss: 0.066527
2025-09-04 03:15:58,443 - INFO - Epoch 4015/5000 - Train Loss: 0.072504, Val Loss: 0.065618
2025-09-04 03:16:35,054 - INFO - Epoch 4016/5000 - Train Loss: 0.073123, Val Loss: 0.066056
2025-09-04 03:17:12,069 - INFO - Epoch 4017/5000 - Train Loss: 0.073329, Val Loss: 0.067139
2025-09-04 03:17:48,563 - INFO - Epoch 4018/5000 - Train Loss: 0.072597, Val Loss: 0.064682
2025-09-04 03:18:25,191 - INFO - Epoch 4019/5000 - Train Loss: 0.072405, Val Loss: 0.063951
2025-09-04 03:19:01,308 - INFO - Epoch 4020/5000 - Train Loss: 0.072883, Val Loss: 0.067761
2025-09-04 03:19:37,657 - INFO - Epoch 4021/5000 - Train Loss: 0.073352, Val Loss: 0.065216
2025-09-04 03:20:14,954 - INFO - Epoch 4022/5000 - Train Loss: 0.072360, Val Loss: 0.064286
2025-09-04 03:20:51,183 - INFO - Epoch 4023/5000 - Train Loss: 0.072283, Val Loss: 0.064947
2025-09-04 03:21:27,412 - INFO - Epoch 4024/5000 - Train Loss: 0.072176, Val Loss: 0.064423
2025-09-04 03:22:03,674 - INFO - Epoch 4025/5000 - Train Loss: 0.072602, Val Loss: 0.064429
2025-09-04 03:22:40,178 - INFO - Epoch 4026/5000 - Train Loss: 0.072282, Val Loss: 0.065904
2025-09-04 03:23:16,518 - INFO - Epoch 4027/5000 - Train Loss: 0.073153, Val Loss: 0.067183
2025-09-04 03:23:53,201 - INFO - Epoch 4028/5000 - Train Loss: 0.073501, Val Loss: 0.065312
2025-09-04 03:24:29,807 - INFO - Epoch 4029/5000 - Train Loss: 0.072320, Val Loss: 0.063971
2025-09-04 03:25:06,640 - INFO - Epoch 4030/5000 - Train Loss: 0.073828, Val Loss: 0.065299
2025-09-04 03:25:43,078 - INFO - Epoch 4031/5000 - Train Loss: 0.073284, Val Loss: 0.064170
2025-09-04 03:26:19,182 - INFO - Epoch 4032/5000 - Train Loss: 0.072493, Val Loss: 0.065694
2025-09-04 03:26:55,415 - INFO - Epoch 4033/5000 - Train Loss: 0.072414, Val Loss: 0.064290
2025-09-04 03:27:31,678 - INFO - Epoch 4034/5000 - Train Loss: 0.072424, Val Loss: 0.065298
2025-09-04 03:28:08,196 - INFO - Epoch 4035/5000 - Train Loss: 0.072569, Val Loss: 0.066019
2025-09-04 03:28:45,120 - INFO - Epoch 4036/5000 - Train Loss: 0.073694, Val Loss: 0.066278
2025-09-04 03:29:21,973 - INFO - Epoch 4037/5000 - Train Loss: 0.073284, Val Loss: 0.064635
2025-09-04 03:29:57,476 - INFO - Epoch 4038/5000 - Train Loss: 0.072812, Val Loss: 0.066060
2025-09-04 03:30:34,057 - INFO - Epoch 4039/5000 - Train Loss: 0.073812, Val Loss: 0.066890
2025-09-04 03:31:10,976 - INFO - Epoch 4040/5000 - Train Loss: 0.073575, Val Loss: 0.068498
2025-09-04 03:31:47,451 - INFO - Epoch 4041/5000 - Train Loss: 0.073136, Val Loss: 0.065535
2025-09-04 03:32:24,309 - INFO - Epoch 4042/5000 - Train Loss: 0.073556, Val Loss: 0.066734
2025-09-04 03:33:01,071 - INFO - Epoch 4043/5000 - Train Loss: 0.072665, Val Loss: 0.064226
2025-09-04 03:33:38,282 - INFO - Epoch 4044/5000 - Train Loss: 0.072379, Val Loss: 0.064115
2025-09-04 03:34:14,585 - INFO - Epoch 4045/5000 - Train Loss: 0.072174, Val Loss: 0.064079
2025-09-04 03:34:51,328 - INFO - Epoch 4046/5000 - Train Loss: 0.072079, Val Loss: 0.065047
2025-09-04 03:35:27,563 - INFO - Epoch 4047/5000 - Train Loss: 0.072727, Val Loss: 0.063884
2025-09-04 03:36:04,122 - INFO - Epoch 4048/5000 - Train Loss: 0.072057, Val Loss: 0.064240
2025-09-04 03:36:40,816 - INFO - Epoch 4049/5000 - Train Loss: 0.071893, Val Loss: 0.064489
2025-09-04 03:37:17,634 - INFO - Epoch 4050/5000 - Train Loss: 0.073244, Val Loss: 0.065479
2025-09-04 03:37:54,299 - INFO - Epoch 4051/5000 - Train Loss: 0.073587, Val Loss: 0.068341
2025-09-04 03:38:30,991 - INFO - Epoch 4052/5000 - Train Loss: 0.073291, Val Loss: 0.065207
2025-09-04 03:39:07,579 - INFO - Epoch 4053/5000 - Train Loss: 0.072484, Val Loss: 0.063819
2025-09-04 03:39:43,344 - INFO - Epoch 4054/5000 - Train Loss: 0.073475, Val Loss: 0.067107
2025-09-04 03:40:19,817 - INFO - Epoch 4055/5000 - Train Loss: 0.073427, Val Loss: 0.065112
2025-09-04 03:40:56,455 - INFO - Epoch 4056/5000 - Train Loss: 0.072447, Val Loss: 0.064905
2025-09-04 03:41:32,835 - INFO - Epoch 4057/5000 - Train Loss: 0.072617, Val Loss: 0.066762
2025-09-04 03:42:09,045 - INFO - Epoch 4058/5000 - Train Loss: 0.073406, Val Loss: 0.064851
2025-09-04 03:42:46,013 - INFO - Epoch 4059/5000 - Train Loss: 0.072247, Val Loss: 0.065062
2025-09-04 03:43:21,878 - INFO - Epoch 4060/5000 - Train Loss: 0.072217, Val Loss: 0.064859
2025-09-04 03:43:58,527 - INFO - Epoch 4061/5000 - Train Loss: 0.071899, Val Loss: 0.063389
2025-09-04 03:44:34,435 - INFO - Epoch 4062/5000 - Train Loss: 0.073029, Val Loss: 0.064461
2025-09-04 03:45:10,566 - INFO - Epoch 4063/5000 - Train Loss: 0.072373, Val Loss: 0.064485
2025-09-04 03:45:47,140 - INFO - Epoch 4064/5000 - Train Loss: 0.072332, Val Loss: 0.066255
2025-09-04 03:46:22,728 - INFO - Epoch 4065/5000 - Train Loss: 0.072782, Val Loss: 0.064229
2025-09-04 03:46:59,093 - INFO - Epoch 4066/5000 - Train Loss: 0.072828, Val Loss: 0.065052
2025-09-04 03:47:35,159 - INFO - Epoch 4067/5000 - Train Loss: 0.073587, Val Loss: 0.064804
2025-09-04 03:48:12,136 - INFO - Epoch 4068/5000 - Train Loss: 0.072299, Val Loss: 0.064286
2025-09-04 03:48:47,613 - INFO - Epoch 4069/5000 - Train Loss: 0.074602, Val Loss: 0.066535
2025-09-04 03:49:23,672 - INFO - Epoch 4070/5000 - Train Loss: 0.072972, Val Loss: 0.064274
2025-09-04 03:50:00,049 - INFO - Epoch 4071/5000 - Train Loss: 0.072320, Val Loss: 0.064541
2025-09-04 03:50:36,012 - INFO - Epoch 4072/5000 - Train Loss: 0.073004, Val Loss: 0.064247
2025-09-04 03:51:11,796 - INFO - Epoch 4073/5000 - Train Loss: 0.072041, Val Loss: 0.065409
2025-09-04 03:51:48,020 - INFO - Epoch 4074/5000 - Train Loss: 0.073257, Val Loss: 0.066509
2025-09-04 03:52:23,700 - INFO - Epoch 4075/5000 - Train Loss: 0.072263, Val Loss: 0.063715
2025-09-04 03:52:59,960 - INFO - Epoch 4076/5000 - Train Loss: 0.072768, Val Loss: 0.064201
2025-09-04 03:53:35,997 - INFO - Epoch 4077/5000 - Train Loss: 0.072572, Val Loss: 0.065090
2025-09-04 03:54:11,575 - INFO - Epoch 4078/5000 - Train Loss: 0.072072, Val Loss: 0.064295
2025-09-04 03:54:47,498 - INFO - Epoch 4079/5000 - Train Loss: 0.072037, Val Loss: 0.064780
2025-09-04 03:55:23,427 - INFO - Epoch 4080/5000 - Train Loss: 0.072624, Val Loss: 0.065071
2025-09-04 03:55:59,189 - INFO - Epoch 4081/5000 - Train Loss: 0.072140, Val Loss: 0.063739
2025-09-04 03:56:34,837 - INFO - Epoch 4082/5000 - Train Loss: 0.071304, Val Loss: 0.065632
2025-09-04 03:57:10,580 - INFO - Epoch 4083/5000 - Train Loss: 0.073007, Val Loss: 0.065638
2025-09-04 03:57:46,211 - INFO - Epoch 4084/5000 - Train Loss: 0.072180, Val Loss: 0.063629
2025-09-04 03:58:23,056 - INFO - Epoch 4085/5000 - Train Loss: 0.072572, Val Loss: 0.063684
2025-09-04 03:58:58,304 - INFO - Epoch 4086/5000 - Train Loss: 0.072063, Val Loss: 0.064126
2025-09-04 03:59:34,925 - INFO - Epoch 4087/5000 - Train Loss: 0.072523, Val Loss: 0.065321
2025-09-04 04:00:12,508 - INFO - Epoch 4088/5000 - Train Loss: 0.072273, Val Loss: 0.064341
2025-09-04 04:00:48,890 - INFO - Epoch 4089/5000 - Train Loss: 0.072345, Val Loss: 0.063856
2025-09-04 04:01:24,856 - INFO - Epoch 4090/5000 - Train Loss: 0.071426, Val Loss: 0.064156
2025-09-04 04:02:00,969 - INFO - Epoch 4091/5000 - Train Loss: 0.072272, Val Loss: 0.065159
2025-09-04 04:02:37,222 - INFO - Epoch 4092/5000 - Train Loss: 0.072612, Val Loss: 0.064464
2025-09-04 04:03:12,978 - INFO - Epoch 4093/5000 - Train Loss: 0.072422, Val Loss: 0.064530
2025-09-04 04:03:49,395 - INFO - Epoch 4094/5000 - Train Loss: 0.071867, Val Loss: 0.064008
2025-09-04 04:04:25,641 - INFO - Epoch 4095/5000 - Train Loss: 0.072697, Val Loss: 0.065090
2025-09-04 04:05:02,063 - INFO - Epoch 4096/5000 - Train Loss: 0.072432, Val Loss: 0.064397
2025-09-04 04:05:38,108 - INFO - Epoch 4097/5000 - Train Loss: 0.072762, Val Loss: 0.067034
2025-09-04 04:06:13,977 - INFO - Epoch 4098/5000 - Train Loss: 0.072353, Val Loss: 0.064228
2025-09-04 04:06:50,355 - INFO - Epoch 4099/5000 - Train Loss: 0.071734, Val Loss: 0.065011
2025-09-04 04:07:26,567 - INFO - Epoch 4100/5000 - Train Loss: 0.071986, Val Loss: 0.063266
2025-09-04 04:07:26,617 - INFO - New best model saved with Val Loss: 0.063266
2025-09-04 04:08:02,858 - INFO - Epoch 4101/5000 - Train Loss: 0.072003, Val Loss: 0.066730
2025-09-04 04:08:38,632 - INFO - Epoch 4102/5000 - Train Loss: 0.072595, Val Loss: 0.064757
2025-09-04 04:09:14,672 - INFO - Epoch 4103/5000 - Train Loss: 0.072097, Val Loss: 0.065451
2025-09-04 04:09:50,924 - INFO - Epoch 4104/5000 - Train Loss: 0.071598, Val Loss: 0.064680
2025-09-04 04:10:27,217 - INFO - Epoch 4105/5000 - Train Loss: 0.072243, Val Loss: 0.066619
2025-09-04 04:11:03,657 - INFO - Epoch 4106/5000 - Train Loss: 0.072118, Val Loss: 0.064833
2025-09-04 04:11:39,575 - INFO - Epoch 4107/5000 - Train Loss: 0.071773, Val Loss: 0.065217
2025-09-04 04:12:15,641 - INFO - Epoch 4108/5000 - Train Loss: 0.072279, Val Loss: 0.065039
2025-09-04 04:12:52,019 - INFO - Epoch 4109/5000 - Train Loss: 0.072639, Val Loss: 0.066822
2025-09-04 04:13:28,555 - INFO - Epoch 4110/5000 - Train Loss: 0.073371, Val Loss: 0.066118
2025-09-04 04:14:05,085 - INFO - Epoch 4111/5000 - Train Loss: 0.072766, Val Loss: 0.063121
2025-09-04 04:14:05,117 - INFO - New best model saved with Val Loss: 0.063121
2025-09-04 04:14:41,399 - INFO - Epoch 4112/5000 - Train Loss: 0.071751, Val Loss: 0.063867
2025-09-04 04:15:17,334 - INFO - Epoch 4113/5000 - Train Loss: 0.072808, Val Loss: 0.067352
2025-09-04 04:15:53,330 - INFO - Epoch 4114/5000 - Train Loss: 0.072472, Val Loss: 0.065344
2025-09-04 04:16:29,932 - INFO - Epoch 4115/5000 - Train Loss: 0.072205, Val Loss: 0.065922
2025-09-04 04:17:06,462 - INFO - Epoch 4116/5000 - Train Loss: 0.072671, Val Loss: 0.065457
2025-09-04 04:17:43,103 - INFO - Epoch 4117/5000 - Train Loss: 0.072165, Val Loss: 0.063497
2025-09-04 04:18:19,605 - INFO - Epoch 4118/5000 - Train Loss: 0.071931, Val Loss: 0.064627
2025-09-04 04:18:55,943 - INFO - Epoch 4119/5000 - Train Loss: 0.072948, Val Loss: 0.064802
2025-09-04 04:19:31,577 - INFO - Epoch 4120/5000 - Train Loss: 0.072202, Val Loss: 0.064704
2025-09-04 04:20:08,380 - INFO - Epoch 4121/5000 - Train Loss: 0.071706, Val Loss: 0.065412
2025-09-04 04:20:43,903 - INFO - Epoch 4122/5000 - Train Loss: 0.071787, Val Loss: 0.064023
2025-09-04 04:21:19,949 - INFO - Epoch 4123/5000 - Train Loss: 0.072021, Val Loss: 0.065653
2025-09-04 04:21:55,905 - INFO - Epoch 4124/5000 - Train Loss: 0.072129, Val Loss: 0.064323
2025-09-04 04:22:32,229 - INFO - Epoch 4125/5000 - Train Loss: 0.072460, Val Loss: 0.066255
2025-09-04 04:23:08,936 - INFO - Epoch 4126/5000 - Train Loss: 0.072980, Val Loss: 0.064775
2025-09-04 04:23:45,317 - INFO - Epoch 4127/5000 - Train Loss: 0.072522, Val Loss: 0.064397
2025-09-04 04:24:21,335 - INFO - Epoch 4128/5000 - Train Loss: 0.071841, Val Loss: 0.066781
2025-09-04 04:24:57,590 - INFO - Epoch 4129/5000 - Train Loss: 0.072196, Val Loss: 0.064608
2025-09-04 04:25:33,342 - INFO - Epoch 4130/5000 - Train Loss: 0.073227, Val Loss: 0.064573
2025-09-04 04:26:09,744 - INFO - Epoch 4131/5000 - Train Loss: 0.072900, Val Loss: 0.064244
2025-09-04 04:26:45,762 - INFO - Epoch 4132/5000 - Train Loss: 0.072160, Val Loss: 0.063154
2025-09-04 04:27:22,245 - INFO - Epoch 4133/5000 - Train Loss: 0.071745, Val Loss: 0.064338
2025-09-04 04:27:58,801 - INFO - Epoch 4134/5000 - Train Loss: 0.071842, Val Loss: 0.064843
2025-09-04 04:28:35,675 - INFO - Epoch 4135/5000 - Train Loss: 0.072077, Val Loss: 0.063852
2025-09-04 04:29:12,173 - INFO - Epoch 4136/5000 - Train Loss: 0.071556, Val Loss: 0.064973
2025-09-04 04:29:48,976 - INFO - Epoch 4137/5000 - Train Loss: 0.072594, Val Loss: 0.065741
2025-09-04 04:30:25,217 - INFO - Epoch 4138/5000 - Train Loss: 0.071980, Val Loss: 0.063196
2025-09-04 04:31:01,811 - INFO - Epoch 4139/5000 - Train Loss: 0.072277, Val Loss: 0.065366
2025-09-04 04:31:38,427 - INFO - Epoch 4140/5000 - Train Loss: 0.072227, Val Loss: 0.066373
2025-09-04 04:32:14,287 - INFO - Epoch 4141/5000 - Train Loss: 0.071696, Val Loss: 0.065966
2025-09-04 04:32:51,658 - INFO - Epoch 4142/5000 - Train Loss: 0.072073, Val Loss: 0.064948
2025-09-04 04:33:28,725 - INFO - Epoch 4143/5000 - Train Loss: 0.071865, Val Loss: 0.064003
2025-09-04 04:34:05,884 - INFO - Epoch 4144/5000 - Train Loss: 0.072334, Val Loss: 0.065234
2025-09-04 04:34:41,906 - INFO - Epoch 4145/5000 - Train Loss: 0.071694, Val Loss: 0.065465
2025-09-04 04:35:18,479 - INFO - Epoch 4146/5000 - Train Loss: 0.072623, Val Loss: 0.066177
2025-09-04 04:35:54,120 - INFO - Epoch 4147/5000 - Train Loss: 0.072225, Val Loss: 0.064799
2025-09-04 04:36:30,435 - INFO - Epoch 4148/5000 - Train Loss: 0.071855, Val Loss: 0.064527
2025-09-04 04:37:07,254 - INFO - Epoch 4149/5000 - Train Loss: 0.071570, Val Loss: 0.064018
2025-09-04 04:37:43,648 - INFO - Epoch 4150/5000 - Train Loss: 0.071361, Val Loss: 0.065759
2025-09-04 04:38:20,739 - INFO - Epoch 4151/5000 - Train Loss: 0.071405, Val Loss: 0.064221
2025-09-04 04:38:57,386 - INFO - Epoch 4152/5000 - Train Loss: 0.072721, Val Loss: 0.064561
2025-09-04 04:39:33,819 - INFO - Epoch 4153/5000 - Train Loss: 0.072160, Val Loss: 0.064877
2025-09-04 04:40:10,651 - INFO - Epoch 4154/5000 - Train Loss: 0.072082, Val Loss: 0.067597
2025-09-04 04:40:46,620 - INFO - Epoch 4155/5000 - Train Loss: 0.073355, Val Loss: 0.064112
2025-09-04 04:41:24,149 - INFO - Epoch 4156/5000 - Train Loss: 0.071837, Val Loss: 0.066188
2025-09-04 04:42:00,929 - INFO - Epoch 4157/5000 - Train Loss: 0.072028, Val Loss: 0.063754
2025-09-04 04:42:36,966 - INFO - Epoch 4158/5000 - Train Loss: 0.072382, Val Loss: 0.064046
2025-09-04 04:43:13,945 - INFO - Epoch 4159/5000 - Train Loss: 0.072081, Val Loss: 0.063781
2025-09-04 04:43:50,819 - INFO - Epoch 4160/5000 - Train Loss: 0.072761, Val Loss: 0.066444
2025-09-04 04:44:27,762 - INFO - Epoch 4161/5000 - Train Loss: 0.072522, Val Loss: 0.063656
2025-09-04 04:45:04,752 - INFO - Epoch 4162/5000 - Train Loss: 0.071305, Val Loss: 0.063618
2025-09-04 04:45:41,768 - INFO - Epoch 4163/5000 - Train Loss: 0.071917, Val Loss: 0.064729
2025-09-04 04:46:18,624 - INFO - Epoch 4164/5000 - Train Loss: 0.072063, Val Loss: 0.064069
2025-09-04 04:46:55,212 - INFO - Epoch 4165/5000 - Train Loss: 0.071729, Val Loss: 0.063734
2025-09-04 04:47:31,734 - INFO - Epoch 4166/5000 - Train Loss: 0.072425, Val Loss: 0.064519
2025-09-04 04:48:08,061 - INFO - Epoch 4167/5000 - Train Loss: 0.071441, Val Loss: 0.063924
2025-09-04 04:48:44,277 - INFO - Epoch 4168/5000 - Train Loss: 0.072817, Val Loss: 0.063667
2025-09-04 04:49:20,554 - INFO - Epoch 4169/5000 - Train Loss: 0.073288, Val Loss: 0.066225
2025-09-04 04:49:56,485 - INFO - Epoch 4170/5000 - Train Loss: 0.072240, Val Loss: 0.065175
2025-09-04 04:50:32,390 - INFO - Epoch 4171/5000 - Train Loss: 0.071549, Val Loss: 0.063275
2025-09-04 04:51:08,467 - INFO - Epoch 4172/5000 - Train Loss: 0.071038, Val Loss: 0.063364
2025-09-04 04:51:44,686 - INFO - Epoch 4173/5000 - Train Loss: 0.071912, Val Loss: 0.064724
2025-09-04 04:52:21,222 - INFO - Epoch 4174/5000 - Train Loss: 0.071580, Val Loss: 0.064521
2025-09-04 04:52:57,948 - INFO - Epoch 4175/5000 - Train Loss: 0.072142, Val Loss: 0.066512
2025-09-04 04:53:34,242 - INFO - Epoch 4176/5000 - Train Loss: 0.072060, Val Loss: 0.066569
2025-09-04 04:54:10,449 - INFO - Epoch 4177/5000 - Train Loss: 0.071237, Val Loss: 0.063191
2025-09-04 04:54:47,317 - INFO - Epoch 4178/5000 - Train Loss: 0.071063, Val Loss: 0.063659
2025-09-04 04:55:24,141 - INFO - Epoch 4179/5000 - Train Loss: 0.071615, Val Loss: 0.064705
2025-09-04 04:56:00,439 - INFO - Epoch 4180/5000 - Train Loss: 0.071889, Val Loss: 0.064235
2025-09-04 04:56:37,309 - INFO - Epoch 4181/5000 - Train Loss: 0.072475, Val Loss: 0.064282
2025-09-04 04:57:13,588 - INFO - Epoch 4182/5000 - Train Loss: 0.072472, Val Loss: 0.063996
2025-09-04 04:57:50,055 - INFO - Epoch 4183/5000 - Train Loss: 0.071848, Val Loss: 0.064623
2025-09-04 04:58:26,340 - INFO - Epoch 4184/5000 - Train Loss: 0.071547, Val Loss: 0.065097
2025-09-04 04:59:02,151 - INFO - Epoch 4185/5000 - Train Loss: 0.071978, Val Loss: 0.063385
2025-09-04 04:59:38,365 - INFO - Epoch 4186/5000 - Train Loss: 0.070781, Val Loss: 0.064197
2025-09-04 05:00:13,988 - INFO - Epoch 4187/5000 - Train Loss: 0.072095, Val Loss: 0.065741
2025-09-04 05:00:49,785 - INFO - Epoch 4188/5000 - Train Loss: 0.071473, Val Loss: 0.065120
2025-09-04 05:01:26,345 - INFO - Epoch 4189/5000 - Train Loss: 0.071909, Val Loss: 0.065292
2025-09-04 05:02:03,010 - INFO - Epoch 4190/5000 - Train Loss: 0.071846, Val Loss: 0.067364
2025-09-04 05:02:40,139 - INFO - Epoch 4191/5000 - Train Loss: 0.073065, Val Loss: 0.064596
2025-09-04 05:03:17,252 - INFO - Epoch 4192/5000 - Train Loss: 0.072414, Val Loss: 0.067747
2025-09-04 05:03:54,422 - INFO - Epoch 4193/5000 - Train Loss: 0.071786, Val Loss: 0.067570
2025-09-04 05:04:30,527 - INFO - Epoch 4194/5000 - Train Loss: 0.072308, Val Loss: 0.067994
2025-09-04 05:05:07,372 - INFO - Epoch 4195/5000 - Train Loss: 0.071739, Val Loss: 0.063490
2025-09-04 05:05:43,927 - INFO - Epoch 4196/5000 - Train Loss: 0.072777, Val Loss: 0.065325
2025-09-04 05:06:20,157 - INFO - Epoch 4197/5000 - Train Loss: 0.071733, Val Loss: 0.064042
2025-09-04 05:06:56,523 - INFO - Epoch 4198/5000 - Train Loss: 0.071341, Val Loss: 0.063932
2025-09-04 05:07:32,908 - INFO - Epoch 4199/5000 - Train Loss: 0.071397, Val Loss: 0.066813
2025-09-04 05:08:08,769 - INFO - Epoch 4200/5000 - Train Loss: 0.071645, Val Loss: 0.064767
2025-09-04 05:08:45,186 - INFO - Epoch 4201/5000 - Train Loss: 0.071419, Val Loss: 0.064900
2025-09-04 05:09:21,931 - INFO - Epoch 4202/5000 - Train Loss: 0.072014, Val Loss: 0.065498
2025-09-04 05:09:58,431 - INFO - Epoch 4203/5000 - Train Loss: 0.071213, Val Loss: 0.065467
2025-09-04 05:10:34,358 - INFO - Epoch 4204/5000 - Train Loss: 0.070942, Val Loss: 0.064362
2025-09-04 05:11:10,870 - INFO - Epoch 4205/5000 - Train Loss: 0.071554, Val Loss: 0.066575
2025-09-04 05:11:47,091 - INFO - Epoch 4206/5000 - Train Loss: 0.072675, Val Loss: 0.064146
2025-09-04 05:12:23,123 - INFO - Epoch 4207/5000 - Train Loss: 0.071559, Val Loss: 0.063473
2025-09-04 05:12:58,979 - INFO - Epoch 4208/5000 - Train Loss: 0.071356, Val Loss: 0.066991
2025-09-04 05:13:35,508 - INFO - Epoch 4209/5000 - Train Loss: 0.070916, Val Loss: 0.063416
2025-09-04 05:14:11,173 - INFO - Epoch 4210/5000 - Train Loss: 0.071608, Val Loss: 0.064418
2025-09-04 05:14:47,328 - INFO - Epoch 4211/5000 - Train Loss: 0.070875, Val Loss: 0.066282
2025-09-04 05:15:23,422 - INFO - Epoch 4212/5000 - Train Loss: 0.071100, Val Loss: 0.063106
2025-09-04 05:15:23,470 - INFO - New best model saved with Val Loss: 0.063106
2025-09-04 05:15:59,369 - INFO - Epoch 4213/5000 - Train Loss: 0.071975, Val Loss: 0.065046
2025-09-04 05:16:35,350 - INFO - Epoch 4214/5000 - Train Loss: 0.072352, Val Loss: 0.064759
2025-09-04 05:17:11,753 - INFO - Epoch 4215/5000 - Train Loss: 0.071416, Val Loss: 0.065333
2025-09-04 05:17:47,854 - INFO - Epoch 4216/5000 - Train Loss: 0.071373, Val Loss: 0.065289
2025-09-04 05:18:24,054 - INFO - Epoch 4217/5000 - Train Loss: 0.072162, Val Loss: 0.063790
2025-09-04 05:18:59,900 - INFO - Epoch 4218/5000 - Train Loss: 0.071345, Val Loss: 0.065127
2025-09-04 05:19:36,115 - INFO - Epoch 4219/5000 - Train Loss: 0.071957, Val Loss: 0.063684
2025-09-04 05:20:12,600 - INFO - Epoch 4220/5000 - Train Loss: 0.070655, Val Loss: 0.063178
2025-09-04 05:20:49,576 - INFO - Epoch 4221/5000 - Train Loss: 0.070741, Val Loss: 0.064027
2025-09-04 05:21:25,128 - INFO - Epoch 4222/5000 - Train Loss: 0.071496, Val Loss: 0.064187
2025-09-04 05:22:01,570 - INFO - Epoch 4223/5000 - Train Loss: 0.070901, Val Loss: 0.062692
2025-09-04 05:22:01,602 - INFO - New best model saved with Val Loss: 0.062692
2025-09-04 05:22:37,794 - INFO - Epoch 4224/5000 - Train Loss: 0.070910, Val Loss: 0.063131
2025-09-04 05:23:13,921 - INFO - Epoch 4225/5000 - Train Loss: 0.071270, Val Loss: 0.062888
2025-09-04 05:23:50,657 - INFO - Epoch 4226/5000 - Train Loss: 0.072394, Val Loss: 0.064311
2025-09-04 05:24:27,428 - INFO - Epoch 4227/5000 - Train Loss: 0.071111, Val Loss: 0.065884
2025-09-04 05:25:03,969 - INFO - Epoch 4228/5000 - Train Loss: 0.071174, Val Loss: 0.065403
2025-09-04 05:25:40,640 - INFO - Epoch 4229/5000 - Train Loss: 0.072509, Val Loss: 0.064802
2025-09-04 05:26:17,831 - INFO - Epoch 4230/5000 - Train Loss: 0.071212, Val Loss: 0.067837
2025-09-04 05:26:54,862 - INFO - Epoch 4231/5000 - Train Loss: 0.071903, Val Loss: 0.065021
2025-09-04 05:27:30,820 - INFO - Epoch 4232/5000 - Train Loss: 0.070680, Val Loss: 0.065768
2025-09-04 05:28:07,375 - INFO - Epoch 4233/5000 - Train Loss: 0.071276, Val Loss: 0.063611
2025-09-04 05:28:44,312 - INFO - Epoch 4234/5000 - Train Loss: 0.071926, Val Loss: 0.064629
2025-09-04 05:29:20,461 - INFO - Epoch 4235/5000 - Train Loss: 0.071118, Val Loss: 0.063524
2025-09-04 05:29:56,434 - INFO - Epoch 4236/5000 - Train Loss: 0.069544, Val Loss: 0.067936
2025-09-04 05:30:32,359 - INFO - Epoch 4237/5000 - Train Loss: 0.071924, Val Loss: 0.062724
2025-09-04 05:31:08,594 - INFO - Epoch 4238/5000 - Train Loss: 0.069600, Val Loss: 0.063264
2025-09-04 05:31:44,331 - INFO - Epoch 4239/5000 - Train Loss: 0.070773, Val Loss: 0.064077
2025-09-04 05:32:20,763 - INFO - Epoch 4240/5000 - Train Loss: 0.070734, Val Loss: 0.063247
2025-09-04 05:32:57,040 - INFO - Epoch 4241/5000 - Train Loss: 0.071230, Val Loss: 0.064385
2025-09-04 05:33:33,278 - INFO - Epoch 4242/5000 - Train Loss: 0.071165, Val Loss: 0.063992
2025-09-04 05:34:09,604 - INFO - Epoch 4243/5000 - Train Loss: 0.071256, Val Loss: 0.063767
2025-09-04 05:34:46,032 - INFO - Epoch 4244/5000 - Train Loss: 0.073685, Val Loss: 0.067948
2025-09-04 05:35:22,122 - INFO - Epoch 4245/5000 - Train Loss: 0.071158, Val Loss: 0.064443
2025-09-04 05:35:58,952 - INFO - Epoch 4246/5000 - Train Loss: 0.071423, Val Loss: 0.066397
2025-09-04 05:36:35,759 - INFO - Epoch 4247/5000 - Train Loss: 0.071540, Val Loss: 0.064622
2025-09-04 05:37:11,958 - INFO - Epoch 4248/5000 - Train Loss: 0.071071, Val Loss: 0.064672
2025-09-04 05:37:48,596 - INFO - Epoch 4249/5000 - Train Loss: 0.070485, Val Loss: 0.063786
2025-09-04 05:38:24,911 - INFO - Epoch 4250/5000 - Train Loss: 0.072356, Val Loss: 0.067295
2025-09-04 05:39:01,481 - INFO - Epoch 4251/5000 - Train Loss: 0.072650, Val Loss: 0.063522
2025-09-04 05:39:38,598 - INFO - Epoch 4252/5000 - Train Loss: 0.069983, Val Loss: 0.062245
2025-09-04 05:39:38,639 - INFO - New best model saved with Val Loss: 0.062245
2025-09-04 05:40:14,952 - INFO - Epoch 4253/5000 - Train Loss: 0.070941, Val Loss: 0.062860
2025-09-04 05:40:51,751 - INFO - Epoch 4254/5000 - Train Loss: 0.070940, Val Loss: 0.063032
2025-09-04 05:41:27,546 - INFO - Epoch 4255/5000 - Train Loss: 0.072018, Val Loss: 0.062685
2025-09-04 05:42:03,854 - INFO - Epoch 4256/5000 - Train Loss: 0.070731, Val Loss: 0.063139
2025-09-04 05:42:39,841 - INFO - Epoch 4257/5000 - Train Loss: 0.071369, Val Loss: 0.063347
2025-09-04 05:43:16,386 - INFO - Epoch 4258/5000 - Train Loss: 0.071322, Val Loss: 0.063891
2025-09-04 05:43:53,150 - INFO - Epoch 4259/5000 - Train Loss: 0.071873, Val Loss: 0.065634
2025-09-04 05:44:29,101 - INFO - Epoch 4260/5000 - Train Loss: 0.071054, Val Loss: 0.063636
2025-09-04 05:45:05,556 - INFO - Epoch 4261/5000 - Train Loss: 0.071423, Val Loss: 0.064170
2025-09-04 05:45:41,992 - INFO - Epoch 4262/5000 - Train Loss: 0.071393, Val Loss: 0.064443
2025-09-04 05:46:18,850 - INFO - Epoch 4263/5000 - Train Loss: 0.070283, Val Loss: 0.065880
2025-09-04 05:46:54,830 - INFO - Epoch 4264/5000 - Train Loss: 0.070818, Val Loss: 0.063163
2025-09-04 05:47:31,158 - INFO - Epoch 4265/5000 - Train Loss: 0.070044, Val Loss: 0.063473
2025-09-04 05:48:07,711 - INFO - Epoch 4266/5000 - Train Loss: 0.070408, Val Loss: 0.065541
2025-09-04 05:48:44,484 - INFO - Epoch 4267/5000 - Train Loss: 0.070532, Val Loss: 0.063812
2025-09-04 05:49:20,153 - INFO - Epoch 4268/5000 - Train Loss: 0.071582, Val Loss: 0.064156
2025-09-04 05:49:57,797 - INFO - Epoch 4269/5000 - Train Loss: 0.070439, Val Loss: 0.063384
2025-09-04 05:50:34,898 - INFO - Epoch 4270/5000 - Train Loss: 0.071302, Val Loss: 0.062895
2025-09-04 05:51:11,700 - INFO - Epoch 4271/5000 - Train Loss: 0.070743, Val Loss: 0.062754
2025-09-04 05:51:49,022 - INFO - Epoch 4272/5000 - Train Loss: 0.072394, Val Loss: 0.063976
2025-09-04 05:52:25,739 - INFO - Epoch 4273/5000 - Train Loss: 0.071298, Val Loss: 0.063363
2025-09-04 05:53:02,279 - INFO - Epoch 4274/5000 - Train Loss: 0.071059, Val Loss: 0.064610
2025-09-04 05:53:39,166 - INFO - Epoch 4275/5000 - Train Loss: 0.071139, Val Loss: 0.064548
2025-09-04 05:54:15,733 - INFO - Epoch 4276/5000 - Train Loss: 0.070973, Val Loss: 0.063728
2025-09-04 05:54:52,730 - INFO - Epoch 4277/5000 - Train Loss: 0.070850, Val Loss: 0.064854
2025-09-04 05:55:29,348 - INFO - Epoch 4278/5000 - Train Loss: 0.070823, Val Loss: 0.063363
2025-09-04 05:56:06,201 - INFO - Epoch 4279/5000 - Train Loss: 0.070322, Val Loss: 0.063191
2025-09-04 05:56:43,914 - INFO - Epoch 4280/5000 - Train Loss: 0.070540, Val Loss: 0.064059
2025-09-04 05:57:21,248 - INFO - Epoch 4281/5000 - Train Loss: 0.070252, Val Loss: 0.064037
2025-09-04 05:57:58,093 - INFO - Epoch 4282/5000 - Train Loss: 0.071461, Val Loss: 0.062623
2025-09-04 05:58:34,261 - INFO - Epoch 4283/5000 - Train Loss: 0.070602, Val Loss: 0.063386
2025-09-04 05:59:10,036 - INFO - Epoch 4284/5000 - Train Loss: 0.070760, Val Loss: 0.064883
2025-09-04 05:59:45,384 - INFO - Epoch 4285/5000 - Train Loss: 0.071146, Val Loss: 0.065700
2025-09-04 06:00:21,175 - INFO - Epoch 4286/5000 - Train Loss: 0.071821, Val Loss: 0.065006
2025-09-04 06:00:58,193 - INFO - Epoch 4287/5000 - Train Loss: 0.071068, Val Loss: 0.065498
2025-09-04 06:01:34,307 - INFO - Epoch 4288/5000 - Train Loss: 0.070910, Val Loss: 0.064216
2025-09-04 06:02:11,342 - INFO - Epoch 4289/5000 - Train Loss: 0.070767, Val Loss: 0.063103
2025-09-04 06:02:48,271 - INFO - Epoch 4290/5000 - Train Loss: 0.069885, Val Loss: 0.062803
2025-09-04 06:03:25,452 - INFO - Epoch 4291/5000 - Train Loss: 0.069644, Val Loss: 0.065325
2025-09-04 06:04:01,305 - INFO - Epoch 4292/5000 - Train Loss: 0.071816, Val Loss: 0.063327
2025-09-04 06:04:36,528 - INFO - Epoch 4293/5000 - Train Loss: 0.070241, Val Loss: 0.063160
2025-09-04 06:05:11,908 - INFO - Epoch 4294/5000 - Train Loss: 0.070898, Val Loss: 0.065697
2025-09-04 06:05:47,485 - INFO - Epoch 4295/5000 - Train Loss: 0.070780, Val Loss: 0.064229
2025-09-04 06:06:23,327 - INFO - Epoch 4296/5000 - Train Loss: 0.070598, Val Loss: 0.063300
2025-09-04 06:06:59,083 - INFO - Epoch 4297/5000 - Train Loss: 0.071094, Val Loss: 0.064637
2025-09-04 06:07:34,997 - INFO - Epoch 4298/5000 - Train Loss: 0.070643, Val Loss: 0.065058
2025-09-04 06:08:11,137 - INFO - Epoch 4299/5000 - Train Loss: 0.070079, Val Loss: 0.063313
2025-09-04 06:08:47,886 - INFO - Epoch 4300/5000 - Train Loss: 0.071372, Val Loss: 0.064529
2025-09-04 06:09:24,043 - INFO - Epoch 4301/5000 - Train Loss: 0.070348, Val Loss: 0.064025
2025-09-04 06:10:00,623 - INFO - Epoch 4302/5000 - Train Loss: 0.070207, Val Loss: 0.063340
2025-09-04 06:10:36,470 - INFO - Epoch 4303/5000 - Train Loss: 0.070874, Val Loss: 0.064168
2025-09-04 06:11:13,113 - INFO - Epoch 4304/5000 - Train Loss: 0.070696, Val Loss: 0.063827
2025-09-04 06:11:50,657 - INFO - Epoch 4305/5000 - Train Loss: 0.070807, Val Loss: 0.062777
2025-09-04 06:12:27,451 - INFO - Epoch 4306/5000 - Train Loss: 0.070057, Val Loss: 0.063305
2025-09-04 06:13:04,040 - INFO - Epoch 4307/5000 - Train Loss: 0.071339, Val Loss: 0.063983
2025-09-04 06:13:40,602 - INFO - Epoch 4308/5000 - Train Loss: 0.071792, Val Loss: 0.064398
2025-09-04 06:14:18,394 - INFO - Epoch 4309/5000 - Train Loss: 0.070912, Val Loss: 0.063611
2025-09-04 06:14:55,621 - INFO - Epoch 4310/5000 - Train Loss: 0.070812, Val Loss: 0.065156
2025-09-04 06:15:31,834 - INFO - Epoch 4311/5000 - Train Loss: 0.070160, Val Loss: 0.062429
2025-09-04 06:16:08,415 - INFO - Epoch 4312/5000 - Train Loss: 0.068617, Val Loss: 0.064542
2025-09-04 06:16:44,952 - INFO - Epoch 4313/5000 - Train Loss: 0.070431, Val Loss: 0.063996
2025-09-04 06:17:21,520 - INFO - Epoch 4314/5000 - Train Loss: 0.070128, Val Loss: 0.063319
2025-09-04 06:17:57,628 - INFO - Epoch 4315/5000 - Train Loss: 0.069724, Val Loss: 0.063867
2025-09-04 06:18:34,105 - INFO - Epoch 4316/5000 - Train Loss: 0.071251, Val Loss: 0.063937
2025-09-04 06:19:11,076 - INFO - Epoch 4317/5000 - Train Loss: 0.070454, Val Loss: 0.063253
2025-09-04 06:19:47,338 - INFO - Epoch 4318/5000 - Train Loss: 0.070099, Val Loss: 0.063428
2025-09-04 06:20:23,955 - INFO - Epoch 4319/5000 - Train Loss: 0.069912, Val Loss: 0.062675
2025-09-04 06:20:59,974 - INFO - Epoch 4320/5000 - Train Loss: 0.070212, Val Loss: 0.065160
2025-09-04 06:21:36,286 - INFO - Epoch 4321/5000 - Train Loss: 0.071970, Val Loss: 0.065091
2025-09-04 06:22:12,936 - INFO - Epoch 4322/5000 - Train Loss: 0.071288, Val Loss: 0.064297
2025-09-04 06:22:49,548 - INFO - Epoch 4323/5000 - Train Loss: 0.069803, Val Loss: 0.062217
2025-09-04 06:22:49,601 - INFO - New best model saved with Val Loss: 0.062217
2025-09-04 06:23:25,778 - INFO - Epoch 4324/5000 - Train Loss: 0.069623, Val Loss: 0.062103
2025-09-04 06:23:25,810 - INFO - New best model saved with Val Loss: 0.062103
2025-09-04 06:24:02,560 - INFO - Epoch 4325/5000 - Train Loss: 0.069727, Val Loss: 0.063595
2025-09-04 06:24:39,642 - INFO - Epoch 4326/5000 - Train Loss: 0.070963, Val Loss: 0.064682
2025-09-04 06:25:16,648 - INFO - Epoch 4327/5000 - Train Loss: 0.070642, Val Loss: 0.065383
2025-09-04 06:25:52,972 - INFO - Epoch 4328/5000 - Train Loss: 0.070498, Val Loss: 0.063969
2025-09-04 06:26:29,842 - INFO - Epoch 4329/5000 - Train Loss: 0.070550, Val Loss: 0.065464
2025-09-04 06:27:06,616 - INFO - Epoch 4330/5000 - Train Loss: 0.071172, Val Loss: 0.063210
2025-09-04 06:27:43,639 - INFO - Epoch 4331/5000 - Train Loss: 0.070624, Val Loss: 0.063361
2025-09-04 06:28:20,715 - INFO - Epoch 4332/5000 - Train Loss: 0.071410, Val Loss: 0.063957
2025-09-04 06:28:56,979 - INFO - Epoch 4333/5000 - Train Loss: 0.071013, Val Loss: 0.063707
2025-09-04 06:29:33,240 - INFO - Epoch 4334/5000 - Train Loss: 0.070262, Val Loss: 0.062912
2025-09-04 06:30:10,197 - INFO - Epoch 4335/5000 - Train Loss: 0.069691, Val Loss: 0.063592
2025-09-04 06:30:46,825 - INFO - Epoch 4336/5000 - Train Loss: 0.069777, Val Loss: 0.064888
2025-09-04 06:31:23,095 - INFO - Epoch 4337/5000 - Train Loss: 0.071401, Val Loss: 0.063537
2025-09-04 06:31:59,145 - INFO - Epoch 4338/5000 - Train Loss: 0.070616, Val Loss: 0.063673
2025-09-04 06:32:35,637 - INFO - Epoch 4339/5000 - Train Loss: 0.070368, Val Loss: 0.065297
2025-09-04 06:33:12,285 - INFO - Epoch 4340/5000 - Train Loss: 0.070095, Val Loss: 0.061578
2025-09-04 06:33:12,340 - INFO - New best model saved with Val Loss: 0.061578
2025-09-04 06:33:49,225 - INFO - Epoch 4341/5000 - Train Loss: 0.070081, Val Loss: 0.062232
2025-09-04 06:34:26,184 - INFO - Epoch 4342/5000 - Train Loss: 0.069934, Val Loss: 0.064127
2025-09-04 06:35:02,209 - INFO - Epoch 4343/5000 - Train Loss: 0.070728, Val Loss: 0.065144
2025-09-04 06:35:38,601 - INFO - Epoch 4344/5000 - Train Loss: 0.070778, Val Loss: 0.064394
2025-09-04 06:36:14,942 - INFO - Epoch 4345/5000 - Train Loss: 0.070609, Val Loss: 0.065386
2025-09-04 06:36:51,740 - INFO - Epoch 4346/5000 - Train Loss: 0.070235, Val Loss: 0.064646
2025-09-04 06:37:27,695 - INFO - Epoch 4347/5000 - Train Loss: 0.070052, Val Loss: 0.066981
2025-09-04 06:38:04,102 - INFO - Epoch 4348/5000 - Train Loss: 0.070643, Val Loss: 0.063530
2025-09-04 06:38:41,287 - INFO - Epoch 4349/5000 - Train Loss: 0.070239, Val Loss: 0.065539
2025-09-04 06:39:17,629 - INFO - Epoch 4350/5000 - Train Loss: 0.070528, Val Loss: 0.063271
2025-09-04 06:39:54,439 - INFO - Epoch 4351/5000 - Train Loss: 0.069725, Val Loss: 0.063753
2025-09-04 06:40:31,114 - INFO - Epoch 4352/5000 - Train Loss: 0.069685, Val Loss: 0.064725
2025-09-04 06:41:08,364 - INFO - Epoch 4353/5000 - Train Loss: 0.070380, Val Loss: 0.065655
2025-09-04 06:41:45,124 - INFO - Epoch 4354/5000 - Train Loss: 0.071549, Val Loss: 0.066389
2025-09-04 06:42:21,123 - INFO - Epoch 4355/5000 - Train Loss: 0.070892, Val Loss: 0.066195
2025-09-04 06:42:57,829 - INFO - Epoch 4356/5000 - Train Loss: 0.069069, Val Loss: 0.064183
2025-09-04 06:43:34,871 - INFO - Epoch 4357/5000 - Train Loss: 0.069600, Val Loss: 0.062109
2025-09-04 06:44:11,902 - INFO - Epoch 4358/5000 - Train Loss: 0.069618, Val Loss: 0.062101
2025-09-04 06:44:48,256 - INFO - Epoch 4359/5000 - Train Loss: 0.069071, Val Loss: 0.062930
2025-09-04 06:45:24,653 - INFO - Epoch 4360/5000 - Train Loss: 0.072569, Val Loss: 0.064681
2025-09-04 06:46:01,155 - INFO - Epoch 4361/5000 - Train Loss: 0.070990, Val Loss: 0.064075
2025-09-04 06:46:37,336 - INFO - Epoch 4362/5000 - Train Loss: 0.071041, Val Loss: 0.064422
2025-09-04 06:47:13,722 - INFO - Epoch 4363/5000 - Train Loss: 0.069713, Val Loss: 0.064469
2025-09-04 06:47:49,968 - INFO - Epoch 4364/5000 - Train Loss: 0.070348, Val Loss: 0.063140
2025-09-04 06:48:26,617 - INFO - Epoch 4365/5000 - Train Loss: 0.070150, Val Loss: 0.062283
2025-09-04 06:49:02,262 - INFO - Epoch 4366/5000 - Train Loss: 0.069528, Val Loss: 0.064276
2025-09-04 06:49:37,951 - INFO - Epoch 4367/5000 - Train Loss: 0.070103, Val Loss: 0.064067
2025-09-04 06:50:14,327 - INFO - Epoch 4368/5000 - Train Loss: 0.071385, Val Loss: 0.063368
2025-09-04 06:50:50,780 - INFO - Epoch 4369/5000 - Train Loss: 0.069715, Val Loss: 0.062311
2025-09-04 06:51:26,879 - INFO - Epoch 4370/5000 - Train Loss: 0.070166, Val Loss: 0.063947
2025-09-04 06:52:04,186 - INFO - Epoch 4371/5000 - Train Loss: 0.069794, Val Loss: 0.062099
2025-09-04 06:52:40,742 - INFO - Epoch 4372/5000 - Train Loss: 0.070136, Val Loss: 0.062922
2025-09-04 06:53:17,764 - INFO - Epoch 4373/5000 - Train Loss: 0.069754, Val Loss: 0.063717
2025-09-04 06:53:54,168 - INFO - Epoch 4374/5000 - Train Loss: 0.070573, Val Loss: 0.062531
2025-09-04 06:54:30,164 - INFO - Epoch 4375/5000 - Train Loss: 0.071149, Val Loss: 0.065371
2025-09-04 06:55:06,825 - INFO - Epoch 4376/5000 - Train Loss: 0.069785, Val Loss: 0.062395
2025-09-04 06:55:43,697 - INFO - Epoch 4377/5000 - Train Loss: 0.070422, Val Loss: 0.067080
2025-09-04 06:56:20,328 - INFO - Epoch 4378/5000 - Train Loss: 0.070118, Val Loss: 0.062606
2025-09-04 06:56:57,338 - INFO - Epoch 4379/5000 - Train Loss: 0.069478, Val Loss: 0.063433
2025-09-04 06:57:33,890 - INFO - Epoch 4380/5000 - Train Loss: 0.069311, Val Loss: 0.063085
2025-09-04 06:58:10,892 - INFO - Epoch 4381/5000 - Train Loss: 0.070243, Val Loss: 0.064407
2025-09-04 06:58:46,745 - INFO - Epoch 4382/5000 - Train Loss: 0.069157, Val Loss: 0.061675
2025-09-04 06:59:23,340 - INFO - Epoch 4383/5000 - Train Loss: 0.070716, Val Loss: 0.063184
2025-09-04 06:59:59,918 - INFO - Epoch 4384/5000 - Train Loss: 0.069633, Val Loss: 0.062139
2025-09-04 07:00:36,851 - INFO - Epoch 4385/5000 - Train Loss: 0.069589, Val Loss: 0.063928
2025-09-04 07:01:13,639 - INFO - Epoch 4386/5000 - Train Loss: 0.070622, Val Loss: 0.063562
2025-09-04 07:01:50,227 - INFO - Epoch 4387/5000 - Train Loss: 0.069151, Val Loss: 0.063459
2025-09-04 07:02:26,999 - INFO - Epoch 4388/5000 - Train Loss: 0.069753, Val Loss: 0.062740
2025-09-04 07:03:03,472 - INFO - Epoch 4389/5000 - Train Loss: 0.069256, Val Loss: 0.062491
2025-09-04 07:03:39,805 - INFO - Epoch 4390/5000 - Train Loss: 0.069538, Val Loss: 0.062975
2025-09-04 07:04:17,302 - INFO - Epoch 4391/5000 - Train Loss: 0.069823, Val Loss: 0.063340
2025-09-04 07:04:54,675 - INFO - Epoch 4392/5000 - Train Loss: 0.069998, Val Loss: 0.064042
2025-09-04 07:05:31,976 - INFO - Epoch 4393/5000 - Train Loss: 0.070859, Val Loss: 0.062221
2025-09-04 07:06:08,881 - INFO - Epoch 4394/5000 - Train Loss: 0.069943, Val Loss: 0.062516
2025-09-04 07:06:45,033 - INFO - Epoch 4395/5000 - Train Loss: 0.069317, Val Loss: 0.062721
2025-09-04 07:07:21,638 - INFO - Epoch 4396/5000 - Train Loss: 0.069604, Val Loss: 0.063339
2025-09-04 07:07:57,484 - INFO - Epoch 4397/5000 - Train Loss: 0.070195, Val Loss: 0.065167
2025-09-04 07:08:33,574 - INFO - Epoch 4398/5000 - Train Loss: 0.070209, Val Loss: 0.065219
2025-09-04 07:09:09,543 - INFO - Epoch 4399/5000 - Train Loss: 0.069897, Val Loss: 0.063598
2025-09-04 07:09:46,133 - INFO - Epoch 4400/5000 - Train Loss: 0.069991, Val Loss: 0.064772
2025-09-04 07:10:22,813 - INFO - Epoch 4401/5000 - Train Loss: 0.070252, Val Loss: 0.062694
2025-09-04 07:10:59,829 - INFO - Epoch 4402/5000 - Train Loss: 0.070431, Val Loss: 0.064348
2025-09-04 07:11:36,371 - INFO - Epoch 4403/5000 - Train Loss: 0.069834, Val Loss: 0.063080
2025-09-04 07:12:12,847 - INFO - Epoch 4404/5000 - Train Loss: 0.070013, Val Loss: 0.068689
2025-09-04 07:12:49,010 - INFO - Epoch 4405/5000 - Train Loss: 0.070917, Val Loss: 0.063865
2025-09-04 07:13:25,785 - INFO - Epoch 4406/5000 - Train Loss: 0.069564, Val Loss: 0.063666
2025-09-04 07:14:02,349 - INFO - Epoch 4407/5000 - Train Loss: 0.071971, Val Loss: 0.064562
2025-09-04 07:14:38,964 - INFO - Epoch 4408/5000 - Train Loss: 0.071340, Val Loss: 0.065558
2025-09-04 07:15:16,141 - INFO - Epoch 4409/5000 - Train Loss: 0.069758, Val Loss: 0.063413
2025-09-04 07:15:52,065 - INFO - Epoch 4410/5000 - Train Loss: 0.070336, Val Loss: 0.063926
2025-09-04 07:16:29,175 - INFO - Epoch 4411/5000 - Train Loss: 0.070483, Val Loss: 0.065338
2025-09-04 07:17:05,604 - INFO - Epoch 4412/5000 - Train Loss: 0.069609, Val Loss: 0.062846
2025-09-04 07:17:42,323 - INFO - Epoch 4413/5000 - Train Loss: 0.069447, Val Loss: 0.064763
2025-09-04 07:18:18,875 - INFO - Epoch 4414/5000 - Train Loss: 0.069241, Val Loss: 0.063077
2025-09-04 07:18:55,074 - INFO - Epoch 4415/5000 - Train Loss: 0.069701, Val Loss: 0.063299
2025-09-04 07:19:32,345 - INFO - Epoch 4416/5000 - Train Loss: 0.069634, Val Loss: 0.063577
2025-09-04 07:20:09,745 - INFO - Epoch 4417/5000 - Train Loss: 0.070016, Val Loss: 0.062557
2025-09-04 07:20:46,977 - INFO - Epoch 4418/5000 - Train Loss: 0.069313, Val Loss: 0.062147
2025-09-04 07:21:23,656 - INFO - Epoch 4419/5000 - Train Loss: 0.070136, Val Loss: 0.063220
2025-09-04 07:22:00,268 - INFO - Epoch 4420/5000 - Train Loss: 0.069917, Val Loss: 0.063853
2025-09-04 07:22:37,312 - INFO - Epoch 4421/5000 - Train Loss: 0.068756, Val Loss: 0.063983
2025-09-04 07:23:14,158 - INFO - Epoch 4422/5000 - Train Loss: 0.069878, Val Loss: 0.064231
2025-09-04 07:23:51,370 - INFO - Epoch 4423/5000 - Train Loss: 0.069958, Val Loss: 0.063030
2025-09-04 07:24:28,609 - INFO - Epoch 4424/5000 - Train Loss: 0.069294, Val Loss: 0.061705
2025-09-04 07:25:05,224 - INFO - Epoch 4425/5000 - Train Loss: 0.069044, Val Loss: 0.062313
2025-09-04 07:25:42,038 - INFO - Epoch 4426/5000 - Train Loss: 0.069771, Val Loss: 0.065351
2025-09-04 07:26:19,096 - INFO - Epoch 4427/5000 - Train Loss: 0.069546, Val Loss: 0.062495
2025-09-04 07:26:56,110 - INFO - Epoch 4428/5000 - Train Loss: 0.069861, Val Loss: 0.063683
2025-09-04 07:27:32,187 - INFO - Epoch 4429/5000 - Train Loss: 0.069322, Val Loss: 0.062440
2025-09-04 07:28:08,799 - INFO - Epoch 4430/5000 - Train Loss: 0.068799, Val Loss: 0.063313
2025-09-04 07:28:45,374 - INFO - Epoch 4431/5000 - Train Loss: 0.069419, Val Loss: 0.064221
2025-09-04 07:29:22,806 - INFO - Epoch 4432/5000 - Train Loss: 0.069401, Val Loss: 0.062552
2025-09-04 07:29:59,450 - INFO - Epoch 4433/5000 - Train Loss: 0.068910, Val Loss: 0.062401
2025-09-04 07:30:36,538 - INFO - Epoch 4434/5000 - Train Loss: 0.068973, Val Loss: 0.063665
2025-09-04 07:31:12,633 - INFO - Epoch 4435/5000 - Train Loss: 0.069927, Val Loss: 0.063569
2025-09-04 07:31:48,629 - INFO - Epoch 4436/5000 - Train Loss: 0.069672, Val Loss: 0.063197
2025-09-04 07:32:25,152 - INFO - Epoch 4437/5000 - Train Loss: 0.069756, Val Loss: 0.062864
2025-09-04 07:33:02,128 - INFO - Epoch 4438/5000 - Train Loss: 0.069462, Val Loss: 0.066284
2025-09-04 07:33:38,067 - INFO - Epoch 4439/5000 - Train Loss: 0.071065, Val Loss: 0.065403
2025-09-04 07:34:15,414 - INFO - Epoch 4440/5000 - Train Loss: 0.070103, Val Loss: 0.063543
2025-09-04 07:34:52,176 - INFO - Epoch 4441/5000 - Train Loss: 0.069630, Val Loss: 0.064339
2025-09-04 07:35:28,303 - INFO - Epoch 4442/5000 - Train Loss: 0.070042, Val Loss: 0.063915
2025-09-04 07:36:04,864 - INFO - Epoch 4443/5000 - Train Loss: 0.069175, Val Loss: 0.064552
2025-09-04 07:36:41,441 - INFO - Epoch 4444/5000 - Train Loss: 0.070068, Val Loss: 0.063781
2025-09-04 07:37:18,653 - INFO - Epoch 4445/5000 - Train Loss: 0.069381, Val Loss: 0.062240
2025-09-04 07:37:55,650 - INFO - Epoch 4446/5000 - Train Loss: 0.069437, Val Loss: 0.061755
2025-09-04 07:38:32,724 - INFO - Epoch 4447/5000 - Train Loss: 0.069007, Val Loss: 0.065192
2025-09-04 07:39:09,821 - INFO - Epoch 4448/5000 - Train Loss: 0.069981, Val Loss: 0.062393
2025-09-04 07:39:47,049 - INFO - Epoch 4449/5000 - Train Loss: 0.069396, Val Loss: 0.062896
2025-09-04 07:40:23,546 - INFO - Epoch 4450/5000 - Train Loss: 0.069988, Val Loss: 0.062243
2025-09-04 07:41:00,833 - INFO - Epoch 4451/5000 - Train Loss: 0.069713, Val Loss: 0.063904
2025-09-04 07:41:37,556 - INFO - Epoch 4452/5000 - Train Loss: 0.069411, Val Loss: 0.063424
2025-09-04 07:42:14,740 - INFO - Epoch 4453/5000 - Train Loss: 0.069416, Val Loss: 0.063041
2025-09-04 07:42:51,800 - INFO - Epoch 4454/5000 - Train Loss: 0.067299, Val Loss: 0.062293
2025-09-04 07:43:28,300 - INFO - Epoch 4455/5000 - Train Loss: 0.068757, Val Loss: 0.063304
2025-09-04 07:44:05,263 - INFO - Epoch 4456/5000 - Train Loss: 0.069028, Val Loss: 0.063150
2025-09-04 07:44:42,374 - INFO - Epoch 4457/5000 - Train Loss: 0.068507, Val Loss: 0.063730
2025-09-04 07:45:19,038 - INFO - Epoch 4458/5000 - Train Loss: 0.069111, Val Loss: 0.063779
2025-09-04 07:45:54,797 - INFO - Epoch 4459/5000 - Train Loss: 0.069792, Val Loss: 0.065208
2025-09-04 07:46:30,411 - INFO - Epoch 4460/5000 - Train Loss: 0.069402, Val Loss: 0.062425
2025-09-04 07:47:07,454 - INFO - Epoch 4461/5000 - Train Loss: 0.069185, Val Loss: 0.062082
2025-09-04 07:47:44,120 - INFO - Epoch 4462/5000 - Train Loss: 0.069485, Val Loss: 0.061711
2025-09-04 07:48:19,938 - INFO - Epoch 4463/5000 - Train Loss: 0.069354, Val Loss: 0.062667
2025-09-04 07:48:56,661 - INFO - Epoch 4464/5000 - Train Loss: 0.069496, Val Loss: 0.065316
2025-09-04 07:49:32,239 - INFO - Epoch 4465/5000 - Train Loss: 0.069109, Val Loss: 0.065749
2025-09-04 07:50:08,512 - INFO - Epoch 4466/5000 - Train Loss: 0.070367, Val Loss: 0.063278
2025-09-04 07:50:44,634 - INFO - Epoch 4467/5000 - Train Loss: 0.068871, Val Loss: 0.062419
2025-09-04 07:51:21,882 - INFO - Epoch 4468/5000 - Train Loss: 0.069201, Val Loss: 0.062081
2025-09-04 07:51:58,322 - INFO - Epoch 4469/5000 - Train Loss: 0.069005, Val Loss: 0.063525
2025-09-04 07:52:34,855 - INFO - Epoch 4470/5000 - Train Loss: 0.068665, Val Loss: 0.062905
2025-09-04 07:53:11,173 - INFO - Epoch 4471/5000 - Train Loss: 0.068866, Val Loss: 0.062687
2025-09-04 07:53:48,446 - INFO - Epoch 4472/5000 - Train Loss: 0.070243, Val Loss: 0.063265
2025-09-04 07:54:25,006 - INFO - Epoch 4473/5000 - Train Loss: 0.069305, Val Loss: 0.063783
2025-09-04 07:55:00,981 - INFO - Epoch 4474/5000 - Train Loss: 0.069300, Val Loss: 0.062454
2025-09-04 07:55:36,381 - INFO - Epoch 4475/5000 - Train Loss: 0.068770, Val Loss: 0.062353
2025-09-04 07:56:12,620 - INFO - Epoch 4476/5000 - Train Loss: 0.069464, Val Loss: 0.063594
2025-09-04 07:56:48,780 - INFO - Epoch 4477/5000 - Train Loss: 0.069547, Val Loss: 0.064866
2025-09-04 07:57:25,029 - INFO - Epoch 4478/5000 - Train Loss: 0.069110, Val Loss: 0.062043
2025-09-04 07:58:01,254 - INFO - Epoch 4479/5000 - Train Loss: 0.068946, Val Loss: 0.062769
2025-09-04 07:58:37,638 - INFO - Epoch 4480/5000 - Train Loss: 0.068606, Val Loss: 0.064053
2025-09-04 07:59:13,994 - INFO - Epoch 4481/5000 - Train Loss: 0.069809, Val Loss: 0.063062
2025-09-04 07:59:49,737 - INFO - Epoch 4482/5000 - Train Loss: 0.069104, Val Loss: 0.062051
2025-09-04 08:00:26,702 - INFO - Epoch 4483/5000 - Train Loss: 0.069063, Val Loss: 0.062931
2025-09-04 08:01:03,145 - INFO - Epoch 4484/5000 - Train Loss: 0.069327, Val Loss: 0.063719
2025-09-04 08:01:39,201 - INFO - Epoch 4485/5000 - Train Loss: 0.069060, Val Loss: 0.061406
2025-09-04 08:01:39,246 - INFO - New best model saved with Val Loss: 0.061406
2025-09-04 08:02:15,950 - INFO - Epoch 4486/5000 - Train Loss: 0.068439, Val Loss: 0.061679
2025-09-04 08:02:52,311 - INFO - Epoch 4487/5000 - Train Loss: 0.068499, Val Loss: 0.061550
2025-09-04 08:03:28,867 - INFO - Epoch 4488/5000 - Train Loss: 0.068568, Val Loss: 0.063015
2025-09-04 08:04:05,471 - INFO - Epoch 4489/5000 - Train Loss: 0.068799, Val Loss: 0.064777
2025-09-04 08:04:41,931 - INFO - Epoch 4490/5000 - Train Loss: 0.069162, Val Loss: 0.062559
2025-09-04 08:05:19,074 - INFO - Epoch 4491/5000 - Train Loss: 0.069047, Val Loss: 0.064822
2025-09-04 08:05:56,099 - INFO - Epoch 4492/5000 - Train Loss: 0.069385, Val Loss: 0.062119
2025-09-04 08:06:32,664 - INFO - Epoch 4493/5000 - Train Loss: 0.068906, Val Loss: 0.064368
2025-09-04 08:07:10,090 - INFO - Epoch 4494/5000 - Train Loss: 0.068932, Val Loss: 0.062241
2025-09-04 08:07:47,513 - INFO - Epoch 4495/5000 - Train Loss: 0.068384, Val Loss: 0.063138
2025-09-04 08:08:24,384 - INFO - Epoch 4496/5000 - Train Loss: 0.068835, Val Loss: 0.061735
2025-09-04 08:09:01,329 - INFO - Epoch 4497/5000 - Train Loss: 0.069036, Val Loss: 0.062357
2025-09-04 08:09:37,556 - INFO - Epoch 4498/5000 - Train Loss: 0.069800, Val Loss: 0.062863
2025-09-04 08:10:14,947 - INFO - Epoch 4499/5000 - Train Loss: 0.069317, Val Loss: 0.061925
2025-09-04 08:10:52,178 - INFO - Epoch 4500/5000 - Train Loss: 0.069755, Val Loss: 0.062730
2025-09-04 08:11:29,883 - INFO - Epoch 4501/5000 - Train Loss: 0.068817, Val Loss: 0.062748
2025-09-04 08:12:06,189 - INFO - Epoch 4502/5000 - Train Loss: 0.068966, Val Loss: 0.061990
2025-09-04 08:12:42,663 - INFO - Epoch 4503/5000 - Train Loss: 0.069958, Val Loss: 0.062876
2025-09-04 08:13:19,600 - INFO - Epoch 4504/5000 - Train Loss: 0.068413, Val Loss: 0.062057
2025-09-04 08:13:55,447 - INFO - Epoch 4505/5000 - Train Loss: 0.068524, Val Loss: 0.063423
2025-09-04 08:14:31,843 - INFO - Epoch 4506/5000 - Train Loss: 0.069370, Val Loss: 0.064133
2025-09-04 08:15:08,312 - INFO - Epoch 4507/5000 - Train Loss: 0.069021, Val Loss: 0.061836
2025-09-04 08:15:44,229 - INFO - Epoch 4508/5000 - Train Loss: 0.068639, Val Loss: 0.062589
2025-09-04 08:16:20,733 - INFO - Epoch 4509/5000 - Train Loss: 0.070234, Val Loss: 0.064338
2025-09-04 08:16:57,143 - INFO - Epoch 4510/5000 - Train Loss: 0.069243, Val Loss: 0.063337
2025-09-04 08:17:34,098 - INFO - Epoch 4511/5000 - Train Loss: 0.069054, Val Loss: 0.061972
2025-09-04 08:18:10,205 - INFO - Epoch 4512/5000 - Train Loss: 0.069051, Val Loss: 0.062578
2025-09-04 08:18:46,639 - INFO - Epoch 4513/5000 - Train Loss: 0.068327, Val Loss: 0.062680
2025-09-04 08:19:22,999 - INFO - Epoch 4514/5000 - Train Loss: 0.068733, Val Loss: 0.063760
2025-09-04 08:20:00,043 - INFO - Epoch 4515/5000 - Train Loss: 0.068233, Val Loss: 0.062067
2025-09-04 08:20:36,443 - INFO - Epoch 4516/5000 - Train Loss: 0.068468, Val Loss: 0.063735
2025-09-04 08:21:12,636 - INFO - Epoch 4517/5000 - Train Loss: 0.069229, Val Loss: 0.062721
2025-09-04 08:21:49,221 - INFO - Epoch 4518/5000 - Train Loss: 0.068661, Val Loss: 0.062162
2025-09-04 08:22:25,642 - INFO - Epoch 4519/5000 - Train Loss: 0.068375, Val Loss: 0.062748
2025-09-04 08:23:02,232 - INFO - Epoch 4520/5000 - Train Loss: 0.068184, Val Loss: 0.063835
2025-09-04 08:23:39,708 - INFO - Epoch 4521/5000 - Train Loss: 0.069365, Val Loss: 0.063496
2025-09-04 08:24:16,553 - INFO - Epoch 4522/5000 - Train Loss: 0.068713, Val Loss: 0.061920
2025-09-04 08:24:52,692 - INFO - Epoch 4523/5000 - Train Loss: 0.068747, Val Loss: 0.062878
2025-09-04 08:25:28,160 - INFO - Epoch 4524/5000 - Train Loss: 0.069467, Val Loss: 0.064631
2025-09-04 08:26:05,101 - INFO - Epoch 4525/5000 - Train Loss: 0.068985, Val Loss: 0.063426
2025-09-04 08:26:42,260 - INFO - Epoch 4526/5000 - Train Loss: 0.069661, Val Loss: 0.062380
2025-09-04 08:27:19,148 - INFO - Epoch 4527/5000 - Train Loss: 0.069501, Val Loss: 0.064334
2025-09-04 08:27:56,091 - INFO - Epoch 4528/5000 - Train Loss: 0.069208, Val Loss: 0.063259
2025-09-04 08:28:32,407 - INFO - Epoch 4529/5000 - Train Loss: 0.068888, Val Loss: 0.063231
2025-09-04 08:29:09,221 - INFO - Epoch 4530/5000 - Train Loss: 0.068840, Val Loss: 0.061626
2025-09-04 08:29:46,294 - INFO - Epoch 4531/5000 - Train Loss: 0.069931, Val Loss: 0.064940
2025-09-04 08:30:23,206 - INFO - Epoch 4532/5000 - Train Loss: 0.069690, Val Loss: 0.061852
2025-09-04 08:30:59,680 - INFO - Epoch 4533/5000 - Train Loss: 0.068633, Val Loss: 0.061883
2025-09-04 08:31:36,040 - INFO - Epoch 4534/5000 - Train Loss: 0.070059, Val Loss: 0.064267
2025-09-04 08:32:11,851 - INFO - Epoch 4535/5000 - Train Loss: 0.068994, Val Loss: 0.065048
2025-09-04 08:32:48,192 - INFO - Epoch 4536/5000 - Train Loss: 0.070990, Val Loss: 0.065977
2025-09-04 08:33:25,404 - INFO - Epoch 4537/5000 - Train Loss: 0.068638, Val Loss: 0.062231
2025-09-04 08:34:02,805 - INFO - Epoch 4538/5000 - Train Loss: 0.068140, Val Loss: 0.063898
2025-09-04 08:34:39,207 - INFO - Epoch 4539/5000 - Train Loss: 0.068232, Val Loss: 0.062592
2025-09-04 08:35:15,657 - INFO - Epoch 4540/5000 - Train Loss: 0.069426, Val Loss: 0.062623
2025-09-04 08:35:51,851 - INFO - Epoch 4541/5000 - Train Loss: 0.069080, Val Loss: 0.062075
2025-09-04 08:36:27,968 - INFO - Epoch 4542/5000 - Train Loss: 0.066496, Val Loss: 0.061507
2025-09-04 08:37:04,713 - INFO - Epoch 4543/5000 - Train Loss: 0.068360, Val Loss: 0.062294
2025-09-04 08:37:41,664 - INFO - Epoch 4544/5000 - Train Loss: 0.068642, Val Loss: 0.062213
2025-09-04 08:38:18,692 - INFO - Epoch 4545/5000 - Train Loss: 0.068879, Val Loss: 0.063450
2025-09-04 08:38:55,414 - INFO - Epoch 4546/5000 - Train Loss: 0.068978, Val Loss: 0.062040
2025-09-04 08:39:31,504 - INFO - Epoch 4547/5000 - Train Loss: 0.068583, Val Loss: 0.062280
2025-09-04 08:40:07,926 - INFO - Epoch 4548/5000 - Train Loss: 0.068408, Val Loss: 0.061483
2025-09-04 08:40:44,062 - INFO - Epoch 4549/5000 - Train Loss: 0.067974, Val Loss: 0.062227
2025-09-04 08:41:19,689 - INFO - Epoch 4550/5000 - Train Loss: 0.068990, Val Loss: 0.063954
2025-09-04 08:41:57,100 - INFO - Epoch 4551/5000 - Train Loss: 0.068733, Val Loss: 0.063544
2025-09-04 08:42:33,481 - INFO - Epoch 4552/5000 - Train Loss: 0.069190, Val Loss: 0.063378
2025-09-04 08:43:09,547 - INFO - Epoch 4553/5000 - Train Loss: 0.068697, Val Loss: 0.062260
2025-09-04 08:43:45,860 - INFO - Epoch 4554/5000 - Train Loss: 0.068827, Val Loss: 0.063481
2025-09-04 08:44:22,999 - INFO - Epoch 4555/5000 - Train Loss: 0.068367, Val Loss: 0.063052
2025-09-04 08:45:00,553 - INFO - Epoch 4556/5000 - Train Loss: 0.068414, Val Loss: 0.061539
2025-09-04 08:45:36,340 - INFO - Epoch 4557/5000 - Train Loss: 0.068240, Val Loss: 0.063971
2025-09-04 08:46:12,003 - INFO - Epoch 4558/5000 - Train Loss: 0.068540, Val Loss: 0.062132
2025-09-04 08:46:48,889 - INFO - Epoch 4559/5000 - Train Loss: 0.067500, Val Loss: 0.063086
2025-09-04 08:47:25,430 - INFO - Epoch 4560/5000 - Train Loss: 0.069040, Val Loss: 0.062321
2025-09-04 08:48:02,628 - INFO - Epoch 4561/5000 - Train Loss: 0.068153, Val Loss: 0.062435
2025-09-04 08:48:39,552 - INFO - Epoch 4562/5000 - Train Loss: 0.069480, Val Loss: 0.063653
2025-09-04 08:49:16,505 - INFO - Epoch 4563/5000 - Train Loss: 0.067957, Val Loss: 0.062344
2025-09-04 08:49:52,210 - INFO - Epoch 4564/5000 - Train Loss: 0.069035, Val Loss: 0.062508
2025-09-04 08:50:28,807 - INFO - Epoch 4565/5000 - Train Loss: 0.069116, Val Loss: 0.061872
2025-09-04 08:51:05,701 - INFO - Epoch 4566/5000 - Train Loss: 0.068529, Val Loss: 0.061422
2025-09-04 08:51:42,058 - INFO - Epoch 4567/5000 - Train Loss: 0.068238, Val Loss: 0.062002
2025-09-04 08:52:18,484 - INFO - Epoch 4568/5000 - Train Loss: 0.068276, Val Loss: 0.061872
2025-09-04 08:52:54,843 - INFO - Epoch 4569/5000 - Train Loss: 0.067696, Val Loss: 0.062176
2025-09-04 08:53:30,162 - INFO - Epoch 4570/5000 - Train Loss: 0.067765, Val Loss: 0.061319
2025-09-04 08:53:30,209 - INFO - New best model saved with Val Loss: 0.061319
2025-09-04 08:54:06,322 - INFO - Epoch 4571/5000 - Train Loss: 0.068689, Val Loss: 0.064859
2025-09-04 08:54:43,083 - INFO - Epoch 4572/5000 - Train Loss: 0.068826, Val Loss: 0.063680
2025-09-04 08:55:19,456 - INFO - Epoch 4573/5000 - Train Loss: 0.070267, Val Loss: 0.063106
2025-09-04 08:55:56,089 - INFO - Epoch 4574/5000 - Train Loss: 0.067993, Val Loss: 0.063473
2025-09-04 08:56:32,849 - INFO - Epoch 4575/5000 - Train Loss: 0.068604, Val Loss: 0.061228
2025-09-04 08:56:32,881 - INFO - New best model saved with Val Loss: 0.061228
2025-09-04 08:57:08,582 - INFO - Epoch 4576/5000 - Train Loss: 0.067749, Val Loss: 0.062843
2025-09-04 08:57:44,178 - INFO - Epoch 4577/5000 - Train Loss: 0.068292, Val Loss: 0.061177
2025-09-04 08:57:44,210 - INFO - New best model saved with Val Loss: 0.061177
2025-09-04 08:58:20,402 - INFO - Epoch 4578/5000 - Train Loss: 0.067731, Val Loss: 0.062418
2025-09-04 08:58:56,717 - INFO - Epoch 4579/5000 - Train Loss: 0.068586, Val Loss: 0.064579
2025-09-04 08:59:33,336 - INFO - Epoch 4580/5000 - Train Loss: 0.069155, Val Loss: 0.062864
2025-09-04 09:00:10,142 - INFO - Epoch 4581/5000 - Train Loss: 0.067935, Val Loss: 0.060563
2025-09-04 09:00:10,176 - INFO - New best model saved with Val Loss: 0.060563
2025-09-04 09:00:46,129 - INFO - Epoch 4582/5000 - Train Loss: 0.068437, Val Loss: 0.062267
2025-09-04 09:01:22,045 - INFO - Epoch 4583/5000 - Train Loss: 0.068523, Val Loss: 0.062073
2025-09-04 09:01:58,212 - INFO - Epoch 4584/5000 - Train Loss: 0.067650, Val Loss: 0.061377
2025-09-04 09:02:33,639 - INFO - Epoch 4585/5000 - Train Loss: 0.067275, Val Loss: 0.063132
2025-09-04 09:03:09,169 - INFO - Epoch 4586/5000 - Train Loss: 0.068785, Val Loss: 0.066117
2025-09-04 09:03:44,291 - INFO - Epoch 4587/5000 - Train Loss: 0.070320, Val Loss: 0.062921
2025-09-04 09:04:19,941 - INFO - Epoch 4588/5000 - Train Loss: 0.068095, Val Loss: 0.062440
2025-09-04 09:04:55,192 - INFO - Epoch 4589/5000 - Train Loss: 0.067922, Val Loss: 0.061781
2025-09-04 09:05:31,838 - INFO - Epoch 4590/5000 - Train Loss: 0.068108, Val Loss: 0.062250
2025-09-04 09:06:08,036 - INFO - Epoch 4591/5000 - Train Loss: 0.068353, Val Loss: 0.064090
2025-09-04 09:06:45,052 - INFO - Epoch 4592/5000 - Train Loss: 0.068169, Val Loss: 0.061163
2025-09-04 09:07:21,667 - INFO - Epoch 4593/5000 - Train Loss: 0.067783, Val Loss: 0.061589
2025-09-04 09:07:58,354 - INFO - Epoch 4594/5000 - Train Loss: 0.068134, Val Loss: 0.061701
2025-09-04 09:08:34,797 - INFO - Epoch 4595/5000 - Train Loss: 0.068586, Val Loss: 0.062161
2025-09-04 09:09:10,872 - INFO - Epoch 4596/5000 - Train Loss: 0.068523, Val Loss: 0.064134
2025-09-04 09:09:47,501 - INFO - Epoch 4597/5000 - Train Loss: 0.068063, Val Loss: 0.063002
2025-09-04 09:10:23,590 - INFO - Epoch 4598/5000 - Train Loss: 0.068523, Val Loss: 0.062750
2025-09-04 09:11:00,356 - INFO - Epoch 4599/5000 - Train Loss: 0.068933, Val Loss: 0.062465
2025-09-04 09:11:37,665 - INFO - Epoch 4600/5000 - Train Loss: 0.068205, Val Loss: 0.061155
2025-09-04 09:12:13,927 - INFO - Epoch 4601/5000 - Train Loss: 0.067647, Val Loss: 0.062122
2025-09-04 09:12:49,906 - INFO - Epoch 4602/5000 - Train Loss: 0.068697, Val Loss: 0.063173
2025-09-04 09:13:25,886 - INFO - Epoch 4603/5000 - Train Loss: 0.068142, Val Loss: 0.061026
2025-09-04 09:14:01,737 - INFO - Epoch 4604/5000 - Train Loss: 0.069129, Val Loss: 0.061905
2025-09-04 09:14:37,780 - INFO - Epoch 4605/5000 - Train Loss: 0.068088, Val Loss: 0.063461
2025-09-04 09:15:14,145 - INFO - Epoch 4606/5000 - Train Loss: 0.068473, Val Loss: 0.061682
2025-09-04 09:15:51,011 - INFO - Epoch 4607/5000 - Train Loss: 0.068729, Val Loss: 0.067106
2025-09-04 09:16:28,060 - INFO - Epoch 4608/5000 - Train Loss: 0.070094, Val Loss: 0.064436
2025-09-04 09:17:04,160 - INFO - Epoch 4609/5000 - Train Loss: 0.068279, Val Loss: 0.062402
2025-09-04 09:17:39,844 - INFO - Epoch 4610/5000 - Train Loss: 0.066670, Val Loss: 0.061991
2025-09-04 09:18:15,514 - INFO - Epoch 4611/5000 - Train Loss: 0.067796, Val Loss: 0.061439
2025-09-04 09:18:51,065 - INFO - Epoch 4612/5000 - Train Loss: 0.067784, Val Loss: 0.063080
2025-09-04 09:19:27,304 - INFO - Epoch 4613/5000 - Train Loss: 0.068536, Val Loss: 0.063416
2025-09-04 09:20:03,569 - INFO - Epoch 4614/5000 - Train Loss: 0.069044, Val Loss: 0.063126
2025-09-04 09:20:39,776 - INFO - Epoch 4615/5000 - Train Loss: 0.068392, Val Loss: 0.063938
2025-09-04 09:21:16,226 - INFO - Epoch 4616/5000 - Train Loss: 0.069203, Val Loss: 0.063714
2025-09-04 09:21:52,587 - INFO - Epoch 4617/5000 - Train Loss: 0.067849, Val Loss: 0.063260
2025-09-04 09:22:28,598 - INFO - Epoch 4618/5000 - Train Loss: 0.068697, Val Loss: 0.062417
2025-09-04 09:23:05,031 - INFO - Epoch 4619/5000 - Train Loss: 0.069218, Val Loss: 0.062012
2025-09-04 09:23:40,544 - INFO - Epoch 4620/5000 - Train Loss: 0.068487, Val Loss: 0.061935
2025-09-04 09:24:17,514 - INFO - Epoch 4621/5000 - Train Loss: 0.067372, Val Loss: 0.062887
2025-09-04 09:24:54,332 - INFO - Epoch 4622/5000 - Train Loss: 0.068116, Val Loss: 0.062214
2025-09-04 09:25:31,024 - INFO - Epoch 4623/5000 - Train Loss: 0.067433, Val Loss: 0.060821
2025-09-04 09:26:07,805 - INFO - Epoch 4624/5000 - Train Loss: 0.068072, Val Loss: 0.062461
2025-09-04 09:26:44,230 - INFO - Epoch 4625/5000 - Train Loss: 0.068849, Val Loss: 0.063065
2025-09-04 09:27:20,497 - INFO - Epoch 4626/5000 - Train Loss: 0.068925, Val Loss: 0.063598
2025-09-04 09:27:56,655 - INFO - Epoch 4627/5000 - Train Loss: 0.068443, Val Loss: 0.062645
2025-09-04 09:28:33,545 - INFO - Epoch 4628/5000 - Train Loss: 0.067679, Val Loss: 0.061321
2025-09-04 09:29:10,479 - INFO - Epoch 4629/5000 - Train Loss: 0.068145, Val Loss: 0.062884
2025-09-04 09:29:47,333 - INFO - Epoch 4630/5000 - Train Loss: 0.067771, Val Loss: 0.062315
2025-09-04 09:30:24,742 - INFO - Epoch 4631/5000 - Train Loss: 0.067579, Val Loss: 0.062229
2025-09-04 09:31:01,508 - INFO - Epoch 4632/5000 - Train Loss: 0.068314, Val Loss: 0.062015
2025-09-04 09:31:37,595 - INFO - Epoch 4633/5000 - Train Loss: 0.068309, Val Loss: 0.061379
2025-09-04 09:32:13,571 - INFO - Epoch 4634/5000 - Train Loss: 0.067461, Val Loss: 0.061662
2025-09-04 09:32:49,908 - INFO - Epoch 4635/5000 - Train Loss: 0.067861, Val Loss: 0.062314
2025-09-04 09:33:26,369 - INFO - Epoch 4636/5000 - Train Loss: 0.067971, Val Loss: 0.061184
2025-09-04 09:34:02,546 - INFO - Epoch 4637/5000 - Train Loss: 0.068348, Val Loss: 0.062118
2025-09-04 09:34:38,525 - INFO - Epoch 4638/5000 - Train Loss: 0.068164, Val Loss: 0.062359
2025-09-04 09:35:14,484 - INFO - Epoch 4639/5000 - Train Loss: 0.068271, Val Loss: 0.062880
2025-09-04 09:35:50,534 - INFO - Epoch 4640/5000 - Train Loss: 0.067290, Val Loss: 0.061034
2025-09-04 09:36:27,044 - INFO - Epoch 4641/5000 - Train Loss: 0.067567, Val Loss: 0.062651
2025-09-04 09:37:03,579 - INFO - Epoch 4642/5000 - Train Loss: 0.067546, Val Loss: 0.061143
2025-09-04 09:37:39,171 - INFO - Epoch 4643/5000 - Train Loss: 0.068377, Val Loss: 0.062968
2025-09-04 09:38:15,034 - INFO - Epoch 4644/5000 - Train Loss: 0.067645, Val Loss: 0.062105
2025-09-04 09:38:51,713 - INFO - Epoch 4645/5000 - Train Loss: 0.068069, Val Loss: 0.061661
2025-09-04 09:39:28,668 - INFO - Epoch 4646/5000 - Train Loss: 0.067455, Val Loss: 0.062242
2025-09-04 09:40:05,726 - INFO - Epoch 4647/5000 - Train Loss: 0.067425, Val Loss: 0.062675
2025-09-04 09:40:42,559 - INFO - Epoch 4648/5000 - Train Loss: 0.067699, Val Loss: 0.061805
2025-09-04 09:41:19,009 - INFO - Epoch 4649/5000 - Train Loss: 0.067293, Val Loss: 0.062219
2025-09-04 09:41:55,579 - INFO - Epoch 4650/5000 - Train Loss: 0.067965, Val Loss: 0.062452
2025-09-04 09:42:32,639 - INFO - Epoch 4651/5000 - Train Loss: 0.068105, Val Loss: 0.063572
2025-09-04 09:43:09,217 - INFO - Epoch 4652/5000 - Train Loss: 0.068457, Val Loss: 0.063298
2025-09-04 09:43:45,787 - INFO - Epoch 4653/5000 - Train Loss: 0.068386, Val Loss: 0.063112
2025-09-04 09:44:22,573 - INFO - Epoch 4654/5000 - Train Loss: 0.068044, Val Loss: 0.060769
2025-09-04 09:44:58,877 - INFO - Epoch 4655/5000 - Train Loss: 0.067546, Val Loss: 0.061634
2025-09-04 09:45:36,146 - INFO - Epoch 4656/5000 - Train Loss: 0.068149, Val Loss: 0.061299
2025-09-04 09:46:12,612 - INFO - Epoch 4657/5000 - Train Loss: 0.067238, Val Loss: 0.060477
2025-09-04 09:46:12,663 - INFO - New best model saved with Val Loss: 0.060477
2025-09-04 09:46:49,110 - INFO - Epoch 4658/5000 - Train Loss: 0.067038, Val Loss: 0.061320
2025-09-04 09:47:25,247 - INFO - Epoch 4659/5000 - Train Loss: 0.068465, Val Loss: 0.061318
2025-09-04 09:48:02,629 - INFO - Epoch 4660/5000 - Train Loss: 0.067685, Val Loss: 0.062289
2025-09-04 09:48:39,809 - INFO - Epoch 4661/5000 - Train Loss: 0.067701, Val Loss: 0.061686
2025-09-04 09:49:16,192 - INFO - Epoch 4662/5000 - Train Loss: 0.067884, Val Loss: 0.061644
2025-09-04 09:49:51,998 - INFO - Epoch 4663/5000 - Train Loss: 0.067461, Val Loss: 0.062366
2025-09-04 09:50:28,774 - INFO - Epoch 4664/5000 - Train Loss: 0.068279, Val Loss: 0.063735
2025-09-04 09:51:05,275 - INFO - Epoch 4665/5000 - Train Loss: 0.067520, Val Loss: 0.060154
2025-09-04 09:51:05,324 - INFO - New best model saved with Val Loss: 0.060154
2025-09-04 09:51:41,016 - INFO - Epoch 4666/5000 - Train Loss: 0.067883, Val Loss: 0.061203
2025-09-04 09:52:17,632 - INFO - Epoch 4667/5000 - Train Loss: 0.065983, Val Loss: 0.060662
2025-09-04 09:52:54,782 - INFO - Epoch 4668/5000 - Train Loss: 0.067598, Val Loss: 0.061659
2025-09-04 09:53:32,239 - INFO - Epoch 4669/5000 - Train Loss: 0.067978, Val Loss: 0.062448
2025-09-04 09:54:08,680 - INFO - Epoch 4670/5000 - Train Loss: 0.067646, Val Loss: 0.062053
2025-09-04 09:54:45,483 - INFO - Epoch 4671/5000 - Train Loss: 0.067381, Val Loss: 0.062101
2025-09-04 09:55:21,924 - INFO - Epoch 4672/5000 - Train Loss: 0.068680, Val Loss: 0.062219
2025-09-04 09:55:58,793 - INFO - Epoch 4673/5000 - Train Loss: 0.067681, Val Loss: 0.061401
2025-09-04 09:56:34,925 - INFO - Epoch 4674/5000 - Train Loss: 0.066931, Val Loss: 0.062629
2025-09-04 09:57:11,617 - INFO - Epoch 4675/5000 - Train Loss: 0.067475, Val Loss: 0.061793
2025-09-04 09:57:48,145 - INFO - Epoch 4676/5000 - Train Loss: 0.068122, Val Loss: 0.062539
2025-09-04 09:58:24,419 - INFO - Epoch 4677/5000 - Train Loss: 0.067278, Val Loss: 0.061622
2025-09-04 09:59:00,485 - INFO - Epoch 4678/5000 - Train Loss: 0.067405, Val Loss: 0.064150
2025-09-04 09:59:36,499 - INFO - Epoch 4679/5000 - Train Loss: 0.068962, Val Loss: 0.062387
2025-09-04 10:00:12,923 - INFO - Epoch 4680/5000 - Train Loss: 0.067652, Val Loss: 0.061361
2025-09-04 10:00:48,712 - INFO - Epoch 4681/5000 - Train Loss: 0.066732, Val Loss: 0.061095
2025-09-04 10:01:25,014 - INFO - Epoch 4682/5000 - Train Loss: 0.067787, Val Loss: 0.061283
2025-09-04 10:02:01,216 - INFO - Epoch 4683/5000 - Train Loss: 0.067325, Val Loss: 0.061118
2025-09-04 10:02:37,670 - INFO - Epoch 4684/5000 - Train Loss: 0.069094, Val Loss: 0.064043
2025-09-04 10:03:14,099 - INFO - Epoch 4685/5000 - Train Loss: 0.068038, Val Loss: 0.062822
2025-09-04 10:03:50,845 - INFO - Epoch 4686/5000 - Train Loss: 0.067226, Val Loss: 0.062292
2025-09-04 10:04:28,167 - INFO - Epoch 4687/5000 - Train Loss: 0.067743, Val Loss: 0.061265
2025-09-04 10:05:04,335 - INFO - Epoch 4688/5000 - Train Loss: 0.067679, Val Loss: 0.062435
2025-09-04 10:05:40,567 - INFO - Epoch 4689/5000 - Train Loss: 0.068155, Val Loss: 0.061839
2025-09-04 10:06:16,768 - INFO - Epoch 4690/5000 - Train Loss: 0.068808, Val Loss: 0.062777
2025-09-04 10:06:52,795 - INFO - Epoch 4691/5000 - Train Loss: 0.067281, Val Loss: 0.062369
2025-09-04 10:07:28,799 - INFO - Epoch 4692/5000 - Train Loss: 0.067704, Val Loss: 0.062450
2025-09-04 10:08:03,481 - INFO - Epoch 4693/5000 - Train Loss: 0.068082, Val Loss: 0.063287
2025-09-04 10:08:39,314 - INFO - Epoch 4694/5000 - Train Loss: 0.068412, Val Loss: 0.063486
2025-09-04 10:09:15,146 - INFO - Epoch 4695/5000 - Train Loss: 0.067914, Val Loss: 0.061682
2025-09-04 10:09:51,603 - INFO - Epoch 4696/5000 - Train Loss: 0.067122, Val Loss: 0.060354
2025-09-04 10:10:27,282 - INFO - Epoch 4697/5000 - Train Loss: 0.067102, Val Loss: 0.060738
2025-09-04 10:11:03,624 - INFO - Epoch 4698/5000 - Train Loss: 0.067533, Val Loss: 0.062096
2025-09-04 10:11:40,090 - INFO - Epoch 4699/5000 - Train Loss: 0.068456, Val Loss: 0.062770
2025-09-04 10:12:16,121 - INFO - Epoch 4700/5000 - Train Loss: 0.067697, Val Loss: 0.061481
2025-09-04 10:12:51,850 - INFO - Epoch 4701/5000 - Train Loss: 0.067333, Val Loss: 0.061337
2025-09-04 10:13:28,491 - INFO - Epoch 4702/5000 - Train Loss: 0.067219, Val Loss: 0.063723
2025-09-04 10:14:04,533 - INFO - Epoch 4703/5000 - Train Loss: 0.067949, Val Loss: 0.061748
2025-09-04 10:14:41,008 - INFO - Epoch 4704/5000 - Train Loss: 0.067881, Val Loss: 0.061499
2025-09-04 10:15:17,032 - INFO - Epoch 4705/5000 - Train Loss: 0.066871, Val Loss: 0.061241
2025-09-04 10:15:52,802 - INFO - Epoch 4706/5000 - Train Loss: 0.067441, Val Loss: 0.061014
2025-09-04 10:16:28,662 - INFO - Epoch 4707/5000 - Train Loss: 0.067748, Val Loss: 0.063165
2025-09-04 10:17:04,614 - INFO - Epoch 4708/5000 - Train Loss: 0.067736, Val Loss: 0.061897
2025-09-04 10:17:40,812 - INFO - Epoch 4709/5000 - Train Loss: 0.067098, Val Loss: 0.061091
2025-09-04 10:18:17,219 - INFO - Epoch 4710/5000 - Train Loss: 0.067200, Val Loss: 0.062183
2025-09-04 10:18:54,661 - INFO - Epoch 4711/5000 - Train Loss: 0.068013, Val Loss: 0.062122
2025-09-04 10:19:30,512 - INFO - Epoch 4712/5000 - Train Loss: 0.067908, Val Loss: 0.063653
2025-09-04 10:20:07,244 - INFO - Epoch 4713/5000 - Train Loss: 0.067576, Val Loss: 0.060875
2025-09-04 10:20:44,083 - INFO - Epoch 4714/5000 - Train Loss: 0.067515, Val Loss: 0.061769
2025-09-04 10:21:21,753 - INFO - Epoch 4715/5000 - Train Loss: 0.067362, Val Loss: 0.063513
2025-09-04 10:21:58,287 - INFO - Epoch 4716/5000 - Train Loss: 0.066986, Val Loss: 0.063318
2025-09-04 10:22:34,328 - INFO - Epoch 4717/5000 - Train Loss: 0.067558, Val Loss: 0.060886
2025-09-04 10:23:10,322 - INFO - Epoch 4718/5000 - Train Loss: 0.066592, Val Loss: 0.060698
2025-09-04 10:23:47,086 - INFO - Epoch 4719/5000 - Train Loss: 0.068022, Val Loss: 0.070691
2025-09-04 10:24:23,288 - INFO - Epoch 4720/5000 - Train Loss: 0.070854, Val Loss: 0.062332
2025-09-04 10:24:59,469 - INFO - Epoch 4721/5000 - Train Loss: 0.067817, Val Loss: 0.062970
2025-09-04 10:25:35,714 - INFO - Epoch 4722/5000 - Train Loss: 0.067827, Val Loss: 0.061188
2025-09-04 10:26:11,555 - INFO - Epoch 4723/5000 - Train Loss: 0.067313, Val Loss: 0.061141
2025-09-04 10:26:48,301 - INFO - Epoch 4724/5000 - Train Loss: 0.066991, Val Loss: 0.061038
2025-09-04 10:27:24,504 - INFO - Epoch 4725/5000 - Train Loss: 0.067309, Val Loss: 0.062509
2025-09-04 10:28:00,586 - INFO - Epoch 4726/5000 - Train Loss: 0.066733, Val Loss: 0.061958
2025-09-04 10:28:37,179 - INFO - Epoch 4727/5000 - Train Loss: 0.067245, Val Loss: 0.065279
2025-09-04 10:29:14,677 - INFO - Epoch 4728/5000 - Train Loss: 0.067501, Val Loss: 0.062511
2025-09-04 10:29:50,767 - INFO - Epoch 4729/5000 - Train Loss: 0.067248, Val Loss: 0.061113
2025-09-04 10:30:27,285 - INFO - Epoch 4730/5000 - Train Loss: 0.066465, Val Loss: 0.060697
2025-09-04 10:31:03,399 - INFO - Epoch 4731/5000 - Train Loss: 0.067237, Val Loss: 0.061089
2025-09-04 10:31:39,669 - INFO - Epoch 4732/5000 - Train Loss: 0.066501, Val Loss: 0.061814
2025-09-04 10:32:16,723 - INFO - Epoch 4733/5000 - Train Loss: 0.067217, Val Loss: 0.068370
2025-09-04 10:32:53,235 - INFO - Epoch 4734/5000 - Train Loss: 0.069835, Val Loss: 0.064311
2025-09-04 10:33:29,775 - INFO - Epoch 4735/5000 - Train Loss: 0.068581, Val Loss: 0.062008
2025-09-04 10:34:05,632 - INFO - Epoch 4736/5000 - Train Loss: 0.067413, Val Loss: 0.061379
2025-09-04 10:34:42,331 - INFO - Epoch 4737/5000 - Train Loss: 0.066816, Val Loss: 0.062532
2025-09-04 10:35:18,866 - INFO - Epoch 4738/5000 - Train Loss: 0.067035, Val Loss: 0.062178
2025-09-04 10:35:54,835 - INFO - Epoch 4739/5000 - Train Loss: 0.067633, Val Loss: 0.062375
2025-09-04 10:36:31,711 - INFO - Epoch 4740/5000 - Train Loss: 0.067652, Val Loss: 0.061888
2025-09-04 10:37:08,667 - INFO - Epoch 4741/5000 - Train Loss: 0.066801, Val Loss: 0.062013
2025-09-04 10:37:44,807 - INFO - Epoch 4742/5000 - Train Loss: 0.067535, Val Loss: 0.061271
2025-09-04 10:38:21,516 - INFO - Epoch 4743/5000 - Train Loss: 0.067079, Val Loss: 0.061795
2025-09-04 10:38:58,008 - INFO - Epoch 4744/5000 - Train Loss: 0.067104, Val Loss: 0.060926
2025-09-04 10:39:33,972 - INFO - Epoch 4745/5000 - Train Loss: 0.067749, Val Loss: 0.062230
2025-09-04 10:40:09,901 - INFO - Epoch 4746/5000 - Train Loss: 0.067363, Val Loss: 0.061698
2025-09-04 10:40:45,225 - INFO - Epoch 4747/5000 - Train Loss: 0.066387, Val Loss: 0.062859
2025-09-04 10:41:21,835 - INFO - Epoch 4748/5000 - Train Loss: 0.067769, Val Loss: 0.062052
2025-09-04 10:41:57,746 - INFO - Epoch 4749/5000 - Train Loss: 0.066835, Val Loss: 0.060568
2025-09-04 10:42:34,174 - INFO - Epoch 4750/5000 - Train Loss: 0.067572, Val Loss: 0.063502
2025-09-04 10:43:11,097 - INFO - Epoch 4751/5000 - Train Loss: 0.067301, Val Loss: 0.063053
2025-09-04 10:43:47,626 - INFO - Epoch 4752/5000 - Train Loss: 0.067184, Val Loss: 0.061374
2025-09-04 10:44:24,277 - INFO - Epoch 4753/5000 - Train Loss: 0.066730, Val Loss: 0.060556
2025-09-04 10:45:01,118 - INFO - Epoch 4754/5000 - Train Loss: 0.067534, Val Loss: 0.061004
2025-09-04 10:45:37,526 - INFO - Epoch 4755/5000 - Train Loss: 0.067312, Val Loss: 0.060828
2025-09-04 10:46:14,070 - INFO - Epoch 4756/5000 - Train Loss: 0.066125, Val Loss: 0.060884
2025-09-04 10:46:50,253 - INFO - Epoch 4757/5000 - Train Loss: 0.066714, Val Loss: 0.060737
2025-09-04 10:47:26,814 - INFO - Epoch 4758/5000 - Train Loss: 0.067807, Val Loss: 0.061117
2025-09-04 10:48:03,513 - INFO - Epoch 4759/5000 - Train Loss: 0.066760, Val Loss: 0.061164
2025-09-04 10:48:39,282 - INFO - Epoch 4760/5000 - Train Loss: 0.066773, Val Loss: 0.062440
2025-09-04 10:49:16,059 - INFO - Epoch 4761/5000 - Train Loss: 0.066468, Val Loss: 0.061154
2025-09-04 10:49:52,199 - INFO - Epoch 4762/5000 - Train Loss: 0.066749, Val Loss: 0.062758
2025-09-04 10:50:28,567 - INFO - Epoch 4763/5000 - Train Loss: 0.066643, Val Loss: 0.061152
2025-09-04 10:51:05,110 - INFO - Epoch 4764/5000 - Train Loss: 0.067094, Val Loss: 0.061233
2025-09-04 10:51:43,633 - INFO - Epoch 4765/5000 - Train Loss: 0.069611, Val Loss: 0.063728
2025-09-04 10:52:20,802 - INFO - Epoch 4766/5000 - Train Loss: 0.066776, Val Loss: 0.060801
2025-09-04 10:52:57,733 - INFO - Epoch 4767/5000 - Train Loss: 0.065428, Val Loss: 0.061047
2025-09-04 10:53:34,231 - INFO - Epoch 4768/5000 - Train Loss: 0.067072, Val Loss: 0.062589
2025-09-04 10:54:10,437 - INFO - Epoch 4769/5000 - Train Loss: 0.068005, Val Loss: 0.060903
2025-09-04 10:54:47,306 - INFO - Epoch 4770/5000 - Train Loss: 0.066768, Val Loss: 0.061127
2025-09-04 10:55:24,183 - INFO - Epoch 4771/5000 - Train Loss: 0.066700, Val Loss: 0.061208
2025-09-04 10:56:01,475 - INFO - Epoch 4772/5000 - Train Loss: 0.066782, Val Loss: 0.061716
2025-09-04 10:56:38,695 - INFO - Epoch 4773/5000 - Train Loss: 0.066844, Val Loss: 0.061174
2025-09-04 10:57:14,874 - INFO - Epoch 4774/5000 - Train Loss: 0.066804, Val Loss: 0.061342
2025-09-04 10:57:50,609 - INFO - Epoch 4775/5000 - Train Loss: 0.067397, Val Loss: 0.061468
2025-09-04 10:58:27,336 - INFO - Epoch 4776/5000 - Train Loss: 0.067691, Val Loss: 0.062385
2025-09-04 10:59:04,258 - INFO - Epoch 4777/5000 - Train Loss: 0.066554, Val Loss: 0.061312
2025-09-04 10:59:42,222 - INFO - Epoch 4778/5000 - Train Loss: 0.067134, Val Loss: 0.062637
2025-09-04 11:00:19,031 - INFO - Epoch 4779/5000 - Train Loss: 0.067259, Val Loss: 0.061376
2025-09-04 11:00:55,569 - INFO - Epoch 4780/5000 - Train Loss: 0.067870, Val Loss: 0.063157
2025-09-04 11:01:33,390 - INFO - Epoch 4781/5000 - Train Loss: 0.067095, Val Loss: 0.060581
2025-09-04 11:02:09,000 - INFO - Epoch 4782/5000 - Train Loss: 0.067577, Val Loss: 0.062062
2025-09-04 11:02:45,897 - INFO - Epoch 4783/5000 - Train Loss: 0.067631, Val Loss: 0.061705
2025-09-04 11:03:23,896 - INFO - Epoch 4784/5000 - Train Loss: 0.066423, Val Loss: 0.063658
2025-09-04 11:04:00,981 - INFO - Epoch 4785/5000 - Train Loss: 0.066770, Val Loss: 0.061045
2025-09-04 11:04:37,692 - INFO - Epoch 4786/5000 - Train Loss: 0.065699, Val Loss: 0.062275
2025-09-04 11:05:13,425 - INFO - Epoch 4787/5000 - Train Loss: 0.067003, Val Loss: 0.061777
2025-09-04 11:05:49,891 - INFO - Epoch 4788/5000 - Train Loss: 0.066657, Val Loss: 0.060338
2025-09-04 11:06:32,084 - INFO - Epoch 4789/5000 - Train Loss: 0.066468, Val Loss: 0.061197
2025-09-04 11:07:10,743 - INFO - Epoch 4790/5000 - Train Loss: 0.066220, Val Loss: 0.061704
2025-09-04 11:07:49,401 - INFO - Epoch 4791/5000 - Train Loss: 0.066578, Val Loss: 0.061251
2025-09-04 11:08:27,115 - INFO - Epoch 4792/5000 - Train Loss: 0.066301, Val Loss: 0.061723
2025-09-04 11:09:03,600 - INFO - Epoch 4793/5000 - Train Loss: 0.067003, Val Loss: 0.063773
2025-09-04 11:09:39,454 - INFO - Epoch 4794/5000 - Train Loss: 0.067533, Val Loss: 0.062780
2025-09-04 11:10:14,914 - INFO - Epoch 4795/5000 - Train Loss: 0.066430, Val Loss: 0.060616
2025-09-04 11:10:50,707 - INFO - Epoch 4796/5000 - Train Loss: 0.066830, Val Loss: 0.060574
2025-09-04 11:11:26,675 - INFO - Epoch 4797/5000 - Train Loss: 0.066349, Val Loss: 0.061096
2025-09-04 11:12:02,617 - INFO - Epoch 4798/5000 - Train Loss: 0.067865, Val Loss: 0.061965
2025-09-04 11:12:38,162 - INFO - Epoch 4799/5000 - Train Loss: 0.067493, Val Loss: 0.061403
2025-09-04 11:13:13,959 - INFO - Epoch 4800/5000 - Train Loss: 0.066698, Val Loss: 0.061857
2025-09-04 11:13:50,339 - INFO - Epoch 4801/5000 - Train Loss: 0.066893, Val Loss: 0.062087
2025-09-04 11:14:26,361 - INFO - Epoch 4802/5000 - Train Loss: 0.067261, Val Loss: 0.060989
2025-09-04 11:15:02,245 - INFO - Epoch 4803/5000 - Train Loss: 0.069062, Val Loss: 0.062714
2025-09-04 11:15:38,424 - INFO - Epoch 4804/5000 - Train Loss: 0.067375, Val Loss: 0.061987
2025-09-04 11:16:14,807 - INFO - Epoch 4805/5000 - Train Loss: 0.066685, Val Loss: 0.061080
2025-09-04 11:16:50,706 - INFO - Epoch 4806/5000 - Train Loss: 0.066102, Val Loss: 0.060685
2025-09-04 11:17:27,308 - INFO - Epoch 4807/5000 - Train Loss: 0.066844, Val Loss: 0.061803
2025-09-04 11:18:04,110 - INFO - Epoch 4808/5000 - Train Loss: 0.066620, Val Loss: 0.060759
2025-09-04 11:18:41,127 - INFO - Epoch 4809/5000 - Train Loss: 0.066428, Val Loss: 0.061800
2025-09-04 11:19:17,555 - INFO - Epoch 4810/5000 - Train Loss: 0.066460, Val Loss: 0.061356
2025-09-04 11:19:54,288 - INFO - Epoch 4811/5000 - Train Loss: 0.066970, Val Loss: 0.062819
2025-09-04 11:20:30,545 - INFO - Epoch 4812/5000 - Train Loss: 0.066378, Val Loss: 0.061793
2025-09-04 11:21:06,388 - INFO - Epoch 4813/5000 - Train Loss: 0.066567, Val Loss: 0.060432
2025-09-04 11:21:43,138 - INFO - Epoch 4814/5000 - Train Loss: 0.067193, Val Loss: 0.062304
2025-09-04 11:22:19,573 - INFO - Epoch 4815/5000 - Train Loss: 0.066323, Val Loss: 0.061631
2025-09-04 11:22:56,118 - INFO - Epoch 4816/5000 - Train Loss: 0.066336, Val Loss: 0.060306
2025-09-04 11:23:32,738 - INFO - Epoch 4817/5000 - Train Loss: 0.065923, Val Loss: 0.060473
2025-09-04 11:24:08,650 - INFO - Epoch 4818/5000 - Train Loss: 0.067113, Val Loss: 0.061815
2025-09-04 11:24:44,664 - INFO - Epoch 4819/5000 - Train Loss: 0.066963, Val Loss: 0.060553
2025-09-04 11:25:21,033 - INFO - Epoch 4820/5000 - Train Loss: 0.066620, Val Loss: 0.060322
2025-09-04 11:25:57,024 - INFO - Epoch 4821/5000 - Train Loss: 0.066427, Val Loss: 0.061571
2025-09-04 11:26:33,123 - INFO - Epoch 4822/5000 - Train Loss: 0.066513, Val Loss: 0.061013
2025-09-04 11:27:08,907 - INFO - Epoch 4823/5000 - Train Loss: 0.066816, Val Loss: 0.062178
2025-09-04 11:27:44,963 - INFO - Epoch 4824/5000 - Train Loss: 0.067018, Val Loss: 0.060514
2025-09-04 11:28:21,804 - INFO - Epoch 4825/5000 - Train Loss: 0.066131, Val Loss: 0.061260
2025-09-04 11:28:57,530 - INFO - Epoch 4826/5000 - Train Loss: 0.067788, Val Loss: 0.061754
2025-09-04 11:29:33,367 - INFO - Epoch 4827/5000 - Train Loss: 0.066534, Val Loss: 0.060927
2025-09-04 11:30:09,484 - INFO - Epoch 4828/5000 - Train Loss: 0.067050, Val Loss: 0.060738
2025-09-04 11:30:45,503 - INFO - Epoch 4829/5000 - Train Loss: 0.066112, Val Loss: 0.061555
2025-09-04 11:31:22,138 - INFO - Epoch 4830/5000 - Train Loss: 0.069677, Val Loss: 0.062968
2025-09-04 11:31:59,084 - INFO - Epoch 4831/5000 - Train Loss: 0.066678, Val Loss: 0.061005
2025-09-04 11:32:35,258 - INFO - Epoch 4832/5000 - Train Loss: 0.066437, Val Loss: 0.062587
2025-09-04 11:33:12,151 - INFO - Epoch 4833/5000 - Train Loss: 0.066364, Val Loss: 0.060769
2025-09-04 11:33:48,150 - INFO - Epoch 4834/5000 - Train Loss: 0.066474, Val Loss: 0.060370
2025-09-04 11:34:24,826 - INFO - Epoch 4835/5000 - Train Loss: 0.065720, Val Loss: 0.060071
2025-09-04 11:34:24,880 - INFO - New best model saved with Val Loss: 0.060071
2025-09-04 11:35:05,765 - INFO - Epoch 4836/5000 - Train Loss: 0.067022, Val Loss: 0.061577
2025-09-04 11:35:42,310 - INFO - Epoch 4837/5000 - Train Loss: 0.067222, Val Loss: 0.061084
2025-09-04 11:36:17,794 - INFO - Epoch 4838/5000 - Train Loss: 0.067137, Val Loss: 0.060228
2025-09-04 11:36:53,546 - INFO - Epoch 4839/5000 - Train Loss: 0.066614, Val Loss: 0.060121
2025-09-04 11:37:29,152 - INFO - Epoch 4840/5000 - Train Loss: 0.065531, Val Loss: 0.061779
2025-09-04 11:38:05,283 - INFO - Epoch 4841/5000 - Train Loss: 0.066250, Val Loss: 0.062716
2025-09-04 11:38:41,297 - INFO - Epoch 4842/5000 - Train Loss: 0.067257, Val Loss: 0.062291
2025-09-04 11:39:17,212 - INFO - Epoch 4843/5000 - Train Loss: 0.067181, Val Loss: 0.061478
2025-09-04 11:39:53,143 - INFO - Epoch 4844/5000 - Train Loss: 0.066052, Val Loss: 0.062883
2025-09-04 11:40:29,026 - INFO - Epoch 4845/5000 - Train Loss: 0.066359, Val Loss: 0.061725
2025-09-04 11:41:04,166 - INFO - Epoch 4846/5000 - Train Loss: 0.066083, Val Loss: 0.060477
2025-09-04 11:41:40,605 - INFO - Epoch 4847/5000 - Train Loss: 0.066754, Val Loss: 0.060743
2025-09-04 11:42:16,799 - INFO - Epoch 4848/5000 - Train Loss: 0.065849, Val Loss: 0.061943
2025-09-04 11:42:52,455 - INFO - Epoch 4849/5000 - Train Loss: 0.066198, Val Loss: 0.061747
2025-09-04 11:43:28,924 - INFO - Epoch 4850/5000 - Train Loss: 0.069423, Val Loss: 0.062544
2025-09-04 11:44:05,681 - INFO - Epoch 4851/5000 - Train Loss: 0.066205, Val Loss: 0.060477
2025-09-04 11:44:41,564 - INFO - Epoch 4852/5000 - Train Loss: 0.065868, Val Loss: 0.064042
2025-09-04 11:45:17,410 - INFO - Epoch 4853/5000 - Train Loss: 0.068145, Val Loss: 0.060534
2025-09-04 11:45:53,875 - INFO - Epoch 4854/5000 - Train Loss: 0.065491, Val Loss: 0.060594
2025-09-04 11:46:30,241 - INFO - Epoch 4855/5000 - Train Loss: 0.066290, Val Loss: 0.063544
2025-09-04 11:47:06,091 - INFO - Epoch 4856/5000 - Train Loss: 0.066788, Val Loss: 0.060976
2025-09-04 11:47:42,998 - INFO - Epoch 4857/5000 - Train Loss: 0.066092, Val Loss: 0.062005
2025-09-04 11:48:18,792 - INFO - Epoch 4858/5000 - Train Loss: 0.066437, Val Loss: 0.060469
2025-09-04 11:48:55,054 - INFO - Epoch 4859/5000 - Train Loss: 0.066051, Val Loss: 0.062256
2025-09-04 11:49:31,483 - INFO - Epoch 4860/5000 - Train Loss: 0.066641, Val Loss: 0.060642
2025-09-04 11:50:08,090 - INFO - Epoch 4861/5000 - Train Loss: 0.065619, Val Loss: 0.062140
2025-09-04 11:50:44,117 - INFO - Epoch 4862/5000 - Train Loss: 0.066850, Val Loss: 0.061822
2025-09-04 11:51:20,470 - INFO - Epoch 4863/5000 - Train Loss: 0.065571, Val Loss: 0.060040
2025-09-04 11:51:20,520 - INFO - New best model saved with Val Loss: 0.060040
2025-09-04 11:51:56,768 - INFO - Epoch 4864/5000 - Train Loss: 0.066124, Val Loss: 0.060545
2025-09-04 11:52:33,608 - INFO - Epoch 4865/5000 - Train Loss: 0.066767, Val Loss: 0.061770
2025-09-04 11:53:09,844 - INFO - Epoch 4866/5000 - Train Loss: 0.066663, Val Loss: 0.061105
2025-09-04 11:53:46,009 - INFO - Epoch 4867/5000 - Train Loss: 0.065973, Val Loss: 0.060532
2025-09-04 11:54:22,006 - INFO - Epoch 4868/5000 - Train Loss: 0.066819, Val Loss: 0.060631
2025-09-04 11:54:58,375 - INFO - Epoch 4869/5000 - Train Loss: 0.066349, Val Loss: 0.060674
2025-09-04 11:55:34,138 - INFO - Epoch 4870/5000 - Train Loss: 0.065673, Val Loss: 0.061793
2025-09-04 11:56:10,094 - INFO - Epoch 4871/5000 - Train Loss: 0.066661, Val Loss: 0.060705
2025-09-04 11:56:45,769 - INFO - Epoch 4872/5000 - Train Loss: 0.065993, Val Loss: 0.059854
2025-09-04 11:56:45,799 - INFO - New best model saved with Val Loss: 0.059854
2025-09-04 11:57:22,204 - INFO - Epoch 4873/5000 - Train Loss: 0.065845, Val Loss: 0.060412
2025-09-04 11:57:58,560 - INFO - Epoch 4874/5000 - Train Loss: 0.066111, Val Loss: 0.060715
2025-09-04 11:58:34,842 - INFO - Epoch 4875/5000 - Train Loss: 0.066713, Val Loss: 0.061939
2025-09-04 11:59:11,133 - INFO - Epoch 4876/5000 - Train Loss: 0.066102, Val Loss: 0.060489
2025-09-04 11:59:47,573 - INFO - Epoch 4877/5000 - Train Loss: 0.065460, Val Loss: 0.060384
2025-09-04 12:00:23,524 - INFO - Epoch 4878/5000 - Train Loss: 0.067173, Val Loss: 0.059953
2025-09-04 12:00:59,904 - INFO - Epoch 4879/5000 - Train Loss: 0.066125, Val Loss: 0.060804
2025-09-04 12:01:35,854 - INFO - Epoch 4880/5000 - Train Loss: 0.066269, Val Loss: 0.060286
2025-09-04 12:02:12,147 - INFO - Epoch 4881/5000 - Train Loss: 0.073827, Val Loss: 0.062548
2025-09-04 12:02:47,754 - INFO - Epoch 4882/5000 - Train Loss: 0.067725, Val Loss: 0.062488
2025-09-04 12:03:23,493 - INFO - Epoch 4883/5000 - Train Loss: 0.066657, Val Loss: 0.060649
2025-09-04 12:03:59,412 - INFO - Epoch 4884/5000 - Train Loss: 0.065913, Val Loss: 0.060913
2025-09-04 12:04:35,360 - INFO - Epoch 4885/5000 - Train Loss: 0.065268, Val Loss: 0.061716
2025-09-04 12:05:11,655 - INFO - Epoch 4886/5000 - Train Loss: 0.066239, Val Loss: 0.061831
2025-09-04 12:05:47,619 - INFO - Epoch 4887/5000 - Train Loss: 0.065666, Val Loss: 0.062052
2025-09-04 12:06:23,840 - INFO - Epoch 4888/5000 - Train Loss: 0.066082, Val Loss: 0.061328
2025-09-04 12:07:00,340 - INFO - Epoch 4889/5000 - Train Loss: 0.065531, Val Loss: 0.060820
2025-09-04 12:07:36,447 - INFO - Epoch 4890/5000 - Train Loss: 0.065717, Val Loss: 0.063222
2025-09-04 12:08:13,106 - INFO - Epoch 4891/5000 - Train Loss: 0.065861, Val Loss: 0.060201
2025-09-04 12:08:49,543 - INFO - Epoch 4892/5000 - Train Loss: 0.065837, Val Loss: 0.062420
2025-09-04 12:09:24,841 - INFO - Epoch 4893/5000 - Train Loss: 0.066235, Val Loss: 0.060661
2025-09-04 12:10:00,973 - INFO - Epoch 4894/5000 - Train Loss: 0.065791, Val Loss: 0.060560
2025-09-04 12:10:37,752 - INFO - Epoch 4895/5000 - Train Loss: 0.065445, Val Loss: 0.060370
2025-09-04 12:11:13,942 - INFO - Epoch 4896/5000 - Train Loss: 0.066338, Val Loss: 0.061312
2025-09-04 12:11:49,939 - INFO - Epoch 4897/5000 - Train Loss: 0.065457, Val Loss: 0.061753
2025-09-04 12:12:25,953 - INFO - Epoch 4898/5000 - Train Loss: 0.065358, Val Loss: 0.059765
2025-09-04 12:12:25,997 - INFO - New best model saved with Val Loss: 0.059765
2025-09-04 12:13:02,272 - INFO - Epoch 4899/5000 - Train Loss: 0.066303, Val Loss: 0.065515
2025-09-04 12:13:38,625 - INFO - Epoch 4900/5000 - Train Loss: 0.066357, Val Loss: 0.060814
2025-09-04 12:14:14,642 - INFO - Epoch 4901/5000 - Train Loss: 0.065400, Val Loss: 0.061463
2025-09-04 12:14:50,345 - INFO - Epoch 4902/5000 - Train Loss: 0.065760, Val Loss: 0.060001
2025-09-04 12:15:26,237 - INFO - Epoch 4903/5000 - Train Loss: 0.066352, Val Loss: 0.060773
2025-09-04 12:16:02,427 - INFO - Epoch 4904/5000 - Train Loss: 0.065772, Val Loss: 0.062968
2025-09-04 12:16:38,445 - INFO - Epoch 4905/5000 - Train Loss: 0.066723, Val Loss: 0.061109
2025-09-04 12:17:14,102 - INFO - Epoch 4906/5000 - Train Loss: 0.065847, Val Loss: 0.060850
2025-09-04 12:17:49,477 - INFO - Epoch 4907/5000 - Train Loss: 0.066377, Val Loss: 0.061542
2025-09-04 12:18:25,221 - INFO - Epoch 4908/5000 - Train Loss: 0.066703, Val Loss: 0.062047
2025-09-04 12:19:01,444 - INFO - Epoch 4909/5000 - Train Loss: 0.065933, Val Loss: 0.064628
2025-09-04 12:19:37,918 - INFO - Epoch 4910/5000 - Train Loss: 0.066769, Val Loss: 0.059791
2025-09-04 12:20:14,442 - INFO - Epoch 4911/5000 - Train Loss: 0.065642, Val Loss: 0.059920
2025-09-04 12:20:49,885 - INFO - Epoch 4912/5000 - Train Loss: 0.065751, Val Loss: 0.061436
2025-09-04 12:21:25,351 - INFO - Epoch 4913/5000 - Train Loss: 0.066307, Val Loss: 0.060743
2025-09-04 12:22:01,213 - INFO - Epoch 4914/5000 - Train Loss: 0.064928, Val Loss: 0.060002
2025-09-04 12:22:37,064 - INFO - Epoch 4915/5000 - Train Loss: 0.066298, Val Loss: 0.061458
2025-09-04 12:23:12,702 - INFO - Epoch 4916/5000 - Train Loss: 0.066849, Val Loss: 0.062183
2025-09-04 12:23:48,880 - INFO - Epoch 4917/5000 - Train Loss: 0.066402, Val Loss: 0.062755
2025-09-04 12:24:25,053 - INFO - Epoch 4918/5000 - Train Loss: 0.067007, Val Loss: 0.060842
2025-09-04 12:25:01,625 - INFO - Epoch 4919/5000 - Train Loss: 0.066618, Val Loss: 0.061484
2025-09-04 12:25:37,958 - INFO - Epoch 4920/5000 - Train Loss: 0.066166, Val Loss: 0.061756
2025-09-04 12:26:14,773 - INFO - Epoch 4921/5000 - Train Loss: 0.065544, Val Loss: 0.060031
2025-09-04 12:26:50,930 - INFO - Epoch 4922/5000 - Train Loss: 0.065458, Val Loss: 0.061909
2025-09-04 12:27:27,407 - INFO - Epoch 4923/5000 - Train Loss: 0.065936, Val Loss: 0.060806
2025-09-04 12:28:03,849 - INFO - Epoch 4924/5000 - Train Loss: 0.065394, Val Loss: 0.060542
2025-09-04 12:28:40,684 - INFO - Epoch 4925/5000 - Train Loss: 0.065714, Val Loss: 0.061899
2025-09-04 12:29:17,170 - INFO - Epoch 4926/5000 - Train Loss: 0.066165, Val Loss: 0.060417
2025-09-04 12:29:52,489 - INFO - Epoch 4927/5000 - Train Loss: 0.065610, Val Loss: 0.060349
2025-09-04 12:30:28,509 - INFO - Epoch 4928/5000 - Train Loss: 0.066771, Val Loss: 0.062311
2025-09-04 12:31:04,080 - INFO - Epoch 4929/5000 - Train Loss: 0.066541, Val Loss: 0.061820
2025-09-04 12:31:39,912 - INFO - Epoch 4930/5000 - Train Loss: 0.066174, Val Loss: 0.061280
2025-09-04 12:32:16,264 - INFO - Epoch 4931/5000 - Train Loss: 0.065538, Val Loss: 0.059718
2025-09-04 12:32:16,312 - INFO - New best model saved with Val Loss: 0.059718
2025-09-04 12:32:52,603 - INFO - Epoch 4932/5000 - Train Loss: 0.066559, Val Loss: 0.060698
2025-09-04 12:33:29,175 - INFO - Epoch 4933/5000 - Train Loss: 0.065832, Val Loss: 0.061717
2025-09-04 12:34:05,825 - INFO - Epoch 4934/5000 - Train Loss: 0.064739, Val Loss: 0.060480
2025-09-04 12:34:42,248 - INFO - Epoch 4935/5000 - Train Loss: 0.065557, Val Loss: 0.059237
2025-09-04 12:34:42,280 - INFO - New best model saved with Val Loss: 0.059237
2025-09-04 12:35:18,345 - INFO - Epoch 4936/5000 - Train Loss: 0.065200, Val Loss: 0.059117
2025-09-04 12:35:18,378 - INFO - New best model saved with Val Loss: 0.059117
2025-09-04 12:35:54,052 - INFO - Epoch 4937/5000 - Train Loss: 0.067354, Val Loss: 0.062368
2025-09-04 12:36:29,442 - INFO - Epoch 4938/5000 - Train Loss: 0.067475, Val Loss: 0.061546
2025-09-04 12:37:05,210 - INFO - Epoch 4939/5000 - Train Loss: 0.066106, Val Loss: 0.061074
2025-09-04 12:37:41,700 - INFO - Epoch 4940/5000 - Train Loss: 0.065762, Val Loss: 0.060748
2025-09-04 12:38:17,817 - INFO - Epoch 4941/5000 - Train Loss: 0.065100, Val Loss: 0.061659
2025-09-04 12:38:53,144 - INFO - Epoch 4942/5000 - Train Loss: 0.065279, Val Loss: 0.060933
2025-09-04 12:39:28,532 - INFO - Epoch 4943/5000 - Train Loss: 0.066314, Val Loss: 0.064234
2025-09-04 12:40:04,914 - INFO - Epoch 4944/5000 - Train Loss: 0.066238, Val Loss: 0.061862
2025-09-04 12:40:40,849 - INFO - Epoch 4945/5000 - Train Loss: 0.066384, Val Loss: 0.061586
2025-09-04 12:41:16,857 - INFO - Epoch 4946/5000 - Train Loss: 0.066219, Val Loss: 0.060951
2025-09-04 12:41:52,720 - INFO - Epoch 4947/5000 - Train Loss: 0.065544, Val Loss: 0.060366
2025-09-04 12:42:28,467 - INFO - Epoch 4948/5000 - Train Loss: 0.065376, Val Loss: 0.060665
2025-09-04 12:43:04,428 - INFO - Epoch 4949/5000 - Train Loss: 0.065049, Val Loss: 0.060802
2025-09-04 12:43:40,502 - INFO - Epoch 4950/5000 - Train Loss: 0.065717, Val Loss: 0.061500
2025-09-04 12:44:16,629 - INFO - Epoch 4951/5000 - Train Loss: 0.066290, Val Loss: 0.060602
2025-09-04 12:44:52,052 - INFO - Epoch 4952/5000 - Train Loss: 0.065307, Val Loss: 0.060395
2025-09-04 12:45:27,739 - INFO - Epoch 4953/5000 - Train Loss: 0.066050, Val Loss: 0.063817
2025-09-04 12:46:03,547 - INFO - Epoch 4954/5000 - Train Loss: 0.066243, Val Loss: 0.060514
2025-09-04 12:46:38,607 - INFO - Epoch 4955/5000 - Train Loss: 0.065739, Val Loss: 0.060000
2025-09-04 12:47:13,888 - INFO - Epoch 4956/5000 - Train Loss: 0.065957, Val Loss: 0.059320
2025-09-04 12:47:49,206 - INFO - Epoch 4957/5000 - Train Loss: 0.065494, Val Loss: 0.059923
2025-09-04 12:48:24,905 - INFO - Epoch 4958/5000 - Train Loss: 0.065648, Val Loss: 0.060800
2025-09-04 12:49:00,976 - INFO - Epoch 4959/5000 - Train Loss: 0.065625, Val Loss: 0.060023
2025-09-04 12:49:36,258 - INFO - Epoch 4960/5000 - Train Loss: 0.065284, Val Loss: 0.060082
2025-09-04 12:50:11,951 - INFO - Epoch 4961/5000 - Train Loss: 0.064530, Val Loss: 0.061504
2025-09-04 12:50:47,915 - INFO - Epoch 4962/5000 - Train Loss: 0.065687, Val Loss: 0.061396
2025-09-04 12:51:24,165 - INFO - Epoch 4963/5000 - Train Loss: 0.066306, Val Loss: 0.060334
2025-09-04 12:51:59,776 - INFO - Epoch 4964/5000 - Train Loss: 0.066081, Val Loss: 0.060403
2025-09-04 12:52:35,895 - INFO - Epoch 4965/5000 - Train Loss: 0.065614, Val Loss: 0.059286
2025-09-04 12:53:11,388 - INFO - Epoch 4966/5000 - Train Loss: 0.065479, Val Loss: 0.060433
2025-09-04 12:53:47,764 - INFO - Epoch 4967/5000 - Train Loss: 0.071579, Val Loss: 0.063681
2025-09-04 12:54:24,314 - INFO - Epoch 4968/5000 - Train Loss: 0.066724, Val Loss: 0.060875
2025-09-04 12:55:00,315 - INFO - Epoch 4969/5000 - Train Loss: 0.065729, Val Loss: 0.061105
2025-09-04 12:55:35,897 - INFO - Epoch 4970/5000 - Train Loss: 0.064991, Val Loss: 0.060427
2025-09-04 12:56:12,033 - INFO - Epoch 4971/5000 - Train Loss: 0.065767, Val Loss: 0.060050
2025-09-04 12:56:48,289 - INFO - Epoch 4972/5000 - Train Loss: 0.065208, Val Loss: 0.061173
2025-09-04 12:57:24,597 - INFO - Epoch 4973/5000 - Train Loss: 0.066337, Val Loss: 0.061687
2025-09-04 12:58:00,315 - INFO - Epoch 4974/5000 - Train Loss: 0.066165, Val Loss: 0.062232
2025-09-04 12:58:36,445 - INFO - Epoch 4975/5000 - Train Loss: 0.065845, Val Loss: 0.060628
2025-09-04 12:59:12,706 - INFO - Epoch 4976/5000 - Train Loss: 0.065462, Val Loss: 0.063150
2025-09-04 12:59:49,171 - INFO - Epoch 4977/5000 - Train Loss: 0.066501, Val Loss: 0.059729
2025-09-04 13:00:25,741 - INFO - Epoch 4978/5000 - Train Loss: 0.065933, Val Loss: 0.060650
2025-09-04 13:01:01,795 - INFO - Epoch 4979/5000 - Train Loss: 0.064994, Val Loss: 0.060174
2025-09-04 13:01:37,756 - INFO - Epoch 4980/5000 - Train Loss: 0.064894, Val Loss: 0.060235
2025-09-04 13:02:13,652 - INFO - Epoch 4981/5000 - Train Loss: 0.065392, Val Loss: 0.061714
2025-09-04 13:02:50,027 - INFO - Epoch 4982/5000 - Train Loss: 0.065546, Val Loss: 0.059910
2025-09-04 13:03:26,076 - INFO - Epoch 4983/5000 - Train Loss: 0.066536, Val Loss: 0.060803
2025-09-04 13:04:02,355 - INFO - Epoch 4984/5000 - Train Loss: 0.065334, Val Loss: 0.060030
2025-09-04 13:04:38,986 - INFO - Epoch 4985/5000 - Train Loss: 0.065441, Val Loss: 0.061346
2025-09-04 13:05:15,097 - INFO - Epoch 4986/5000 - Train Loss: 0.065684, Val Loss: 0.059613
2025-09-04 13:05:51,674 - INFO - Epoch 4987/5000 - Train Loss: 0.064956, Val Loss: 0.059878
2025-09-04 13:06:27,645 - INFO - Epoch 4988/5000 - Train Loss: 0.065653, Val Loss: 0.060350
2025-09-04 13:07:03,778 - INFO - Epoch 4989/5000 - Train Loss: 0.065047, Val Loss: 0.059724
2025-09-04 13:07:39,988 - INFO - Epoch 4990/5000 - Train Loss: 0.065712, Val Loss: 0.060026
2025-09-04 13:08:16,230 - INFO - Epoch 4991/5000 - Train Loss: 0.065624, Val Loss: 0.060480
2025-09-04 13:08:52,622 - INFO - Epoch 4992/5000 - Train Loss: 0.065827, Val Loss: 0.060835
2025-09-04 13:09:28,829 - INFO - Epoch 4993/5000 - Train Loss: 0.065732, Val Loss: 0.059870
2025-09-04 13:10:03,732 - INFO - Epoch 4994/5000 - Train Loss: 0.064806, Val Loss: 0.060467
2025-09-04 13:10:39,170 - INFO - Epoch 4995/5000 - Train Loss: 0.063820, Val Loss: 0.060636
2025-09-04 13:11:15,437 - INFO - Epoch 4996/5000 - Train Loss: 0.064625, Val Loss: 0.059154
2025-09-04 13:11:51,197 - INFO - Epoch 4997/5000 - Train Loss: 0.065965, Val Loss: 0.060408
2025-09-04 13:12:27,634 - INFO - Epoch 4998/5000 - Train Loss: 0.066034, Val Loss: 0.061717
2025-09-04 13:13:03,208 - INFO - Epoch 4999/5000 - Train Loss: 0.065595, Val Loss: 0.060223
2025-09-04 13:13:38,634 - INFO - Epoch 5000/5000 - Train Loss: 0.064873, Val Loss: 0.060101
2025-09-04 13:13:38,887 - INFO - Final model saved to experiments/Test/final_model.pth
2025-09-04 13:13:38,909 - INFO - Testing the final model
2025-09-04 13:13:51,811 - INFO - Total MSE across all processes: 7.087629318237305
2025-09-04 13:13:51,814 - INFO - mean value for all_targets: {tmp}
2025-09-04 13:13:51,821 - INFO - Test MSE: 0.062172, Test MAE: 0.144258, Max AE: 27.454285, Test R2: 0.9415
2025-09-04 13:13:51,821 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-09-04 13:13:51,821 - INFO - Total inference time:  0.35s for 114 samples
2025-09-04 13:13:51,843 - INFO - Testing the best model
2025-09-04 13:14:03,297 - INFO - Total MSE across all processes: 6.877278804779053
2025-09-04 13:14:03,300 - INFO - mean value for all_targets: {tmp}
2025-09-04 13:14:03,305 - INFO - Test MSE: 0.060327, Test MAE: 0.142507, Max AE: 27.106272, Test R2: 0.9432
2025-09-04 13:14:03,306 - INFO - Relative L2 Error: inf, Relative L1 error: inf
2025-09-04 13:14:03,306 - INFO - Total inference time:  0.29s for 114 samples
